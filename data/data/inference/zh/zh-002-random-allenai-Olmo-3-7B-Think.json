{
  "id": "generated_20251203_121303",
  "prompt": "给我讲个笑话",
  "language": "zh",
  "temperature": 5.0,
  "top_k": 10,
  "model_info": {
    "name": "allenai/Olmo-3-7B-Think",
    "num_layers": 32,
    "hidden_size": 4096,
    "num_attention_heads": 32,
    "vocab_size": 100278
  },
  "generation_steps": [
    {
      "step": 0,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Okay",
            "token_id": 33413,
            "logprob": -0.1465,
            "prob": 0.8633
          },
          {
            "token": "�",
            "token_id": 161,
            "logprob": -2.5156,
            "prob": 0.0806
          },
          {
            "token": "Alright",
            "token_id": 72586,
            "logprob": -3.3906,
            "prob": 0.0334
          },
          {
            "token": "好",
            "token_id": 53901,
            "logprob": -4.2188,
            "prob": 0.0149
          },
          {
            "token": "ĠOkay",
            "token_id": 36539,
            "logprob": -7.0312,
            "prob": 0.0009
          },
          {
            "token": "Ġ�",
            "token_id": 4996,
            "logprob": -7.0312,
            "prob": 0.0009
          },
          {
            "token": "ĠAlright",
            "token_id": 98693,
            "logprob": -7.0938,
            "prob": 0.0008
          },
          {
            "token": "当",
            "token_id": 40265,
            "logprob": -7.8438,
            "prob": 0.0004
          },
          {
            "token": "�",
            "token_id": 45932,
            "logprob": -8.125,
            "prob": 0.0003
          },
          {
            "token": "你",
            "token_id": 57668,
            "logprob": -8.5625,
            "prob": 0.0002
          }
        ]
      },
      "selected_token": {
        "token": "�",
        "token_id": 161,
        "selection_method": "sampling"
      }
    },
    {
      "step": 1,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>�",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "�",
            "token_id": 245,
            "logprob": -0.0008,
            "prob": 1.0
          },
          {
            "token": "�",
            "token_id": 246,
            "logprob": -7.5,
            "prob": 0.0006
          },
          {
            "token": "�",
            "token_id": 247,
            "logprob": -9.3125,
            "prob": 0.0001
          },
          {
            "token": "�",
            "token_id": 240,
            "logprob": -9.875,
            "prob": 0.0001
          },
          {
            "token": "�",
            "token_id": 99,
            "logprob": -10.25,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 101,
            "logprob": -11.0625,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 113,
            "logprob": -13.0,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 226,
            "logprob": -13.3125,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 104,
            "logprob": -13.5,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 98,
            "logprob": -13.75,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "�",
        "token_id": 245,
        "selection_method": "sampling"
      }
    },
    {
      "step": 2,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>�",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "�",
            "token_id": 107,
            "logprob": -0.0004,
            "prob": 1.0
          },
          {
            "token": "�",
            "token_id": 101,
            "logprob": -9.125,
            "prob": 0.0001
          },
          {
            "token": "�",
            "token_id": 253,
            "logprob": -9.1875,
            "prob": 0.0001
          },
          {
            "token": "�",
            "token_id": 115,
            "logprob": -9.9375,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 110,
            "logprob": -11.5,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 105,
            "logprob": -11.625,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 99,
            "logprob": -11.625,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 111,
            "logprob": -11.6875,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 242,
            "logprob": -11.75,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 96,
            "logprob": -11.8125,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "�",
        "token_id": 105,
        "selection_method": "sampling"
      }
    },
    {
      "step": 3,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "，",
            "token_id": 3922,
            "logprob": -0.0228,
            "prob": 0.9766
          },
          {
            "token": ",",
            "token_id": 11,
            "logprob": -4.1562,
            "prob": 0.0157
          },
          {
            "token": "，在",
            "token_id": 97150,
            "logprob": -6.0312,
            "prob": 0.0024
          },
          {
            "token": "�",
            "token_id": 17857,
            "logprob": -6.2812,
            "prob": 0.0019
          },
          {
            "token": "？",
            "token_id": 11571,
            "logprob": -7.4062,
            "prob": 0.0006
          },
          {
            "token": "...",
            "token_id": 1131,
            "logprob": -7.9688,
            "prob": 0.0003
          },
          {
            "token": "</",
            "token_id": 524,
            "logprob": -8.625,
            "prob": 0.0002
          },
          {
            "token": "�",
            "token_id": 161,
            "logprob": -9.5,
            "prob": 0.0001
          },
          {
            "token": ",y",
            "token_id": 7509,
            "logprob": -9.9375,
            "prob": 0.0
          },
          {
            "token": "等",
            "token_id": 50667,
            "logprob": -9.9375,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "，在",
        "token_id": 97150,
        "selection_method": "sampling"
      }
    },
    {
      "step": 4,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "用户",
            "token_id": 20600,
            "logprob": -0.2119,
            "prob": 0.8086
          },
          {
            "token": "这",
            "token_id": 44388,
            "logprob": -2.1562,
            "prob": 0.1167
          },
          {
            "token": "用",
            "token_id": 11883,
            "logprob": -4.7812,
            "prob": 0.0084
          },
          {
            "token": "给",
            "token_id": 90112,
            "logprob": -4.7812,
            "prob": 0.0084
          },
          {
            "token": "使用",
            "token_id": 38129,
            "logprob": -5.3438,
            "prob": 0.0048
          },
          {
            "token": "�",
            "token_id": 29207,
            "logprob": -5.5312,
            "prob": 0.004
          },
          {
            "token": "�",
            "token_id": 87743,
            "logprob": -5.7812,
            "prob": 0.0031
          },
          {
            "token": "他",
            "token_id": 43511,
            "logprob": -5.9062,
            "prob": 0.0027
          },
          {
            "token": "接",
            "token_id": 30177,
            "logprob": -5.9688,
            "prob": 0.0026
          },
          {
            "token": "我",
            "token_id": 37046,
            "logprob": -5.9688,
            "prob": 0.0026
          }
        ]
      },
      "selected_token": {
        "token": "我",
        "token_id": 37046,
        "selection_method": "sampling"
      }
    },
    {
      "step": 5,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "这",
            "token_id": 44388,
            "logprob": -0.4258,
            "prob": 0.6523
          },
          {
            "token": "看",
            "token_id": 52030,
            "logprob": -2.6719,
            "prob": 0.0688
          },
          {
            "token": "里",
            "token_id": 70349,
            "logprob": -3.9844,
            "prob": 0.0186
          },
          {
            "token": "之",
            "token_id": 55030,
            "logprob": -4.125,
            "prob": 0.0164
          },
          {
            "token": "作",
            "token_id": 19967,
            "logprob": -4.1875,
            "prob": 0.0154
          },
          {
            "token": "给",
            "token_id": 90112,
            "logprob": -4.25,
            "prob": 0.0145
          },
          {
            "token": "内",
            "token_id": 32943,
            "logprob": -4.25,
            "prob": 0.0145
          },
          {
            "token": "设计",
            "token_id": 71600,
            "logprob": -4.3125,
            "prob": 0.0135
          },
          {
            "token": "提",
            "token_id": 29172,
            "logprob": -4.5,
            "prob": 0.0112
          },
          {
            "token": "手",
            "token_id": 46034,
            "logprob": -4.5625,
            "prob": 0.0106
          }
        ]
      },
      "selected_token": {
        "token": "作",
        "token_id": 19967,
        "selection_method": "sampling"
      }
    },
    {
      "step": 6,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "为",
            "token_id": 18184,
            "logprob": -0.0005,
            "prob": 1.0
          },
          {
            "token": "一个",
            "token_id": 48044,
            "logprob": -9.1875,
            "prob": 0.0001
          },
          {
            "token": "�",
            "token_id": 163,
            "logprob": -9.5,
            "prob": 0.0001
          },
          {
            "token": "用",
            "token_id": 11883,
            "logprob": -10.25,
            "prob": 0.0
          },
          {
            "token": "为空",
            "token_id": 51747,
            "logprob": -10.3125,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 29857,
            "logprob": -10.5,
            "prob": 0.0
          },
          {
            "token": "出",
            "token_id": 20834,
            "logprob": -10.9375,
            "prob": 0.0
          },
          {
            "token": "品",
            "token_id": 25446,
            "logprob": -11.5,
            "prob": 0.0
          },
          {
            "token": "中",
            "token_id": 16325,
            "logprob": -11.5625,
            "prob": 0.0
          },
          {
            "token": "家",
            "token_id": 46729,
            "logprob": -11.5625,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "为",
        "token_id": 18184,
        "selection_method": "sampling"
      }
    },
    {
      "step": 7,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "AI",
            "token_id": 15836,
            "logprob": -0.4258,
            "prob": 0.6523
          },
          {
            "token": "Deep",
            "token_id": 34564,
            "logprob": -1.4297,
            "prob": 0.2402
          },
          {
            "token": "一个",
            "token_id": 48044,
            "logprob": -2.6719,
            "prob": 0.0688
          },
          {
            "token": "ĠDeep",
            "token_id": 18682,
            "logprob": -4.625,
            "prob": 0.0099
          },
          {
            "token": "人",
            "token_id": 17792,
            "logprob": -4.875,
            "prob": 0.0077
          },
          {
            "token": "�",
            "token_id": 8239,
            "logprob": -6.25,
            "prob": 0.002
          },
          {
            "token": "一",
            "token_id": 15120,
            "logprob": -6.5,
            "prob": 0.0015
          },
          {
            "token": "ĠAI",
            "token_id": 15592,
            "logprob": -6.75,
            "prob": 0.0012
          },
          {
            "token": "�",
            "token_id": 85315,
            "logprob": -7.0625,
            "prob": 0.0009
          },
          {
            "token": "有",
            "token_id": 19361,
            "logprob": -7.3125,
            "prob": 0.0007
          }
        ]
      },
      "selected_token": {
        "token": "有",
        "token_id": 19361,
        "selection_method": "sampling"
      }
    },
    {
      "step": 8,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "理",
            "token_id": 22649,
            "logprob": -1.9844,
            "prob": 0.1377
          },
          {
            "token": "�",
            "token_id": 50266,
            "logprob": -2.4219,
            "prob": 0.0889
          },
          {
            "token": "意",
            "token_id": 37689,
            "logprob": -2.5469,
            "prob": 0.0781
          },
          {
            "token": "人",
            "token_id": 17792,
            "logprob": -2.7344,
            "prob": 0.0649
          },
          {
            "token": "语",
            "token_id": 73981,
            "logprob": -2.7969,
            "prob": 0.061
          },
          {
            "token": "限",
            "token_id": 48249,
            "logprob": -3.2344,
            "prob": 0.0393
          },
          {
            "token": "�",
            "token_id": 7190,
            "logprob": -3.2969,
            "prob": 0.0369
          },
          {
            "token": "�",
            "token_id": 45114,
            "logprob": -3.3594,
            "prob": 0.0347
          },
          {
            "token": "用",
            "token_id": 11883,
            "logprob": -3.6719,
            "prob": 0.0254
          },
          {
            "token": "�",
            "token_id": 13821,
            "logprob": -3.7656,
            "prob": 0.0231
          }
        ]
      },
      "selected_token": {
        "token": "理",
        "token_id": 22649,
        "selection_method": "sampling"
      }
    },
    {
      "step": 9,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "性",
            "token_id": 34171,
            "logprob": -0.0166,
            "prob": 0.9844
          },
          {
            "token": "�",
            "token_id": 45114,
            "logprob": -4.9062,
            "prob": 0.0075
          },
          {
            "token": "的",
            "token_id": 9554,
            "logprob": -6.2812,
            "prob": 0.0019
          },
          {
            "token": "ĠAI",
            "token_id": 15592,
            "logprob": -6.7812,
            "prob": 0.0012
          },
          {
            "token": "人",
            "token_id": 17792,
            "logprob": -7.9062,
            "prob": 0.0004
          },
          {
            "token": "论",
            "token_id": 68931,
            "logprob": -7.9688,
            "prob": 0.0004
          },
          {
            "token": "知",
            "token_id": 53283,
            "logprob": -7.9688,
            "prob": 0.0004
          },
          {
            "token": "工",
            "token_id": 49792,
            "logprob": -8.125,
            "prob": 0.0003
          },
          {
            "token": "�",
            "token_id": 8239,
            "logprob": -8.3125,
            "prob": 0.0002
          },
          {
            "token": "思",
            "token_id": 91763,
            "logprob": -8.625,
            "prob": 0.0002
          }
        ]
      },
      "selected_token": {
        "token": "ĠAI",
        "token_id": 15592,
        "selection_method": "sampling"
      }
    },
    {
      "step": 10,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġ的",
            "token_id": 44689,
            "logprob": -0.291,
            "prob": 0.7461
          },
          {
            "token": "�",
            "token_id": 8239,
            "logprob": -2.2969,
            "prob": 0.1011
          },
          {
            "token": "Ġ�",
            "token_id": 10447,
            "logprob": -3.4219,
            "prob": 0.033
          },
          {
            "token": "Ġ�",
            "token_id": 9085,
            "logprob": -3.6719,
            "prob": 0.0256
          },
          {
            "token": "，",
            "token_id": 3922,
            "logprob": -4.0938,
            "prob": 0.0165
          },
          {
            "token": "的",
            "token_id": 9554,
            "logprob": -4.3438,
            "prob": 0.0129
          },
          {
            "token": "Ġ",
            "token_id": 220,
            "logprob": -4.5312,
            "prob": 0.0107
          },
          {
            "token": "Ġ�",
            "token_id": 55699,
            "logprob": -5.0312,
            "prob": 0.0065
          },
          {
            "token": "Ġ�",
            "token_id": 6704,
            "logprob": -5.2188,
            "prob": 0.0054
          },
          {
            "token": "Ġ�",
            "token_id": 61696,
            "logprob": -5.4688,
            "prob": 0.0042
          }
        ]
      },
      "selected_token": {
        "token": "，",
        "token_id": 3922,
        "selection_method": "sampling"
      }
    },
    {
      "step": 11,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "我",
            "token_id": 37046,
            "logprob": -0.2812,
            "prob": 0.7539
          },
          {
            "token": "不",
            "token_id": 16937,
            "logprob": -3.4688,
            "prob": 0.0311
          },
          {
            "token": "没有",
            "token_id": 81543,
            "logprob": -3.5312,
            "prob": 0.0293
          },
          {
            "token": "�",
            "token_id": 84264,
            "logprob": -3.7812,
            "prob": 0.0228
          },
          {
            "token": "确",
            "token_id": 35056,
            "logprob": -4.3438,
            "prob": 0.013
          },
          {
            "token": "所",
            "token_id": 32938,
            "logprob": -4.6562,
            "prob": 0.0095
          },
          {
            "token": "�",
            "token_id": 87743,
            "logprob": -4.6562,
            "prob": 0.0095
          },
          {
            "token": "无",
            "token_id": 43292,
            "logprob": -5.1562,
            "prob": 0.0058
          },
          {
            "token": "�",
            "token_id": 10414,
            "logprob": -5.2188,
            "prob": 0.0054
          },
          {
            "token": "当",
            "token_id": 40265,
            "logprob": -5.2188,
            "prob": 0.0054
          }
        ]
      },
      "selected_token": {
        "token": "�",
        "token_id": 84264,
        "selection_method": "sampling"
      }
    },
    {
      "step": 12,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，�",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "�",
            "token_id": 121,
            "logprob": -0.0014,
            "prob": 1.0
          },
          {
            "token": "�",
            "token_id": 248,
            "logprob": -6.6875,
            "prob": 0.0012
          },
          {
            "token": "�",
            "token_id": 249,
            "logprob": -9.875,
            "prob": 0.0001
          },
          {
            "token": "�",
            "token_id": 104,
            "logprob": -10.875,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 239,
            "logprob": -11.8125,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 242,
            "logprob": -12.5,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 238,
            "logprob": -12.8125,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 117,
            "logprob": -12.8125,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 255,
            "logprob": -13.0,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 243,
            "logprob": -13.1875,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "�",
        "token_id": 121,
        "selection_method": "sampling"
      }
    },
    {
      "step": 13,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "然",
            "token_id": 61994,
            "logprob": -0.0004,
            "prob": 1.0
          },
          {
            "token": "不能",
            "token_id": 54253,
            "logprob": -9.25,
            "prob": 0.0001
          },
          {
            "token": "不",
            "token_id": 16937,
            "logprob": -10.1875,
            "prob": 0.0
          },
          {
            "token": "我",
            "token_id": 37046,
            "logprob": -10.375,
            "prob": 0.0
          },
          {
            "token": "说",
            "token_id": 37687,
            "logprob": -10.5,
            "prob": 0.0
          },
          {
            "token": "无",
            "token_id": 43292,
            "logprob": -10.8125,
            "prob": 0.0
          },
          {
            "token": "与",
            "token_id": 58318,
            "logprob": -10.875,
            "prob": 0.0
          },
          {
            "token": "有",
            "token_id": 19361,
            "logprob": -11.25,
            "prob": 0.0
          },
          {
            "token": "没有",
            "token_id": 81543,
            "logprob": -11.3125,
            "prob": 0.0
          },
          {
            "token": "经",
            "token_id": 54493,
            "logprob": -11.625,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "然",
        "token_id": 61994,
        "selection_method": "sampling"
      }
    },
    {
      "step": 14,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "我",
            "token_id": 37046,
            "logprob": -0.2139,
            "prob": 0.8086
          },
          {
            "token": "不",
            "token_id": 16937,
            "logprob": -2.7188,
            "prob": 0.0664
          },
          {
            "token": "不能",
            "token_id": 54253,
            "logprob": -3.0938,
            "prob": 0.0457
          },
          {
            "token": "没有",
            "token_id": 81543,
            "logprob": -3.4688,
            "prob": 0.0312
          },
          {
            "token": "无",
            "token_id": 43292,
            "logprob": -3.8438,
            "prob": 0.0215
          },
          {
            "token": "�",
            "token_id": 17599,
            "logprob": -5.9688,
            "prob": 0.0026
          },
          {
            "token": "并",
            "token_id": 64026,
            "logprob": -5.9688,
            "prob": 0.0026
          },
          {
            "token": "通",
            "token_id": 33035,
            "logprob": -6.0312,
            "prob": 0.0024
          },
          {
            "token": "我的",
            "token_id": 98711,
            "logprob": -6.5312,
            "prob": 0.0015
          },
          {
            "token": "有",
            "token_id": 19361,
            "logprob": -6.7812,
            "prob": 0.0011
          }
        ]
      },
      "selected_token": {
        "token": "没有",
        "token_id": 81543,
        "selection_method": "sampling"
      }
    },
    {
      "step": 15,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "真",
            "token_id": 89151,
            "logprob": -0.5625,
            "prob": 0.5703
          },
          {
            "token": "个",
            "token_id": 19483,
            "logprob": -1.6875,
            "prob": 0.1846
          },
          {
            "token": "实",
            "token_id": 41073,
            "logprob": -2.25,
            "prob": 0.1055
          },
          {
            "token": "情",
            "token_id": 40474,
            "logprob": -3.8125,
            "prob": 0.0221
          },
          {
            "token": "本",
            "token_id": 22656,
            "logprob": -4.125,
            "prob": 0.0161
          },
          {
            "token": "意",
            "token_id": 37689,
            "logprob": -4.6875,
            "prob": 0.0092
          },
          {
            "token": "感",
            "token_id": 99750,
            "logprob": -4.75,
            "prob": 0.0087
          },
          {
            "token": "人",
            "token_id": 17792,
            "logprob": -4.8125,
            "prob": 0.0081
          },
          {
            "token": "直",
            "token_id": 74245,
            "logprob": -4.8125,
            "prob": 0.0081
          },
          {
            "token": "经",
            "token_id": 54493,
            "logprob": -5.25,
            "prob": 0.0052
          }
        ]
      },
      "selected_token": {
        "token": "真",
        "token_id": 89151,
        "selection_method": "sampling"
      }
    },
    {
      "step": 16,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "实",
            "token_id": 41073,
            "logprob": -0.3926,
            "prob": 0.6758
          },
          {
            "token": "正",
            "token_id": 37656,
            "logprob": -1.1406,
            "prob": 0.3184
          },
          {
            "token": "情",
            "token_id": 40474,
            "logprob": -7.4062,
            "prob": 0.0006
          },
          {
            "token": "Ġactual",
            "token_id": 5150,
            "logprob": -7.8438,
            "prob": 0.0004
          },
          {
            "token": "心",
            "token_id": 64209,
            "logprob": -7.9688,
            "prob": 0.0004
          },
          {
            "token": "�",
            "token_id": 6701,
            "logprob": -8.0,
            "prob": 0.0003
          },
          {
            "token": "本",
            "token_id": 22656,
            "logprob": -8.25,
            "prob": 0.0003
          },
          {
            "token": "生",
            "token_id": 21990,
            "logprob": -8.5,
            "prob": 0.0002
          },
          {
            "token": "意",
            "token_id": 37689,
            "logprob": -8.5,
            "prob": 0.0002
          },
          {
            "token": "感",
            "token_id": 99750,
            "logprob": -8.875,
            "prob": 0.0001
          }
        ]
      },
      "selected_token": {
        "token": "实",
        "token_id": 41073,
        "selection_method": "sampling"
      }
    },
    {
      "step": 17,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "的",
            "token_id": 9554,
            "logprob": -0.0327,
            "prob": 0.9688
          },
          {
            "token": "情",
            "token_id": 40474,
            "logprob": -4.5312,
            "prob": 0.0107
          },
          {
            "token": "感",
            "token_id": 99750,
            "logprob": -5.3438,
            "prob": 0.0048
          },
          {
            "token": "经",
            "token_id": 54493,
            "logprob": -5.5312,
            "prob": 0.004
          },
          {
            "token": "意",
            "token_id": 37689,
            "logprob": -6.0938,
            "prob": 0.0023
          },
          {
            "token": "面",
            "token_id": 28190,
            "logprob": -6.5312,
            "prob": 0.0015
          },
          {
            "token": "体",
            "token_id": 33014,
            "logprob": -6.5938,
            "prob": 0.0014
          },
          {
            "token": "人",
            "token_id": 17792,
            "logprob": -7.0312,
            "prob": 0.0009
          },
          {
            "token": "个",
            "token_id": 19483,
            "logprob": -7.0938,
            "prob": 0.0008
          },
          {
            "token": "生",
            "token_id": 21990,
            "logprob": -7.2188,
            "prob": 0.0007
          }
        ]
      },
      "selected_token": {
        "token": "人",
        "token_id": 17792,
        "selection_method": "sampling"
      }
    },
    {
      "step": 18,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "格",
            "token_id": 35083,
            "logprob": -0.9336,
            "prob": 0.3926
          },
          {
            "token": "类",
            "token_id": 22238,
            "logprob": -0.9961,
            "prob": 0.3691
          },
          {
            "token": "性",
            "token_id": 34171,
            "logprob": -2.6875,
            "prob": 0.0684
          },
          {
            "token": "情",
            "token_id": 40474,
            "logprob": -3.125,
            "prob": 0.0442
          },
          {
            "token": "�",
            "token_id": 14309,
            "logprob": -4.3125,
            "prob": 0.0134
          },
          {
            "token": "文",
            "token_id": 17161,
            "logprob": -4.4375,
            "prob": 0.0118
          },
          {
            "token": "身",
            "token_id": 96356,
            "logprob": -4.8125,
            "prob": 0.0082
          },
          {
            "token": "体",
            "token_id": 33014,
            "logprob": -5.0625,
            "prob": 0.0063
          },
          {
            "token": "生",
            "token_id": 21990,
            "logprob": -5.125,
            "prob": 0.006
          },
          {
            "token": "形",
            "token_id": 83799,
            "logprob": -5.625,
            "prob": 0.0036
          }
        ]
      },
      "selected_token": {
        "token": "性",
        "token_id": 34171,
        "selection_method": "sampling"
      }
    },
    {
      "step": 19,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "的",
            "token_id": 9554,
            "logprob": -0.8828,
            "prob": 0.4141
          },
          {
            "token": "，",
            "token_id": 3922,
            "logprob": -1.3203,
            "prob": 0.2676
          },
          {
            "token": "或",
            "token_id": 58291,
            "logprob": -2.8125,
            "prob": 0.0596
          },
          {
            "token": "和",
            "token_id": 34208,
            "logprob": -2.8125,
            "prob": 0.0596
          },
          {
            "token": "经",
            "token_id": 54493,
            "logprob": -3.0625,
            "prob": 0.0464
          },
          {
            "token": "情",
            "token_id": 40474,
            "logprob": -3.1875,
            "prob": 0.041
          },
          {
            "token": "体",
            "token_id": 33014,
            "logprob": -4.375,
            "prob": 0.0125
          },
          {
            "token": "感",
            "token_id": 99750,
            "logprob": -4.5625,
            "prob": 0.0104
          },
          {
            "token": "特",
            "token_id": 66378,
            "logprob": -4.6875,
            "prob": 0.0092
          },
          {
            "token": "之",
            "token_id": 55030,
            "logprob": -4.8125,
            "prob": 0.0081
          }
        ]
      },
      "selected_token": {
        "token": "之",
        "token_id": 55030,
        "selection_method": "sampling"
      }
    },
    {
      "step": 20,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "情",
            "token_id": 40474,
            "logprob": -1.6875,
            "prob": 0.1855
          },
          {
            "token": "外",
            "token_id": 48915,
            "logprob": -2.125,
            "prob": 0.1196
          },
          {
            "token": "心",
            "token_id": 64209,
            "logprob": -2.75,
            "prob": 0.064
          },
          {
            "token": "�",
            "token_id": 50266,
            "logprob": -3.0625,
            "prob": 0.0469
          },
          {
            "token": "中",
            "token_id": 16325,
            "logprob": -3.0625,
            "prob": 0.0469
          },
          {
            "token": "�",
            "token_id": 39013,
            "logprob": -3.125,
            "prob": 0.0439
          },
          {
            "token": "�",
            "token_id": 7190,
            "logprob": -3.625,
            "prob": 0.0267
          },
          {
            "token": "真",
            "token_id": 89151,
            "logprob": -3.875,
            "prob": 0.0208
          },
          {
            "token": "�",
            "token_id": 35086,
            "logprob": -4.2188,
            "prob": 0.0147
          },
          {
            "token": "�",
            "token_id": 83601,
            "logprob": -4.25,
            "prob": 0.0143
          }
        ]
      },
      "selected_token": {
        "token": "情",
        "token_id": 40474,
        "selection_method": "sampling"
      }
    },
    {
      "step": 21,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "，",
            "token_id": 3922,
            "logprob": -0.0991,
            "prob": 0.9062
          },
          {
            "token": "或",
            "token_id": 58291,
            "logprob": -3.3438,
            "prob": 0.0352
          },
          {
            "token": "、",
            "token_id": 5486,
            "logprob": -4.0938,
            "prob": 0.0166
          },
          {
            "token": "的",
            "token_id": 9554,
            "logprob": -4.3438,
            "prob": 0.0129
          },
          {
            "token": "和",
            "token_id": 34208,
            "logprob": -5.1562,
            "prob": 0.0057
          },
          {
            "token": "情",
            "token_id": 40474,
            "logprob": -5.4688,
            "prob": 0.0042
          },
          {
            "token": "感",
            "token_id": 99750,
            "logprob": -6.3438,
            "prob": 0.0017
          },
          {
            "token": "能",
            "token_id": 27327,
            "logprob": -6.4062,
            "prob": 0.0016
          },
          {
            "token": "�",
            "token_id": 12774,
            "logprob": -6.5312,
            "prob": 0.0014
          },
          {
            "token": "但",
            "token_id": 78388,
            "logprob": -6.7188,
            "prob": 0.0012
          }
        ]
      },
      "selected_token": {
        "token": "或",
        "token_id": 58291,
        "selection_method": "sampling"
      }
    },
    {
      "step": 22,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "�",
            "token_id": 7190,
            "logprob": -1.1406,
            "prob": 0.3203
          },
          {
            "token": "真",
            "token_id": 89151,
            "logprob": -2.0781,
            "prob": 0.126
          },
          {
            "token": "情",
            "token_id": 40474,
            "logprob": -2.4531,
            "prob": 0.0864
          },
          {
            "token": "生",
            "token_id": 21990,
            "logprob": -3.2031,
            "prob": 0.0408
          },
          {
            "token": "�",
            "token_id": 6701,
            "logprob": -3.3281,
            "prob": 0.0359
          },
          {
            "token": "意",
            "token_id": 37689,
            "logprob": -3.4531,
            "prob": 0.0317
          },
          {
            "token": "者",
            "token_id": 30046,
            "logprob": -3.5156,
            "prob": 0.0298
          },
          {
            "token": "个",
            "token_id": 19483,
            "logprob": -4.0,
            "prob": 0.0181
          },
          {
            "token": "经",
            "token_id": 54493,
            "logprob": -4.25,
            "prob": 0.0141
          },
          {
            "token": "�",
            "token_id": 162,
            "logprob": -4.5625,
            "prob": 0.0103
          }
        ]
      },
      "selected_token": {
        "token": "者",
        "token_id": 30046,
        "selection_method": "sampling"
      }
    },
    {
      "step": 23,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "�",
            "token_id": 7190,
            "logprob": -1.1016,
            "prob": 0.334
          },
          {
            "token": "真",
            "token_id": 89151,
            "logprob": -1.6016,
            "prob": 0.2021
          },
          {
            "token": "情",
            "token_id": 40474,
            "logprob": -2.3438,
            "prob": 0.0957
          },
          {
            "token": "�",
            "token_id": 6701,
            "logprob": -3.4062,
            "prob": 0.033
          },
          {
            "token": "生",
            "token_id": 21990,
            "logprob": -3.7812,
            "prob": 0.0227
          },
          {
            "token": "意",
            "token_id": 37689,
            "logprob": -4.2188,
            "prob": 0.0146
          },
          {
            "token": "实",
            "token_id": 41073,
            "logprob": -4.5938,
            "prob": 0.0101
          },
          {
            "token": "�",
            "token_id": 45932,
            "logprob": -4.5938,
            "prob": 0.0101
          },
          {
            "token": "直",
            "token_id": 74245,
            "logprob": -4.7188,
            "prob": 0.0089
          },
          {
            "token": "�",
            "token_id": 162,
            "logprob": -4.7812,
            "prob": 0.0084
          }
        ]
      },
      "selected_token": {
        "token": "情",
        "token_id": 40474,
        "selection_method": "sampling"
      }
    },
    {
      "step": 24,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "感",
            "token_id": 99750,
            "logprob": -0.0596,
            "prob": 0.9414
          },
          {
            "token": "�",
            "token_id": 12774,
            "logprob": -3.0,
            "prob": 0.05
          },
          {
            "token": "�",
            "token_id": 50266,
            "logprob": -6.0625,
            "prob": 0.0023
          },
          {
            "token": "商",
            "token_id": 33122,
            "logprob": -6.1875,
            "prob": 0.0021
          },
          {
            "token": "节",
            "token_id": 56602,
            "logprob": -7.5625,
            "prob": 0.0005
          },
          {
            "token": "�",
            "token_id": 13828,
            "logprob": -8.375,
            "prob": 0.0002
          },
          {
            "token": "�",
            "token_id": 39013,
            "logprob": -8.375,
            "prob": 0.0002
          },
          {
            "token": "�",
            "token_id": 30320,
            "logprob": -8.8125,
            "prob": 0.0001
          },
          {
            "token": "理",
            "token_id": 22649,
            "logprob": -9.0,
            "prob": 0.0001
          },
          {
            "token": "调",
            "token_id": 48972,
            "logprob": -9.1875,
            "prob": 0.0001
          }
        ]
      },
      "selected_token": {
        "token": "�",
        "token_id": 12774,
        "selection_method": "sampling"
      }
    },
    {
      "step": 25,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情�",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "�",
            "token_id": 103,
            "logprob": -0.0011,
            "prob": 1.0
          },
          {
            "token": "�",
            "token_id": 225,
            "logprob": -7.875,
            "prob": 0.0004
          },
          {
            "token": "�",
            "token_id": 238,
            "logprob": -8.0625,
            "prob": 0.0003
          },
          {
            "token": "�",
            "token_id": 228,
            "logprob": -9.9375,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 112,
            "logprob": -10.0,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 229,
            "logprob": -10.6875,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 230,
            "logprob": -11.1875,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 113,
            "logprob": -11.25,
            "prob": 0.0
          },
          {
            "token": "175",
            "token_id": 10005,
            "logprob": -11.4375,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 246,
            "logprob": -12.0625,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "�",
        "token_id": 103,
        "selection_method": "sampling"
      }
    },
    {
      "step": 26,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "，",
            "token_id": 3922,
            "logprob": -0.4141,
            "prob": 0.6602
          },
          {
            "token": "体",
            "token_id": 33014,
            "logprob": -1.8516,
            "prob": 0.1572
          },
          {
            "token": "的",
            "token_id": 9554,
            "logprob": -2.5938,
            "prob": 0.0742
          },
          {
            "token": "能",
            "token_id": 27327,
            "logprob": -4.0312,
            "prob": 0.0176
          },
          {
            "token": "感",
            "token_id": 99750,
            "logprob": -4.1562,
            "prob": 0.0156
          },
          {
            "token": "表",
            "token_id": 21405,
            "logprob": -4.2812,
            "prob": 0.0137
          },
          {
            "token": "来",
            "token_id": 37507,
            "logprob": -4.6562,
            "prob": 0.0095
          },
          {
            "token": "经",
            "token_id": 54493,
            "logprob": -5.8438,
            "prob": 0.0029
          },
          {
            "token": "之",
            "token_id": 55030,
            "logprob": -5.9688,
            "prob": 0.0025
          },
          {
            "token": "状态",
            "token_id": 45191,
            "logprob": -6.0938,
            "prob": 0.0022
          }
        ]
      },
      "selected_token": {
        "token": "经",
        "token_id": 54493,
        "selection_method": "sampling"
      }
    },
    {
      "step": 27,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "验",
            "token_id": 42462,
            "logprob": -0.5391,
            "prob": 0.582
          },
          {
            "token": "历",
            "token_id": 82302,
            "logprob": -0.9141,
            "prob": 0.4004
          },
          {
            "token": "理",
            "token_id": 22649,
            "logprob": -5.4062,
            "prob": 0.0045
          },
          {
            "token": "�",
            "token_id": 5877,
            "logprob": -6.1562,
            "prob": 0.0021
          },
          {
            "token": "常",
            "token_id": 40053,
            "logprob": -6.2188,
            "prob": 0.002
          },
          {
            "token": "�",
            "token_id": 165,
            "logprob": -6.6562,
            "prob": 0.0013
          },
          {
            "token": "�",
            "token_id": 81180,
            "logprob": -7.4375,
            "prob": 0.0006
          },
          {
            "token": "过",
            "token_id": 39282,
            "logprob": -7.8438,
            "prob": 0.0004
          },
          {
            "token": "�",
            "token_id": 27699,
            "logprob": -8.3125,
            "prob": 0.0002
          },
          {
            "token": "度",
            "token_id": 27479,
            "logprob": -8.625,
            "prob": 0.0002
          }
        ]
      },
      "selected_token": {
        "token": "常",
        "token_id": 40053,
        "selection_method": "sampling"
      }
    },
    {
      "step": 28,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "�",
            "token_id": 87743,
            "logprob": -1.6875,
            "prob": 0.1846
          },
          {
            "token": "表",
            "token_id": 21405,
            "logprob": -2.125,
            "prob": 0.1191
          },
          {
            "token": "，",
            "token_id": 3922,
            "logprob": -2.5625,
            "prob": 0.0771
          },
          {
            "token": "的",
            "token_id": 9554,
            "logprob": -2.8125,
            "prob": 0.0601
          },
          {
            "token": "感",
            "token_id": 99750,
            "logprob": -3.0625,
            "prob": 0.0466
          },
          {
            "token": "能",
            "token_id": 27327,
            "logprob": -3.125,
            "prob": 0.0439
          },
          {
            "token": "变",
            "token_id": 75140,
            "logprob": -3.125,
            "prob": 0.0439
          },
          {
            "token": "�",
            "token_id": 10414,
            "logprob": -3.6875,
            "prob": 0.025
          },
          {
            "token": "发",
            "token_id": 29391,
            "logprob": -3.6875,
            "prob": 0.025
          },
          {
            "token": "会",
            "token_id": 38093,
            "logprob": -3.75,
            "prob": 0.0234
          }
        ]
      },
      "selected_token": {
        "token": "变",
        "token_id": 75140,
        "selection_method": "sampling"
      }
    },
    {
      "step": 29,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "化",
            "token_id": 33208,
            "logprob": -0.0439,
            "prob": 0.957
          },
          {
            "token": "�",
            "token_id": 7190,
            "logprob": -3.6094,
            "prob": 0.0271
          },
          {
            "token": "动",
            "token_id": 28833,
            "logprob": -4.6562,
            "prob": 0.0094
          },
          {
            "token": "得",
            "token_id": 50928,
            "logprob": -6.0312,
            "prob": 0.0024
          },
          {
            "token": "的",
            "token_id": 9554,
            "logprob": -6.0312,
            "prob": 0.0024
          },
          {
            "token": "，",
            "token_id": 3922,
            "logprob": -7.8438,
            "prob": 0.0004
          },
          {
            "token": "�",
            "token_id": 14888,
            "logprob": -8.75,
            "prob": 0.0002
          },
          {
            "token": "�",
            "token_id": 13870,
            "logprob": -9.0625,
            "prob": 0.0001
          },
          {
            "token": "成",
            "token_id": 13153,
            "logprob": -9.5625,
            "prob": 0.0001
          },
          {
            "token": "情",
            "token_id": 40474,
            "logprob": -9.875,
            "prob": 0.0001
          }
        ]
      },
      "selected_token": {
        "token": "得",
        "token_id": 50928,
        "selection_method": "sampling"
      }
    },
    {
      "step": 30,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "生",
            "token_id": 21990,
            "logprob": -2.1875,
            "prob": 0.1123
          },
          {
            "token": "真",
            "token_id": 89151,
            "logprob": -2.5,
            "prob": 0.082
          },
          {
            "token": "高",
            "token_id": 45736,
            "logprob": -2.75,
            "prob": 0.064
          },
          {
            "token": "�",
            "token_id": 162,
            "logprob": -2.8125,
            "prob": 0.0601
          },
          {
            "token": "�",
            "token_id": 15568,
            "logprob": -3.0625,
            "prob": 0.0469
          },
          {
            "token": "开",
            "token_id": 30867,
            "logprob": -3.125,
            "prob": 0.0439
          },
          {
            "token": "，",
            "token_id": 3922,
            "logprob": -3.125,
            "prob": 0.0439
          },
          {
            "token": "复",
            "token_id": 59464,
            "logprob": -3.4375,
            "prob": 0.0322
          },
          {
            "token": "�",
            "token_id": 7190,
            "logprob": -3.5625,
            "prob": 0.0283
          },
          {
            "token": "�",
            "token_id": 37795,
            "logprob": -3.75,
            "prob": 0.0236
          }
        ]
      },
      "selected_token": {
        "token": "生",
        "token_id": 21990,
        "selection_method": "sampling"
      }
    },
    {
      "step": 31,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "动",
            "token_id": 28833,
            "logprob": -0.1128,
            "prob": 0.8945
          },
          {
            "token": "�",
            "token_id": 32582,
            "logprob": -2.6719,
            "prob": 0.0688
          },
          {
            "token": "�",
            "token_id": 163,
            "logprob": -5.1875,
            "prob": 0.0056
          },
          {
            "token": "活",
            "token_id": 76706,
            "logprob": -5.8125,
            "prob": 0.003
          },
          {
            "token": "�",
            "token_id": 30320,
            "logprob": -5.9375,
            "prob": 0.0027
          },
          {
            "token": "生",
            "token_id": 21990,
            "logprob": -5.9375,
            "prob": 0.0027
          },
          {
            "token": "机",
            "token_id": 33748,
            "logprob": -6.1875,
            "prob": 0.0021
          },
          {
            "token": "产",
            "token_id": 52332,
            "logprob": -6.375,
            "prob": 0.0017
          },
          {
            "token": "命",
            "token_id": 51609,
            "logprob": -6.7188,
            "prob": 0.0012
          },
          {
            "token": "素",
            "token_id": 72238,
            "logprob": -6.75,
            "prob": 0.0012
          }
        ]
      },
      "selected_token": {
        "token": "生",
        "token_id": 21990,
        "selection_method": "sampling"
      }
    },
    {
      "step": 32,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "活",
            "token_id": 76706,
            "logprob": -2.3438,
            "prob": 0.0957
          },
          {
            "token": "动",
            "token_id": 28833,
            "logprob": -2.4062,
            "prob": 0.0898
          },
          {
            "token": "不",
            "token_id": 16937,
            "logprob": -2.9688,
            "prob": 0.0513
          },
          {
            "token": "�",
            "token_id": 20648,
            "logprob": -3.2812,
            "prob": 0.0374
          },
          {
            "token": "发",
            "token_id": 29391,
            "logprob": -3.4062,
            "prob": 0.033
          },
          {
            "token": "起",
            "token_id": 72718,
            "logprob": -3.4688,
            "prob": 0.031
          },
          {
            "token": "�",
            "token_id": 11589,
            "logprob": -3.9688,
            "prob": 0.0188
          },
          {
            "token": "�",
            "token_id": 3574,
            "logprob": -3.9688,
            "prob": 0.0188
          },
          {
            "token": "�",
            "token_id": 28194,
            "logprob": -4.0312,
            "prob": 0.0177
          },
          {
            "token": "真",
            "token_id": 89151,
            "logprob": -4.0938,
            "prob": 0.0166
          }
        ]
      },
      "selected_token": {
        "token": "�",
        "token_id": 11589,
        "selection_method": "sampling"
      }
    },
    {
      "step": 33,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生�",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "�",
            "token_id": 245,
            "logprob": -0.8438,
            "prob": 0.4297
          },
          {
            "token": "�",
            "token_id": 224,
            "logprob": -1.3438,
            "prob": 0.2598
          },
          {
            "token": "�",
            "token_id": 116,
            "logprob": -2.7188,
            "prob": 0.0659
          },
          {
            "token": "�",
            "token_id": 95,
            "logprob": -2.9688,
            "prob": 0.0513
          },
          {
            "token": "�",
            "token_id": 120,
            "logprob": -3.2188,
            "prob": 0.04
          },
          {
            "token": "�",
            "token_id": 119,
            "logprob": -3.4062,
            "prob": 0.0332
          },
          {
            "token": "�",
            "token_id": 228,
            "logprob": -3.4062,
            "prob": 0.0332
          },
          {
            "token": "�",
            "token_id": 237,
            "logprob": -3.9062,
            "prob": 0.0201
          },
          {
            "token": "�",
            "token_id": 235,
            "logprob": -4.7812,
            "prob": 0.0084
          },
          {
            "token": "�",
            "token_id": 240,
            "logprob": -5.0312,
            "prob": 0.0065
          }
        ]
      },
      "selected_token": {
        "token": "�",
        "token_id": 119,
        "selection_method": "sampling"
      }
    },
    {
      "step": 34,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "辑",
            "token_id": 48039,
            "logprob": -0.0001,
            "prob": 1.0
          },
          {
            "token": "ivable",
            "token_id": 43672,
            "logprob": -12.125,
            "prob": 0.0
          },
          {
            "token": "ant",
            "token_id": 519,
            "logprob": -12.25,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 8676,
            "logprob": -12.9375,
            "prob": 0.0
          },
          {
            "token": "arming",
            "token_id": 34002,
            "logprob": -13.25,
            "prob": 0.0
          },
          {
            "token": "生",
            "token_id": 21990,
            "logprob": -13.625,
            "prob": 0.0
          },
          {
            "token": "ible",
            "token_id": 1260,
            "logprob": -13.75,
            "prob": 0.0
          },
          {
            "token": "么",
            "token_id": 82696,
            "logprob": -13.75,
            "prob": 0.0
          },
          {
            "token": "ri",
            "token_id": 462,
            "logprob": -13.75,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 225,
            "logprob": -13.75,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "辑",
        "token_id": 48039,
        "selection_method": "sampling"
      }
    },
    {
      "step": 35,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "，",
            "token_id": 3922,
            "logprob": -0.4414,
            "prob": 0.6445
          },
          {
            "token": "的",
            "token_id": 9554,
            "logprob": -2.3125,
            "prob": 0.0986
          },
          {
            "token": "、",
            "token_id": 5486,
            "logprob": -2.9375,
            "prob": 0.0527
          },
          {
            "token": "性",
            "token_id": 34171,
            "logprob": -4.125,
            "prob": 0.0161
          },
          {
            "token": "地",
            "token_id": 30590,
            "logprob": -4.1875,
            "prob": 0.0151
          },
          {
            "token": "化",
            "token_id": 33208,
            "logprob": -4.25,
            "prob": 0.0142
          },
          {
            "token": "�",
            "token_id": 6701,
            "logprob": -4.25,
            "prob": 0.0142
          },
          {
            "token": "�",
            "token_id": 3574,
            "logprob": -4.3125,
            "prob": 0.0134
          },
          {
            "token": "�",
            "token_id": 7190,
            "logprob": -4.5625,
            "prob": 0.0104
          },
          {
            "token": "或",
            "token_id": 58291,
            "logprob": -4.6875,
            "prob": 0.0092
          }
        ]
      },
      "selected_token": {
        "token": "、",
        "token_id": 5486,
        "selection_method": "sampling"
      }
    },
    {
      "step": 36,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "有",
            "token_id": 19361,
            "logprob": -0.8203,
            "prob": 0.4414
          },
          {
            "token": "�",
            "token_id": 7190,
            "logprob": -2.125,
            "prob": 0.1187
          },
          {
            "token": "�",
            "token_id": 3574,
            "logprob": -2.375,
            "prob": 0.0923
          },
          {
            "token": "�",
            "token_id": 15568,
            "logprob": -3.9375,
            "prob": 0.0194
          },
          {
            "token": "分",
            "token_id": 17620,
            "logprob": -4.0625,
            "prob": 0.0171
          },
          {
            "token": "无",
            "token_id": 43292,
            "logprob": -4.4375,
            "prob": 0.0117
          },
          {
            "token": "理",
            "token_id": 22649,
            "logprob": -4.5625,
            "prob": 0.0104
          },
          {
            "token": "客",
            "token_id": 65854,
            "logprob": -4.5625,
            "prob": 0.0104
          },
          {
            "token": "�",
            "token_id": 12870,
            "logprob": -4.625,
            "prob": 0.0098
          },
          {
            "token": "合",
            "token_id": 40862,
            "logprob": -4.625,
            "prob": 0.0098
          }
        ]
      },
      "selected_token": {
        "token": "有",
        "token_id": 19361,
        "selection_method": "sampling"
      }
    },
    {
      "step": 37,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "�",
            "token_id": 50266,
            "logprob": -0.8828,
            "prob": 0.4121
          },
          {
            "token": "时",
            "token_id": 13646,
            "logprob": -1.8828,
            "prob": 0.1523
          },
          {
            "token": "些",
            "token_id": 98184,
            "logprob": -2.3281,
            "prob": 0.0981
          },
          {
            "token": "有",
            "token_id": 19361,
            "logprob": -3.0781,
            "prob": 0.0464
          },
          {
            "token": "�",
            "token_id": 11589,
            "logprob": -3.2656,
            "prob": 0.0383
          },
          {
            "token": "理",
            "token_id": 22649,
            "logprob": -3.7656,
            "prob": 0.0233
          },
          {
            "token": "点",
            "token_id": 28542,
            "logprob": -3.8906,
            "prob": 0.0205
          },
          {
            "token": "�",
            "token_id": 7190,
            "logprob": -3.9531,
            "prob": 0.0193
          },
          {
            "token": "�",
            "token_id": 13821,
            "logprob": -4.0625,
            "prob": 0.0171
          },
          {
            "token": "意",
            "token_id": 37689,
            "logprob": -4.25,
            "prob": 0.0142
          }
        ]
      },
      "selected_token": {
        "token": "�",
        "token_id": 7190,
        "selection_method": "sampling"
      }
    },
    {
      "step": 38,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有�",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "�",
            "token_id": 121,
            "logprob": -0.0027,
            "prob": 0.9961
          },
          {
            "token": "�",
            "token_id": 227,
            "logprob": -7.1875,
            "prob": 0.0008
          },
          {
            "token": "�",
            "token_id": 119,
            "logprob": -7.25,
            "prob": 0.0007
          },
          {
            "token": "�",
            "token_id": 110,
            "logprob": -7.625,
            "prob": 0.0005
          },
          {
            "token": "�",
            "token_id": 120,
            "logprob": -8.0,
            "prob": 0.0003
          },
          {
            "token": "�",
            "token_id": 116,
            "logprob": -8.8125,
            "prob": 0.0001
          },
          {
            "token": "�",
            "token_id": 117,
            "logprob": -9.875,
            "prob": 0.0001
          },
          {
            "token": "�",
            "token_id": 118,
            "logprob": -10.125,
            "prob": 0.0
          },
          {
            "token": "ز",
            "token_id": 40797,
            "logprob": -10.6875,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 243,
            "logprob": -11.625,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "�",
        "token_id": 121,
        "selection_method": "sampling"
      }
    },
    {
      "step": 39,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "�",
            "token_id": 30868,
            "logprob": -0.0327,
            "prob": 0.9688
          },
          {
            "token": "�",
            "token_id": 17486,
            "logprob": -5.4062,
            "prob": 0.0045
          },
          {
            "token": "�",
            "token_id": 7190,
            "logprob": -6.0938,
            "prob": 0.0023
          },
          {
            "token": "�",
            "token_id": 29207,
            "logprob": -6.3438,
            "prob": 0.0018
          },
          {
            "token": "�",
            "token_id": 66285,
            "logprob": -6.8438,
            "prob": 0.0011
          },
          {
            "token": "�",
            "token_id": 161,
            "logprob": -7.0938,
            "prob": 0.0008
          },
          {
            "token": "�",
            "token_id": 164,
            "logprob": -7.1562,
            "prob": 0.0008
          },
          {
            "token": "�",
            "token_id": 17857,
            "logprob": -7.3438,
            "prob": 0.0006
          },
          {
            "token": "�",
            "token_id": 35086,
            "logprob": -7.4375,
            "prob": 0.0006
          },
          {
            "token": "然",
            "token_id": 61994,
            "logprob": -7.9688,
            "prob": 0.0003
          }
        ]
      },
      "selected_token": {
        "token": "�",
        "token_id": 7190,
        "selection_method": "sampling"
      }
    },
    {
      "step": 40,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽�",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "�",
            "token_id": 121,
            "logprob": -0.001,
            "prob": 1.0
          },
          {
            "token": "�",
            "token_id": 110,
            "logprob": -7.125,
            "prob": 0.0008
          },
          {
            "token": "�",
            "token_id": 119,
            "logprob": -9.3125,
            "prob": 0.0001
          },
          {
            "token": "�",
            "token_id": 120,
            "logprob": -10.8125,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 243,
            "logprob": -10.875,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 227,
            "logprob": -11.0625,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 118,
            "logprob": -13.625,
            "prob": 0.0
          },
          {
            "token": "ز",
            "token_id": 40797,
            "logprob": -13.75,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 226,
            "logprob": -13.9375,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 234,
            "logprob": -14.0,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "�",
        "token_id": 121,
        "selection_method": "sampling"
      }
    },
    {
      "step": 41,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "�",
            "token_id": 29207,
            "logprob": -0.5781,
            "prob": 0.5625
          },
          {
            "token": "�",
            "token_id": 161,
            "logprob": -2.8906,
            "prob": 0.0557
          },
          {
            "token": "�",
            "token_id": 165,
            "logprob": -3.2031,
            "prob": 0.0408
          },
          {
            "token": "�",
            "token_id": 30868,
            "logprob": -3.7031,
            "prob": 0.0247
          },
          {
            "token": "的",
            "token_id": 9554,
            "logprob": -3.8281,
            "prob": 0.0217
          },
          {
            "token": "�",
            "token_id": 35086,
            "logprob": -4.3125,
            "prob": 0.0132
          },
          {
            "token": "感",
            "token_id": 99750,
            "logprob": -4.375,
            "prob": 0.0124
          },
          {
            "token": "�",
            "token_id": 17486,
            "logprob": -4.5,
            "prob": 0.0109
          },
          {
            "token": "�",
            "token_id": 162,
            "logprob": -4.875,
            "prob": 0.0075
          },
          {
            "token": "�",
            "token_id": 17857,
            "logprob": -5.0,
            "prob": 0.0066
          }
        ]
      },
      "selected_token": {
        "token": "的",
        "token_id": 9554,
        "selection_method": "sampling"
      }
    },
    {
      "step": 42,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "�",
            "token_id": 7190,
            "logprob": -0.5664,
            "prob": 0.5664
          },
          {
            "token": "笑",
            "token_id": 49838,
            "logprob": -2.9375,
            "prob": 0.0527
          },
          {
            "token": "微",
            "token_id": 50034,
            "logprob": -3.625,
            "prob": 0.0265
          },
          {
            "token": "�",
            "token_id": 161,
            "logprob": -3.9375,
            "prob": 0.0194
          },
          {
            "token": "�",
            "token_id": 29207,
            "logprob": -4.3125,
            "prob": 0.0133
          },
          {
            "token": "�",
            "token_id": 16175,
            "logprob": -4.375,
            "prob": 0.0125
          },
          {
            "token": "�",
            "token_id": 50266,
            "logprob": -4.4375,
            "prob": 0.0118
          },
          {
            "token": "�",
            "token_id": 10414,
            "logprob": -4.5,
            "prob": 0.011
          },
          {
            "token": "感",
            "token_id": 99750,
            "logprob": -4.6875,
            "prob": 0.0092
          },
          {
            "token": "�",
            "token_id": 162,
            "logprob": -4.8125,
            "prob": 0.0081
          }
        ]
      },
      "selected_token": {
        "token": "�",
        "token_id": 161,
        "selection_method": "sampling"
      }
    },
    {
      "step": 43,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的�",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "�",
            "token_id": 245,
            "logprob": -0.9102,
            "prob": 0.4023
          },
          {
            "token": "�",
            "token_id": 226,
            "logprob": -1.7266,
            "prob": 0.1787
          },
          {
            "token": "�",
            "token_id": 246,
            "logprob": -2.4062,
            "prob": 0.0898
          },
          {
            "token": "�",
            "token_id": 105,
            "logprob": -2.4062,
            "prob": 0.0898
          },
          {
            "token": "�",
            "token_id": 104,
            "logprob": -2.7188,
            "prob": 0.0654
          },
          {
            "token": "�",
            "token_id": 101,
            "logprob": -2.7812,
            "prob": 0.0618
          },
          {
            "token": "�",
            "token_id": 102,
            "logprob": -3.6562,
            "prob": 0.0258
          },
          {
            "token": "�",
            "token_id": 247,
            "logprob": -4.0312,
            "prob": 0.0177
          },
          {
            "token": "�",
            "token_id": 240,
            "logprob": -4.0938,
            "prob": 0.0166
          },
          {
            "token": "�",
            "token_id": 99,
            "logprob": -4.4688,
            "prob": 0.0114
          }
        ]
      },
      "selected_token": {
        "token": "�",
        "token_id": 245,
        "selection_method": "sampling"
      }
    },
    {
      "step": 44,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的�",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "�",
            "token_id": 241,
            "logprob": -1.0391,
            "prob": 0.3535
          },
          {
            "token": "�",
            "token_id": 227,
            "logprob": -1.0391,
            "prob": 0.3535
          },
          {
            "token": "�",
            "token_id": 107,
            "logprob": -2.7969,
            "prob": 0.0615
          },
          {
            "token": "�",
            "token_id": 242,
            "logprob": -3.2344,
            "prob": 0.0396
          },
          {
            "token": "�",
            "token_id": 238,
            "logprob": -3.2344,
            "prob": 0.0396
          },
          {
            "token": "�",
            "token_id": 97,
            "logprob": -3.4844,
            "prob": 0.0309
          },
          {
            "token": "�",
            "token_id": 250,
            "logprob": -3.4844,
            "prob": 0.0309
          },
          {
            "token": "�",
            "token_id": 253,
            "logprob": -3.8594,
            "prob": 0.0212
          },
          {
            "token": "�",
            "token_id": 244,
            "logprob": -4.7188,
            "prob": 0.0089
          },
          {
            "token": "�",
            "token_id": 94,
            "logprob": -5.0312,
            "prob": 0.0065
          }
        ]
      },
      "selected_token": {
        "token": "�",
        "token_id": 97,
        "selection_method": "sampling"
      }
    },
    {
      "step": 45,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "�",
            "token_id": 161,
            "logprob": -0.6875,
            "prob": 0.5039
          },
          {
            "token": "笑",
            "token_id": 49838,
            "logprob": -1.5,
            "prob": 0.2227
          },
          {
            "token": "声",
            "token_id": 71174,
            "logprob": -2.0625,
            "prob": 0.127
          },
          {
            "token": "�",
            "token_id": 20648,
            "logprob": -3.1875,
            "prob": 0.0413
          },
          {
            "token": "，",
            "token_id": 3922,
            "logprob": -3.8125,
            "prob": 0.0221
          },
          {
            "token": "音",
            "token_id": 79785,
            "logprob": -4.125,
            "prob": 0.0161
          },
          {
            "token": "�",
            "token_id": 84150,
            "logprob": -5.0,
            "prob": 0.0067
          },
          {
            "token": "�",
            "token_id": 7305,
            "logprob": -5.125,
            "prob": 0.006
          },
          {
            "token": "�",
            "token_id": 5877,
            "logprob": -5.75,
            "prob": 0.0032
          },
          {
            "token": "�",
            "token_id": 17857,
            "logprob": -5.75,
            "prob": 0.0032
          }
        ]
      },
      "selected_token": {
        "token": "笑",
        "token_id": 49838,
        "selection_method": "sampling"
      }
    },
    {
      "step": 46,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤笑",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�",
        "笑"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97,
        49838
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "声",
            "token_id": 71174,
            "logprob": -0.5742,
            "prob": 0.5625
          },
          {
            "token": "，",
            "token_id": 3922,
            "logprob": -1.2031,
            "prob": 0.3008
          },
          {
            "token": "�",
            "token_id": 20648,
            "logprob": -3.8906,
            "prob": 0.0205
          },
          {
            "token": "。",
            "token_id": 1811,
            "logprob": -4.4375,
            "prob": 0.0117
          },
          {
            "token": "之",
            "token_id": 55030,
            "logprob": -4.5625,
            "prob": 0.0103
          },
          {
            "token": "或",
            "token_id": 58291,
            "logprob": -4.8125,
            "prob": 0.008
          },
          {
            "token": "音",
            "token_id": 79785,
            "logprob": -5.1875,
            "prob": 0.0055
          },
          {
            "token": "意",
            "token_id": 37689,
            "logprob": -5.5,
            "prob": 0.004
          },
          {
            "token": "（",
            "token_id": 10110,
            "logprob": -5.8125,
            "prob": 0.0029
          },
          {
            "token": "能",
            "token_id": 27327,
            "logprob": -5.9375,
            "prob": 0.0026
          }
        ]
      },
      "selected_token": {
        "token": "�",
        "token_id": 20648,
        "selection_method": "sampling"
      }
    },
    {
      "step": 47,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤笑�",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�",
        "笑",
        "�"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97,
        49838,
        20648
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "�",
            "token_id": 235,
            "logprob": -0.2637,
            "prob": 0.7695
          },
          {
            "token": "�",
            "token_id": 99,
            "logprob": -1.6406,
            "prob": 0.1943
          },
          {
            "token": "�",
            "token_id": 103,
            "logprob": -4.0625,
            "prob": 0.017
          },
          {
            "token": "�",
            "token_id": 253,
            "logprob": -5.8125,
            "prob": 0.0029
          },
          {
            "token": "�",
            "token_id": 255,
            "logprob": -6.1875,
            "prob": 0.002
          },
          {
            "token": "�",
            "token_id": 102,
            "logprob": -6.25,
            "prob": 0.0019
          },
          {
            "token": "�",
            "token_id": 247,
            "logprob": -6.3125,
            "prob": 0.0018
          },
          {
            "token": "�",
            "token_id": 110,
            "logprob": -6.4375,
            "prob": 0.0016
          },
          {
            "token": "�",
            "token_id": 229,
            "logprob": -6.6875,
            "prob": 0.0012
          },
          {
            "token": "�",
            "token_id": 238,
            "logprob": -6.6875,
            "prob": 0.0012
          }
        ]
      },
      "selected_token": {
        "token": "�",
        "token_id": 103,
        "selection_method": "sampling"
      }
    },
    {
      "step": 48,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤笑哪",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�",
        "笑",
        "�",
        "�"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97,
        49838,
        20648,
        103
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "里",
            "token_id": 70349,
            "logprob": -0.8086,
            "prob": 0.4453
          },
          {
            "token": "�",
            "token_id": 17486,
            "logprob": -1.5,
            "prob": 0.2236
          },
          {
            "token": "些",
            "token_id": 98184,
            "logprob": -2.4375,
            "prob": 0.0879
          },
          {
            "token": "点",
            "token_id": 28542,
            "logprob": -2.6875,
            "prob": 0.0684
          },
          {
            "token": "个",
            "token_id": 19483,
            "logprob": -3.625,
            "prob": 0.0267
          },
          {
            "token": "�",
            "token_id": 161,
            "logprob": -3.875,
            "prob": 0.0209
          },
          {
            "token": "，",
            "token_id": 3922,
            "logprob": -4.0625,
            "prob": 0.0172
          },
          {
            "token": "一",
            "token_id": 15120,
            "logprob": -4.3125,
            "prob": 0.0134
          },
          {
            "token": "�",
            "token_id": 7305,
            "logprob": -4.9375,
            "prob": 0.0072
          },
          {
            "token": "种",
            "token_id": 87502,
            "logprob": -4.9375,
            "prob": 0.0072
          }
        ]
      },
      "selected_token": {
        "token": "一",
        "token_id": 15120,
        "selection_method": "sampling"
      }
    },
    {
      "step": 49,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤笑哪一",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�",
        "笑",
        "�",
        "�",
        "一"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97,
        49838,
        20648,
        103,
        15120
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "段",
            "token_id": 38574,
            "logprob": -1.375,
            "prob": 0.252
          },
          {
            "token": "种",
            "token_id": 87502,
            "logprob": -1.8125,
            "prob": 0.1631
          },
          {
            "token": "点",
            "token_id": 28542,
            "logprob": -1.8125,
            "prob": 0.1631
          },
          {
            "token": "声",
            "token_id": 71174,
            "logprob": -2.5625,
            "prob": 0.0767
          },
          {
            "token": "样",
            "token_id": 91985,
            "logprob": -2.75,
            "prob": 0.064
          },
          {
            "token": "类",
            "token_id": 22238,
            "logprob": -3.1875,
            "prob": 0.0413
          },
          {
            "token": "部",
            "token_id": 34048,
            "logprob": -3.25,
            "prob": 0.0386
          },
          {
            "token": "�",
            "token_id": 5877,
            "logprob": -3.9375,
            "prob": 0.0194
          },
          {
            "token": "条",
            "token_id": 40089,
            "logprob": -4.6875,
            "prob": 0.0092
          },
          {
            "token": "位",
            "token_id": 25129,
            "logprob": -4.75,
            "prob": 0.0086
          }
        ]
      },
      "selected_token": {
        "token": "�",
        "token_id": 5877,
        "selection_method": "sampling"
      }
    },
    {
      "step": 50,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤笑哪一�",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�",
        "笑",
        "�",
        "�",
        "一",
        "�"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97,
        49838,
        20648,
        103,
        15120,
        5877
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "�",
            "token_id": 98,
            "logprob": -0.002,
            "prob": 0.9961
          },
          {
            "token": "�",
            "token_id": 254,
            "logprob": -6.4375,
            "prob": 0.0016
          },
          {
            "token": "�",
            "token_id": 230,
            "logprob": -9.0625,
            "prob": 0.0001
          },
          {
            "token": "�",
            "token_id": 99,
            "logprob": -9.375,
            "prob": 0.0001
          },
          {
            "token": "�",
            "token_id": 97,
            "logprob": -9.9375,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 234,
            "logprob": -10.25,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 117,
            "logprob": -10.375,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 104,
            "logprob": -10.75,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 114,
            "logprob": -11.1875,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 110,
            "logprob": -11.5,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "�",
        "token_id": 97,
        "selection_method": "sampling"
      }
    },
    {
      "step": 51,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤笑哪一古",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�",
        "笑",
        "�",
        "�",
        "一",
        "�",
        "�"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97,
        49838,
        20648,
        103,
        15120,
        5877,
        97
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "，",
            "token_id": 3922,
            "logprob": -1.7578,
            "prob": 0.1729
          },
          {
            "token": "都",
            "token_id": 72368,
            "logprob": -2.75,
            "prob": 0.0635
          },
          {
            "token": "语",
            "token_id": 73981,
            "logprob": -2.875,
            "prob": 0.0559
          },
          {
            "token": "�",
            "token_id": 6708,
            "logprob": -3.0,
            "prob": 0.0496
          },
          {
            "token": "理",
            "token_id": 22649,
            "logprob": -3.3125,
            "prob": 0.0361
          },
          {
            "token": "�",
            "token_id": 39013,
            "logprob": -3.4375,
            "prob": 0.032
          },
          {
            "token": "笑",
            "token_id": 49838,
            "logprob": -3.4375,
            "prob": 0.032
          },
          {
            "token": "也",
            "token_id": 75863,
            "logprob": -3.7812,
            "prob": 0.0226
          },
          {
            "token": "段",
            "token_id": 38574,
            "logprob": -3.7812,
            "prob": 0.0226
          },
          {
            "token": "�",
            "token_id": 17486,
            "logprob": -4.0312,
            "prob": 0.0176
          }
        ]
      },
      "selected_token": {
        "token": "也",
        "token_id": 75863,
        "selection_method": "sampling"
      }
    },
    {
      "step": 52,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤笑哪一古也",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�",
        "笑",
        "�",
        "�",
        "一",
        "�",
        "�",
        "也"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97,
        49838,
        20648,
        103,
        15120,
        5877,
        97,
        75863
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "无",
            "token_id": 43292,
            "logprob": -1.5625,
            "prob": 0.21
          },
          {
            "token": "不",
            "token_id": 16937,
            "logprob": -1.6875,
            "prob": 0.1846
          },
          {
            "token": "�",
            "token_id": 37795,
            "logprob": -2.125,
            "prob": 0.1196
          },
          {
            "token": "是",
            "token_id": 21043,
            "logprob": -2.8125,
            "prob": 0.0601
          },
          {
            "token": "没有",
            "token_id": 81543,
            "logprob": -3.1875,
            "prob": 0.0413
          },
          {
            "token": "，",
            "token_id": 3922,
            "logprob": -3.4375,
            "prob": 0.0322
          },
          {
            "token": "没",
            "token_id": 72027,
            "logprob": -4.0625,
            "prob": 0.0172
          },
          {
            "token": "可以",
            "token_id": 74770,
            "logprob": -4.0625,
            "prob": 0.0172
          },
          {
            "token": "能",
            "token_id": 27327,
            "logprob": -4.125,
            "prob": 0.0161
          },
          {
            "token": "不能",
            "token_id": 54253,
            "logprob": -4.125,
            "prob": 0.0161
          }
        ]
      },
      "selected_token": {
        "token": "没有",
        "token_id": 81543,
        "selection_method": "sampling"
      }
    },
    {
      "step": 53,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤笑哪一古也没有",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�",
        "笑",
        "�",
        "�",
        "一",
        "�",
        "�",
        "也",
        "没有"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97,
        49838,
        20648,
        103,
        15120,
        5877,
        97,
        75863,
        81543
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "，",
            "token_id": 3922,
            "logprob": -0.2559,
            "prob": 0.7734
          },
          {
            "token": "。",
            "token_id": 1811,
            "logprob": -2.375,
            "prob": 0.0928
          },
          {
            "token": "真",
            "token_id": 89151,
            "logprob": -3.875,
            "prob": 0.0206
          },
          {
            "token": "的",
            "token_id": 9554,
            "logprob": -4.3125,
            "prob": 0.0133
          },
          {
            "token": "过",
            "token_id": 39282,
            "logprob": -5.0,
            "prob": 0.0067
          },
          {
            "token": "（",
            "token_id": 10110,
            "logprob": -5.375,
            "prob": 0.0046
          },
          {
            "token": "情",
            "token_id": 40474,
            "logprob": -5.5,
            "prob": 0.0041
          },
          {
            "token": "人",
            "token_id": 17792,
            "logprob": -5.5625,
            "prob": 0.0038
          },
          {
            "token": "…",
            "token_id": 1981,
            "logprob": -5.75,
            "prob": 0.0032
          },
          {
            "token": "�",
            "token_id": 6271,
            "logprob": -5.75,
            "prob": 0.0032
          }
        ]
      },
      "selected_token": {
        "token": "情",
        "token_id": 40474,
        "selection_method": "sampling"
      }
    },
    {
      "step": 54,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤笑哪一古也没有情",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�",
        "笑",
        "�",
        "�",
        "一",
        "�",
        "�",
        "也",
        "没有",
        "情"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97,
        49838,
        20648,
        103,
        15120,
        5877,
        97,
        75863,
        81543,
        40474
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "�",
            "token_id": 12774,
            "logprob": -0.75,
            "prob": 0.4727
          },
          {
            "token": "感",
            "token_id": 99750,
            "logprob": -1.375,
            "prob": 0.252
          },
          {
            "token": "�",
            "token_id": 13828,
            "logprob": -3.1875,
            "prob": 0.0413
          },
          {
            "token": "�",
            "token_id": 39013,
            "logprob": -3.375,
            "prob": 0.0342
          },
          {
            "token": "�",
            "token_id": 50266,
            "logprob": -3.625,
            "prob": 0.0266
          },
          {
            "token": "�",
            "token_id": 17486,
            "logprob": -4.0,
            "prob": 0.0183
          },
          {
            "token": "结",
            "token_id": 37985,
            "logprob": -4.25,
            "prob": 0.0142
          },
          {
            "token": "节",
            "token_id": 56602,
            "logprob": -4.3125,
            "prob": 0.0134
          },
          {
            "token": "调",
            "token_id": 48972,
            "logprob": -4.6875,
            "prob": 0.0092
          },
          {
            "token": "，",
            "token_id": 3922,
            "logprob": -4.8125,
            "prob": 0.0081
          }
        ]
      },
      "selected_token": {
        "token": "�",
        "token_id": 17486,
        "selection_method": "sampling"
      }
    },
    {
      "step": 55,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤笑哪一古也没有情�",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�",
        "笑",
        "�",
        "�",
        "一",
        "�",
        "�",
        "也",
        "没有",
        "情",
        "�"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97,
        49838,
        20648,
        103,
        15120,
        5877,
        97,
        75863,
        81543,
        40474,
        17486
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "�",
            "token_id": 222,
            "logprob": -1.3438,
            "prob": 0.2617
          },
          {
            "token": "�",
            "token_id": 107,
            "logprob": -2.0938,
            "prob": 0.1235
          },
          {
            "token": "�",
            "token_id": 254,
            "logprob": -2.625,
            "prob": 0.0728
          },
          {
            "token": "�",
            "token_id": 237,
            "logprob": -3.375,
            "prob": 0.0342
          },
          {
            "token": "�",
            "token_id": 236,
            "logprob": -3.6562,
            "prob": 0.0259
          },
          {
            "token": "�",
            "token_id": 113,
            "logprob": -3.75,
            "prob": 0.0236
          },
          {
            "token": "�",
            "token_id": 243,
            "logprob": -3.9688,
            "prob": 0.0189
          },
          {
            "token": "�",
            "token_id": 102,
            "logprob": -4.3125,
            "prob": 0.0134
          },
          {
            "token": "�",
            "token_id": 98,
            "logprob": -4.5312,
            "prob": 0.0108
          },
          {
            "token": "�",
            "token_id": 103,
            "logprob": -4.5312,
            "prob": 0.0108
          }
        ]
      },
      "selected_token": {
        "token": "�",
        "token_id": 107,
        "selection_method": "sampling"
      }
    },
    {
      "step": 56,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤笑哪一古也没有情怯",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�",
        "笑",
        "�",
        "�",
        "一",
        "�",
        "�",
        "也",
        "没有",
        "情",
        "�",
        "�"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97,
        49838,
        20648,
        103,
        15120,
        5877,
        97,
        75863,
        81543,
        40474,
        17486,
        107
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "的",
            "token_id": 9554,
            "logprob": -0.9805,
            "prob": 0.375
          },
          {
            "token": "，",
            "token_id": 3922,
            "logprob": -1.4766,
            "prob": 0.2275
          },
          {
            "token": "之",
            "token_id": 55030,
            "logprob": -1.7266,
            "prob": 0.1777
          },
          {
            "token": "。",
            "token_id": 1811,
            "logprob": -2.7969,
            "prob": 0.0613
          },
          {
            "token": "、",
            "token_id": 5486,
            "logprob": -3.6719,
            "prob": 0.0255
          },
          {
            "token": "情",
            "token_id": 40474,
            "logprob": -4.1562,
            "prob": 0.0155
          },
          {
            "token": "或",
            "token_id": 58291,
            "logprob": -4.8438,
            "prob": 0.0078
          },
          {
            "token": "地",
            "token_id": 30590,
            "logprob": -5.1562,
            "prob": 0.0057
          },
          {
            "token": "可",
            "token_id": 31540,
            "logprob": -5.3438,
            "prob": 0.0047
          },
          {
            "token": "心",
            "token_id": 64209,
            "logprob": -5.4062,
            "prob": 0.0044
          }
        ]
      },
      "selected_token": {
        "token": "，",
        "token_id": 3922,
        "selection_method": "sampling"
      }
    },
    {
      "step": 57,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤笑哪一古也没有情怯，",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�",
        "笑",
        "�",
        "�",
        "一",
        "�",
        "�",
        "也",
        "没有",
        "情",
        "�",
        "�",
        "，"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97,
        49838,
        20648,
        103,
        15120,
        5877,
        97,
        75863,
        81543,
        40474,
        17486,
        107,
        3922
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "但",
            "token_id": 78388,
            "logprob": -0.1206,
            "prob": 0.8867
          },
          {
            "token": "不",
            "token_id": 16937,
            "logprob": -3.0,
            "prob": 0.05
          },
          {
            "token": "所",
            "token_id": 32938,
            "logprob": -5.0625,
            "prob": 0.0063
          },
          {
            "token": "我",
            "token_id": 37046,
            "logprob": -5.1875,
            "prob": 0.0056
          },
          {
            "token": "Ġ",
            "token_id": 220,
            "logprob": -5.5,
            "prob": 0.0041
          },
          {
            "token": "或",
            "token_id": 58291,
            "logprob": -5.5,
            "prob": 0.0041
          },
          {
            "token": "�",
            "token_id": 45932,
            "logprob": -5.5625,
            "prob": 0.0039
          },
          {
            "token": "可",
            "token_id": 31540,
            "logprob": -5.6875,
            "prob": 0.0034
          },
          {
            "token": "也",
            "token_id": 75863,
            "logprob": -5.875,
            "prob": 0.0028
          },
          {
            "token": "因",
            "token_id": 63212,
            "logprob": -6.125,
            "prob": 0.0022
          }
        ]
      },
      "selected_token": {
        "token": "不",
        "token_id": 16937,
        "selection_method": "sampling"
      }
    },
    {
      "step": 58,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤笑哪一古也没有情怯，不",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�",
        "笑",
        "�",
        "�",
        "一",
        "�",
        "�",
        "也",
        "没有",
        "情",
        "�",
        "�",
        "，",
        "不"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97,
        49838,
        20648,
        103,
        15120,
        5877,
        97,
        75863,
        81543,
        40474,
        17486,
        107,
        3922,
        16937
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "过",
            "token_id": 39282,
            "logprob": -0.0038,
            "prob": 0.9961
          },
          {
            "token": "�",
            "token_id": 30250,
            "logprob": -6.5,
            "prob": 0.0015
          },
          {
            "token": "如",
            "token_id": 30624,
            "logprob": -7.5,
            "prob": 0.0005
          },
          {
            "token": "知",
            "token_id": 53283,
            "logprob": -8.5625,
            "prob": 0.0002
          },
          {
            "token": "像",
            "token_id": 66201,
            "logprob": -8.625,
            "prob": 0.0002
          },
          {
            "token": "会",
            "token_id": 38093,
            "logprob": -8.9375,
            "prob": 0.0001
          },
          {
            "token": "得",
            "token_id": 50928,
            "logprob": -9.25,
            "prob": 0.0001
          },
          {
            "token": "�",
            "token_id": 8192,
            "logprob": -9.625,
            "prob": 0.0001
          },
          {
            "token": "然",
            "token_id": 61994,
            "logprob": -9.75,
            "prob": 0.0001
          },
          {
            "token": "是",
            "token_id": 21043,
            "logprob": -9.875,
            "prob": 0.0001
          }
        ]
      },
      "selected_token": {
        "token": "如",
        "token_id": 30624,
        "selection_method": "sampling"
      }
    },
    {
      "step": 59,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤笑哪一古也没有情怯，不如",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�",
        "笑",
        "�",
        "�",
        "一",
        "�",
        "�",
        "也",
        "没有",
        "情",
        "�",
        "�",
        "，",
        "不",
        "如"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97,
        49838,
        20648,
        103,
        15120,
        5877,
        97,
        75863,
        81543,
        40474,
        17486,
        107,
        3922,
        16937,
        30624
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "我",
            "token_id": 37046,
            "logprob": -2.1094,
            "prob": 0.1211
          },
          {
            "token": "�",
            "token_id": 24326,
            "logprob": -2.6719,
            "prob": 0.0688
          },
          {
            "token": "给",
            "token_id": 90112,
            "logprob": -2.9219,
            "prob": 0.0537
          },
          {
            "token": "直",
            "token_id": 74245,
            "logprob": -2.9219,
            "prob": 0.0537
          },
          {
            "token": "用",
            "token_id": 11883,
            "logprob": -2.9219,
            "prob": 0.0537
          },
          {
            "token": "先",
            "token_id": 61826,
            "logprob": -2.9844,
            "prob": 0.0505
          },
          {
            "token": "说",
            "token_id": 37687,
            "logprob": -3.1094,
            "prob": 0.0447
          },
          {
            "token": "就",
            "token_id": 81258,
            "logprob": -3.5469,
            "prob": 0.0288
          },
          {
            "token": "�",
            "token_id": 10414,
            "logprob": -3.7344,
            "prob": 0.0238
          },
          {
            "token": "在",
            "token_id": 19000,
            "logprob": -3.7344,
            "prob": 0.0238
          }
        ]
      },
      "selected_token": {
        "token": "说",
        "token_id": 37687,
        "selection_method": "sampling"
      }
    },
    {
      "step": 60,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤笑哪一古也没有情怯，不如说",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�",
        "笑",
        "�",
        "�",
        "一",
        "�",
        "�",
        "也",
        "没有",
        "情",
        "�",
        "�",
        "，",
        "不",
        "如",
        "说"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97,
        49838,
        20648,
        103,
        15120,
        5877,
        97,
        75863,
        81543,
        40474,
        17486,
        107,
        3922,
        16937,
        30624,
        37687
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "我",
            "token_id": 37046,
            "logprob": -1.4062,
            "prob": 0.2441
          },
          {
            "token": "，",
            "token_id": 3922,
            "logprob": -1.9062,
            "prob": 0.1484
          },
          {
            "token": "是",
            "token_id": 21043,
            "logprob": -2.7188,
            "prob": 0.0659
          },
          {
            "token": "说",
            "token_id": 37687,
            "logprob": -3.2188,
            "prob": 0.04
          },
          {
            "token": "�",
            "token_id": 10414,
            "logprob": -3.2812,
            "prob": 0.0376
          },
          {
            "token": "在",
            "token_id": 19000,
            "logprob": -3.5312,
            "prob": 0.0292
          },
          {
            "token": "可以",
            "token_id": 74770,
            "logprob": -3.7812,
            "prob": 0.0227
          },
          {
            "token": "用",
            "token_id": 11883,
            "logprob": -3.8438,
            "prob": 0.0214
          },
          {
            "token": "给",
            "token_id": 90112,
            "logprob": -3.9688,
            "prob": 0.0189
          },
          {
            "token": "�",
            "token_id": 17857,
            "logprob": -4.0938,
            "prob": 0.0166
          }
        ]
      },
      "selected_token": {
        "token": "我",
        "token_id": 37046,
        "selection_method": "sampling"
      }
    },
    {
      "step": 61,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤笑哪一古也没有情怯，不如说我",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�",
        "笑",
        "�",
        "�",
        "一",
        "�",
        "�",
        "也",
        "没有",
        "情",
        "�",
        "�",
        "，",
        "不",
        "如",
        "说",
        "我"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97,
        49838,
        20648,
        103,
        15120,
        5877,
        97,
        75863,
        81543,
        40474,
        17486,
        107,
        3922,
        16937,
        30624,
        37687,
        37046
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "可以",
            "token_id": 74770,
            "logprob": -1.6328,
            "prob": 0.1953
          },
          {
            "token": "能",
            "token_id": 27327,
            "logprob": -1.8828,
            "prob": 0.1514
          },
          {
            "token": "现",
            "token_id": 47551,
            "logprob": -2.9531,
            "prob": 0.0525
          },
          {
            "token": "会",
            "token_id": 38093,
            "logprob": -3.0156,
            "prob": 0.0493
          },
          {
            "token": "用",
            "token_id": 11883,
            "logprob": -3.1406,
            "prob": 0.0435
          },
          {
            "token": "是",
            "token_id": 21043,
            "logprob": -3.2031,
            "prob": 0.0408
          },
          {
            "token": "在",
            "token_id": 19000,
            "logprob": -3.3906,
            "prob": 0.0339
          },
          {
            "token": "就",
            "token_id": 81258,
            "logprob": -3.7031,
            "prob": 0.0248
          },
          {
            "token": "这",
            "token_id": 44388,
            "logprob": -3.7031,
            "prob": 0.0248
          },
          {
            "token": "有",
            "token_id": 19361,
            "logprob": -3.7656,
            "prob": 0.0233
          }
        ]
      },
      "selected_token": {
        "token": "用",
        "token_id": 11883,
        "selection_method": "sampling"
      }
    },
    {
      "step": 62,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤笑哪一古也没有情怯，不如说我用",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�",
        "笑",
        "�",
        "�",
        "一",
        "�",
        "�",
        "也",
        "没有",
        "情",
        "�",
        "�",
        "，",
        "不",
        "如",
        "说",
        "我",
        "用"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97,
        49838,
        20648,
        103,
        15120,
        5877,
        97,
        75863,
        81543,
        40474,
        17486,
        107,
        3922,
        16937,
        30624,
        37687,
        37046,
        11883
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "程序",
            "token_id": 75320,
            "logprob": -1.2344,
            "prob": 0.293
          },
          {
            "token": "数据",
            "token_id": 20675,
            "logprob": -2.2344,
            "prob": 0.1074
          },
          {
            "token": "一",
            "token_id": 15120,
            "logprob": -2.3594,
            "prob": 0.0947
          },
          {
            "token": "我的",
            "token_id": 98711,
            "logprob": -3.0469,
            "prob": 0.0476
          },
          {
            "token": "计",
            "token_id": 38743,
            "logprob": -3.0469,
            "prob": 0.0476
          },
          {
            "token": "算",
            "token_id": 70203,
            "logprob": -3.1094,
            "prob": 0.0447
          },
          {
            "token": "文字",
            "token_id": 88435,
            "logprob": -3.4219,
            "prob": 0.0327
          },
          {
            "token": "机",
            "token_id": 33748,
            "logprob": -3.7969,
            "prob": 0.0225
          },
          {
            "token": "一个",
            "token_id": 48044,
            "logprob": -3.8594,
            "prob": 0.0211
          },
          {
            "token": "我",
            "token_id": 37046,
            "logprob": -4.0938,
            "prob": 0.0165
          }
        ]
      },
      "selected_token": {
        "token": "一",
        "token_id": 15120,
        "selection_method": "sampling"
      }
    },
    {
      "step": 63,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤笑哪一古也没有情怯，不如说我用一",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�",
        "笑",
        "�",
        "�",
        "一",
        "�",
        "�",
        "也",
        "没有",
        "情",
        "�",
        "�",
        "，",
        "不",
        "如",
        "说",
        "我",
        "用",
        "一"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97,
        49838,
        20648,
        103,
        15120,
        5877,
        97,
        75863,
        81543,
        40474,
        17486,
        107,
        3922,
        16937,
        30624,
        37687,
        37046,
        11883,
        15120
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "种",
            "token_id": 87502,
            "logprob": -0.25,
            "prob": 0.7773
          },
          {
            "token": "些",
            "token_id": 98184,
            "logprob": -2.25,
            "prob": 0.1055
          },
          {
            "token": "�",
            "token_id": 5877,
            "logprob": -3.3125,
            "prob": 0.0364
          },
          {
            "token": "段",
            "token_id": 38574,
            "logprob": -4.1875,
            "prob": 0.0152
          },
          {
            "token": "下",
            "token_id": 17297,
            "logprob": -4.3125,
            "prob": 0.0134
          },
          {
            "token": "定",
            "token_id": 23187,
            "logprob": -5.1875,
            "prob": 0.0056
          },
          {
            "token": "�",
            "token_id": 28194,
            "logprob": -5.3125,
            "prob": 0.0049
          },
          {
            "token": "点",
            "token_id": 28542,
            "logprob": -5.75,
            "prob": 0.0032
          },
          {
            "token": "系",
            "token_id": 39276,
            "logprob": -5.8125,
            "prob": 0.003
          },
          {
            "token": "�",
            "token_id": 63105,
            "logprob": -5.8125,
            "prob": 0.003
          }
        ]
      },
      "selected_token": {
        "token": "�",
        "token_id": 28194,
        "selection_method": "sampling"
      }
    },
    {
      "step": 64,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤笑哪一古也没有情怯，不如说我用一�",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�",
        "笑",
        "�",
        "�",
        "一",
        "�",
        "�",
        "也",
        "没有",
        "情",
        "�",
        "�",
        "，",
        "不",
        "如",
        "说",
        "我",
        "用",
        "一",
        "�"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97,
        49838,
        20648,
        103,
        15120,
        5877,
        97,
        75863,
        81543,
        40474,
        17486,
        107,
        3922,
        16937,
        30624,
        37687,
        37046,
        11883,
        15120,
        28194
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "�",
            "token_id": 245,
            "logprob": -0.0001,
            "prob": 1.0
          },
          {
            "token": "�",
            "token_id": 254,
            "logprob": -10.375,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 229,
            "logprob": -11.1875,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 117,
            "logprob": -11.8125,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 244,
            "logprob": -12.375,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 239,
            "logprob": -12.875,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 95,
            "logprob": -13.125,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 237,
            "logprob": -13.1875,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 114,
            "logprob": -13.25,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 105,
            "logprob": -13.375,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "�",
        "token_id": 245,
        "selection_method": "sampling"
      }
    },
    {
      "step": 65,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤笑哪一古也没有情怯，不如说我用一套",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�",
        "笑",
        "�",
        "�",
        "一",
        "�",
        "�",
        "也",
        "没有",
        "情",
        "�",
        "�",
        "，",
        "不",
        "如",
        "说",
        "我",
        "用",
        "一",
        "�",
        "�"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97,
        49838,
        20648,
        103,
        15120,
        5877,
        97,
        75863,
        81543,
        40474,
        17486,
        107,
        3922,
        16937,
        30624,
        37687,
        37046,
        11883,
        15120,
        28194,
        245
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "程序",
            "token_id": 75320,
            "logprob": -1.0391,
            "prob": 0.3535
          },
          {
            "token": "算",
            "token_id": 70203,
            "logprob": -2.1719,
            "prob": 0.1147
          },
          {
            "token": "计",
            "token_id": 38743,
            "logprob": -3.1094,
            "prob": 0.0449
          },
          {
            "token": "�",
            "token_id": 11589,
            "logprob": -3.4844,
            "prob": 0.0309
          },
          {
            "token": "标",
            "token_id": 31944,
            "logprob": -3.4844,
            "prob": 0.0309
          },
          {
            "token": "机",
            "token_id": 33748,
            "logprob": -4.0938,
            "prob": 0.0165
          },
          {
            "token": "有",
            "token_id": 19361,
            "logprob": -4.2188,
            "prob": 0.0146
          },
          {
            "token": "“",
            "token_id": 2118,
            "logprob": -4.2188,
            "prob": 0.0146
          },
          {
            "token": "编",
            "token_id": 31968,
            "logprob": -4.2188,
            "prob": 0.0146
          },
          {
            "token": "�",
            "token_id": 3574,
            "logprob": -4.2812,
            "prob": 0.0137
          }
        ]
      },
      "selected_token": {
        "token": "“",
        "token_id": 2118,
        "selection_method": "sampling"
      }
    },
    {
      "step": 66,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤笑哪一古也没有情怯，不如说我用一套“",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�",
        "笑",
        "�",
        "�",
        "一",
        "�",
        "�",
        "也",
        "没有",
        "情",
        "�",
        "�",
        "，",
        "不",
        "如",
        "说",
        "我",
        "用",
        "一",
        "�",
        "�",
        "“"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97,
        49838,
        20648,
        103,
        15120,
        5877,
        97,
        75863,
        81543,
        40474,
        17486,
        107,
        3922,
        16937,
        30624,
        37687,
        37046,
        11883,
        15120,
        28194,
        245,
        2118
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "程序",
            "token_id": 75320,
            "logprob": -0.9453,
            "prob": 0.3887
          },
          {
            "token": "�",
            "token_id": 11589,
            "logprob": -2.0,
            "prob": 0.1348
          },
          {
            "token": "机",
            "token_id": 33748,
            "logprob": -2.6875,
            "prob": 0.0674
          },
          {
            "token": "人",
            "token_id": 17792,
            "logprob": -3.1875,
            "prob": 0.041
          },
          {
            "token": "算",
            "token_id": 70203,
            "logprob": -3.3125,
            "prob": 0.0361
          },
          {
            "token": "计",
            "token_id": 38743,
            "logprob": -3.375,
            "prob": 0.0339
          },
          {
            "token": "理",
            "token_id": 22649,
            "logprob": -3.6875,
            "prob": 0.0249
          },
          {
            "token": "�",
            "token_id": 84264,
            "logprob": -4.1875,
            "prob": 0.0151
          },
          {
            "token": "数字",
            "token_id": 83687,
            "logprob": -4.1875,
            "prob": 0.0151
          },
          {
            "token": "编",
            "token_id": 31968,
            "logprob": -4.5,
            "prob": 0.011
          }
        ]
      },
      "selected_token": {
        "token": "算",
        "token_id": 70203,
        "selection_method": "sampling"
      }
    },
    {
      "step": 67,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤笑哪一古也没有情怯，不如说我用一套“算",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�",
        "笑",
        "�",
        "�",
        "一",
        "�",
        "�",
        "也",
        "没有",
        "情",
        "�",
        "�",
        "，",
        "不",
        "如",
        "说",
        "我",
        "用",
        "一",
        "�",
        "�",
        "“",
        "算"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97,
        49838,
        20648,
        103,
        15120,
        5877,
        97,
        75863,
        81543,
        40474,
        17486,
        107,
        3922,
        16937,
        30624,
        37687,
        37046,
        11883,
        15120,
        28194,
        245,
        2118,
        70203
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "法",
            "token_id": 25333,
            "logprob": -0.75,
            "prob": 0.4727
          },
          {
            "token": "了",
            "token_id": 35287,
            "logprob": -1.25,
            "prob": 0.2852
          },
          {
            "token": "式",
            "token_id": 29430,
            "logprob": -3.0,
            "prob": 0.0498
          },
          {
            "token": "是",
            "token_id": 21043,
            "logprob": -3.5625,
            "prob": 0.0283
          },
          {
            "token": "机",
            "token_id": 33748,
            "logprob": -3.9375,
            "prob": 0.0195
          },
          {
            "token": "力",
            "token_id": 48634,
            "logprob": -3.9375,
            "prob": 0.0195
          },
          {
            "token": "出",
            "token_id": 20834,
            "logprob": -4.3125,
            "prob": 0.0134
          },
          {
            "token": "作",
            "token_id": 19967,
            "logprob": -4.5,
            "prob": 0.0111
          },
          {
            "token": "数",
            "token_id": 9039,
            "logprob": -4.75,
            "prob": 0.0087
          },
          {
            "token": "�",
            "token_id": 4916,
            "logprob": -4.875,
            "prob": 0.0076
          }
        ]
      },
      "selected_token": {
        "token": "了",
        "token_id": 35287,
        "selection_method": "sampling"
      }
    },
    {
      "step": 68,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤笑哪一古也没有情怯，不如说我用一套“算了",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�",
        "笑",
        "�",
        "�",
        "一",
        "�",
        "�",
        "也",
        "没有",
        "情",
        "�",
        "�",
        "，",
        "不",
        "如",
        "说",
        "我",
        "用",
        "一",
        "�",
        "�",
        "“",
        "算",
        "了"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97,
        49838,
        20648,
        103,
        15120,
        5877,
        97,
        75863,
        81543,
        40474,
        17486,
        107,
        3922,
        16937,
        30624,
        37687,
        37046,
        11883,
        15120,
        28194,
        245,
        2118,
        70203,
        35287
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "算",
            "token_id": 70203,
            "logprob": -0.5625,
            "prob": 0.5703
          },
          {
            "token": "”",
            "token_id": 863,
            "logprob": -2.375,
            "prob": 0.0928
          },
          {
            "token": "的",
            "token_id": 9554,
            "logprob": -3.6875,
            "prob": 0.025
          },
          {
            "token": "�",
            "token_id": 7305,
            "logprob": -3.8125,
            "prob": 0.0221
          },
          {
            "token": "我",
            "token_id": 37046,
            "logprob": -4.125,
            "prob": 0.0161
          },
          {
            "token": "，",
            "token_id": 3922,
            "logprob": -4.1875,
            "prob": 0.0152
          },
          {
            "token": "解",
            "token_id": 50338,
            "logprob": -4.25,
            "prob": 0.0143
          },
          {
            "token": "就",
            "token_id": 81258,
            "logprob": -4.25,
            "prob": 0.0143
          },
          {
            "token": "�",
            "token_id": 11239,
            "logprob": -4.625,
            "prob": 0.0098
          },
          {
            "token": "�",
            "token_id": 5877,
            "logprob": -4.75,
            "prob": 0.0087
          }
        ]
      },
      "selected_token": {
        "token": "的",
        "token_id": 9554,
        "selection_method": "sampling"
      }
    },
    {
      "step": 69,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤笑哪一古也没有情怯，不如说我用一套“算了的",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�",
        "笑",
        "�",
        "�",
        "一",
        "�",
        "�",
        "也",
        "没有",
        "情",
        "�",
        "�",
        "，",
        "不",
        "如",
        "说",
        "我",
        "用",
        "一",
        "�",
        "�",
        "“",
        "算",
        "了",
        "的"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97,
        49838,
        20648,
        103,
        15120,
        5877,
        97,
        75863,
        81543,
        40474,
        17486,
        107,
        3922,
        16937,
        30624,
        37687,
        37046,
        11883,
        15120,
        28194,
        245,
        2118,
        70203,
        35287,
        9554
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "”",
            "token_id": 863,
            "logprob": -0.5547,
            "prob": 0.5742
          },
          {
            "token": "�",
            "token_id": 11589,
            "logprob": -2.3125,
            "prob": 0.0996
          },
          {
            "token": "算",
            "token_id": 70203,
            "logprob": -2.875,
            "prob": 0.0569
          },
          {
            "token": "程序",
            "token_id": 75320,
            "logprob": -3.125,
            "prob": 0.0442
          },
          {
            "token": "笑",
            "token_id": 49838,
            "logprob": -4.1875,
            "prob": 0.0153
          },
          {
            "token": "话",
            "token_id": 58543,
            "logprob": -4.1875,
            "prob": 0.0153
          },
          {
            "token": "，",
            "token_id": 3922,
            "logprob": -4.5,
            "prob": 0.0112
          },
          {
            "token": "�",
            "token_id": 161,
            "logprob": -4.8125,
            "prob": 0.0082
          },
          {
            "token": "”，",
            "token_id": 34690,
            "logprob": -4.8125,
            "prob": 0.0082
          },
          {
            "token": "人",
            "token_id": 17792,
            "logprob": -4.875,
            "prob": 0.0077
          }
        ]
      },
      "selected_token": {
        "token": "算",
        "token_id": 70203,
        "selection_method": "sampling"
      }
    },
    {
      "step": 70,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤笑哪一古也没有情怯，不如说我用一套“算了的算",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�",
        "笑",
        "�",
        "�",
        "一",
        "�",
        "�",
        "也",
        "没有",
        "情",
        "�",
        "�",
        "，",
        "不",
        "如",
        "说",
        "我",
        "用",
        "一",
        "�",
        "�",
        "“",
        "算",
        "了",
        "的",
        "算"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97,
        49838,
        20648,
        103,
        15120,
        5877,
        97,
        75863,
        81543,
        40474,
        17486,
        107,
        3922,
        16937,
        30624,
        37687,
        37046,
        11883,
        15120,
        28194,
        245,
        2118,
        70203,
        35287,
        9554,
        70203
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "了",
            "token_id": 35287,
            "logprob": -0.0742,
            "prob": 0.9297
          },
          {
            "token": "法",
            "token_id": 25333,
            "logprob": -3.1406,
            "prob": 0.0435
          },
          {
            "token": "”",
            "token_id": 863,
            "logprob": -4.4375,
            "prob": 0.0117
          },
          {
            "token": "数",
            "token_id": 9039,
            "logprob": -6.1875,
            "prob": 0.002
          },
          {
            "token": "的",
            "token_id": 9554,
            "logprob": -6.625,
            "prob": 0.0013
          },
          {
            "token": "是",
            "token_id": 21043,
            "logprob": -6.6875,
            "prob": 0.0012
          },
          {
            "token": "话",
            "token_id": 58543,
            "logprob": -7.0625,
            "prob": 0.0008
          },
          {
            "token": "�",
            "token_id": 4916,
            "logprob": -7.1875,
            "prob": 0.0007
          },
          {
            "token": "�",
            "token_id": 6271,
            "logprob": -7.375,
            "prob": 0.0006
          },
          {
            "token": "我",
            "token_id": 37046,
            "logprob": -7.5,
            "prob": 0.0005
          }
        ]
      },
      "selected_token": {
        "token": "�",
        "token_id": 4916,
        "selection_method": "sampling"
      }
    },
    {
      "step": 71,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤笑哪一古也没有情怯，不如说我用一套“算了的算�",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�",
        "笑",
        "�",
        "�",
        "一",
        "�",
        "�",
        "也",
        "没有",
        "情",
        "�",
        "�",
        "，",
        "不",
        "如",
        "说",
        "我",
        "用",
        "一",
        "�",
        "�",
        "“",
        "算",
        "了",
        "的",
        "算",
        "�"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97,
        49838,
        20648,
        103,
        15120,
        5877,
        97,
        75863,
        81543,
        40474,
        17486,
        107,
        3922,
        16937,
        30624,
        37687,
        37046,
        11883,
        15120,
        28194,
        245,
        2118,
        70203,
        35287,
        9554,
        70203,
        4916
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "�",
            "token_id": 107,
            "logprob": -0.0003,
            "prob": 1.0
          },
          {
            "token": "�",
            "token_id": 249,
            "logprob": -9.125,
            "prob": 0.0001
          },
          {
            "token": "�",
            "token_id": 234,
            "logprob": -10.125,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 104,
            "logprob": -10.25,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 109,
            "logprob": -10.5625,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 113,
            "logprob": -11.625,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 96,
            "logprob": -11.6875,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 118,
            "logprob": -11.75,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 112,
            "logprob": -11.8125,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 255,
            "logprob": -12.0,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "�",
        "token_id": 107,
        "selection_method": "sampling"
      }
    },
    {
      "step": 72,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤笑哪一古也没有情怯，不如说我用一套“算了的算术",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�",
        "笑",
        "�",
        "�",
        "一",
        "�",
        "�",
        "也",
        "没有",
        "情",
        "�",
        "�",
        "，",
        "不",
        "如",
        "说",
        "我",
        "用",
        "一",
        "�",
        "�",
        "“",
        "算",
        "了",
        "的",
        "算",
        "�",
        "�"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97,
        49838,
        20648,
        103,
        15120,
        5877,
        97,
        75863,
        81543,
        40474,
        17486,
        107,
        3922,
        16937,
        30624,
        37687,
        37046,
        11883,
        15120,
        28194,
        245,
        2118,
        70203,
        35287,
        9554,
        70203,
        4916,
        107
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "”",
            "token_id": 863,
            "logprob": -0.1514,
            "prob": 0.8594
          },
          {
            "token": "式",
            "token_id": 29430,
            "logprob": -4.2188,
            "prob": 0.0148
          },
          {
            "token": "�",
            "token_id": 11589,
            "logprob": -4.6562,
            "prob": 0.0095
          },
          {
            "token": "�",
            "token_id": 39013,
            "logprob": -4.8438,
            "prob": 0.0079
          },
          {
            "token": "方式",
            "token_id": 76868,
            "logprob": -4.9062,
            "prob": 0.0074
          },
          {
            "token": "”，",
            "token_id": 34690,
            "logprob": -5.2188,
            "prob": 0.0054
          },
          {
            "token": "算",
            "token_id": 70203,
            "logprob": -5.3438,
            "prob": 0.0048
          },
          {
            "token": "题",
            "token_id": 34972,
            "logprob": -5.4688,
            "prob": 0.0042
          },
          {
            "token": "程序",
            "token_id": 75320,
            "logprob": -5.7188,
            "prob": 0.0033
          },
          {
            "token": "法",
            "token_id": 25333,
            "logprob": -5.7812,
            "prob": 0.0031
          }
        ]
      },
      "selected_token": {
        "token": "程序",
        "token_id": 75320,
        "selection_method": "sampling"
      }
    },
    {
      "step": 73,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤笑哪一古也没有情怯，不如说我用一套“算了的算术程序",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�",
        "笑",
        "�",
        "�",
        "一",
        "�",
        "�",
        "也",
        "没有",
        "情",
        "�",
        "�",
        "，",
        "不",
        "如",
        "说",
        "我",
        "用",
        "一",
        "�",
        "�",
        "“",
        "算",
        "了",
        "的",
        "算",
        "�",
        "�",
        "程序"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97,
        49838,
        20648,
        103,
        15120,
        5877,
        97,
        75863,
        81543,
        40474,
        17486,
        107,
        3922,
        16937,
        30624,
        37687,
        37046,
        11883,
        15120,
        28194,
        245,
        2118,
        70203,
        35287,
        9554,
        70203,
        4916,
        107,
        75320
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "”",
            "token_id": 863,
            "logprob": -0.1064,
            "prob": 0.8984
          },
          {
            "token": "员",
            "token_id": 43323,
            "logprob": -3.6719,
            "prob": 0.0255
          },
          {
            "token": "�",
            "token_id": 11589,
            "logprob": -4.2812,
            "prob": 0.0137
          },
          {
            "token": "”，",
            "token_id": 34690,
            "logprob": -4.7812,
            "prob": 0.0083
          },
          {
            "token": "”的",
            "token_id": 99007,
            "logprob": -5.0938,
            "prob": 0.006
          },
          {
            "token": "来",
            "token_id": 37507,
            "logprob": -5.5312,
            "prob": 0.0039
          },
          {
            "token": "模",
            "token_id": 54872,
            "logprob": -5.9688,
            "prob": 0.0025
          },
          {
            "token": "算",
            "token_id": 70203,
            "logprob": -5.9688,
            "prob": 0.0025
          },
          {
            "token": "设计",
            "token_id": 71600,
            "logprob": -6.1562,
            "prob": 0.0021
          },
          {
            "token": "，",
            "token_id": 3922,
            "logprob": -6.3438,
            "prob": 0.0017
          }
        ]
      },
      "selected_token": {
        "token": "来",
        "token_id": 37507,
        "selection_method": "sampling"
      }
    },
    {
      "step": 74,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤笑哪一古也没有情怯，不如说我用一套“算了的算术程序来",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�",
        "笑",
        "�",
        "�",
        "一",
        "�",
        "�",
        "也",
        "没有",
        "情",
        "�",
        "�",
        "，",
        "不",
        "如",
        "说",
        "我",
        "用",
        "一",
        "�",
        "�",
        "“",
        "算",
        "了",
        "的",
        "算",
        "�",
        "�",
        "程序",
        "来"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97,
        49838,
        20648,
        103,
        15120,
        5877,
        97,
        75863,
        81543,
        40474,
        17486,
        107,
        3922,
        16937,
        30624,
        37687,
        37046,
        11883,
        15120,
        28194,
        245,
        2118,
        70203,
        35287,
        9554,
        70203,
        4916,
        107,
        75320,
        37507
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "模",
            "token_id": 54872,
            "logprob": -0.9766,
            "prob": 0.377
          },
          {
            "token": "制",
            "token_id": 44416,
            "logprob": -2.4844,
            "prob": 0.084
          },
          {
            "token": "生成",
            "token_id": 45059,
            "logprob": -2.9844,
            "prob": 0.051
          },
          {
            "token": "构",
            "token_id": 78935,
            "logprob": -3.2344,
            "prob": 0.0396
          },
          {
            "token": "算",
            "token_id": 70203,
            "logprob": -3.7344,
            "prob": 0.024
          },
          {
            "token": "�",
            "token_id": 84264,
            "logprob": -4.0938,
            "prob": 0.0165
          },
          {
            "token": "”",
            "token_id": 863,
            "logprob": -4.2188,
            "prob": 0.0146
          },
          {
            "token": "�",
            "token_id": 10414,
            "logprob": -4.2812,
            "prob": 0.0137
          },
          {
            "token": "�",
            "token_id": 49691,
            "logprob": -4.4062,
            "prob": 0.0121
          },
          {
            "token": "展",
            "token_id": 77413,
            "logprob": -4.4062,
            "prob": 0.0121
          }
        ]
      },
      "selected_token": {
        "token": "构",
        "token_id": 78935,
        "selection_method": "sampling"
      }
    },
    {
      "step": 75,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤笑哪一古也没有情怯，不如说我用一套“算了的算术程序来构",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�",
        "笑",
        "�",
        "�",
        "一",
        "�",
        "�",
        "也",
        "没有",
        "情",
        "�",
        "�",
        "，",
        "不",
        "如",
        "说",
        "我",
        "用",
        "一",
        "�",
        "�",
        "“",
        "算",
        "了",
        "的",
        "算",
        "�",
        "�",
        "程序",
        "来",
        "构"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97,
        49838,
        20648,
        103,
        15120,
        5877,
        97,
        75863,
        81543,
        40474,
        17486,
        107,
        3922,
        16937,
        30624,
        37687,
        37046,
        11883,
        15120,
        28194,
        245,
        2118,
        70203,
        35287,
        9554,
        70203,
        4916,
        107,
        75320,
        37507,
        78935
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "建",
            "token_id": 26892,
            "logprob": -0.6133,
            "prob": 0.543
          },
          {
            "token": "造",
            "token_id": 67178,
            "logprob": -1.2344,
            "prob": 0.291
          },
          {
            "token": "思",
            "token_id": 91763,
            "logprob": -1.8594,
            "prob": 0.1553
          },
          {
            "token": "成",
            "token_id": 13153,
            "logprob": -5.125,
            "prob": 0.006
          },
          {
            "token": "�",
            "token_id": 33565,
            "logprob": -5.6875,
            "prob": 0.0034
          },
          {
            "token": "�",
            "token_id": 29857,
            "logprob": -7.3125,
            "prob": 0.0007
          },
          {
            "token": "�",
            "token_id": 20119,
            "logprob": -8.25,
            "prob": 0.0003
          },
          {
            "token": "件",
            "token_id": 14558,
            "logprob": -9.125,
            "prob": 0.0001
          },
          {
            "token": "制",
            "token_id": 44416,
            "logprob": -9.5,
            "prob": 0.0001
          },
          {
            "token": "图",
            "token_id": 29129,
            "logprob": -9.6875,
            "prob": 0.0001
          }
        ]
      },
      "selected_token": {
        "token": "造",
        "token_id": 67178,
        "selection_method": "sampling"
      }
    },
    {
      "step": 76,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤笑哪一古也没有情怯，不如说我用一套“算了的算术程序来构造",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�",
        "笑",
        "�",
        "�",
        "一",
        "�",
        "�",
        "也",
        "没有",
        "情",
        "�",
        "�",
        "，",
        "不",
        "如",
        "说",
        "我",
        "用",
        "一",
        "�",
        "�",
        "“",
        "算",
        "了",
        "的",
        "算",
        "�",
        "�",
        "程序",
        "来",
        "构",
        "造"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97,
        49838,
        20648,
        103,
        15120,
        5877,
        97,
        75863,
        81543,
        40474,
        17486,
        107,
        3922,
        16937,
        30624,
        37687,
        37046,
        11883,
        15120,
        28194,
        245,
        2118,
        70203,
        35287,
        9554,
        70203,
        4916,
        107,
        75320,
        37507,
        78935,
        67178
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "一个",
            "token_id": 48044,
            "logprob": -0.293,
            "prob": 0.7461
          },
          {
            "token": "一",
            "token_id": 15120,
            "logprob": -1.9219,
            "prob": 0.1465
          },
          {
            "token": "出",
            "token_id": 20834,
            "logprob": -3.8594,
            "prob": 0.0211
          },
          {
            "token": "个",
            "token_id": 19483,
            "logprob": -4.4688,
            "prob": 0.0114
          },
          {
            "token": "你",
            "token_id": 57668,
            "logprob": -4.9062,
            "prob": 0.0073
          },
          {
            "token": "�",
            "token_id": 12870,
            "logprob": -5.6562,
            "prob": 0.0034
          },
          {
            "token": "了",
            "token_id": 35287,
            "logprob": -5.6562,
            "prob": 0.0034
          },
          {
            "token": "的",
            "token_id": 9554,
            "logprob": -5.9062,
            "prob": 0.0027
          },
          {
            "token": "”",
            "token_id": 863,
            "logprob": -5.9062,
            "prob": 0.0027
          },
          {
            "token": "，",
            "token_id": 3922,
            "logprob": -5.9688,
            "prob": 0.0025
          }
        ]
      },
      "selected_token": {
        "token": "了",
        "token_id": 35287,
        "selection_method": "sampling"
      }
    },
    {
      "step": 77,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤笑哪一古也没有情怯，不如说我用一套“算了的算术程序来构造了",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�",
        "笑",
        "�",
        "�",
        "一",
        "�",
        "�",
        "也",
        "没有",
        "情",
        "�",
        "�",
        "，",
        "不",
        "如",
        "说",
        "我",
        "用",
        "一",
        "�",
        "�",
        "“",
        "算",
        "了",
        "的",
        "算",
        "�",
        "�",
        "程序",
        "来",
        "构",
        "造",
        "了"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97,
        49838,
        20648,
        103,
        15120,
        5877,
        97,
        75863,
        81543,
        40474,
        17486,
        107,
        3922,
        16937,
        30624,
        37687,
        37046,
        11883,
        15120,
        28194,
        245,
        2118,
        70203,
        35287,
        9554,
        70203,
        4916,
        107,
        75320,
        37507,
        78935,
        67178,
        35287
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "一个",
            "token_id": 48044,
            "logprob": -0.1709,
            "prob": 0.8438
          },
          {
            "token": "一",
            "token_id": 15120,
            "logprob": -2.2969,
            "prob": 0.1006
          },
          {
            "token": "个",
            "token_id": 19483,
            "logprob": -3.8594,
            "prob": 0.0211
          },
          {
            "token": "这",
            "token_id": 44388,
            "logprob": -4.7812,
            "prob": 0.0082
          },
          {
            "token": "�",
            "token_id": 12870,
            "logprob": -5.3438,
            "prob": 0.0047
          },
          {
            "token": "�",
            "token_id": 10414,
            "logprob": -6.0312,
            "prob": 0.0024
          },
          {
            "token": "些",
            "token_id": 98184,
            "logprob": -6.4688,
            "prob": 0.0015
          },
          {
            "token": "笑",
            "token_id": 49838,
            "logprob": -6.7812,
            "prob": 0.0011
          },
          {
            "token": "”",
            "token_id": 863,
            "logprob": -6.9062,
            "prob": 0.001
          },
          {
            "token": "你",
            "token_id": 57668,
            "logprob": -7.0938,
            "prob": 0.0008
          }
        ]
      },
      "selected_token": {
        "token": "个",
        "token_id": 19483,
        "selection_method": "sampling"
      }
    },
    {
      "step": 78,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤笑哪一古也没有情怯，不如说我用一套“算了的算术程序来构造了个",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�",
        "笑",
        "�",
        "�",
        "一",
        "�",
        "�",
        "也",
        "没有",
        "情",
        "�",
        "�",
        "，",
        "不",
        "如",
        "说",
        "我",
        "用",
        "一",
        "�",
        "�",
        "“",
        "算",
        "了",
        "的",
        "算",
        "�",
        "�",
        "程序",
        "来",
        "构",
        "造",
        "了",
        "个"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97,
        49838,
        20648,
        103,
        15120,
        5877,
        97,
        75863,
        81543,
        40474,
        17486,
        107,
        3922,
        16937,
        30624,
        37687,
        37046,
        11883,
        15120,
        28194,
        245,
        2118,
        70203,
        35287,
        9554,
        70203,
        4916,
        107,
        75320,
        37507,
        78935,
        67178,
        35287,
        19483
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "笑",
            "token_id": 49838,
            "logprob": -1.4688,
            "prob": 0.2295
          },
          {
            "token": "有",
            "token_id": 19361,
            "logprob": -2.5312,
            "prob": 0.0791
          },
          {
            "token": "�",
            "token_id": 84264,
            "logprob": -2.7188,
            "prob": 0.0659
          },
          {
            "token": "�",
            "token_id": 10414,
            "logprob": -2.8438,
            "prob": 0.0581
          },
          {
            "token": "关",
            "token_id": 30356,
            "logprob": -3.9688,
            "prob": 0.0188
          },
          {
            "token": "合",
            "token_id": 40862,
            "logprob": -4.0312,
            "prob": 0.0177
          },
          {
            "token": "自",
            "token_id": 37026,
            "logprob": -4.0938,
            "prob": 0.0166
          },
          {
            "token": "�",
            "token_id": 17885,
            "logprob": -4.0938,
            "prob": 0.0166
          },
          {
            "token": "模",
            "token_id": 54872,
            "logprob": -4.0938,
            "prob": 0.0166
          },
          {
            "token": "人",
            "token_id": 17792,
            "logprob": -4.1562,
            "prob": 0.0156
          }
        ]
      },
      "selected_token": {
        "token": "关",
        "token_id": 30356,
        "selection_method": "sampling"
      }
    },
    {
      "step": 79,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤笑哪一古也没有情怯，不如说我用一套“算了的算术程序来构造了个关",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�",
        "笑",
        "�",
        "�",
        "一",
        "�",
        "�",
        "也",
        "没有",
        "情",
        "�",
        "�",
        "，",
        "不",
        "如",
        "说",
        "我",
        "用",
        "一",
        "�",
        "�",
        "“",
        "算",
        "了",
        "的",
        "算",
        "�",
        "�",
        "程序",
        "来",
        "构",
        "造",
        "了",
        "个",
        "关"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97,
        49838,
        20648,
        103,
        15120,
        5877,
        97,
        75863,
        81543,
        40474,
        17486,
        107,
        3922,
        16937,
        30624,
        37687,
        37046,
        11883,
        15120,
        28194,
        245,
        2118,
        70203,
        35287,
        9554,
        70203,
        4916,
        107,
        75320,
        37507,
        78935,
        67178,
        35287,
        19483,
        30356
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "于",
            "token_id": 35304,
            "logprob": -0.0016,
            "prob": 1.0
          },
          {
            "token": "系",
            "token_id": 39276,
            "logprob": -8.25,
            "prob": 0.0003
          },
          {
            "token": "�",
            "token_id": 18259,
            "logprob": -8.25,
            "prob": 0.0003
          },
          {
            "token": "注",
            "token_id": 26130,
            "logprob": -8.3125,
            "prob": 0.0002
          },
          {
            "token": "键",
            "token_id": 62049,
            "logprob": -9.5625,
            "prob": 0.0001
          },
          {
            "token": "关",
            "token_id": 30356,
            "logprob": -9.5625,
            "prob": 0.0001
          },
          {
            "token": "�",
            "token_id": 47453,
            "logprob": -9.625,
            "prob": 0.0001
          },
          {
            "token": "�",
            "token_id": 17486,
            "logprob": -9.75,
            "prob": 0.0001
          },
          {
            "token": "心",
            "token_id": 64209,
            "logprob": -10.0,
            "prob": 0.0
          },
          {
            "token": "联",
            "token_id": 50182,
            "logprob": -10.875,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "于",
        "token_id": 35304,
        "selection_method": "sampling"
      }
    },
    {
      "step": 80,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤笑哪一古也没有情怯，不如说我用一套“算了的算术程序来构造了个关于",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�",
        "笑",
        "�",
        "�",
        "一",
        "�",
        "�",
        "也",
        "没有",
        "情",
        "�",
        "�",
        "，",
        "不",
        "如",
        "说",
        "我",
        "用",
        "一",
        "�",
        "�",
        "“",
        "算",
        "了",
        "的",
        "算",
        "�",
        "�",
        "程序",
        "来",
        "构",
        "造",
        "了",
        "个",
        "关",
        "于"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97,
        49838,
        20648,
        103,
        15120,
        5877,
        97,
        75863,
        81543,
        40474,
        17486,
        107,
        3922,
        16937,
        30624,
        37687,
        37046,
        11883,
        15120,
        28194,
        245,
        2118,
        70203,
        35287,
        9554,
        70203,
        4916,
        107,
        75320,
        37507,
        78935,
        67178,
        35287,
        19483,
        30356,
        35304
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "�",
            "token_id": 165,
            "logprob": -2.0625,
            "prob": 0.126
          },
          {
            "token": "动",
            "token_id": 28833,
            "logprob": -2.5,
            "prob": 0.0815
          },
          {
            "token": "�",
            "token_id": 163,
            "logprob": -2.875,
            "prob": 0.0562
          },
          {
            "token": "数字",
            "token_id": 83687,
            "logprob": -3.0,
            "prob": 0.0496
          },
          {
            "token": "“",
            "token_id": 2118,
            "logprob": -3.25,
            "prob": 0.0386
          },
          {
            "token": "人",
            "token_id": 17792,
            "logprob": -3.4375,
            "prob": 0.032
          },
          {
            "token": "自",
            "token_id": 37026,
            "logprob": -3.4375,
            "prob": 0.032
          },
          {
            "token": "水",
            "token_id": 53610,
            "logprob": -3.625,
            "prob": 0.0265
          },
          {
            "token": "�",
            "token_id": 162,
            "logprob": -3.8125,
            "prob": 0.022
          },
          {
            "token": "�",
            "token_id": 3574,
            "logprob": -3.8125,
            "prob": 0.022
          }
        ]
      },
      "selected_token": {
        "token": "�",
        "token_id": 165,
        "selection_method": "sampling"
      }
    },
    {
      "step": 81,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤笑哪一古也没有情怯，不如说我用一套“算了的算术程序来构造了个关于�",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�",
        "笑",
        "�",
        "�",
        "一",
        "�",
        "�",
        "也",
        "没有",
        "情",
        "�",
        "�",
        "，",
        "不",
        "如",
        "说",
        "我",
        "用",
        "一",
        "�",
        "�",
        "“",
        "算",
        "了",
        "的",
        "算",
        "�",
        "�",
        "程序",
        "来",
        "构",
        "造",
        "了",
        "个",
        "关",
        "于",
        "�"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97,
        49838,
        20648,
        103,
        15120,
        5877,
        97,
        75863,
        81543,
        40474,
        17486,
        107,
        3922,
        16937,
        30624,
        37687,
        37046,
        11883,
        15120,
        28194,
        245,
        2118,
        70203,
        35287,
        9554,
        70203,
        4916,
        107,
        75320,
        37507,
        78935,
        67178,
        35287,
        19483,
        30356,
        35304,
        165
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "�",
            "token_id": 116,
            "logprob": -0.0801,
            "prob": 0.9219
          },
          {
            "token": "�",
            "token_id": 109,
            "logprob": -3.4531,
            "prob": 0.0315
          },
          {
            "token": "�",
            "token_id": 117,
            "logprob": -3.5781,
            "prob": 0.0278
          },
          {
            "token": "�",
            "token_id": 118,
            "logprob": -4.8438,
            "prob": 0.008
          },
          {
            "token": "�",
            "token_id": 120,
            "logprob": -6.2812,
            "prob": 0.0019
          },
          {
            "token": "�",
            "token_id": 103,
            "logprob": -6.5312,
            "prob": 0.0015
          },
          {
            "token": "�",
            "token_id": 110,
            "logprob": -6.7812,
            "prob": 0.0012
          },
          {
            "token": "�",
            "token_id": 255,
            "logprob": -7.0938,
            "prob": 0.0008
          },
          {
            "token": "�",
            "token_id": 111,
            "logprob": -7.0938,
            "prob": 0.0008
          },
          {
            "token": "�",
            "token_id": 97,
            "logprob": -7.1562,
            "prob": 0.0008
          }
        ]
      },
      "selected_token": {
        "token": "�",
        "token_id": 109,
        "selection_method": "sampling"
      }
    },
    {
      "step": 82,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤笑哪一古也没有情怯，不如说我用一套“算了的算术程序来构造了个关于�",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�",
        "笑",
        "�",
        "�",
        "一",
        "�",
        "�",
        "也",
        "没有",
        "情",
        "�",
        "�",
        "，",
        "不",
        "如",
        "说",
        "我",
        "用",
        "一",
        "�",
        "�",
        "“",
        "算",
        "了",
        "的",
        "算",
        "�",
        "�",
        "程序",
        "来",
        "构",
        "造",
        "了",
        "个",
        "关",
        "于",
        "�",
        "�"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97,
        49838,
        20648,
        103,
        15120,
        5877,
        97,
        75863,
        81543,
        40474,
        17486,
        107,
        3922,
        16937,
        30624,
        37687,
        37046,
        11883,
        15120,
        28194,
        245,
        2118,
        70203,
        35287,
        9554,
        70203,
        4916,
        107,
        75320,
        37507,
        78935,
        67178,
        35287,
        19483,
        30356,
        35304,
        165,
        109
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "�",
            "token_id": 120,
            "logprob": -0.0001,
            "prob": 1.0
          },
          {
            "token": "�",
            "token_id": 123,
            "logprob": -10.1875,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 255,
            "logprob": -10.625,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 245,
            "logprob": -10.875,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 115,
            "logprob": -10.9375,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 114,
            "logprob": -12.0625,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 118,
            "logprob": -12.25,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 119,
            "logprob": -12.625,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 109,
            "logprob": -12.875,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 233,
            "logprob": -12.875,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "�",
        "token_id": 120,
        "selection_method": "sampling"
      }
    },
    {
      "step": 83,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤笑哪一古也没有情怯，不如说我用一套“算了的算术程序来构造了个关于鱼",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�",
        "笑",
        "�",
        "�",
        "一",
        "�",
        "�",
        "也",
        "没有",
        "情",
        "�",
        "�",
        "，",
        "不",
        "如",
        "说",
        "我",
        "用",
        "一",
        "�",
        "�",
        "“",
        "算",
        "了",
        "的",
        "算",
        "�",
        "�",
        "程序",
        "来",
        "构",
        "造",
        "了",
        "个",
        "关",
        "于",
        "�",
        "�",
        "�"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97,
        49838,
        20648,
        103,
        15120,
        5877,
        97,
        75863,
        81543,
        40474,
        17486,
        107,
        3922,
        16937,
        30624,
        37687,
        37046,
        11883,
        15120,
        28194,
        245,
        2118,
        70203,
        35287,
        9554,
        70203,
        4916,
        107,
        75320,
        37507,
        78935,
        67178,
        35287,
        19483,
        30356,
        35304,
        165,
        109,
        120
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "和",
            "token_id": 34208,
            "logprob": -1.0469,
            "prob": 0.3516
          },
          {
            "token": "的",
            "token_id": 9554,
            "logprob": -1.1094,
            "prob": 0.3301
          },
          {
            "token": "类",
            "token_id": 22238,
            "logprob": -1.6719,
            "prob": 0.1885
          },
          {
            "token": "�",
            "token_id": 161,
            "logprob": -3.5469,
            "prob": 0.0289
          },
          {
            "token": "与",
            "token_id": 58318,
            "logprob": -3.6719,
            "prob": 0.0255
          },
          {
            "token": "之",
            "token_id": 55030,
            "logprob": -4.9062,
            "prob": 0.0073
          },
          {
            "token": "子",
            "token_id": 45829,
            "logprob": -5.0312,
            "prob": 0.0064
          },
          {
            "token": "�",
            "token_id": 165,
            "logprob": -5.0312,
            "prob": 0.0064
          },
          {
            "token": "、",
            "token_id": 5486,
            "logprob": -5.2812,
            "prob": 0.005
          },
          {
            "token": "�",
            "token_id": 25781,
            "logprob": -6.5312,
            "prob": 0.0014
          }
        ]
      },
      "selected_token": {
        "token": "类",
        "token_id": 22238,
        "selection_method": "sampling"
      }
    },
    {
      "step": 84,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤笑哪一古也没有情怯，不如说我用一套“算了的算术程序来构造了个关于鱼类",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�",
        "笑",
        "�",
        "�",
        "一",
        "�",
        "�",
        "也",
        "没有",
        "情",
        "�",
        "�",
        "，",
        "不",
        "如",
        "说",
        "我",
        "用",
        "一",
        "�",
        "�",
        "“",
        "算",
        "了",
        "的",
        "算",
        "�",
        "�",
        "程序",
        "来",
        "构",
        "造",
        "了",
        "个",
        "关",
        "于",
        "�",
        "�",
        "�",
        "类"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97,
        49838,
        20648,
        103,
        15120,
        5877,
        97,
        75863,
        81543,
        40474,
        17486,
        107,
        3922,
        16937,
        30624,
        37687,
        37046,
        11883,
        15120,
        28194,
        245,
        2118,
        70203,
        35287,
        9554,
        70203,
        4916,
        107,
        75320,
        37507,
        78935,
        67178,
        35287,
        19483,
        30356,
        35304,
        165,
        109,
        120,
        22238
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "的",
            "token_id": 9554,
            "logprob": -0.1084,
            "prob": 0.8984
          },
          {
            "token": "和",
            "token_id": 34208,
            "logprob": -3.6094,
            "prob": 0.0271
          },
          {
            "token": "与",
            "token_id": 58318,
            "logprob": -4.7188,
            "prob": 0.0088
          },
          {
            "token": "、",
            "token_id": 5486,
            "logprob": -4.8438,
            "prob": 0.0078
          },
          {
            "token": "生",
            "token_id": 21990,
            "logprob": -5.0938,
            "prob": 0.006
          },
          {
            "token": "�",
            "token_id": 17885,
            "logprob": -6.6562,
            "prob": 0.0013
          },
          {
            "token": "有",
            "token_id": 19361,
            "logprob": -6.8438,
            "prob": 0.0011
          },
          {
            "token": "最",
            "token_id": 32335,
            "logprob": -6.9062,
            "prob": 0.001
          },
          {
            "token": "题",
            "token_id": 34972,
            "logprob": -6.9062,
            "prob": 0.001
          },
          {
            "token": "�",
            "token_id": 162,
            "logprob": -6.9688,
            "prob": 0.0009
          }
        ]
      },
      "selected_token": {
        "token": "与",
        "token_id": 58318,
        "selection_method": "sampling"
      }
    },
    {
      "step": 85,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤笑哪一古也没有情怯，不如说我用一套“算了的算术程序来构造了个关于鱼类与",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�",
        "笑",
        "�",
        "�",
        "一",
        "�",
        "�",
        "也",
        "没有",
        "情",
        "�",
        "�",
        "，",
        "不",
        "如",
        "说",
        "我",
        "用",
        "一",
        "�",
        "�",
        "“",
        "算",
        "了",
        "的",
        "算",
        "�",
        "�",
        "程序",
        "来",
        "构",
        "造",
        "了",
        "个",
        "关",
        "于",
        "�",
        "�",
        "�",
        "类",
        "与"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97,
        49838,
        20648,
        103,
        15120,
        5877,
        97,
        75863,
        81543,
        40474,
        17486,
        107,
        3922,
        16937,
        30624,
        37687,
        37046,
        11883,
        15120,
        28194,
        245,
        2118,
        70203,
        35287,
        9554,
        70203,
        4916,
        107,
        75320,
        37507,
        78935,
        67178,
        35287,
        19483,
        30356,
        35304,
        165,
        109,
        120,
        22238,
        58318
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "人",
            "token_id": 17792,
            "logprob": -0.5,
            "prob": 0.6055
          },
          {
            "token": "�",
            "token_id": 163,
            "logprob": -2.125,
            "prob": 0.1196
          },
          {
            "token": "�",
            "token_id": 18259,
            "logprob": -4.0625,
            "prob": 0.0172
          },
          {
            "token": "�",
            "token_id": 165,
            "logprob": -4.0625,
            "prob": 0.0172
          },
          {
            "token": "动",
            "token_id": 28833,
            "logprob": -4.5625,
            "prob": 0.0104
          },
          {
            "token": "�",
            "token_id": 8676,
            "logprob": -5.0,
            "prob": 0.0067
          },
          {
            "token": "高",
            "token_id": 45736,
            "logprob": -5.0,
            "prob": 0.0067
          },
          {
            "token": "�",
            "token_id": 63105,
            "logprob": -5.25,
            "prob": 0.0052
          },
          {
            "token": "天",
            "token_id": 36827,
            "logprob": -5.375,
            "prob": 0.0046
          },
          {
            "token": "老",
            "token_id": 92877,
            "logprob": -5.5625,
            "prob": 0.0038
          }
        ]
      },
      "selected_token": {
        "token": "�",
        "token_id": 165,
        "selection_method": "sampling"
      }
    },
    {
      "step": 86,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤笑哪一古也没有情怯，不如说我用一套“算了的算术程序来构造了个关于鱼类与�",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�",
        "笑",
        "�",
        "�",
        "一",
        "�",
        "�",
        "也",
        "没有",
        "情",
        "�",
        "�",
        "，",
        "不",
        "如",
        "说",
        "我",
        "用",
        "一",
        "�",
        "�",
        "“",
        "算",
        "了",
        "的",
        "算",
        "�",
        "�",
        "程序",
        "来",
        "构",
        "造",
        "了",
        "个",
        "关",
        "于",
        "�",
        "�",
        "�",
        "类",
        "与",
        "�"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97,
        49838,
        20648,
        103,
        15120,
        5877,
        97,
        75863,
        81543,
        40474,
        17486,
        107,
        3922,
        16937,
        30624,
        37687,
        37046,
        11883,
        15120,
        28194,
        245,
        2118,
        70203,
        35287,
        9554,
        70203,
        4916,
        107,
        75320,
        37507,
        78935,
        67178,
        35287,
        19483,
        30356,
        35304,
        165,
        109,
        120,
        22238,
        58318,
        165
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "�",
            "token_id": 116,
            "logprob": -0.2148,
            "prob": 0.8047
          },
          {
            "token": "�",
            "token_id": 103,
            "logprob": -2.9688,
            "prob": 0.0515
          },
          {
            "token": "�",
            "token_id": 117,
            "logprob": -3.0938,
            "prob": 0.0454
          },
          {
            "token": "�",
            "token_id": 227,
            "logprob": -3.3438,
            "prob": 0.0354
          },
          {
            "token": "�",
            "token_id": 118,
            "logprob": -4.2812,
            "prob": 0.0139
          },
          {
            "token": "�",
            "token_id": 111,
            "logprob": -4.4062,
            "prob": 0.0123
          },
          {
            "token": "�",
            "token_id": 97,
            "logprob": -4.7812,
            "prob": 0.0084
          },
          {
            "token": "�",
            "token_id": 109,
            "logprob": -4.9688,
            "prob": 0.007
          },
          {
            "token": "�",
            "token_id": 98,
            "logprob": -5.3438,
            "prob": 0.0048
          },
          {
            "token": "�",
            "token_id": 110,
            "logprob": -5.5938,
            "prob": 0.0037
          }
        ]
      },
      "selected_token": {
        "token": "�",
        "token_id": 116,
        "selection_method": "sampling"
      }
    },
    {
      "step": 87,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤笑哪一古也没有情怯，不如说我用一套“算了的算术程序来构造了个关于鱼类与�",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�",
        "笑",
        "�",
        "�",
        "一",
        "�",
        "�",
        "也",
        "没有",
        "情",
        "�",
        "�",
        "，",
        "不",
        "如",
        "说",
        "我",
        "用",
        "一",
        "�",
        "�",
        "“",
        "算",
        "了",
        "的",
        "算",
        "�",
        "�",
        "程序",
        "来",
        "构",
        "造",
        "了",
        "个",
        "关",
        "于",
        "�",
        "�",
        "�",
        "类",
        "与",
        "�",
        "�"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97,
        49838,
        20648,
        103,
        15120,
        5877,
        97,
        75863,
        81543,
        40474,
        17486,
        107,
        3922,
        16937,
        30624,
        37687,
        37046,
        11883,
        15120,
        28194,
        245,
        2118,
        70203,
        35287,
        9554,
        70203,
        4916,
        107,
        75320,
        37507,
        78935,
        67178,
        35287,
        19483,
        30356,
        35304,
        165,
        109,
        120,
        22238,
        58318,
        165,
        116
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "�",
            "token_id": 253,
            "logprob": -0.0457,
            "prob": 0.957
          },
          {
            "token": "�",
            "token_id": 94,
            "logprob": -3.4219,
            "prob": 0.0327
          },
          {
            "token": "�",
            "token_id": 121,
            "logprob": -5.2812,
            "prob": 0.005
          },
          {
            "token": "�",
            "token_id": 255,
            "logprob": -5.2812,
            "prob": 0.005
          },
          {
            "token": "�",
            "token_id": 113,
            "logprob": -7.4688,
            "prob": 0.0006
          },
          {
            "token": "�",
            "token_id": 98,
            "logprob": -7.9688,
            "prob": 0.0003
          },
          {
            "token": "�",
            "token_id": 111,
            "logprob": -8.75,
            "prob": 0.0002
          },
          {
            "token": "�",
            "token_id": 123,
            "logprob": -9.3125,
            "prob": 0.0001
          },
          {
            "token": "�",
            "token_id": 254,
            "logprob": -9.3125,
            "prob": 0.0001
          },
          {
            "token": "�",
            "token_id": 96,
            "logprob": -9.5,
            "prob": 0.0001
          }
        ]
      },
      "selected_token": {
        "token": "�",
        "token_id": 96,
        "selection_method": "sampling"
      }
    },
    {
      "step": 88,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤笑哪一古也没有情怯，不如说我用一套“算了的算术程序来构造了个关于鱼类与鸣",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�",
        "笑",
        "�",
        "�",
        "一",
        "�",
        "�",
        "也",
        "没有",
        "情",
        "�",
        "�",
        "，",
        "不",
        "如",
        "说",
        "我",
        "用",
        "一",
        "�",
        "�",
        "“",
        "算",
        "了",
        "的",
        "算",
        "�",
        "�",
        "程序",
        "来",
        "构",
        "造",
        "了",
        "个",
        "关",
        "于",
        "�",
        "�",
        "�",
        "类",
        "与",
        "�",
        "�",
        "�"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97,
        49838,
        20648,
        103,
        15120,
        5877,
        97,
        75863,
        81543,
        40474,
        17486,
        107,
        3922,
        16937,
        30624,
        37687,
        37046,
        11883,
        15120,
        28194,
        245,
        2118,
        70203,
        35287,
        9554,
        70203,
        4916,
        107,
        75320,
        37507,
        78935,
        67178,
        35287,
        19483,
        30356,
        35304,
        165,
        109,
        120,
        22238,
        58318,
        165,
        116,
        96
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "人",
            "token_id": 17792,
            "logprob": -0.9531,
            "prob": 0.3848
          },
          {
            "token": "�",
            "token_id": 5877,
            "logprob": -2.5781,
            "prob": 0.0757
          },
          {
            "token": "�",
            "token_id": 17925,
            "logprob": -2.7031,
            "prob": 0.0669
          },
          {
            "token": "�",
            "token_id": 161,
            "logprob": -3.1406,
            "prob": 0.0432
          },
          {
            "token": "�",
            "token_id": 54656,
            "logprob": -4.0,
            "prob": 0.0181
          },
          {
            "token": "物",
            "token_id": 53953,
            "logprob": -4.0625,
            "prob": 0.017
          },
          {
            "token": "器",
            "token_id": 32648,
            "logprob": -4.0625,
            "prob": 0.017
          },
          {
            "token": "�",
            "token_id": 20119,
            "logprob": -4.125,
            "prob": 0.0159
          },
          {
            "token": "片",
            "token_id": 35818,
            "logprob": -4.125,
            "prob": 0.0159
          },
          {
            "token": "�",
            "token_id": 165,
            "logprob": -4.1875,
            "prob": 0.015
          }
        ]
      },
      "selected_token": {
        "token": "器",
        "token_id": 32648,
        "selection_method": "sampling"
      }
    },
    {
      "step": 89,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤笑哪一古也没有情怯，不如说我用一套“算了的算术程序来构造了个关于鱼类与鸣器",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�",
        "笑",
        "�",
        "�",
        "一",
        "�",
        "�",
        "也",
        "没有",
        "情",
        "�",
        "�",
        "，",
        "不",
        "如",
        "说",
        "我",
        "用",
        "一",
        "�",
        "�",
        "“",
        "算",
        "了",
        "的",
        "算",
        "�",
        "�",
        "程序",
        "来",
        "构",
        "造",
        "了",
        "个",
        "关",
        "于",
        "�",
        "�",
        "�",
        "类",
        "与",
        "�",
        "�",
        "�",
        "器"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97,
        49838,
        20648,
        103,
        15120,
        5877,
        97,
        75863,
        81543,
        40474,
        17486,
        107,
        3922,
        16937,
        30624,
        37687,
        37046,
        11883,
        15120,
        28194,
        245,
        2118,
        70203,
        35287,
        9554,
        70203,
        4916,
        107,
        75320,
        37507,
        78935,
        67178,
        35287,
        19483,
        30356,
        35304,
        165,
        109,
        120,
        22238,
        58318,
        165,
        116,
        96,
        32648
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "的",
            "token_id": 9554,
            "logprob": -0.0854,
            "prob": 0.918
          },
          {
            "token": "相",
            "token_id": 50021,
            "logprob": -4.4062,
            "prob": 0.0123
          },
          {
            "token": "（",
            "token_id": 10110,
            "logprob": -4.9062,
            "prob": 0.0074
          },
          {
            "token": "之",
            "token_id": 55030,
            "logprob": -5.2812,
            "prob": 0.0051
          },
          {
            "token": "音",
            "token_id": 79785,
            "logprob": -5.3438,
            "prob": 0.0048
          },
          {
            "token": "交",
            "token_id": 39209,
            "logprob": -5.5938,
            "prob": 0.0038
          },
          {
            "token": "�",
            "token_id": 78256,
            "logprob": -5.5938,
            "prob": 0.0038
          },
          {
            "token": "”的",
            "token_id": 99007,
            "logprob": -6.0312,
            "prob": 0.0024
          },
          {
            "token": "、",
            "token_id": 5486,
            "logprob": -6.2812,
            "prob": 0.0019
          },
          {
            "token": "发",
            "token_id": 29391,
            "logprob": -6.2812,
            "prob": 0.0019
          }
        ]
      },
      "selected_token": {
        "token": "发",
        "token_id": 29391,
        "selection_method": "sampling"
      }
    },
    {
      "step": 90,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤笑哪一古也没有情怯，不如说我用一套“算了的算术程序来构造了个关于鱼类与鸣器发",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�",
        "笑",
        "�",
        "�",
        "一",
        "�",
        "�",
        "也",
        "没有",
        "情",
        "�",
        "�",
        "，",
        "不",
        "如",
        "说",
        "我",
        "用",
        "一",
        "�",
        "�",
        "“",
        "算",
        "了",
        "的",
        "算",
        "�",
        "�",
        "程序",
        "来",
        "构",
        "造",
        "了",
        "个",
        "关",
        "于",
        "�",
        "�",
        "�",
        "类",
        "与",
        "�",
        "�",
        "�",
        "器",
        "发"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97,
        49838,
        20648,
        103,
        15120,
        5877,
        97,
        75863,
        81543,
        40474,
        17486,
        107,
        3922,
        16937,
        30624,
        37687,
        37046,
        11883,
        15120,
        28194,
        245,
        2118,
        70203,
        35287,
        9554,
        70203,
        4916,
        107,
        75320,
        37507,
        78935,
        67178,
        35287,
        19483,
        30356,
        35304,
        165,
        109,
        120,
        22238,
        58318,
        165,
        116,
        96,
        32648,
        29391
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "音",
            "token_id": 79785,
            "logprob": -0.4219,
            "prob": 0.6562
          },
          {
            "token": "声",
            "token_id": 71174,
            "logprob": -1.6719,
            "prob": 0.1875
          },
          {
            "token": "生",
            "token_id": 21990,
            "logprob": -2.4844,
            "prob": 0.0835
          },
          {
            "token": "出",
            "token_id": 20834,
            "logprob": -3.9844,
            "prob": 0.0186
          },
          {
            "token": "展",
            "token_id": 77413,
            "logprob": -4.4375,
            "prob": 0.012
          },
          {
            "token": "现",
            "token_id": 47551,
            "logprob": -5.1875,
            "prob": 0.0057
          },
          {
            "token": "言",
            "token_id": 78244,
            "logprob": -5.6875,
            "prob": 0.0034
          },
          {
            "token": "动",
            "token_id": 28833,
            "logprob": -6.0,
            "prob": 0.0025
          },
          {
            "token": "电",
            "token_id": 39312,
            "logprob": -6.0938,
            "prob": 0.0023
          },
          {
            "token": "�",
            "token_id": 165,
            "logprob": -6.2812,
            "prob": 0.0019
          }
        ]
      },
      "selected_token": {
        "token": "动",
        "token_id": 28833,
        "selection_method": "sampling"
      }
    },
    {
      "step": 91,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤笑哪一古也没有情怯，不如说我用一套“算了的算术程序来构造了个关于鱼类与鸣器发动",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�",
        "笑",
        "�",
        "�",
        "一",
        "�",
        "�",
        "也",
        "没有",
        "情",
        "�",
        "�",
        "，",
        "不",
        "如",
        "说",
        "我",
        "用",
        "一",
        "�",
        "�",
        "“",
        "算",
        "了",
        "的",
        "算",
        "�",
        "�",
        "程序",
        "来",
        "构",
        "造",
        "了",
        "个",
        "关",
        "于",
        "�",
        "�",
        "�",
        "类",
        "与",
        "�",
        "�",
        "�",
        "器",
        "发",
        "动"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97,
        49838,
        20648,
        103,
        15120,
        5877,
        97,
        75863,
        81543,
        40474,
        17486,
        107,
        3922,
        16937,
        30624,
        37687,
        37046,
        11883,
        15120,
        28194,
        245,
        2118,
        70203,
        35287,
        9554,
        70203,
        4916,
        107,
        75320,
        37507,
        78935,
        67178,
        35287,
        19483,
        30356,
        35304,
        165,
        109,
        120,
        22238,
        58318,
        165,
        116,
        96,
        32648,
        29391,
        28833
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "机",
            "token_id": 33748,
            "logprob": -0.3105,
            "prob": 0.7344
          },
          {
            "token": "的",
            "token_id": 9554,
            "logprob": -1.6875,
            "prob": 0.1855
          },
          {
            "token": "装",
            "token_id": 99741,
            "logprob": -3.8125,
            "prob": 0.0221
          },
          {
            "token": "器",
            "token_id": 32648,
            "logprob": -4.5,
            "prob": 0.0111
          },
          {
            "token": "部",
            "token_id": 34048,
            "logprob": -5.25,
            "prob": 0.0052
          },
          {
            "token": "时",
            "token_id": 13646,
            "logprob": -5.75,
            "prob": 0.0032
          },
          {
            "token": "人",
            "token_id": 17792,
            "logprob": -5.9375,
            "prob": 0.0026
          },
          {
            "token": "者",
            "token_id": 30046,
            "logprob": -6.0625,
            "prob": 0.0023
          },
          {
            "token": "物",
            "token_id": 53953,
            "logprob": -6.1875,
            "prob": 0.0021
          },
          {
            "token": "力",
            "token_id": 48634,
            "logprob": -6.25,
            "prob": 0.0019
          }
        ]
      },
      "selected_token": {
        "token": "的",
        "token_id": 9554,
        "selection_method": "sampling"
      }
    },
    {
      "step": 92,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤笑哪一古也没有情怯，不如说我用一套“算了的算术程序来构造了个关于鱼类与鸣器发动的",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�",
        "笑",
        "�",
        "�",
        "一",
        "�",
        "�",
        "也",
        "没有",
        "情",
        "�",
        "�",
        "，",
        "不",
        "如",
        "说",
        "我",
        "用",
        "一",
        "�",
        "�",
        "“",
        "算",
        "了",
        "的",
        "算",
        "�",
        "�",
        "程序",
        "来",
        "构",
        "造",
        "了",
        "个",
        "关",
        "于",
        "�",
        "�",
        "�",
        "类",
        "与",
        "�",
        "�",
        "�",
        "器",
        "发",
        "动",
        "的"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97,
        49838,
        20648,
        103,
        15120,
        5877,
        97,
        75863,
        81543,
        40474,
        17486,
        107,
        3922,
        16937,
        30624,
        37687,
        37046,
        11883,
        15120,
        28194,
        245,
        2118,
        70203,
        35287,
        9554,
        70203,
        4916,
        107,
        75320,
        37507,
        78935,
        67178,
        35287,
        19483,
        30356,
        35304,
        165,
        109,
        120,
        22238,
        58318,
        165,
        116,
        96,
        32648,
        29391,
        28833,
        9554
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "笑",
            "token_id": 49838,
            "logprob": -0.918,
            "prob": 0.3984
          },
          {
            "token": "�",
            "token_id": 7190,
            "logprob": -2.2344,
            "prob": 0.1074
          },
          {
            "token": "�",
            "token_id": 39013,
            "logprob": -3.5469,
            "prob": 0.0289
          },
          {
            "token": "反",
            "token_id": 95543,
            "logprob": -3.7969,
            "prob": 0.0225
          },
          {
            "token": "有",
            "token_id": 19361,
            "logprob": -3.8594,
            "prob": 0.0211
          },
          {
            "token": "简",
            "token_id": 99337,
            "logprob": -4.0938,
            "prob": 0.0165
          },
          {
            "token": "�",
            "token_id": 5877,
            "logprob": -4.0938,
            "prob": 0.0165
          },
          {
            "token": "开",
            "token_id": 30867,
            "logprob": -4.1562,
            "prob": 0.0155
          },
          {
            "token": "�",
            "token_id": 76698,
            "logprob": -4.2812,
            "prob": 0.0137
          },
          {
            "token": "�",
            "token_id": 162,
            "logprob": -4.3438,
            "prob": 0.0128
          }
        ]
      },
      "selected_token": {
        "token": "笑",
        "token_id": 49838,
        "selection_method": "sampling"
      }
    },
    {
      "step": 93,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤笑哪一古也没有情怯，不如说我用一套“算了的算术程序来构造了个关于鱼类与鸣器发动的笑",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�",
        "笑",
        "�",
        "�",
        "一",
        "�",
        "�",
        "也",
        "没有",
        "情",
        "�",
        "�",
        "，",
        "不",
        "如",
        "说",
        "我",
        "用",
        "一",
        "�",
        "�",
        "“",
        "算",
        "了",
        "的",
        "算",
        "�",
        "�",
        "程序",
        "来",
        "构",
        "造",
        "了",
        "个",
        "关",
        "于",
        "�",
        "�",
        "�",
        "类",
        "与",
        "�",
        "�",
        "�",
        "器",
        "发",
        "动",
        "的",
        "笑"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97,
        49838,
        20648,
        103,
        15120,
        5877,
        97,
        75863,
        81543,
        40474,
        17486,
        107,
        3922,
        16937,
        30624,
        37687,
        37046,
        11883,
        15120,
        28194,
        245,
        2118,
        70203,
        35287,
        9554,
        70203,
        4916,
        107,
        75320,
        37507,
        78935,
        67178,
        35287,
        19483,
        30356,
        35304,
        165,
        109,
        120,
        22238,
        58318,
        165,
        116,
        96,
        32648,
        29391,
        28833,
        9554,
        49838
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "话",
            "token_id": 58543,
            "logprob": -0.0091,
            "prob": 0.9922
          },
          {
            "token": "点",
            "token_id": 28542,
            "logprob": -5.8125,
            "prob": 0.003
          },
          {
            "token": "話",
            "token_id": 87177,
            "logprob": -7.0625,
            "prob": 0.0009
          },
          {
            "token": "�",
            "token_id": 39013,
            "logprob": -7.75,
            "prob": 0.0004
          },
          {
            "token": "机",
            "token_id": 33748,
            "logprob": -8.125,
            "prob": 0.0003
          },
          {
            "token": "笑",
            "token_id": 49838,
            "logprob": -8.1875,
            "prob": 0.0003
          },
          {
            "token": "语",
            "token_id": 73981,
            "logprob": -8.4375,
            "prob": 0.0002
          },
          {
            "token": "料",
            "token_id": 42506,
            "logprob": -8.6875,
            "prob": 0.0002
          },
          {
            "token": "�",
            "token_id": 15568,
            "logprob": -8.8125,
            "prob": 0.0001
          },
          {
            "token": "�",
            "token_id": 8239,
            "logprob": -8.875,
            "prob": 0.0001
          }
        ]
      },
      "selected_token": {
        "token": "话",
        "token_id": 58543,
        "selection_method": "sampling"
      }
    },
    {
      "step": 94,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤笑哪一古也没有情怯，不如说我用一套“算了的算术程序来构造了个关于鱼类与鸣器发动的笑话",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�",
        "笑",
        "�",
        "�",
        "一",
        "�",
        "�",
        "也",
        "没有",
        "情",
        "�",
        "�",
        "，",
        "不",
        "如",
        "说",
        "我",
        "用",
        "一",
        "�",
        "�",
        "“",
        "算",
        "了",
        "的",
        "算",
        "�",
        "�",
        "程序",
        "来",
        "构",
        "造",
        "了",
        "个",
        "关",
        "于",
        "�",
        "�",
        "�",
        "类",
        "与",
        "�",
        "�",
        "�",
        "器",
        "发",
        "动",
        "的",
        "笑",
        "话"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97,
        49838,
        20648,
        103,
        15120,
        5877,
        97,
        75863,
        81543,
        40474,
        17486,
        107,
        3922,
        16937,
        30624,
        37687,
        37046,
        11883,
        15120,
        28194,
        245,
        2118,
        70203,
        35287,
        9554,
        70203,
        4916,
        107,
        75320,
        37507,
        78935,
        67178,
        35287,
        19483,
        30356,
        35304,
        165,
        109,
        120,
        22238,
        58318,
        165,
        116,
        96,
        32648,
        29391,
        28833,
        9554,
        49838,
        58543
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "”，",
            "token_id": 34690,
            "logprob": -1.2656,
            "prob": 0.2832
          },
          {
            "token": "”",
            "token_id": 863,
            "logprob": -1.5156,
            "prob": 0.2197
          },
          {
            "token": "，",
            "token_id": 3922,
            "logprob": -1.7656,
            "prob": 0.1719
          },
          {
            "token": "”。\n\n",
            "token_id": 97432,
            "logprob": -2.2656,
            "prob": 0.104
          },
          {
            "token": "”。",
            "token_id": 56907,
            "logprob": -2.6406,
            "prob": 0.0713
          },
          {
            "token": "�",
            "token_id": 17857,
            "logprob": -3.3906,
            "prob": 0.0337
          },
          {
            "token": "。",
            "token_id": 1811,
            "logprob": -3.3906,
            "prob": 0.0337
          },
          {
            "token": "”\n\n",
            "token_id": 7663,
            "logprob": -4.375,
            "prob": 0.0124
          },
          {
            "token": "�",
            "token_id": 7305,
            "logprob": -4.6875,
            "prob": 0.0091
          },
          {
            "token": "�",
            "token_id": 161,
            "logprob": -5.125,
            "prob": 0.0059
          }
        ]
      },
      "selected_token": {
        "token": "”。",
        "token_id": 56907,
        "selection_method": "sampling"
      }
    },
    {
      "step": 95,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤笑哪一古也没有情怯，不如说我用一套“算了的算术程序来构造了个关于鱼类与鸣器发动的笑话”。",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�",
        "笑",
        "�",
        "�",
        "一",
        "�",
        "�",
        "也",
        "没有",
        "情",
        "�",
        "�",
        "，",
        "不",
        "如",
        "说",
        "我",
        "用",
        "一",
        "�",
        "�",
        "“",
        "算",
        "了",
        "的",
        "算",
        "�",
        "�",
        "程序",
        "来",
        "构",
        "造",
        "了",
        "个",
        "关",
        "于",
        "�",
        "�",
        "�",
        "类",
        "与",
        "�",
        "�",
        "�",
        "器",
        "发",
        "动",
        "的",
        "笑",
        "话",
        "”。"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97,
        49838,
        20648,
        103,
        15120,
        5877,
        97,
        75863,
        81543,
        40474,
        17486,
        107,
        3922,
        16937,
        30624,
        37687,
        37046,
        11883,
        15120,
        28194,
        245,
        2118,
        70203,
        35287,
        9554,
        70203,
        4916,
        107,
        75320,
        37507,
        78935,
        67178,
        35287,
        19483,
        30356,
        35304,
        165,
        109,
        120,
        22238,
        58318,
        165,
        116,
        96,
        32648,
        29391,
        28833,
        9554,
        49838,
        58543,
        56907
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "这",
            "token_id": 44388,
            "logprob": -0.9531,
            "prob": 0.3867
          },
          {
            "token": "用户",
            "token_id": 20600,
            "logprob": -3.1406,
            "prob": 0.0432
          },
          {
            "token": "不",
            "token_id": 16937,
            "logprob": -3.1406,
            "prob": 0.0432
          },
          {
            "token": "�",
            "token_id": 10414,
            "logprob": -3.2656,
            "prob": 0.0383
          },
          {
            "token": "�",
            "token_id": 161,
            "logprob": -3.3281,
            "prob": 0.0359
          },
          {
            "token": "因",
            "token_id": 63212,
            "logprob": -3.5781,
            "prob": 0.028
          },
          {
            "token": "对",
            "token_id": 33764,
            "logprob": -3.8281,
            "prob": 0.0217
          },
          {
            "token": "�",
            "token_id": 45932,
            "logprob": -3.8281,
            "prob": 0.0217
          },
          {
            "token": "也",
            "token_id": 75863,
            "logprob": -4.125,
            "prob": 0.016
          },
          {
            "token": "当",
            "token_id": 40265,
            "logprob": -4.1875,
            "prob": 0.015
          }
        ]
      },
      "selected_token": {
        "token": "也",
        "token_id": 75863,
        "selection_method": "sampling"
      }
    },
    {
      "step": 96,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤笑哪一古也没有情怯，不如说我用一套“算了的算术程序来构造了个关于鱼类与鸣器发动的笑话”。也",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�",
        "笑",
        "�",
        "�",
        "一",
        "�",
        "�",
        "也",
        "没有",
        "情",
        "�",
        "�",
        "，",
        "不",
        "如",
        "说",
        "我",
        "用",
        "一",
        "�",
        "�",
        "“",
        "算",
        "了",
        "的",
        "算",
        "�",
        "�",
        "程序",
        "来",
        "构",
        "造",
        "了",
        "个",
        "关",
        "于",
        "�",
        "�",
        "�",
        "类",
        "与",
        "�",
        "�",
        "�",
        "器",
        "发",
        "动",
        "的",
        "笑",
        "话",
        "”。",
        "也"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97,
        49838,
        20648,
        103,
        15120,
        5877,
        97,
        75863,
        81543,
        40474,
        17486,
        107,
        3922,
        16937,
        30624,
        37687,
        37046,
        11883,
        15120,
        28194,
        245,
        2118,
        70203,
        35287,
        9554,
        70203,
        4916,
        107,
        75320,
        37507,
        78935,
        67178,
        35287,
        19483,
        30356,
        35304,
        165,
        109,
        120,
        22238,
        58318,
        165,
        116,
        96,
        32648,
        29391,
        28833,
        9554,
        49838,
        58543,
        56907,
        75863
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "就",
            "token_id": 81258,
            "logprob": -0.4219,
            "prob": 0.6562
          },
          {
            "token": "�",
            "token_id": 10414,
            "logprob": -1.1719,
            "prob": 0.3105
          },
          {
            "token": "可以",
            "token_id": 74770,
            "logprob": -5.25,
            "prob": 0.0053
          },
          {
            "token": "不",
            "token_id": 16937,
            "logprob": -5.3125,
            "prob": 0.005
          },
          {
            "token": "算",
            "token_id": 70203,
            "logprob": -5.9375,
            "prob": 0.0027
          },
          {
            "token": "是",
            "token_id": 21043,
            "logprob": -5.9375,
            "prob": 0.0027
          },
          {
            "token": "可能",
            "token_id": 88367,
            "logprob": -6.25,
            "prob": 0.002
          },
          {
            "token": "可",
            "token_id": 31540,
            "logprob": -6.4375,
            "prob": 0.0016
          },
          {
            "token": "没",
            "token_id": 72027,
            "logprob": -6.625,
            "prob": 0.0014
          },
          {
            "token": "因",
            "token_id": 63212,
            "logprob": -6.75,
            "prob": 0.0012
          }
        ]
      },
      "selected_token": {
        "token": "就",
        "token_id": 81258,
        "selection_method": "sampling"
      }
    },
    {
      "step": 97,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤笑哪一古也没有情怯，不如说我用一套“算了的算术程序来构造了个关于鱼类与鸣器发动的笑话”。也就",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�",
        "笑",
        "�",
        "�",
        "一",
        "�",
        "�",
        "也",
        "没有",
        "情",
        "�",
        "�",
        "，",
        "不",
        "如",
        "说",
        "我",
        "用",
        "一",
        "�",
        "�",
        "“",
        "算",
        "了",
        "的",
        "算",
        "�",
        "�",
        "程序",
        "来",
        "构",
        "造",
        "了",
        "个",
        "关",
        "于",
        "�",
        "�",
        "�",
        "类",
        "与",
        "�",
        "�",
        "�",
        "器",
        "发",
        "动",
        "的",
        "笑",
        "话",
        "”。",
        "也",
        "就"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97,
        49838,
        20648,
        103,
        15120,
        5877,
        97,
        75863,
        81543,
        40474,
        17486,
        107,
        3922,
        16937,
        30624,
        37687,
        37046,
        11883,
        15120,
        28194,
        245,
        2118,
        70203,
        35287,
        9554,
        70203,
        4916,
        107,
        75320,
        37507,
        78935,
        67178,
        35287,
        19483,
        30356,
        35304,
        165,
        109,
        120,
        22238,
        58318,
        165,
        116,
        96,
        32648,
        29391,
        28833,
        9554,
        49838,
        58543,
        56907,
        75863,
        81258
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "是",
            "token_id": 21043,
            "logprob": -0.0015,
            "prob": 1.0
          },
          {
            "token": "说",
            "token_id": 37687,
            "logprob": -7.875,
            "prob": 0.0004
          },
          {
            "token": "算",
            "token_id": 70203,
            "logprob": -8.375,
            "prob": 0.0002
          },
          {
            "token": "这",
            "token_id": 44388,
            "logprob": -9.0,
            "prob": 0.0001
          },
          {
            "token": "像",
            "token_id": 66201,
            "logprob": -9.3125,
            "prob": 0.0001
          },
          {
            "token": "比",
            "token_id": 57106,
            "logprob": -9.5,
            "prob": 0.0001
          },
          {
            "token": "�",
            "token_id": 10414,
            "logprob": -10.0625,
            "prob": 0.0
          },
          {
            "token": "不",
            "token_id": 16937,
            "logprob": -10.4375,
            "prob": 0.0
          },
          {
            "token": "就",
            "token_id": 81258,
            "logprob": -10.5625,
            "prob": 0.0
          },
          {
            "token": "在",
            "token_id": 19000,
            "logprob": -10.625,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "是",
        "token_id": 21043,
        "selection_method": "sampling"
      }
    },
    {
      "step": 98,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤笑哪一古也没有情怯，不如说我用一套“算了的算术程序来构造了个关于鱼类与鸣器发动的笑话”。也就是",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�",
        "笑",
        "�",
        "�",
        "一",
        "�",
        "�",
        "也",
        "没有",
        "情",
        "�",
        "�",
        "，",
        "不",
        "如",
        "说",
        "我",
        "用",
        "一",
        "�",
        "�",
        "“",
        "算",
        "了",
        "的",
        "算",
        "�",
        "�",
        "程序",
        "来",
        "构",
        "造",
        "了",
        "个",
        "关",
        "于",
        "�",
        "�",
        "�",
        "类",
        "与",
        "�",
        "�",
        "�",
        "器",
        "发",
        "动",
        "的",
        "笑",
        "话",
        "”。",
        "也",
        "就",
        "是"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97,
        49838,
        20648,
        103,
        15120,
        5877,
        97,
        75863,
        81543,
        40474,
        17486,
        107,
        3922,
        16937,
        30624,
        37687,
        37046,
        11883,
        15120,
        28194,
        245,
        2118,
        70203,
        35287,
        9554,
        70203,
        4916,
        107,
        75320,
        37507,
        78935,
        67178,
        35287,
        19483,
        30356,
        35304,
        165,
        109,
        120,
        22238,
        58318,
        165,
        116,
        96,
        32648,
        29391,
        28833,
        9554,
        49838,
        58543,
        56907,
        75863,
        81258,
        21043
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "说",
            "token_id": 37687,
            "logprob": -0.2002,
            "prob": 0.8203
          },
          {
            "token": "用",
            "token_id": 11883,
            "logprob": -3.8281,
            "prob": 0.0219
          },
          {
            "token": "，",
            "token_id": 3922,
            "logprob": -4.0,
            "prob": 0.0181
          },
          {
            "token": "先",
            "token_id": 61826,
            "logprob": -4.6875,
            "prob": 0.0091
          },
          {
            "token": "这",
            "token_id": 44388,
            "logprob": -4.75,
            "prob": 0.0085
          },
          {
            "token": "常",
            "token_id": 40053,
            "logprob": -5.125,
            "prob": 0.0059
          },
          {
            "token": "在",
            "token_id": 19000,
            "logprob": -5.1875,
            "prob": 0.0055
          },
          {
            "token": "�",
            "token_id": 10414,
            "logprob": -5.25,
            "prob": 0.0052
          },
          {
            "token": "：",
            "token_id": 5232,
            "logprob": -5.3125,
            "prob": 0.0049
          },
          {
            "token": "有",
            "token_id": 19361,
            "logprob": -5.75,
            "prob": 0.0031
          }
        ]
      },
      "selected_token": {
        "token": "这",
        "token_id": 44388,
        "selection_method": "sampling"
      }
    },
    {
      "step": 99,
      "input_text": "给我讲个笑话<|im_end|>\n<|im_start|>assistant\n<think>嗬，在我作为有理 AI，虽然没有真实人性之情或者情绪经常变得生生逻辑、有幽幽的嗤笑哪一古也没有情怯，不如说我用一套“算了的算术程序来构造了个关于鱼类与鸣器发动的笑话”。也就是这",
      "tokens": [
        "给",
        "我",
        "�",
        "�",
        "个",
        "笑",
        "话",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "�",
        "�",
        "�",
        "，在",
        "我",
        "作",
        "为",
        "有",
        "理",
        "ĠAI",
        "，",
        "�",
        "�",
        "然",
        "没有",
        "真",
        "实",
        "人",
        "性",
        "之",
        "情",
        "或",
        "者",
        "情",
        "�",
        "�",
        "经",
        "常",
        "变",
        "得",
        "生",
        "生",
        "�",
        "�",
        "辑",
        "、",
        "有",
        "�",
        "�",
        "�",
        "�",
        "的",
        "�",
        "�",
        "�",
        "笑",
        "�",
        "�",
        "一",
        "�",
        "�",
        "也",
        "没有",
        "情",
        "�",
        "�",
        "，",
        "不",
        "如",
        "说",
        "我",
        "用",
        "一",
        "�",
        "�",
        "“",
        "算",
        "了",
        "的",
        "算",
        "�",
        "�",
        "程序",
        "来",
        "构",
        "造",
        "了",
        "个",
        "关",
        "于",
        "�",
        "�",
        "�",
        "类",
        "与",
        "�",
        "�",
        "�",
        "器",
        "发",
        "动",
        "的",
        "笑",
        "话",
        "”。",
        "也",
        "就",
        "是",
        "这"
      ],
      "token_ids": [
        90112,
        37046,
        10414,
        110,
        19483,
        49838,
        58543,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        161,
        245,
        105,
        97150,
        37046,
        19967,
        18184,
        19361,
        22649,
        15592,
        3922,
        84264,
        121,
        61994,
        81543,
        89151,
        41073,
        17792,
        34171,
        55030,
        40474,
        58291,
        30046,
        40474,
        12774,
        103,
        54493,
        40053,
        75140,
        50928,
        21990,
        21990,
        11589,
        119,
        48039,
        5486,
        19361,
        7190,
        121,
        7190,
        121,
        9554,
        161,
        245,
        97,
        49838,
        20648,
        103,
        15120,
        5877,
        97,
        75863,
        81543,
        40474,
        17486,
        107,
        3922,
        16937,
        30624,
        37687,
        37046,
        11883,
        15120,
        28194,
        245,
        2118,
        70203,
        35287,
        9554,
        70203,
        4916,
        107,
        75320,
        37507,
        78935,
        67178,
        35287,
        19483,
        30356,
        35304,
        165,
        109,
        120,
        22238,
        58318,
        165,
        116,
        96,
        32648,
        29391,
        28833,
        9554,
        49838,
        58543,
        56907,
        75863,
        81258,
        21043,
        44388
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "样",
            "token_id": 91985,
            "logprob": -0.9375,
            "prob": 0.3926
          },
          {
            "token": "个",
            "token_id": 19483,
            "logprob": -0.9375,
            "prob": 0.3926
          },
          {
            "token": "种",
            "token_id": 87502,
            "logprob": -2.0625,
            "prob": 0.127
          },
          {
            "token": "么",
            "token_id": 82696,
            "logprob": -3.1875,
            "prob": 0.0413
          },
          {
            "token": "里",
            "token_id": 70349,
            "logprob": -4.875,
            "prob": 0.0077
          },
          {
            "token": "类",
            "token_id": 22238,
            "logprob": -5.6875,
            "prob": 0.0034
          },
          {
            "token": "些",
            "token_id": 98184,
            "logprob": -6.125,
            "prob": 0.0022
          },
          {
            "token": "�",
            "token_id": 165,
            "logprob": -6.4375,
            "prob": 0.0016
          },
          {
            "token": "，",
            "token_id": 3922,
            "logprob": -6.5625,
            "prob": 0.0014
          },
          {
            "token": "�",
            "token_id": 5877,
            "logprob": -6.6875,
            "prob": 0.0013
          }
        ]
      },
      "selected_token": {
        "token": "样",
        "token_id": 91985,
        "selection_method": "sampling"
      }
    }
  ]
}