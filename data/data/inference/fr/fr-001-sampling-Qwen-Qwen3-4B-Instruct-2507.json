{
  "id": "generated_20251203_120735",
  "prompt": "Qui es-tu?",
  "language": "fr",
  "temperature": 1.0,
  "top_k": 10,
  "model_info": {
    "name": "Qwen/Qwen3-4B-Instruct-2507",
    "num_layers": 36,
    "hidden_size": 2560,
    "num_attention_heads": 32,
    "vocab_size": 151936
  },
  "generation_steps": [
    {
      "step": 0,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Je",
            "token_id": 29754,
            "logprob": -0.0703,
            "prob": 0.9336
          },
          {
            "token": "Bonjour",
            "token_id": 81581,
            "logprob": -2.7031,
            "prob": 0.0674
          },
          {
            "token": "Sal",
            "token_id": 17245,
            "logprob": -8.0625,
            "prob": 0.0003
          },
          {
            "token": "J",
            "token_id": 41,
            "logprob": -10.6875,
            "prob": 0.0
          },
          {
            "token": "Hello",
            "token_id": 9707,
            "logprob": -10.8125,
            "prob": 0.0
          },
          {
            "token": "B",
            "token_id": 33,
            "logprob": -11.1875,
            "prob": 0.0
          },
          {
            "token": "je",
            "token_id": 3756,
            "logprob": -11.4375,
            "prob": 0.0
          },
          {
            "token": "Hola",
            "token_id": 68012,
            "logprob": -11.5625,
            "prob": 0.0
          },
          {
            "token": "Bien",
            "token_id": 81506,
            "logprob": -11.6875,
            "prob": 0.0
          },
          {
            "token": "Bon",
            "token_id": 46596,
            "logprob": -11.9375,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Je",
        "token_id": 29754,
        "selection_method": "sampling"
      }
    },
    {
      "step": 1,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġsuis",
            "token_id": 35631,
            "logprob": -0.2256,
            "prob": 0.7969
          },
          {
            "token": "Ġm",
            "token_id": 296,
            "logprob": -1.6016,
            "prob": 0.2021
          },
          {
            "token": "Ġme",
            "token_id": 752,
            "logprob": -9.75,
            "prob": 0.0001
          },
          {
            "token": "Ġvous",
            "token_id": 9012,
            "logprob": -10.75,
            "prob": 0.0
          },
          {
            "token": "Ġvi",
            "token_id": 3275,
            "logprob": -12.125,
            "prob": 0.0
          },
          {
            "token": "Ġfais",
            "token_id": 65417,
            "logprob": -12.25,
            "prob": 0.0
          },
          {
            "token": "Ġne",
            "token_id": 834,
            "logprob": -12.375,
            "prob": 0.0
          },
          {
            "token": "Ġdois",
            "token_id": 50341,
            "logprob": -12.5,
            "prob": 0.0
          },
          {
            "token": "Ġsommes",
            "token_id": 73433,
            "logprob": -12.75,
            "prob": 0.0
          },
          {
            "token": "Ġvais",
            "token_id": 90407,
            "logprob": -12.8125,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġsuis",
        "token_id": 35631,
        "selection_method": "sampling"
      }
    },
    {
      "step": 2,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "ĠQ",
            "token_id": 1207,
            "logprob": -0.0055,
            "prob": 0.9961
          },
          {
            "token": "Ġun",
            "token_id": 650,
            "logprob": -5.25,
            "prob": 0.0052
          },
          {
            "token": "Q",
            "token_id": 48,
            "logprob": -9.25,
            "prob": 0.0001
          },
          {
            "token": "ĠTong",
            "token_id": 50391,
            "logprob": -10.125,
            "prob": 0.0
          },
          {
            "token": "Ġ**",
            "token_id": 3070,
            "logprob": -10.125,
            "prob": 0.0
          },
          {
            "token": "Ġune",
            "token_id": 6185,
            "logprob": -10.25,
            "prob": 0.0
          },
          {
            "token": "ĠQin",
            "token_id": 73351,
            "logprob": -11.875,
            "prob": 0.0
          },
          {
            "token": "ĠQing",
            "token_id": 61912,
            "logprob": -12.125,
            "prob": 0.0
          },
          {
            "token": "ĠChat",
            "token_id": 12853,
            "logprob": -12.25,
            "prob": 0.0
          },
          {
            "token": "Ġtout",
            "token_id": 16559,
            "logprob": -12.8125,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "ĠQ",
        "token_id": 1207,
        "selection_method": "sampling"
      }
    },
    {
      "step": 3,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Q",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "wen",
            "token_id": 16948,
            "logprob": -0.0,
            "prob": 1.0
          },
          {
            "token": "w",
            "token_id": 86,
            "logprob": -12.25,
            "prob": 0.0
          },
          {
            "token": "ween",
            "token_id": 1780,
            "logprob": -12.375,
            "prob": 0.0
          },
          {
            "token": "ian",
            "token_id": 1103,
            "logprob": -13.75,
            "prob": 0.0
          },
          {
            "token": "wan",
            "token_id": 16556,
            "logprob": -13.875,
            "prob": 0.0
          },
          {
            "token": "W",
            "token_id": 54,
            "logprob": -14.8125,
            "prob": 0.0
          },
          {
            "token": "&A",
            "token_id": 35021,
            "logprob": -15.875,
            "prob": 0.0
          },
          {
            "token": "im",
            "token_id": 318,
            "logprob": -16.875,
            "prob": 0.0
          },
          {
            "token": "wn",
            "token_id": 1522,
            "logprob": -17.375,
            "prob": 0.0
          },
          {
            "token": "we",
            "token_id": 896,
            "logprob": -17.5,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "wen",
        "token_id": 16948,
        "selection_method": "sampling"
      }
    },
    {
      "step": 4,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": ",",
            "token_id": 11,
            "logprob": -0.0,
            "prob": 1.0
          },
          {
            "token": "Ġ(",
            "token_id": 320,
            "logprob": -13.875,
            "prob": 0.0
          },
          {
            "token": "Ġ,",
            "token_id": 1154,
            "logprob": -15.0,
            "prob": 0.0
          },
          {
            "token": ".",
            "token_id": 13,
            "logprob": -17.125,
            "prob": 0.0
          },
          {
            "token": "，",
            "token_id": 3837,
            "logprob": -19.0,
            "prob": 0.0
          },
          {
            "token": "Ġou",
            "token_id": 5908,
            "logprob": -19.25,
            "prob": 0.0
          },
          {
            "token": "Ġdévelopp",
            "token_id": 67766,
            "logprob": -19.5,
            "prob": 0.0
          },
          {
            "token": "Ġet",
            "token_id": 1842,
            "logprob": -19.75,
            "prob": 0.0
          },
          {
            "token": "Ġfait",
            "token_id": 19694,
            "logprob": -19.875,
            "prob": 0.0
          },
          {
            "token": "Ġ",
            "token_id": 220,
            "logprob": -20.125,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": ",",
        "token_id": 11,
        "selection_method": "sampling"
      }
    },
    {
      "step": 5,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen,",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ","
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġun",
            "token_id": 650,
            "logprob": -0.0007,
            "prob": 1.0
          },
          {
            "token": "Ġle",
            "token_id": 512,
            "logprob": -7.375,
            "prob": 0.0006
          },
          {
            "token": "Ġune",
            "token_id": 6185,
            "logprob": -9.625,
            "prob": 0.0001
          },
          {
            "token": "un",
            "token_id": 359,
            "logprob": -14.625,
            "prob": 0.0
          },
          {
            "token": "Ġl",
            "token_id": 326,
            "logprob": -15.25,
            "prob": 0.0
          },
          {
            "token": "\tun",
            "token_id": 20479,
            "logprob": -15.375,
            "prob": 0.0
          },
          {
            "token": "Ġmodèle",
            "token_id": 82497,
            "logprob": -15.5,
            "prob": 0.0
          },
          {
            "token": ".un",
            "token_id": 6307,
            "logprob": -16.625,
            "prob": 0.0
          },
          {
            "token": "Ġla",
            "token_id": 1187,
            "logprob": -16.75,
            "prob": 0.0
          },
          {
            "token": "Ġtout",
            "token_id": 16559,
            "logprob": -17.25,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġun",
        "token_id": 650,
        "selection_method": "sampling"
      }
    },
    {
      "step": 6,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġmodèle",
            "token_id": 82497,
            "logprob": -0.0713,
            "prob": 0.9297
          },
          {
            "token": "Ġgrand",
            "token_id": 6662,
            "logprob": -2.7031,
            "prob": 0.0674
          },
          {
            "token": "Ġlarge",
            "token_id": 3460,
            "logprob": -7.8125,
            "prob": 0.0004
          },
          {
            "token": "Ġimmense",
            "token_id": 37783,
            "logprob": -8.3125,
            "prob": 0.0002
          },
          {
            "token": "Ġmod",
            "token_id": 1463,
            "logprob": -8.9375,
            "prob": 0.0001
          },
          {
            "token": "Ġgrands",
            "token_id": 93427,
            "logprob": -9.1875,
            "prob": 0.0001
          },
          {
            "token": "Ġgros",
            "token_id": 24490,
            "logprob": -9.8125,
            "prob": 0.0001
          },
          {
            "token": "Ġcolossal",
            "token_id": 96837,
            "logprob": -9.875,
            "prob": 0.0001
          },
          {
            "token": "Ġgrande",
            "token_id": 24604,
            "logprob": -10.375,
            "prob": 0.0
          },
          {
            "token": "Ġmodel",
            "token_id": 1614,
            "logprob": -10.4375,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġmodèle",
        "token_id": 82497,
        "selection_method": "sampling"
      }
    },
    {
      "step": 7,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġde",
            "token_id": 409,
            "logprob": -0.0018,
            "prob": 1.0
          },
          {
            "token": "Ġlingu",
            "token_id": 38503,
            "logprob": -6.75,
            "prob": 0.0012
          },
          {
            "token": "Ġà",
            "token_id": 3784,
            "logprob": -7.75,
            "prob": 0.0004
          },
          {
            "token": "Ġd",
            "token_id": 294,
            "logprob": -9.125,
            "prob": 0.0001
          },
          {
            "token": "Ġlang",
            "token_id": 8688,
            "logprob": -9.875,
            "prob": 0.0001
          },
          {
            "token": "Ġlanguage",
            "token_id": 4128,
            "logprob": -11.625,
            "prob": 0.0
          },
          {
            "token": "Ġpré",
            "token_id": 26293,
            "logprob": -11.625,
            "prob": 0.0
          },
          {
            "token": "ĠLang",
            "token_id": 22463,
            "logprob": -13.75,
            "prob": 0.0
          },
          {
            "token": "Ġdé",
            "token_id": 7439,
            "logprob": -13.8125,
            "prob": 0.0
          },
          {
            "token": "语言",
            "token_id": 102064,
            "logprob": -13.8125,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġde",
        "token_id": 409,
        "selection_method": "sampling"
      }
    },
    {
      "step": 8,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġlang",
            "token_id": 8688,
            "logprob": -0.009,
            "prob": 0.9922
          },
          {
            "token": "Ġlangue",
            "token_id": 95182,
            "logprob": -5.625,
            "prob": 0.0036
          },
          {
            "token": "Ġlanguage",
            "token_id": 4128,
            "logprob": -5.625,
            "prob": 0.0036
          },
          {
            "token": "Ġlingu",
            "token_id": 38503,
            "logprob": -7.375,
            "prob": 0.0006
          },
          {
            "token": "Ġgéné",
            "token_id": 45580,
            "logprob": -7.75,
            "prob": 0.0004
          },
          {
            "token": "语言",
            "token_id": 102064,
            "logprob": -8.125,
            "prob": 0.0003
          },
          {
            "token": "Ġgrande",
            "token_id": 24604,
            "logprob": -9.0,
            "prob": 0.0001
          },
          {
            "token": "Ġgrandes",
            "token_id": 37446,
            "logprob": -9.5,
            "prob": 0.0001
          },
          {
            "token": "-lang",
            "token_id": 75460,
            "logprob": -10.375,
            "prob": 0.0
          },
          {
            "token": "Ġtraitement",
            "token_id": 88614,
            "logprob": -10.375,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġlang",
        "token_id": 8688,
        "selection_method": "sampling"
      }
    },
    {
      "step": 9,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de lang",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "age",
            "token_id": 424,
            "logprob": -0.0001,
            "prob": 1.0
          },
          {
            "token": "ages",
            "token_id": 1134,
            "logprob": -10.25,
            "prob": 0.0
          },
          {
            "token": "AGE",
            "token_id": 3585,
            "logprob": -10.875,
            "prob": 0.0
          },
          {
            "token": "ues",
            "token_id": 1137,
            "logprob": -12.125,
            "prob": 0.0
          },
          {
            "token": "aged",
            "token_id": 3279,
            "logprob": -17.0,
            "prob": 0.0
          },
          {
            "token": "ag",
            "token_id": 351,
            "logprob": -17.625,
            "prob": 0.0
          },
          {
            "token": "Ġage",
            "token_id": 4231,
            "logprob": -17.625,
            "prob": 0.0
          },
          {
            "token": "uelle",
            "token_id": 29937,
            "logprob": -18.0,
            "prob": 0.0
          },
          {
            "token": "agen",
            "token_id": 8535,
            "logprob": -18.0,
            "prob": 0.0
          },
          {
            "token": "ue",
            "token_id": 361,
            "logprob": -18.125,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "age",
        "token_id": 424,
        "selection_method": "sampling"
      }
    },
    {
      "step": 10,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġà",
            "token_id": 3784,
            "logprob": -0.0046,
            "prob": 0.9961
          },
          {
            "token": "Ġde",
            "token_id": 409,
            "logprob": -5.875,
            "prob": 0.0028
          },
          {
            "token": "Ġd",
            "token_id": 294,
            "logprob": -8.1875,
            "prob": 0.0003
          },
          {
            "token": "Ġlarge",
            "token_id": 3460,
            "logprob": -8.5625,
            "prob": 0.0002
          },
          {
            "token": "Ġgé",
            "token_id": 73572,
            "logprob": -8.8125,
            "prob": 0.0001
          },
          {
            "token": "Ġlarg",
            "token_id": 4053,
            "logprob": -8.875,
            "prob": 0.0001
          },
          {
            "token": "Ġcomport",
            "token_id": 51862,
            "logprob": -9.125,
            "prob": 0.0001
          },
          {
            "token": "Ġpar",
            "token_id": 1346,
            "logprob": -9.4375,
            "prob": 0.0001
          },
          {
            "token": "Ġé",
            "token_id": 3958,
            "logprob": -9.4375,
            "prob": 0.0001
          },
          {
            "token": "Ġgrand",
            "token_id": 6662,
            "logprob": -9.75,
            "prob": 0.0001
          }
        ]
      },
      "selected_token": {
        "token": "Ġà",
        "token_id": 3784,
        "selection_method": "sampling"
      }
    },
    {
      "step": 11,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġtrès",
            "token_id": 24901,
            "logprob": -0.0081,
            "prob": 0.9922
          },
          {
            "token": "Ġgrande",
            "token_id": 24604,
            "logprob": -4.875,
            "prob": 0.0076
          },
          {
            "token": "Ġvery",
            "token_id": 1602,
            "logprob": -8.375,
            "prob": 0.0002
          },
          {
            "token": "Ġgrand",
            "token_id": 6662,
            "logprob": -9.5,
            "prob": 0.0001
          },
          {
            "token": "Ġfort",
            "token_id": 11845,
            "logprob": -10.25,
            "prob": 0.0
          },
          {
            "token": "Ġgrandes",
            "token_id": 37446,
            "logprob": -10.5,
            "prob": 0.0
          },
          {
            "token": "Ġgrands",
            "token_id": 93427,
            "logprob": -10.625,
            "prob": 0.0
          },
          {
            "token": "Ġgros",
            "token_id": 24490,
            "logprob": -11.25,
            "prob": 0.0
          },
          {
            "token": "很",
            "token_id": 99165,
            "logprob": -12.5,
            "prob": 0.0
          },
          {
            "token": "很大",
            "token_id": 101235,
            "logprob": -12.625,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġtrès",
        "token_id": 24901,
        "selection_method": "sampling"
      }
    },
    {
      "step": 12,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġgrande",
            "token_id": 24604,
            "logprob": -0.0027,
            "prob": 0.9961
          },
          {
            "token": "Ġgrandes",
            "token_id": 37446,
            "logprob": -6.875,
            "prob": 0.001
          },
          {
            "token": "Ġgrand",
            "token_id": 6662,
            "logprob": -6.875,
            "prob": 0.001
          },
          {
            "token": "Ġgrands",
            "token_id": 93427,
            "logprob": -7.5,
            "prob": 0.0006
          },
          {
            "token": "Ġhaute",
            "token_id": 79998,
            "logprob": -10.5,
            "prob": 0.0
          },
          {
            "token": "ĠGrande",
            "token_id": 36523,
            "logprob": -10.75,
            "prob": 0.0
          },
          {
            "token": "Ġgros",
            "token_id": 24490,
            "logprob": -11.25,
            "prob": 0.0
          },
          {
            "token": "Ġlarge",
            "token_id": 3460,
            "logprob": -11.25,
            "prob": 0.0
          },
          {
            "token": "Ġhaut",
            "token_id": 61221,
            "logprob": -13.25,
            "prob": 0.0
          },
          {
            "token": "Ġforte",
            "token_id": 63958,
            "logprob": -13.25,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġgrande",
        "token_id": 24604,
        "selection_method": "sampling"
      }
    },
    {
      "step": 13,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġé",
            "token_id": 3958,
            "logprob": -0.0022,
            "prob": 0.9961
          },
          {
            "token": "Ġcapacité",
            "token_id": 139536,
            "logprob": -7.125,
            "prob": 0.0008
          },
          {
            "token": "Ġdimension",
            "token_id": 12871,
            "logprob": -7.125,
            "prob": 0.0008
          },
          {
            "token": "Ġtaille",
            "token_id": 61727,
            "logprob": -8.5,
            "prob": 0.0002
          },
          {
            "token": "Ġample",
            "token_id": 41753,
            "logprob": -9.625,
            "prob": 0.0001
          },
          {
            "token": "Ġscale",
            "token_id": 5452,
            "logprob": -9.75,
            "prob": 0.0001
          },
          {
            "token": "Ġport",
            "token_id": 2635,
            "logprob": -10.0,
            "prob": 0.0
          },
          {
            "token": "Ġen",
            "token_id": 662,
            "logprob": -10.8125,
            "prob": 0.0
          },
          {
            "token": "Ġét",
            "token_id": 13916,
            "logprob": -11.125,
            "prob": 0.0
          },
          {
            "token": "Ġextension",
            "token_id": 8894,
            "logprob": -11.3125,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġé",
        "token_id": 3958,
        "selection_method": "sampling"
      }
    },
    {
      "step": 14,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande é",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "ch",
            "token_id": 331,
            "logprob": -0.0002,
            "prob": 1.0
          },
          {
            "token": "ché",
            "token_id": 74017,
            "logprob": -8.875,
            "prob": 0.0001
          },
          {
            "token": "cha",
            "token_id": 6447,
            "logprob": -10.5,
            "prob": 0.0
          },
          {
            "token": "pu",
            "token_id": 5584,
            "logprob": -12.75,
            "prob": 0.0
          },
          {
            "token": "vent",
            "token_id": 684,
            "logprob": -12.75,
            "prob": 0.0
          },
          {
            "token": "to",
            "token_id": 983,
            "logprob": -12.875,
            "prob": 0.0
          },
          {
            "token": "chant",
            "token_id": 11681,
            "logprob": -12.875,
            "prob": 0.0
          },
          {
            "token": "quipe",
            "token_id": 60573,
            "logprob": -13.0,
            "prob": 0.0
          },
          {
            "token": "lastic",
            "token_id": 51179,
            "logprob": -13.375,
            "prob": 0.0
          },
          {
            "token": "chine",
            "token_id": 87895,
            "logprob": -13.5,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "ch",
        "token_id": 331,
        "selection_method": "sampling"
      }
    },
    {
      "step": 15,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande éch",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "elle",
            "token_id": 6712,
            "logprob": -0.0,
            "prob": 1.0
          },
          {
            "token": "elles",
            "token_id": 36807,
            "logprob": -12.75,
            "prob": 0.0
          },
          {
            "token": "elon",
            "token_id": 64367,
            "logprob": -13.125,
            "prob": 0.0
          },
          {
            "token": "el",
            "token_id": 301,
            "logprob": -15.1875,
            "prob": 0.0
          },
          {
            "token": "ance",
            "token_id": 681,
            "logprob": -15.625,
            "prob": 0.0
          },
          {
            "token": "ée",
            "token_id": 7888,
            "logprob": -16.875,
            "prob": 0.0
          },
          {
            "token": "app",
            "token_id": 676,
            "logprob": -17.625,
            "prob": 0.0
          },
          {
            "token": "op",
            "token_id": 453,
            "logprob": -17.75,
            "prob": 0.0
          },
          {
            "token": "Ġelle",
            "token_id": 26451,
            "logprob": -17.875,
            "prob": 0.0
          },
          {
            "token": "ograph",
            "token_id": 3178,
            "logprob": -18.0,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "elle",
        "token_id": 6712,
        "selection_method": "sampling"
      }
    },
    {
      "step": 16,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġdévelopp",
            "token_id": 67766,
            "logprob": -0.001,
            "prob": 1.0
          },
          {
            "token": "Ġdé",
            "token_id": 7439,
            "logprob": -7.625,
            "prob": 0.0005
          },
          {
            "token": "Ġcon",
            "token_id": 390,
            "logprob": -9.25,
            "prob": 0.0001
          },
          {
            "token": "Ġdévelop",
            "token_id": 51795,
            "logprob": -9.5,
            "prob": 0.0001
          },
          {
            "token": "Ġdevelop",
            "token_id": 2225,
            "logprob": -10.0,
            "prob": 0.0
          },
          {
            "token": "Ġet",
            "token_id": 1842,
            "logprob": -10.0,
            "prob": 0.0
          },
          {
            "token": "Ġdéveloppe",
            "token_id": 138681,
            "logprob": -10.375,
            "prob": 0.0
          },
          {
            "token": "Ġcréé",
            "token_id": 140613,
            "logprob": -10.75,
            "prob": 0.0
          },
          {
            "token": "ĠDé",
            "token_id": 49401,
            "logprob": -10.875,
            "prob": 0.0
          },
          {
            "token": "Ġdevel",
            "token_id": 89770,
            "logprob": -10.875,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġdévelopp",
        "token_id": 67766,
        "selection_method": "sampling"
      }
    },
    {
      "step": 17,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développ",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "é",
            "token_id": 963,
            "logprob": -0.0,
            "prob": 1.0
          },
          {
            "token": "ée",
            "token_id": 7888,
            "logprob": -16.375,
            "prob": 0.0
          },
          {
            "token": "és",
            "token_id": 5397,
            "logprob": -18.75,
            "prob": 0.0
          },
          {
            "token": "É",
            "token_id": 26789,
            "logprob": -23.0,
            "prob": 0.0
          },
          {
            "token": "né",
            "token_id": 51135,
            "logprob": -24.5,
            "prob": 0.0
          },
          {
            "token": "Ġé",
            "token_id": 3958,
            "logprob": -24.625,
            "prob": 0.0
          },
          {
            "token": "è",
            "token_id": 4458,
            "logprob": -24.75,
            "prob": 0.0
          },
          {
            "token": "éd",
            "token_id": 15083,
            "logprob": -25.0,
            "prob": 0.0
          },
          {
            "token": "ées",
            "token_id": 13700,
            "logprob": -25.125,
            "prob": 0.0
          },
          {
            "token": "ém",
            "token_id": 16647,
            "logprob": -25.5,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "é",
        "token_id": 963,
        "selection_method": "sampling"
      }
    },
    {
      "step": 18,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġpar",
            "token_id": 1346,
            "logprob": -0.1133,
            "prob": 0.8945
          },
          {
            "token": "Ġind",
            "token_id": 1257,
            "logprob": -2.2344,
            "prob": 0.1064
          },
          {
            "token": "Ġindepend",
            "token_id": 7011,
            "logprob": -8.875,
            "prob": 0.0001
          },
          {
            "token": "Ġaut",
            "token_id": 3078,
            "logprob": -10.75,
            "prob": 0.0
          },
          {
            "token": "Ġautonom",
            "token_id": 94003,
            "logprob": -10.875,
            "prob": 0.0
          },
          {
            "token": "Ġde",
            "token_id": 409,
            "logprob": -11.375,
            "prob": 0.0
          },
          {
            "token": "Ġen",
            "token_id": 662,
            "logprob": -11.375,
            "prob": 0.0
          },
          {
            "token": "Ġspéc",
            "token_id": 70169,
            "logprob": -12.5,
            "prob": 0.0
          },
          {
            "token": "Ġindependent",
            "token_id": 9489,
            "logprob": -12.5,
            "prob": 0.0
          },
          {
            "token": "Ġinde",
            "token_id": 5167,
            "logprob": -12.5,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġpar",
        "token_id": 1346,
        "selection_method": "sampling"
      }
    },
    {
      "step": 19,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "ĠAlibaba",
            "token_id": 54364,
            "logprob": -0.0233,
            "prob": 0.9766
          },
          {
            "token": "Ġle",
            "token_id": 512,
            "logprob": -4.1562,
            "prob": 0.0157
          },
          {
            "token": "ĠAl",
            "token_id": 1674,
            "logprob": -5.5312,
            "prob": 0.004
          },
          {
            "token": "Ġl",
            "token_id": 326,
            "logprob": -6.7812,
            "prob": 0.0011
          },
          {
            "token": "Ġal",
            "token_id": 452,
            "logprob": -6.9062,
            "prob": 0.001
          },
          {
            "token": "ĠTencent",
            "token_id": 69921,
            "logprob": -7.2812,
            "prob": 0.0007
          },
          {
            "token": "ĠHuawei",
            "token_id": 50607,
            "logprob": -9.25,
            "prob": 0.0001
          },
          {
            "token": "Ġles",
            "token_id": 3541,
            "logprob": -10.25,
            "prob": 0.0
          },
          {
            "token": "ĠAli",
            "token_id": 14583,
            "logprob": -10.375,
            "prob": 0.0
          },
          {
            "token": "Ġla",
            "token_id": 1187,
            "logprob": -10.4375,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "ĠAlibaba",
        "token_id": 54364,
        "selection_method": "sampling"
      }
    },
    {
      "step": 20,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "ĠCloud",
            "token_id": 14817,
            "logprob": -0.0008,
            "prob": 1.0
          },
          {
            "token": "ĠGroup",
            "token_id": 5737,
            "logprob": -7.375,
            "prob": 0.0006
          },
          {
            "token": "Cloud",
            "token_id": 16055,
            "logprob": -9.375,
            "prob": 0.0001
          },
          {
            "token": ".",
            "token_id": 13,
            "logprob": -9.875,
            "prob": 0.0001
          },
          {
            "token": "集团",
            "token_id": 100338,
            "logprob": -13.75,
            "prob": 0.0
          },
          {
            "token": ".Cloud",
            "token_id": 94492,
            "logprob": -14.375,
            "prob": 0.0
          },
          {
            "token": "ĠGroups",
            "token_id": 34580,
            "logprob": -14.875,
            "prob": 0.0
          },
          {
            "token": "Ġgroupe",
            "token_id": 56851,
            "logprob": -15.1875,
            "prob": 0.0
          },
          {
            "token": "_cloud",
            "token_id": 37356,
            "logprob": -15.1875,
            "prob": 0.0
          },
          {
            "token": "Ġcloud",
            "token_id": 9437,
            "logprob": -15.1875,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "ĠCloud",
        "token_id": 14817,
        "selection_method": "sampling"
      }
    },
    {
      "step": 21,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": ".",
            "token_id": 13,
            "logprob": -0.0005,
            "prob": 1.0
          },
          {
            "token": ",",
            "token_id": 11,
            "logprob": -7.625,
            "prob": 0.0005
          },
          {
            "token": "'s",
            "token_id": 594,
            "logprob": -11.375,
            "prob": 0.0
          },
          {
            "token": "Ġet",
            "token_id": 1842,
            "logprob": -12.375,
            "prob": 0.0
          },
          {
            "token": "Ġde",
            "token_id": 409,
            "logprob": -12.5625,
            "prob": 0.0
          },
          {
            "token": "Ġen",
            "token_id": 662,
            "logprob": -13.3125,
            "prob": 0.0
          },
          {
            "token": "Ġ(",
            "token_id": 320,
            "logprob": -13.4375,
            "prob": 0.0
          },
          {
            "token": "Ġafin",
            "token_id": 53301,
            "logprob": -13.5,
            "prob": 0.0
          },
          {
            "token": "Ġpour",
            "token_id": 4914,
            "logprob": -13.5625,
            "prob": 0.0
          },
          {
            "token": "ĠResearch",
            "token_id": 8319,
            "logprob": -13.625,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": ".",
        "token_id": 13,
        "selection_method": "sampling"
      }
    },
    {
      "step": 22,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud.",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        "."
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "ĠJe",
            "token_id": 14133,
            "logprob": -0.0032,
            "prob": 0.9961
          },
          {
            "token": "ĠVous",
            "token_id": 40521,
            "logprob": -6.375,
            "prob": 0.0017
          },
          {
            "token": "ĠEn",
            "token_id": 2925,
            "logprob": -7.125,
            "prob": 0.0008
          },
          {
            "token": "ĠJ",
            "token_id": 619,
            "logprob": -7.375,
            "prob": 0.0006
          },
          {
            "token": "Je",
            "token_id": 29754,
            "logprob": -10.125,
            "prob": 0.0
          },
          {
            "token": "ĠSi",
            "token_id": 11832,
            "logprob": -11.0,
            "prob": 0.0
          },
          {
            "token": "ĠIl",
            "token_id": 7543,
            "logprob": -11.5,
            "prob": 0.0
          },
          {
            "token": "ĠÀ",
            "token_id": 64281,
            "logprob": -13.0,
            "prob": 0.0
          },
          {
            "token": "ĠCe",
            "token_id": 23769,
            "logprob": -13.0,
            "prob": 0.0
          },
          {
            "token": "Ġje",
            "token_id": 4759,
            "logprob": -13.0,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "ĠJe",
        "token_id": 14133,
        "selection_method": "sampling"
      }
    },
    {
      "step": 23,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġpeux",
            "token_id": 93197,
            "logprob": -0.3926,
            "prob": 0.6758
          },
          {
            "token": "Ġsuis",
            "token_id": 35631,
            "logprob": -1.1406,
            "prob": 0.3184
          },
          {
            "token": "Ġpeut",
            "token_id": 24666,
            "logprob": -5.2812,
            "prob": 0.0052
          },
          {
            "token": "Ġposs",
            "token_id": 2229,
            "logprob": -8.25,
            "prob": 0.0003
          },
          {
            "token": "Ġpuis",
            "token_id": 43729,
            "logprob": -9.625,
            "prob": 0.0001
          },
          {
            "token": "Ġpour",
            "token_id": 4914,
            "logprob": -10.625,
            "prob": 0.0
          },
          {
            "token": "Ġpropose",
            "token_id": 29614,
            "logprob": -10.75,
            "prob": 0.0
          },
          {
            "token": "Ġrépond",
            "token_id": 74771,
            "logprob": -11.25,
            "prob": 0.0
          },
          {
            "token": "Ġne",
            "token_id": 834,
            "logprob": -11.875,
            "prob": 0.0
          },
          {
            "token": "Ġpou",
            "token_id": 16836,
            "logprob": -11.875,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġpeux",
        "token_id": 93197,
        "selection_method": "sampling"
      }
    },
    {
      "step": 24,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġrépond",
            "token_id": 74771,
            "logprob": -0.1074,
            "prob": 0.8984
          },
          {
            "token": "Ġaider",
            "token_id": 90778,
            "logprob": -2.4844,
            "prob": 0.0835
          },
          {
            "token": "Ġvous",
            "token_id": 9012,
            "logprob": -4.7188,
            "prob": 0.0088
          },
          {
            "token": "Ġt",
            "token_id": 259,
            "logprob": -5.0938,
            "prob": 0.006
          },
          {
            "token": "Ġfourn",
            "token_id": 80894,
            "logprob": -6.0938,
            "prob": 0.0022
          },
          {
            "token": "Ġré",
            "token_id": 9333,
            "logprob": -7.4688,
            "prob": 0.0006
          },
          {
            "token": "Ġeffect",
            "token_id": 2456,
            "logprob": -8.125,
            "prob": 0.0003
          },
          {
            "token": "Ġrés",
            "token_id": 30707,
            "logprob": -9.25,
            "prob": 0.0001
          },
          {
            "token": "Ġprodu",
            "token_id": 2497,
            "logprob": -9.9375,
            "prob": 0.0
          },
          {
            "token": "Ġresponder",
            "token_id": 64034,
            "logprob": -9.9375,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġrépond",
        "token_id": 74771,
        "selection_method": "sampling"
      }
    },
    {
      "step": 25,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répond",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "re",
            "token_id": 265,
            "logprob": 0.0,
            "prob": 1.0
          },
          {
            "token": "ré",
            "token_id": 42611,
            "logprob": -18.625,
            "prob": 0.0
          },
          {
            "token": "s",
            "token_id": 82,
            "logprob": -19.125,
            "prob": 0.0
          },
          {
            "token": "res",
            "token_id": 416,
            "logprob": -20.25,
            "prob": 0.0
          },
          {
            "token": "rez",
            "token_id": 22741,
            "logprob": -20.875,
            "prob": 0.0
          },
          {
            "token": "RE",
            "token_id": 787,
            "logprob": -21.125,
            "prob": 0.0
          },
          {
            "token": "ra",
            "token_id": 956,
            "logprob": -21.25,
            "prob": 0.0
          },
          {
            "token": "Ġà",
            "token_id": 3784,
            "logprob": -21.875,
            "prob": 0.0
          },
          {
            "token": "Ġre",
            "token_id": 312,
            "logprob": -22.0,
            "prob": 0.0
          },
          {
            "token": "reau",
            "token_id": 89949,
            "logprob": -22.375,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "re",
        "token_id": 265,
        "selection_method": "sampling"
      }
    },
    {
      "step": 26,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġà",
            "token_id": 3784,
            "logprob": -0.0098,
            "prob": 0.9922
          },
          {
            "token": "Ġaux",
            "token_id": 10047,
            "logprob": -4.625,
            "prob": 0.0097
          },
          {
            "token": "Ġeffic",
            "token_id": 30814,
            "logprob": -12.25,
            "prob": 0.0
          },
          {
            "token": "Ġrapidement",
            "token_id": 99098,
            "logprob": -12.625,
            "prob": 0.0
          },
          {
            "token": "Ġa",
            "token_id": 264,
            "logprob": -12.625,
            "prob": 0.0
          },
          {
            "token": "à",
            "token_id": 6362,
            "logprob": -12.75,
            "prob": 0.0
          },
          {
            "token": "Ġàs",
            "token_id": 52529,
            "logprob": -12.875,
            "prob": 0.0
          },
          {
            "token": "ĠÀ",
            "token_id": 64281,
            "logprob": -13.5,
            "prob": 0.0
          },
          {
            "token": "Ġdes",
            "token_id": 939,
            "logprob": -14.5,
            "prob": 0.0
          },
          {
            "token": ",",
            "token_id": 11,
            "logprob": -15.0,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġà",
        "token_id": 3784,
        "selection_method": "sampling"
      }
    },
    {
      "step": 27,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġdes",
            "token_id": 939,
            "logprob": -0.0114,
            "prob": 0.9883
          },
          {
            "token": "Ġvos",
            "token_id": 25251,
            "logprob": -4.5,
            "prob": 0.011
          },
          {
            "token": "Ġtoutes",
            "token_id": 39644,
            "logprob": -8.75,
            "prob": 0.0002
          },
          {
            "token": "Ġdivers",
            "token_id": 21113,
            "logprob": -9.0,
            "prob": 0.0001
          },
          {
            "token": "Ġtes",
            "token_id": 50209,
            "logprob": -11.0,
            "prob": 0.0
          },
          {
            "token": "Ġde",
            "token_id": 409,
            "logprob": -11.0,
            "prob": 0.0
          },
          {
            "token": "Ġdifférentes",
            "token_id": 95542,
            "logprob": -11.25,
            "prob": 0.0
          },
          {
            "token": "Ġvotre",
            "token_id": 14918,
            "logprob": -11.625,
            "prob": 0.0
          },
          {
            "token": "Ġune",
            "token_id": 6185,
            "logprob": -13.0,
            "prob": 0.0
          },
          {
            "token": "Ġtoute",
            "token_id": 42805,
            "logprob": -13.0,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġvos",
        "token_id": 25251,
        "selection_method": "sampling"
      }
    },
    {
      "step": 28,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġquestions",
            "token_id": 4755,
            "logprob": -0.0001,
            "prob": 1.0
          },
          {
            "token": "questions",
            "token_id": 17348,
            "logprob": -9.625,
            "prob": 0.0001
          },
          {
            "token": "Ġinterrog",
            "token_id": 36439,
            "logprob": -10.875,
            "prob": 0.0
          },
          {
            "token": "Ġquestion",
            "token_id": 3405,
            "logprob": -11.625,
            "prob": 0.0
          },
          {
            "token": "Ġdemand",
            "token_id": 7479,
            "logprob": -11.75,
            "prob": 0.0
          },
          {
            "token": "ĠQuestions",
            "token_id": 23382,
            "logprob": -11.75,
            "prob": 0.0
          },
          {
            "token": "Questions",
            "token_id": 35249,
            "logprob": -11.875,
            "prob": 0.0
          },
          {
            "token": "Ġprobl",
            "token_id": 50988,
            "logprob": -12.375,
            "prob": 0.0
          },
          {
            "token": "/questions",
            "token_id": 43319,
            "logprob": -12.875,
            "prob": 0.0
          },
          {
            "token": "Ġdifférentes",
            "token_id": 95542,
            "logprob": -13.125,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġquestions",
        "token_id": 4755,
        "selection_method": "sampling"
      }
    },
    {
      "step": 29,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": ",",
            "token_id": 11,
            "logprob": -0.0,
            "prob": 1.0
          },
          {
            "token": "Ġsur",
            "token_id": 1729,
            "logprob": -11.375,
            "prob": 0.0
          },
          {
            "token": "Ġde",
            "token_id": 409,
            "logprob": -13.25,
            "prob": 0.0
          },
          {
            "token": "Ġet",
            "token_id": 1842,
            "logprob": -14.125,
            "prob": 0.0
          },
          {
            "token": "Ġdans",
            "token_id": 6866,
            "logprob": -14.625,
            "prob": 0.0
          },
          {
            "token": "Ġen",
            "token_id": 662,
            "logprob": -16.0,
            "prob": 0.0
          },
          {
            "token": "Ġ,",
            "token_id": 1154,
            "logprob": -17.5,
            "prob": 0.0
          },
          {
            "token": "Ġà",
            "token_id": 3784,
            "logprob": -18.0,
            "prob": 0.0
          },
          {
            "token": "Ġou",
            "token_id": 5908,
            "logprob": -18.125,
            "prob": 0.0
          },
          {
            "token": "Ġd",
            "token_id": 294,
            "logprob": -18.25,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": ",",
        "token_id": 11,
        "selection_method": "sampling"
      }
    },
    {
      "step": 30,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions,",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ","
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġcréer",
            "token_id": 74731,
            "logprob": -0.0347,
            "prob": 0.9648
          },
          {
            "token": "Ġé",
            "token_id": 3958,
            "logprob": -4.4062,
            "prob": 0.0121
          },
          {
            "token": "Ġaider",
            "token_id": 90778,
            "logprob": -4.9062,
            "prob": 0.0074
          },
          {
            "token": "Ġprodu",
            "token_id": 2497,
            "logprob": -5.5312,
            "prob": 0.0039
          },
          {
            "token": "Ġvous",
            "token_id": 9012,
            "logprob": -5.9062,
            "prob": 0.0027
          },
          {
            "token": "Ġré",
            "token_id": 9333,
            "logprob": -5.9062,
            "prob": 0.0027
          },
          {
            "token": "ĠCré",
            "token_id": 135893,
            "logprob": -6.7812,
            "prob": 0.0011
          },
          {
            "token": "Ġcré",
            "token_id": 33180,
            "logprob": -7.1562,
            "prob": 0.0008
          },
          {
            "token": "Ġfourn",
            "token_id": 80894,
            "logprob": -7.6562,
            "prob": 0.0005
          },
          {
            "token": "cré",
            "token_id": 129532,
            "logprob": -7.9062,
            "prob": 0.0004
          }
        ]
      },
      "selected_token": {
        "token": "Ġcréer",
        "token_id": 74731,
        "selection_method": "sampling"
      }
    },
    {
      "step": 31,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġdes",
            "token_id": 939,
            "logprob": -0.0068,
            "prob": 0.9922
          },
          {
            "token": "Ġdu",
            "token_id": 3845,
            "logprob": -5.0,
            "prob": 0.0067
          },
          {
            "token": "Ġde",
            "token_id": 409,
            "logprob": -10.0,
            "prob": 0.0
          },
          {
            "token": "des",
            "token_id": 5799,
            "logprob": -14.625,
            "prob": 0.0
          },
          {
            "token": "Ġcontenu",
            "token_id": 75254,
            "logprob": -14.75,
            "prob": 0.0
          },
          {
            "token": "Ġet",
            "token_id": 1842,
            "logprob": -15.0,
            "prob": 0.0
          },
          {
            "token": "Ġdivers",
            "token_id": 21113,
            "logprob": -15.875,
            "prob": 0.0
          },
          {
            "token": "Ġun",
            "token_id": 650,
            "logprob": -15.875,
            "prob": 0.0
          },
          {
            "token": "Ġtout",
            "token_id": 16559,
            "logprob": -16.125,
            "prob": 0.0
          },
          {
            "token": "Ġtexte",
            "token_id": 67967,
            "logprob": -16.25,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġdes",
        "token_id": 939,
        "selection_method": "sampling"
      }
    },
    {
      "step": 32,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġtext",
            "token_id": 1467,
            "logprob": -0.024,
            "prob": 0.9766
          },
          {
            "token": "Ġtexts",
            "token_id": 21984,
            "logprob": -4.1562,
            "prob": 0.0157
          },
          {
            "token": "Ġtexte",
            "token_id": 67967,
            "logprob": -5.9062,
            "prob": 0.0027
          },
          {
            "token": "Ġhisto",
            "token_id": 76517,
            "logprob": -6.5312,
            "prob": 0.0015
          },
          {
            "token": "Ġcont",
            "token_id": 683,
            "logprob": -6.5312,
            "prob": 0.0015
          },
          {
            "token": "Ġdocuments",
            "token_id": 9293,
            "logprob": -6.9062,
            "prob": 0.001
          },
          {
            "token": "Ġécrit",
            "token_id": 88432,
            "logprob": -7.2812,
            "prob": 0.0007
          },
          {
            "token": "文本",
            "token_id": 108704,
            "logprob": -9.125,
            "prob": 0.0001
          },
          {
            "token": "Ġré",
            "token_id": 9333,
            "logprob": -9.25,
            "prob": 0.0001
          },
          {
            "token": "Ġtexto",
            "token_id": 32025,
            "logprob": -9.875,
            "prob": 0.0001
          }
        ]
      },
      "selected_token": {
        "token": "Ġtext",
        "token_id": 1467,
        "selection_method": "sampling"
      }
    },
    {
      "step": 33,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des text",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "es",
            "token_id": 288,
            "logprob": 0.0,
            "prob": 1.0
          },
          {
            "token": "os",
            "token_id": 436,
            "logprob": -21.5,
            "prob": 0.0
          },
          {
            "token": "ES",
            "token_id": 1570,
            "logprob": -22.0,
            "prob": 0.0
          },
          {
            "token": "esp",
            "token_id": 24610,
            "logprob": -24.25,
            "prob": 0.0
          },
          {
            "token": "ez",
            "token_id": 10125,
            "logprob": -24.75,
            "prob": 0.0
          },
          {
            "token": "esi",
            "token_id": 33083,
            "logprob": -25.25,
            "prob": 0.0
          },
          {
            "token": "ès",
            "token_id": 12142,
            "logprob": -25.625,
            "prob": 0.0
          },
          {
            "token": "uels",
            "token_id": 60144,
            "logprob": -25.75,
            "prob": 0.0
          },
          {
            "token": ",",
            "token_id": 11,
            "logprob": -25.875,
            "prob": 0.0
          },
          {
            "token": "uelles",
            "token_id": 64732,
            "logprob": -26.25,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "es",
        "token_id": 288,
        "selection_method": "sampling"
      }
    },
    {
      "step": 34,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġt",
            "token_id": 259,
            "logprob": -0.2949,
            "prob": 0.7461
          },
          {
            "token": ",",
            "token_id": 11,
            "logprob": -2.0469,
            "prob": 0.1299
          },
          {
            "token": "Ġcomme",
            "token_id": 21572,
            "logprob": -2.1719,
            "prob": 0.1143
          },
          {
            "token": "Ġ(",
            "token_id": 320,
            "logprob": -5.4062,
            "prob": 0.0044
          },
          {
            "token": "Ġsuch",
            "token_id": 1741,
            "logprob": -6.1562,
            "prob": 0.0021
          },
          {
            "token": "Ġde",
            "token_id": 409,
            "logprob": -7.4688,
            "prob": 0.0006
          },
          {
            "token": "Ġtel",
            "token_id": 18708,
            "logprob": -7.4688,
            "prob": 0.0006
          },
          {
            "token": "Ġà",
            "token_id": 3784,
            "logprob": -7.5312,
            "prob": 0.0005
          },
          {
            "token": "如",
            "token_id": 29524,
            "logprob": -7.9062,
            "prob": 0.0004
          },
          {
            "token": "Ġcomo",
            "token_id": 7953,
            "logprob": -7.9688,
            "prob": 0.0003
          }
        ]
      },
      "selected_token": {
        "token": "Ġt",
        "token_id": 259,
        "selection_method": "sampling"
      }
    },
    {
      "step": 35,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes t",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "els",
            "token_id": 2010,
            "logprob": -0.0,
            "prob": 1.0
          },
          {
            "token": "elle",
            "token_id": 6712,
            "logprob": -10.625,
            "prob": 0.0
          },
          {
            "token": "ELS",
            "token_id": 97852,
            "logprob": -15.25,
            "prob": 0.0
          },
          {
            "token": "Ġt",
            "token_id": 259,
            "logprob": -18.5,
            "prob": 0.0
          },
          {
            "token": "als",
            "token_id": 1127,
            "logprob": -18.875,
            "prob": 0.0
          },
          {
            "token": "elt",
            "token_id": 3818,
            "logprob": -20.5,
            "prob": 0.0
          },
          {
            "token": "ais",
            "token_id": 2782,
            "logprob": -20.5,
            "prob": 0.0
          },
          {
            "token": "outs",
            "token_id": 11672,
            "logprob": -20.625,
            "prob": 0.0
          },
          {
            "token": "él",
            "token_id": 18503,
            "logprob": -20.75,
            "prob": 0.0
          },
          {
            "token": "ém",
            "token_id": 16647,
            "logprob": -20.875,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "els",
        "token_id": 2010,
        "selection_method": "sampling"
      }
    },
    {
      "step": 36,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġque",
            "token_id": 1709,
            "logprob": -0.0001,
            "prob": 1.0
          },
          {
            "token": "Ġqu",
            "token_id": 922,
            "logprob": -9.625,
            "prob": 0.0001
          },
          {
            "token": "Ġdes",
            "token_id": 939,
            "logprob": -17.125,
            "prob": 0.0
          },
          {
            "token": "Ġthat",
            "token_id": 429,
            "logprob": -17.125,
            "prob": 0.0
          },
          {
            "token": "que",
            "token_id": 591,
            "logprob": -19.5,
            "prob": 0.0
          },
          {
            "token": "Ġdass",
            "token_id": 14948,
            "logprob": -20.25,
            "prob": 0.0
          },
          {
            "token": "_que",
            "token_id": 47342,
            "logprob": -20.625,
            "prob": 0.0
          },
          {
            "token": "ĠQue",
            "token_id": 9418,
            "logprob": -21.5,
            "prob": 0.0
          },
          {
            "token": "ĠQUE",
            "token_id": 29676,
            "logprob": -22.5,
            "prob": 0.0
          },
          {
            "token": "qu",
            "token_id": 446,
            "logprob": -22.625,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġque",
        "token_id": 1709,
        "selection_method": "sampling"
      }
    },
    {
      "step": 37,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġdes",
            "token_id": 939,
            "logprob": -0.0006,
            "prob": 1.0
          },
          {
            "token": "Ġde",
            "token_id": 409,
            "logprob": -7.75,
            "prob": 0.0004
          },
          {
            "token": "Ġles",
            "token_id": 3541,
            "logprob": -9.125,
            "prob": 0.0001
          },
          {
            "token": "Ġdu",
            "token_id": 3845,
            "logprob": -11.625,
            "prob": 0.0
          },
          {
            "token": "Ġré",
            "token_id": 9333,
            "logprob": -12.375,
            "prob": 0.0
          },
          {
            "token": "Ġl",
            "token_id": 326,
            "logprob": -14.625,
            "prob": 0.0
          },
          {
            "token": "Ġrh",
            "token_id": 21669,
            "logprob": -15.0,
            "prob": 0.0
          },
          {
            "token": "Ġle",
            "token_id": 512,
            "logprob": -15.5,
            "prob": 0.0
          },
          {
            "token": "Ġd",
            "token_id": 294,
            "logprob": -15.5,
            "prob": 0.0
          },
          {
            "token": "Ġra",
            "token_id": 15122,
            "logprob": -15.625,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġdes",
        "token_id": 939,
        "selection_method": "sampling"
      }
    },
    {
      "step": 38,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġhisto",
            "token_id": 76517,
            "logprob": -0.3945,
            "prob": 0.6719
          },
          {
            "token": "Ġré",
            "token_id": 9333,
            "logprob": -1.1484,
            "prob": 0.3184
          },
          {
            "token": "Ġstories",
            "token_id": 7343,
            "logprob": -6.2812,
            "prob": 0.0019
          },
          {
            "token": "Ġess",
            "token_id": 3956,
            "logprob": -7.1562,
            "prob": 0.0008
          },
          {
            "token": "Ġnouvelles",
            "token_id": 78980,
            "logprob": -7.2812,
            "prob": 0.0007
          },
          {
            "token": "Ġcont",
            "token_id": 683,
            "logprob": -7.4062,
            "prob": 0.0006
          },
          {
            "token": "Ġr",
            "token_id": 435,
            "logprob": -7.4062,
            "prob": 0.0006
          },
          {
            "token": "Ġhistoire",
            "token_id": 86710,
            "logprob": -7.7812,
            "prob": 0.0004
          },
          {
            "token": "Ġstory",
            "token_id": 3364,
            "logprob": -7.7812,
            "prob": 0.0004
          },
          {
            "token": "Ġarticles",
            "token_id": 9709,
            "logprob": -7.9062,
            "prob": 0.0004
          }
        ]
      },
      "selected_token": {
        "token": "Ġhisto",
        "token_id": 76517,
        "selection_method": "sampling"
      }
    },
    {
      "step": 39,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histo",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "ires",
            "token_id": 3861,
            "logprob": 0.0,
            "prob": 1.0
          },
          {
            "token": "ired",
            "token_id": 2690,
            "logprob": -17.0,
            "prob": 0.0
          },
          {
            "token": "ries",
            "token_id": 4019,
            "logprob": -18.125,
            "prob": 0.0
          },
          {
            "token": "ire",
            "token_id": 554,
            "logprob": -19.25,
            "prob": 0.0
          },
          {
            "token": "ines",
            "token_id": 1543,
            "logprob": -19.75,
            "prob": 0.0
          },
          {
            "token": "iques",
            "token_id": 8303,
            "logprob": -20.625,
            "prob": 0.0
          },
          {
            "token": "ites",
            "token_id": 3611,
            "logprob": -20.75,
            "prob": 0.0
          },
          {
            "token": "ies",
            "token_id": 550,
            "logprob": -20.875,
            "prob": 0.0
          },
          {
            "token": "ques",
            "token_id": 13968,
            "logprob": -21.25,
            "prob": 0.0
          },
          {
            "token": "iles",
            "token_id": 3658,
            "logprob": -21.375,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "ires",
        "token_id": 3861,
        "selection_method": "sampling"
      }
    },
    {
      "step": 40,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": ",",
            "token_id": 11,
            "logprob": 0.0,
            "prob": 1.0
          },
          {
            "token": "Ġ,",
            "token_id": 1154,
            "logprob": -18.75,
            "prob": 0.0
          },
          {
            "token": "、",
            "token_id": 5373,
            "logprob": -21.375,
            "prob": 0.0
          },
          {
            "token": "Ġou",
            "token_id": 5908,
            "logprob": -21.375,
            "prob": 0.0
          },
          {
            "token": "Ġet",
            "token_id": 1842,
            "logprob": -21.875,
            "prob": 0.0
          },
          {
            "token": ",\n",
            "token_id": 345,
            "logprob": -22.5,
            "prob": 0.0
          },
          {
            "token": ",c",
            "token_id": 10109,
            "logprob": -22.75,
            "prob": 0.0
          },
          {
            "token": ",l",
            "token_id": 22206,
            "logprob": -22.75,
            "prob": 0.0
          },
          {
            "token": "Ġré",
            "token_id": 9333,
            "logprob": -23.0,
            "prob": 0.0
          },
          {
            "token": ",p",
            "token_id": 7237,
            "logprob": -23.25,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": ",",
        "token_id": 11,
        "selection_method": "sampling"
      }
    },
    {
      "step": 41,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires,",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ","
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġdes",
            "token_id": 939,
            "logprob": -0.0001,
            "prob": 1.0
          },
          {
            "token": "Ġdu",
            "token_id": 3845,
            "logprob": -9.625,
            "prob": 0.0001
          },
          {
            "token": "Ġde",
            "token_id": 409,
            "logprob": -12.5,
            "prob": 0.0
          },
          {
            "token": "Ġdocuments",
            "token_id": 9293,
            "logprob": -13.375,
            "prob": 0.0
          },
          {
            "token": "\tdes",
            "token_id": 52912,
            "logprob": -14.125,
            "prob": 0.0
          },
          {
            "token": "des",
            "token_id": 5799,
            "logprob": -15.0,
            "prob": 0.0
          },
          {
            "token": "Ġdess",
            "token_id": 20624,
            "logprob": -16.0,
            "prob": 0.0
          },
          {
            "token": "_des",
            "token_id": 15768,
            "logprob": -17.0,
            "prob": 0.0
          },
          {
            "token": "ĠDes",
            "token_id": 3874,
            "logprob": -17.125,
            "prob": 0.0
          },
          {
            "token": "(des",
            "token_id": 34590,
            "logprob": -17.375,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġdes",
        "token_id": 939,
        "selection_method": "sampling"
      }
    },
    {
      "step": 42,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires, des",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ",",
        "Ġdes"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11,
        939
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġdocuments",
            "token_id": 9293,
            "logprob": -0.1211,
            "prob": 0.8867
          },
          {
            "token": "Ġrap",
            "token_id": 7327,
            "logprob": -3.625,
            "prob": 0.0267
          },
          {
            "token": "Ġemails",
            "token_id": 14298,
            "logprob": -3.75,
            "prob": 0.0236
          },
          {
            "token": "Ġcour",
            "token_id": 2081,
            "logprob": -4.0,
            "prob": 0.0184
          },
          {
            "token": "Ġarticles",
            "token_id": 9709,
            "logprob": -4.875,
            "prob": 0.0077
          },
          {
            "token": "Ġdess",
            "token_id": 20624,
            "logprob": -5.0,
            "prob": 0.0068
          },
          {
            "token": "Ġpo",
            "token_id": 3193,
            "logprob": -5.375,
            "prob": 0.0046
          },
          {
            "token": "Ġmails",
            "token_id": 85558,
            "logprob": -5.5,
            "prob": 0.0041
          },
          {
            "token": "Ġdocs",
            "token_id": 26340,
            "logprob": -5.5,
            "prob": 0.0041
          },
          {
            "token": "Ġess",
            "token_id": 3956,
            "logprob": -5.875,
            "prob": 0.0028
          }
        ]
      },
      "selected_token": {
        "token": "Ġdocuments",
        "token_id": 9293,
        "selection_method": "sampling"
      }
    },
    {
      "step": 43,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires, des documents",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ",",
        "Ġdes",
        "Ġdocuments"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11,
        939,
        9293
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġoffic",
            "token_id": 2786,
            "logprob": -0.0217,
            "prob": 0.9766
          },
          {
            "token": "Ġprofession",
            "token_id": 4808,
            "logprob": -3.8906,
            "prob": 0.0203
          },
          {
            "token": "Ġacad",
            "token_id": 10406,
            "logprob": -7.7812,
            "prob": 0.0004
          },
          {
            "token": "Ġtechniques",
            "token_id": 12538,
            "logprob": -8.375,
            "prob": 0.0002
          },
          {
            "token": ",",
            "token_id": 11,
            "logprob": -8.5,
            "prob": 0.0002
          },
          {
            "token": "Ġcommerc",
            "token_id": 94094,
            "logprob": -9.5,
            "prob": 0.0001
          },
          {
            "token": "Ġadministr",
            "token_id": 11150,
            "logprob": -9.75,
            "prob": 0.0001
          },
          {
            "token": "Ġform",
            "token_id": 1352,
            "logprob": -10.0,
            "prob": 0.0
          },
          {
            "token": "Ġoff",
            "token_id": 1007,
            "logprob": -10.125,
            "prob": 0.0
          },
          {
            "token": "Ġde",
            "token_id": 409,
            "logprob": -10.625,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġoffic",
        "token_id": 2786,
        "selection_method": "sampling"
      }
    },
    {
      "step": 44,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires, des documents offic",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ",",
        "Ġdes",
        "Ġdocuments",
        "Ġoffic"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11,
        939,
        9293,
        2786
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "i",
            "token_id": 72,
            "logprob": -0.0,
            "prob": 1.0
          },
          {
            "token": "iel",
            "token_id": 13029,
            "logprob": -12.5,
            "prob": 0.0
          },
          {
            "token": "ieux",
            "token_id": 52719,
            "logprob": -13.25,
            "prob": 0.0
          },
          {
            "token": "iers",
            "token_id": 4813,
            "logprob": -15.0,
            "prob": 0.0
          },
          {
            "token": "iants",
            "token_id": 62278,
            "logprob": -15.5,
            "prob": 0.0
          },
          {
            "token": "iaux",
            "token_id": 82291,
            "logprob": -15.75,
            "prob": 0.0
          },
          {
            "token": "uels",
            "token_id": 60144,
            "logprob": -15.75,
            "prob": 0.0
          },
          {
            "token": "IEL",
            "token_id": 9061,
            "logprob": -15.875,
            "prob": 0.0
          },
          {
            "token": "iates",
            "token_id": 42298,
            "logprob": -16.75,
            "prob": 0.0
          },
          {
            "token": "iable",
            "token_id": 2156,
            "logprob": -16.875,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "i",
        "token_id": 72,
        "selection_method": "sampling"
      }
    },
    {
      "step": 45,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires, des documents offici",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ",",
        "Ġdes",
        "Ġdocuments",
        "Ġoffic",
        "i"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11,
        939,
        9293,
        2786,
        72
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "els",
            "token_id": 2010,
            "logprob": -0.0,
            "prob": 1.0
          },
          {
            "token": "és",
            "token_id": 5397,
            "logprob": -13.875,
            "prob": 0.0
          },
          {
            "token": "elt",
            "token_id": 3818,
            "logprob": -14.0,
            "prob": 0.0
          },
          {
            "token": "elle",
            "token_id": 6712,
            "logprob": -14.5,
            "prob": 0.0
          },
          {
            "token": "ells",
            "token_id": 6436,
            "logprob": -14.625,
            "prob": 0.0
          },
          {
            "token": "nels",
            "token_id": 35427,
            "logprob": -15.625,
            "prob": 0.0
          },
          {
            "token": "ell",
            "token_id": 613,
            "logprob": -16.0,
            "prob": 0.0
          },
          {
            "token": "ELS",
            "token_id": 97852,
            "logprob": -16.125,
            "prob": 0.0
          },
          {
            "token": "él",
            "token_id": 18503,
            "logprob": -16.25,
            "prob": 0.0
          },
          {
            "token": "ellen",
            "token_id": 15671,
            "logprob": -16.75,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "els",
        "token_id": 2010,
        "selection_method": "sampling"
      }
    },
    {
      "step": 46,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires, des documents officiels",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ",",
        "Ġdes",
        "Ġdocuments",
        "Ġoffic",
        "i",
        "els"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11,
        939,
        9293,
        2786,
        72,
        2010
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": ",",
            "token_id": 11,
            "logprob": -0.0002,
            "prob": 1.0
          },
          {
            "token": "Ġet",
            "token_id": 1842,
            "logprob": -9.0,
            "prob": 0.0001
          },
          {
            "token": "Ġou",
            "token_id": 5908,
            "logprob": -9.25,
            "prob": 0.0001
          },
          {
            "token": "Ġde",
            "token_id": 409,
            "logprob": -16.125,
            "prob": 0.0
          },
          {
            "token": "Ġd",
            "token_id": 294,
            "logprob": -18.125,
            "prob": 0.0
          },
          {
            "token": "Ġprofession",
            "token_id": 4808,
            "logprob": -18.125,
            "prob": 0.0
          },
          {
            "token": "Ġ,",
            "token_id": 1154,
            "logprob": -18.75,
            "prob": 0.0
          },
          {
            "token": "Ġ(",
            "token_id": 320,
            "logprob": -19.125,
            "prob": 0.0
          },
          {
            "token": "Ġen",
            "token_id": 662,
            "logprob": -19.75,
            "prob": 0.0
          },
          {
            "token": "Ġform",
            "token_id": 1352,
            "logprob": -19.875,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": ",",
        "token_id": 11,
        "selection_method": "sampling"
      }
    },
    {
      "step": 47,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires, des documents officiels,",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ",",
        "Ġdes",
        "Ġdocuments",
        "Ġoffic",
        "i",
        "els",
        ","
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11,
        939,
        9293,
        2786,
        72,
        2010,
        11
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġdes",
            "token_id": 939,
            "logprob": -0.0,
            "prob": 1.0
          },
          {
            "token": "Ġdu",
            "token_id": 3845,
            "logprob": -11.375,
            "prob": 0.0
          },
          {
            "token": "Ġde",
            "token_id": 409,
            "logprob": -12.875,
            "prob": 0.0
          },
          {
            "token": "Ġemails",
            "token_id": 14298,
            "logprob": -15.0,
            "prob": 0.0
          },
          {
            "token": "des",
            "token_id": 5799,
            "logprob": -15.625,
            "prob": 0.0
          },
          {
            "token": "Ġmails",
            "token_id": 85558,
            "logprob": -15.875,
            "prob": 0.0
          },
          {
            "token": "Ġetc",
            "token_id": 4992,
            "logprob": -16.375,
            "prob": 0.0
          },
          {
            "token": "Ġet",
            "token_id": 1842,
            "logprob": -16.875,
            "prob": 0.0
          },
          {
            "token": "ĠDes",
            "token_id": 3874,
            "logprob": -17.125,
            "prob": 0.0
          },
          {
            "token": "Ġou",
            "token_id": 5908,
            "logprob": -17.75,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġdes",
        "token_id": 939,
        "selection_method": "sampling"
      }
    },
    {
      "step": 48,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires, des documents officiels, des",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ",",
        "Ġdes",
        "Ġdocuments",
        "Ġoffic",
        "i",
        "els",
        ",",
        "Ġdes"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11,
        939,
        9293,
        2786,
        72,
        2010,
        11,
        939
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġe",
            "token_id": 384,
            "logprob": -0.9023,
            "prob": 0.4062
          },
          {
            "token": "Ġemails",
            "token_id": 14298,
            "logprob": -1.2734,
            "prob": 0.2793
          },
          {
            "token": "Ġcour",
            "token_id": 2081,
            "logprob": -2.1562,
            "prob": 0.1162
          },
          {
            "token": "Ġrap",
            "token_id": 7327,
            "logprob": -2.1562,
            "prob": 0.1162
          },
          {
            "token": "Ġmails",
            "token_id": 85558,
            "logprob": -3.0312,
            "prob": 0.0486
          },
          {
            "token": "Ġlet",
            "token_id": 1077,
            "logprob": -3.6562,
            "prob": 0.026
          },
          {
            "token": "-mails",
            "token_id": 60220,
            "logprob": -6.9062,
            "prob": 0.001
          },
          {
            "token": "Ġré",
            "token_id": 9333,
            "logprob": -7.0312,
            "prob": 0.0009
          },
          {
            "token": "Ġemail",
            "token_id": 2551,
            "logprob": -7.6562,
            "prob": 0.0005
          },
          {
            "token": "Ġscripts",
            "token_id": 19502,
            "logprob": -7.7812,
            "prob": 0.0004
          }
        ]
      },
      "selected_token": {
        "token": "Ġe",
        "token_id": 384,
        "selection_method": "sampling"
      }
    },
    {
      "step": 49,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires, des documents officiels, des e",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ",",
        "Ġdes",
        "Ġdocuments",
        "Ġoffic",
        "i",
        "els",
        ",",
        "Ġdes",
        "Ġe"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11,
        939,
        9293,
        2786,
        72,
        2010,
        11,
        939,
        384
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "-mails",
            "token_id": 60220,
            "logprob": -0.0003,
            "prob": 1.0
          },
          {
            "token": "-m",
            "token_id": 1448,
            "logprob": -8.5,
            "prob": 0.0002
          },
          {
            "token": "-mail",
            "token_id": 11468,
            "logprob": -10.0,
            "prob": 0.0
          },
          {
            "token": "Ġmails",
            "token_id": 85558,
            "logprob": -10.125,
            "prob": 0.0
          },
          {
            "token": "-books",
            "token_id": 83091,
            "logprob": -13.125,
            "prob": 0.0
          },
          {
            "token": "-c",
            "token_id": 1786,
            "logprob": -13.625,
            "prob": 0.0
          },
          {
            "token": "-",
            "token_id": 12,
            "logprob": -14.125,
            "prob": 0.0
          },
          {
            "token": "ul",
            "token_id": 360,
            "logprob": -14.25,
            "prob": 0.0
          },
          {
            "token": "-commerce",
            "token_id": 41585,
            "logprob": -14.375,
            "prob": 0.0
          },
          {
            "token": "-messages",
            "token_id": 88142,
            "logprob": -15.0,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "-mails",
        "token_id": 60220,
        "selection_method": "sampling"
      }
    },
    {
      "step": 50,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires, des documents officiels, des e-mails",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ",",
        "Ġdes",
        "Ġdocuments",
        "Ġoffic",
        "i",
        "els",
        ",",
        "Ġdes",
        "Ġe",
        "-mails"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11,
        939,
        9293,
        2786,
        72,
        2010,
        11,
        939,
        384,
        60220
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": ",",
            "token_id": 11,
            "logprob": -0.0132,
            "prob": 0.9883
          },
          {
            "token": "Ġou",
            "token_id": 5908,
            "logprob": -4.375,
            "prob": 0.0125
          },
          {
            "token": "Ġet",
            "token_id": 1842,
            "logprob": -7.25,
            "prob": 0.0007
          },
          {
            "token": "Ġetc",
            "token_id": 4992,
            "logprob": -13.125,
            "prob": 0.0
          },
          {
            "token": "Ġmarketing",
            "token_id": 8493,
            "logprob": -14.625,
            "prob": 0.0
          },
          {
            "token": "Ġde",
            "token_id": 409,
            "logprob": -14.75,
            "prob": 0.0
          },
          {
            "token": "Ġen",
            "token_id": 662,
            "logprob": -16.125,
            "prob": 0.0
          },
          {
            "token": "Ġ,",
            "token_id": 1154,
            "logprob": -17.0,
            "prob": 0.0
          },
          {
            "token": "Ġd",
            "token_id": 294,
            "logprob": -17.125,
            "prob": 0.0
          },
          {
            "token": "Ġpar",
            "token_id": 1346,
            "logprob": -17.375,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": ",",
        "token_id": 11,
        "selection_method": "sampling"
      }
    },
    {
      "step": 51,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires, des documents officiels, des e-mails,",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ",",
        "Ġdes",
        "Ġdocuments",
        "Ġoffic",
        "i",
        "els",
        ",",
        "Ġdes",
        "Ġe",
        "-mails",
        ","
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11,
        939,
        9293,
        2786,
        72,
        2010,
        11,
        939,
        384,
        60220,
        11
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġdes",
            "token_id": 939,
            "logprob": -0.0002,
            "prob": 1.0
          },
          {
            "token": "Ġetc",
            "token_id": 4992,
            "logprob": -9.25,
            "prob": 0.0001
          },
          {
            "token": "Ġdu",
            "token_id": 3845,
            "logprob": -9.5,
            "prob": 0.0001
          },
          {
            "token": "Ġde",
            "token_id": 409,
            "logprob": -10.75,
            "prob": 0.0
          },
          {
            "token": "Ġet",
            "token_id": 1842,
            "logprob": -12.625,
            "prob": 0.0
          },
          {
            "token": "Ġou",
            "token_id": 5908,
            "logprob": -14.25,
            "prob": 0.0
          },
          {
            "token": "ĠDes",
            "token_id": 3874,
            "logprob": -15.5,
            "prob": 0.0
          },
          {
            "token": "des",
            "token_id": 5799,
            "logprob": -15.875,
            "prob": 0.0
          },
          {
            "token": "Ġscripts",
            "token_id": 19502,
            "logprob": -16.125,
            "prob": 0.0
          },
          {
            "token": "Ġainsi",
            "token_id": 43251,
            "logprob": -16.125,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġdes",
        "token_id": 939,
        "selection_method": "sampling"
      }
    },
    {
      "step": 52,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires, des documents officiels, des e-mails, des",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ",",
        "Ġdes",
        "Ġdocuments",
        "Ġoffic",
        "i",
        "els",
        ",",
        "Ġdes",
        "Ġe",
        "-mails",
        ",",
        "Ġdes"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11,
        939,
        9293,
        2786,
        72,
        2010,
        11,
        939,
        384,
        60220,
        11,
        939
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġsc",
            "token_id": 1136,
            "logprob": -0.2891,
            "prob": 0.75
          },
          {
            "token": "Ġscripts",
            "token_id": 19502,
            "logprob": -2.0469,
            "prob": 0.1299
          },
          {
            "token": "Ġrap",
            "token_id": 7327,
            "logprob": -2.4219,
            "prob": 0.0894
          },
          {
            "token": "Ġcour",
            "token_id": 2081,
            "logprob": -5.6562,
            "prob": 0.0035
          },
          {
            "token": "Ġrais",
            "token_id": 6369,
            "logprob": -5.7812,
            "prob": 0.0031
          },
          {
            "token": "Ġscript",
            "token_id": 5316,
            "logprob": -6.0312,
            "prob": 0.0024
          },
          {
            "token": "Ġtrans",
            "token_id": 1356,
            "logprob": -6.1562,
            "prob": 0.0021
          },
          {
            "token": "Ġarticles",
            "token_id": 9709,
            "logprob": -6.5938,
            "prob": 0.0014
          },
          {
            "token": "Ġess",
            "token_id": 3956,
            "logprob": -6.7188,
            "prob": 0.0012
          },
          {
            "token": "Ġdialog",
            "token_id": 7254,
            "logprob": -6.9062,
            "prob": 0.001
          }
        ]
      },
      "selected_token": {
        "token": "Ġscripts",
        "token_id": 19502,
        "selection_method": "sampling"
      }
    },
    {
      "step": 53,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires, des documents officiels, des e-mails, des scripts",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ",",
        "Ġdes",
        "Ġdocuments",
        "Ġoffic",
        "i",
        "els",
        ",",
        "Ġdes",
        "Ġe",
        "-mails",
        ",",
        "Ġdes",
        "Ġscripts"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11,
        939,
        9293,
        2786,
        72,
        2010,
        11,
        939,
        384,
        60220,
        11,
        939,
        19502
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": ",",
            "token_id": 11,
            "logprob": -0.0444,
            "prob": 0.957
          },
          {
            "token": "Ġde",
            "token_id": 409,
            "logprob": -3.2969,
            "prob": 0.0371
          },
          {
            "token": "Ġetc",
            "token_id": 4992,
            "logprob": -5.7812,
            "prob": 0.0031
          },
          {
            "token": "Ġet",
            "token_id": 1842,
            "logprob": -5.7812,
            "prob": 0.0031
          },
          {
            "token": "Ġpour",
            "token_id": 4914,
            "logprob": -9.1875,
            "prob": 0.0001
          },
          {
            "token": "Ġou",
            "token_id": 5908,
            "logprob": -9.9375,
            "prob": 0.0
          },
          {
            "token": "Ġd",
            "token_id": 294,
            "logprob": -11.1875,
            "prob": 0.0
          },
          {
            "token": "Ġvidéo",
            "token_id": 56046,
            "logprob": -11.4375,
            "prob": 0.0
          },
          {
            "token": "Ġdes",
            "token_id": 939,
            "logprob": -12.8125,
            "prob": 0.0
          },
          {
            "token": "Ġcinéma",
            "token_id": 143377,
            "logprob": -13.0625,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": ",",
        "token_id": 11,
        "selection_method": "sampling"
      }
    },
    {
      "step": 54,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires, des documents officiels, des e-mails, des scripts,",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ",",
        "Ġdes",
        "Ġdocuments",
        "Ġoffic",
        "i",
        "els",
        ",",
        "Ġdes",
        "Ġe",
        "-mails",
        ",",
        "Ġdes",
        "Ġscripts",
        ","
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11,
        939,
        9293,
        2786,
        72,
        2010,
        11,
        939,
        384,
        60220,
        11,
        939,
        19502,
        11
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġetc",
            "token_id": 4992,
            "logprob": -0.2227,
            "prob": 0.8008
          },
          {
            "token": "Ġet",
            "token_id": 1842,
            "logprob": -2.3438,
            "prob": 0.0957
          },
          {
            "token": "Ġdes",
            "token_id": 939,
            "logprob": -3.0938,
            "prob": 0.0452
          },
          {
            "token": "Ġexpr",
            "token_id": 15169,
            "logprob": -3.3438,
            "prob": 0.0352
          },
          {
            "token": "Ġentre",
            "token_id": 9281,
            "logprob": -5.0938,
            "prob": 0.0061
          },
          {
            "token": "Ġainsi",
            "token_id": 43251,
            "logprob": -5.2188,
            "prob": 0.0054
          },
          {
            "token": "Ġfaire",
            "token_id": 19463,
            "logprob": -5.7188,
            "prob": 0.0033
          },
          {
            "token": "Ġeffect",
            "token_id": 2456,
            "logprob": -5.8438,
            "prob": 0.0029
          },
          {
            "token": "Ġde",
            "token_id": 409,
            "logprob": -6.9688,
            "prob": 0.0009
          },
          {
            "token": "Ġou",
            "token_id": 5908,
            "logprob": -7.0938,
            "prob": 0.0008
          }
        ]
      },
      "selected_token": {
        "token": "Ġetc",
        "token_id": 4992,
        "selection_method": "sampling"
      }
    },
    {
      "step": 55,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires, des documents officiels, des e-mails, des scripts, etc",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ",",
        "Ġdes",
        "Ġdocuments",
        "Ġoffic",
        "i",
        "els",
        ",",
        "Ġdes",
        "Ġe",
        "-mails",
        ",",
        "Ġdes",
        "Ġscripts",
        ",",
        "Ġetc"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11,
        939,
        9293,
        2786,
        72,
        2010,
        11,
        939,
        384,
        60220,
        11,
        939,
        19502,
        11,
        4992
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": ".,",
            "token_id": 2572,
            "logprob": -0.0002,
            "prob": 1.0
          },
          {
            "token": ".",
            "token_id": 13,
            "logprob": -8.75,
            "prob": 0.0002
          },
          {
            "token": ",",
            "token_id": 11,
            "logprob": -16.5,
            "prob": 0.0
          },
          {
            "token": ".;",
            "token_id": 15642,
            "logprob": -19.75,
            "prob": 0.0
          },
          {
            "token": ".*,",
            "token_id": 52816,
            "logprob": -20.375,
            "prob": 0.0
          },
          {
            "token": ".),",
            "token_id": 24389,
            "logprob": -20.875,
            "prob": 0.0
          },
          {
            "token": "..",
            "token_id": 496,
            "logprob": -21.125,
            "prob": 0.0
          },
          {
            "token": ".',",
            "token_id": 15670,
            "logprob": -22.375,
            "prob": 0.0
          },
          {
            "token": ".\",",
            "token_id": 10465,
            "logprob": -22.875,
            "prob": 0.0
          },
          {
            "token": "./",
            "token_id": 1725,
            "logprob": -24.25,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": ".,",
        "token_id": 2572,
        "selection_method": "sampling"
      }
    },
    {
      "step": 56,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires, des documents officiels, des e-mails, des scripts, etc.,",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ",",
        "Ġdes",
        "Ġdocuments",
        "Ġoffic",
        "i",
        "els",
        ",",
        "Ġdes",
        "Ġe",
        "-mails",
        ",",
        "Ġdes",
        "Ġscripts",
        ",",
        "Ġetc",
        ".,"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11,
        939,
        9293,
        2786,
        72,
        2010,
        11,
        939,
        384,
        60220,
        11,
        939,
        19502,
        11,
        4992,
        2572
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġeffect",
            "token_id": 2456,
            "logprob": -0.3887,
            "prob": 0.6797
          },
          {
            "token": "Ġainsi",
            "token_id": 43251,
            "logprob": -2.0156,
            "prob": 0.1338
          },
          {
            "token": "Ġet",
            "token_id": 1842,
            "logprob": -2.5156,
            "prob": 0.0811
          },
          {
            "token": "Ġréal",
            "token_id": 58057,
            "logprob": -2.7656,
            "prob": 0.063
          },
          {
            "token": "Ġou",
            "token_id": 5908,
            "logprob": -3.8906,
            "prob": 0.0205
          },
          {
            "token": "Ġfaire",
            "token_id": 19463,
            "logprob": -4.125,
            "prob": 0.016
          },
          {
            "token": "Ġtout",
            "token_id": 16559,
            "logprob": -6.0,
            "prob": 0.0024
          },
          {
            "token": "Ġex",
            "token_id": 505,
            "logprob": -7.125,
            "prob": 0.0008
          },
          {
            "token": "Ġaccompl",
            "token_id": 13089,
            "logprob": -7.25,
            "prob": 0.0007
          },
          {
            "token": "Ġprodu",
            "token_id": 2497,
            "logprob": -7.625,
            "prob": 0.0005
          }
        ]
      },
      "selected_token": {
        "token": "Ġeffect",
        "token_id": 2456,
        "selection_method": "sampling"
      }
    },
    {
      "step": 57,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires, des documents officiels, des e-mails, des scripts, etc., effect",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ",",
        "Ġdes",
        "Ġdocuments",
        "Ġoffic",
        "i",
        "els",
        ",",
        "Ġdes",
        "Ġe",
        "-mails",
        ",",
        "Ġdes",
        "Ġscripts",
        ",",
        "Ġetc",
        ".,",
        "Ġeffect"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11,
        939,
        9293,
        2786,
        72,
        2010,
        11,
        939,
        384,
        60220,
        11,
        939,
        19502,
        11,
        4992,
        2572,
        2456
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "uer",
            "token_id": 8801,
            "logprob": -0.0,
            "prob": 1.0
          },
          {
            "token": "uez",
            "token_id": 27600,
            "logprob": -15.875,
            "prob": 0.0
          },
          {
            "token": "uar",
            "token_id": 18731,
            "logprob": -17.375,
            "prob": 0.0
          },
          {
            "token": "ué",
            "token_id": 95459,
            "logprob": -17.5,
            "prob": 0.0
          },
          {
            "token": "ue",
            "token_id": 361,
            "logprob": -17.875,
            "prob": 0.0
          },
          {
            "token": "eur",
            "token_id": 12559,
            "logprob": -18.75,
            "prob": 0.0
          },
          {
            "token": "uant",
            "token_id": 27574,
            "logprob": -19.375,
            "prob": 0.0
          },
          {
            "token": "ivement",
            "token_id": 90540,
            "logprob": -20.75,
            "prob": 0.0
          },
          {
            "token": "er",
            "token_id": 261,
            "logprob": -20.875,
            "prob": 0.0
          },
          {
            "token": "ua",
            "token_id": 4284,
            "logprob": -21.5,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "uer",
        "token_id": 8801,
        "selection_method": "sampling"
      }
    },
    {
      "step": 58,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires, des documents officiels, des e-mails, des scripts, etc., effectuer",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ",",
        "Ġdes",
        "Ġdocuments",
        "Ġoffic",
        "i",
        "els",
        ",",
        "Ġdes",
        "Ġe",
        "-mails",
        ",",
        "Ġdes",
        "Ġscripts",
        ",",
        "Ġetc",
        ".,",
        "Ġeffect",
        "uer"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11,
        939,
        9293,
        2786,
        72,
        2010,
        11,
        939,
        384,
        60220,
        11,
        939,
        19502,
        11,
        4992,
        2572,
        2456,
        8801
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġdes",
            "token_id": 939,
            "logprob": -0.0096,
            "prob": 0.9922
          },
          {
            "token": "Ġdu",
            "token_id": 3845,
            "logprob": -5.0,
            "prob": 0.0067
          },
          {
            "token": "Ġde",
            "token_id": 409,
            "logprob": -6.125,
            "prob": 0.0022
          },
          {
            "token": "Ġla",
            "token_id": 1187,
            "logprob": -7.375,
            "prob": 0.0006
          },
          {
            "token": "Ġle",
            "token_id": 512,
            "logprob": -9.375,
            "prob": 0.0001
          },
          {
            "token": "Ġles",
            "token_id": 3541,
            "logprob": -11.0,
            "prob": 0.0
          },
          {
            "token": "Ġraison",
            "token_id": 72073,
            "logprob": -12.0,
            "prob": 0.0
          },
          {
            "token": "Ġl",
            "token_id": 326,
            "logprob": -12.25,
            "prob": 0.0
          },
          {
            "token": "Ġune",
            "token_id": 6185,
            "logprob": -12.5,
            "prob": 0.0
          },
          {
            "token": "Ġun",
            "token_id": 650,
            "logprob": -13.125,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġdes",
        "token_id": 939,
        "selection_method": "sampling"
      }
    },
    {
      "step": 59,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires, des documents officiels, des e-mails, des scripts, etc., effectuer des",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ",",
        "Ġdes",
        "Ġdocuments",
        "Ġoffic",
        "i",
        "els",
        ",",
        "Ġdes",
        "Ġe",
        "-mails",
        ",",
        "Ġdes",
        "Ġscripts",
        ",",
        "Ġetc",
        ".,",
        "Ġeffect",
        "uer",
        "Ġdes"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11,
        939,
        9293,
        2786,
        72,
        2010,
        11,
        939,
        384,
        60220,
        11,
        939,
        19502,
        11,
        4992,
        2572,
        2456,
        8801,
        939
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġrais",
            "token_id": 6369,
            "logprob": -0.0137,
            "prob": 0.9883
          },
          {
            "token": "Ġcalcul",
            "token_id": 5812,
            "logprob": -4.75,
            "prob": 0.0085
          },
          {
            "token": "Ġré",
            "token_id": 9333,
            "logprob": -5.875,
            "prob": 0.0028
          },
          {
            "token": "Ġraison",
            "token_id": 72073,
            "logprob": -6.375,
            "prob": 0.0017
          },
          {
            "token": "Ġr",
            "token_id": 435,
            "logprob": -8.125,
            "prob": 0.0003
          },
          {
            "token": "Ġrag",
            "token_id": 20475,
            "logprob": -9.875,
            "prob": 0.0001
          },
          {
            "token": "ĠCalcul",
            "token_id": 31359,
            "logprob": -10.25,
            "prob": 0.0
          },
          {
            "token": "Ġreason",
            "token_id": 2874,
            "logprob": -10.5,
            "prob": 0.0
          },
          {
            "token": "Ġrés",
            "token_id": 30707,
            "logprob": -10.75,
            "prob": 0.0
          },
          {
            "token": "raison",
            "token_id": 76503,
            "logprob": -10.875,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġrais",
        "token_id": 6369,
        "selection_method": "sampling"
      }
    },
    {
      "step": 60,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires, des documents officiels, des e-mails, des scripts, etc., effectuer des rais",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ",",
        "Ġdes",
        "Ġdocuments",
        "Ġoffic",
        "i",
        "els",
        ",",
        "Ġdes",
        "Ġe",
        "-mails",
        ",",
        "Ġdes",
        "Ġscripts",
        ",",
        "Ġetc",
        ".,",
        "Ġeffect",
        "uer",
        "Ġdes",
        "Ġrais"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11,
        939,
        9293,
        2786,
        72,
        2010,
        11,
        939,
        384,
        60220,
        11,
        939,
        19502,
        11,
        4992,
        2572,
        2456,
        8801,
        939,
        6369
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "onn",
            "token_id": 26378,
            "logprob": -0.0052,
            "prob": 0.9961
          },
          {
            "token": "onnement",
            "token_id": 89980,
            "logprob": -5.25,
            "prob": 0.0052
          },
          {
            "token": "ons",
            "token_id": 2382,
            "logprob": -12.0,
            "prob": 0.0
          },
          {
            "token": "oning",
            "token_id": 19744,
            "logprob": -12.75,
            "prob": 0.0
          },
          {
            "token": "onne",
            "token_id": 28952,
            "logprob": -13.0,
            "prob": 0.0
          },
          {
            "token": "on",
            "token_id": 263,
            "logprob": -14.375,
            "prob": 0.0
          },
          {
            "token": "onné",
            "token_id": 134824,
            "logprob": -15.125,
            "prob": 0.0
          },
          {
            "token": "он",
            "token_id": 17316,
            "logprob": -17.0,
            "prob": 0.0
          },
          {
            "token": "son",
            "token_id": 930,
            "logprob": -17.875,
            "prob": 0.0
          },
          {
            "token": "onna",
            "token_id": 13459,
            "logprob": -18.75,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "onn",
        "token_id": 26378,
        "selection_method": "sampling"
      }
    },
    {
      "step": 61,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires, des documents officiels, des e-mails, des scripts, etc., effectuer des raisonn",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ",",
        "Ġdes",
        "Ġdocuments",
        "Ġoffic",
        "i",
        "els",
        ",",
        "Ġdes",
        "Ġe",
        "-mails",
        ",",
        "Ġdes",
        "Ġscripts",
        ",",
        "Ġetc",
        ".,",
        "Ġeffect",
        "uer",
        "Ġdes",
        "Ġrais",
        "onn"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11,
        939,
        9293,
        2786,
        72,
        2010,
        11,
        939,
        384,
        60220,
        11,
        939,
        19502,
        11,
        4992,
        2572,
        2456,
        8801,
        939,
        6369,
        26378
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "ements",
            "token_id": 3723,
            "logprob": -0.0,
            "prob": 1.0
          },
          {
            "token": "ments",
            "token_id": 1368,
            "logprob": -12.5,
            "prob": 0.0
          },
          {
            "token": "ement",
            "token_id": 1114,
            "logprob": -15.75,
            "prob": 0.0
          },
          {
            "token": "em",
            "token_id": 336,
            "logprob": -16.5,
            "prob": 0.0
          },
          {
            "token": "eme",
            "token_id": 3894,
            "logprob": -16.875,
            "prob": 0.0
          },
          {
            "token": "ations",
            "token_id": 804,
            "logprob": -17.0,
            "prob": 0.0
          },
          {
            "token": "ants",
            "token_id": 1783,
            "logprob": -17.125,
            "prob": 0.0
          },
          {
            "token": "ings",
            "token_id": 819,
            "logprob": -17.25,
            "prob": 0.0
          },
          {
            "token": "emens",
            "token_id": 72737,
            "logprob": -17.375,
            "prob": 0.0
          },
          {
            "token": "ancements",
            "token_id": 38581,
            "logprob": -18.0,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "ements",
        "token_id": 3723,
        "selection_method": "sampling"
      }
    },
    {
      "step": 62,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires, des documents officiels, des e-mails, des scripts, etc., effectuer des raisonnements",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ",",
        "Ġdes",
        "Ġdocuments",
        "Ġoffic",
        "i",
        "els",
        ",",
        "Ġdes",
        "Ġe",
        "-mails",
        ",",
        "Ġdes",
        "Ġscripts",
        ",",
        "Ġetc",
        ".,",
        "Ġeffect",
        "uer",
        "Ġdes",
        "Ġrais",
        "onn",
        "ements"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11,
        939,
        9293,
        2786,
        72,
        2010,
        11,
        939,
        384,
        60220,
        11,
        939,
        19502,
        11,
        4992,
        2572,
        2456,
        8801,
        939,
        6369,
        26378,
        3723
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġlog",
            "token_id": 1487,
            "logprob": -0.0004,
            "prob": 1.0
          },
          {
            "token": "Ġmath",
            "token_id": 6888,
            "logprob": -8.625,
            "prob": 0.0002
          },
          {
            "token": ",",
            "token_id": 11,
            "logprob": -9.25,
            "prob": 0.0001
          },
          {
            "token": "log",
            "token_id": 839,
            "logprob": -10.0,
            "prob": 0.0
          },
          {
            "token": "Ġlogarith",
            "token_id": 89936,
            "logprob": -11.125,
            "prob": 0.0
          },
          {
            "token": "Ġlogs",
            "token_id": 18422,
            "logprob": -11.5,
            "prob": 0.0
          },
          {
            "token": "Ġlogic",
            "token_id": 12218,
            "logprob": -11.75,
            "prob": 0.0
          },
          {
            "token": "Ġet",
            "token_id": 1842,
            "logprob": -11.875,
            "prob": 0.0
          },
          {
            "token": "Ġcomplexes",
            "token_id": 68025,
            "logprob": -11.875,
            "prob": 0.0
          },
          {
            "token": "-log",
            "token_id": 46332,
            "logprob": -13.0,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġlog",
        "token_id": 1487,
        "selection_method": "sampling"
      }
    },
    {
      "step": 63,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires, des documents officiels, des e-mails, des scripts, etc., effectuer des raisonnements log",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ",",
        "Ġdes",
        "Ġdocuments",
        "Ġoffic",
        "i",
        "els",
        ",",
        "Ġdes",
        "Ġe",
        "-mails",
        ",",
        "Ġdes",
        "Ġscripts",
        ",",
        "Ġetc",
        ".,",
        "Ġeffect",
        "uer",
        "Ġdes",
        "Ġrais",
        "onn",
        "ements",
        "Ġlog"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11,
        939,
        9293,
        2786,
        72,
        2010,
        11,
        939,
        384,
        60220,
        11,
        939,
        19502,
        11,
        4992,
        2572,
        2456,
        8801,
        939,
        6369,
        26378,
        3723,
        1487
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "iques",
            "token_id": 8303,
            "logprob": -0.0002,
            "prob": 1.0
          },
          {
            "token": "ici",
            "token_id": 3375,
            "logprob": -8.75,
            "prob": 0.0002
          },
          {
            "token": "ique",
            "token_id": 2372,
            "logprob": -12.5,
            "prob": 0.0
          },
          {
            "token": "iqu",
            "token_id": 5011,
            "logprob": -14.375,
            "prob": 0.0
          },
          {
            "token": "iquement",
            "token_id": 80135,
            "logprob": -15.0,
            "prob": 0.0
          },
          {
            "token": "ico",
            "token_id": 3955,
            "logprob": -15.125,
            "prob": 0.0
          },
          {
            "token": "icos",
            "token_id": 16627,
            "logprob": -16.875,
            "prob": 0.0
          },
          {
            "token": "iq",
            "token_id": 23740,
            "logprob": -17.0,
            "prob": 0.0
          },
          {
            "token": "ics",
            "token_id": 1211,
            "logprob": -17.625,
            "prob": 0.0
          },
          {
            "token": "ich",
            "token_id": 713,
            "logprob": -18.5,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "iques",
        "token_id": 8303,
        "selection_method": "sampling"
      }
    },
    {
      "step": 64,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires, des documents officiels, des e-mails, des scripts, etc., effectuer des raisonnements logiques",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ",",
        "Ġdes",
        "Ġdocuments",
        "Ġoffic",
        "i",
        "els",
        ",",
        "Ġdes",
        "Ġe",
        "-mails",
        ",",
        "Ġdes",
        "Ġscripts",
        ",",
        "Ġetc",
        ".,",
        "Ġeffect",
        "uer",
        "Ġdes",
        "Ġrais",
        "onn",
        "ements",
        "Ġlog",
        "iques"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11,
        939,
        9293,
        2786,
        72,
        2010,
        11,
        939,
        384,
        60220,
        11,
        939,
        19502,
        11,
        4992,
        2572,
        2456,
        8801,
        939,
        6369,
        26378,
        3723,
        1487,
        8303
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": ",",
            "token_id": 11,
            "logprob": -0.0004,
            "prob": 1.0
          },
          {
            "token": "Ġet",
            "token_id": 1842,
            "logprob": -8.125,
            "prob": 0.0003
          },
          {
            "token": "Ġou",
            "token_id": 5908,
            "logprob": -10.375,
            "prob": 0.0
          },
          {
            "token": "Ġcomplexes",
            "token_id": 68025,
            "logprob": -10.375,
            "prob": 0.0
          },
          {
            "token": "Ġanaly",
            "token_id": 8510,
            "logprob": -12.375,
            "prob": 0.0
          },
          {
            "token": "Ġtout",
            "token_id": 16559,
            "logprob": -12.875,
            "prob": 0.0
          },
          {
            "token": "Ġcomple",
            "token_id": 1907,
            "logprob": -13.625,
            "prob": 0.0
          },
          {
            "token": "Ġ,",
            "token_id": 1154,
            "logprob": -13.625,
            "prob": 0.0
          },
          {
            "token": "Ġainsi",
            "token_id": 43251,
            "logprob": -13.875,
            "prob": 0.0
          },
          {
            "token": "Ġen",
            "token_id": 662,
            "logprob": -14.375,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": ",",
        "token_id": 11,
        "selection_method": "sampling"
      }
    },
    {
      "step": 65,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires, des documents officiels, des e-mails, des scripts, etc., effectuer des raisonnements logiques,",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ",",
        "Ġdes",
        "Ġdocuments",
        "Ġoffic",
        "i",
        "els",
        ",",
        "Ġdes",
        "Ġe",
        "-mails",
        ",",
        "Ġdes",
        "Ġscripts",
        ",",
        "Ġetc",
        ".,",
        "Ġeffect",
        "uer",
        "Ġdes",
        "Ġrais",
        "onn",
        "ements",
        "Ġlog",
        "iques",
        ","
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11,
        939,
        9293,
        2786,
        72,
        2010,
        11,
        939,
        384,
        60220,
        11,
        939,
        19502,
        11,
        4992,
        2572,
        2456,
        8801,
        939,
        6369,
        26378,
        3723,
        1487,
        8303,
        11
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġprogrammer",
            "token_id": 47788,
            "logprob": -0.457,
            "prob": 0.6328
          },
          {
            "token": "Ġdes",
            "token_id": 939,
            "logprob": -1.7031,
            "prob": 0.1816
          },
          {
            "token": "Ġrés",
            "token_id": 30707,
            "logprob": -2.7031,
            "prob": 0.0669
          },
          {
            "token": "Ġet",
            "token_id": 1842,
            "logprob": -3.2031,
            "prob": 0.0405
          },
          {
            "token": "Ġeffect",
            "token_id": 2456,
            "logprob": -3.4531,
            "prob": 0.0315
          },
          {
            "token": "Ġdu",
            "token_id": 3845,
            "logprob": -4.5938,
            "prob": 0.0103
          },
          {
            "token": "Ġcoder",
            "token_id": 83542,
            "logprob": -4.9688,
            "prob": 0.007
          },
          {
            "token": "Ġde",
            "token_id": 409,
            "logprob": -5.5938,
            "prob": 0.0038
          },
          {
            "token": "Ġré",
            "token_id": 9333,
            "logprob": -6.0938,
            "prob": 0.0023
          },
          {
            "token": "Ġfaire",
            "token_id": 19463,
            "logprob": -6.2188,
            "prob": 0.002
          }
        ]
      },
      "selected_token": {
        "token": "Ġprogrammer",
        "token_id": 47788,
        "selection_method": "sampling"
      }
    },
    {
      "step": 66,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires, des documents officiels, des e-mails, des scripts, etc., effectuer des raisonnements logiques, programmer",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ",",
        "Ġdes",
        "Ġdocuments",
        "Ġoffic",
        "i",
        "els",
        ",",
        "Ġdes",
        "Ġe",
        "-mails",
        ",",
        "Ġdes",
        "Ġscripts",
        ",",
        "Ġetc",
        ".,",
        "Ġeffect",
        "uer",
        "Ġdes",
        "Ġrais",
        "onn",
        "ements",
        "Ġlog",
        "iques",
        ",",
        "Ġprogrammer"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11,
        939,
        9293,
        2786,
        72,
        2010,
        11,
        939,
        384,
        60220,
        11,
        939,
        19502,
        11,
        4992,
        2572,
        2456,
        8801,
        939,
        6369,
        26378,
        3723,
        1487,
        8303,
        11,
        47788
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": ",",
            "token_id": 11,
            "logprob": -0.4004,
            "prob": 0.6719
          },
          {
            "token": "Ġet",
            "token_id": 1842,
            "logprob": -1.1484,
            "prob": 0.3164
          },
          {
            "token": "Ġen",
            "token_id": 662,
            "logprob": -5.4062,
            "prob": 0.0045
          },
          {
            "token": "Ġainsi",
            "token_id": 43251,
            "logprob": -5.5312,
            "prob": 0.004
          },
          {
            "token": "Ġdans",
            "token_id": 6866,
            "logprob": -6.1562,
            "prob": 0.0021
          },
          {
            "token": "Ġdes",
            "token_id": 939,
            "logprob": -7.0312,
            "prob": 0.0009
          },
          {
            "token": "Ġou",
            "token_id": 5908,
            "logprob": -7.5312,
            "prob": 0.0005
          },
          {
            "token": "Ġde",
            "token_id": 409,
            "logprob": -8.125,
            "prob": 0.0003
          },
          {
            "token": "Ġetc",
            "token_id": 4992,
            "logprob": -8.75,
            "prob": 0.0002
          },
          {
            "token": "Ġtout",
            "token_id": 16559,
            "logprob": -9.0,
            "prob": 0.0001
          }
        ]
      },
      "selected_token": {
        "token": ",",
        "token_id": 11,
        "selection_method": "sampling"
      }
    },
    {
      "step": 67,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires, des documents officiels, des e-mails, des scripts, etc., effectuer des raisonnements logiques, programmer,",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ",",
        "Ġdes",
        "Ġdocuments",
        "Ġoffic",
        "i",
        "els",
        ",",
        "Ġdes",
        "Ġe",
        "-mails",
        ",",
        "Ġdes",
        "Ġscripts",
        ",",
        "Ġetc",
        ".,",
        "Ġeffect",
        "uer",
        "Ġdes",
        "Ġrais",
        "onn",
        "ements",
        "Ġlog",
        "iques",
        ",",
        "Ġprogrammer",
        ","
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11,
        939,
        9293,
        2786,
        72,
        2010,
        11,
        939,
        384,
        60220,
        11,
        939,
        19502,
        11,
        4992,
        2572,
        2456,
        8801,
        939,
        6369,
        26378,
        3723,
        1487,
        8303,
        11,
        47788,
        11
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġet",
            "token_id": 1842,
            "logprob": -0.0459,
            "prob": 0.957
          },
          {
            "token": "Ġexpr",
            "token_id": 15169,
            "logprob": -3.5469,
            "prob": 0.0288
          },
          {
            "token": "Ġainsi",
            "token_id": 43251,
            "logprob": -4.7812,
            "prob": 0.0082
          },
          {
            "token": "Ġou",
            "token_id": 5908,
            "logprob": -5.6562,
            "prob": 0.0034
          },
          {
            "token": "Ġetc",
            "token_id": 4992,
            "logprob": -5.9062,
            "prob": 0.0027
          },
          {
            "token": "Ġpuis",
            "token_id": 43729,
            "logprob": -8.0625,
            "prob": 0.0003
          },
          {
            "token": "Ġeffect",
            "token_id": 2456,
            "logprob": -8.1875,
            "prob": 0.0003
          },
          {
            "token": "Ġbien",
            "token_id": 14370,
            "logprob": -8.5625,
            "prob": 0.0002
          },
          {
            "token": "Ġfaire",
            "token_id": 19463,
            "logprob": -9.875,
            "prob": 0.0001
          },
          {
            "token": "Ġé",
            "token_id": 3958,
            "logprob": -10.0,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġet",
        "token_id": 1842,
        "selection_method": "sampling"
      }
    },
    {
      "step": 68,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires, des documents officiels, des e-mails, des scripts, etc., effectuer des raisonnements logiques, programmer, et",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ",",
        "Ġdes",
        "Ġdocuments",
        "Ġoffic",
        "i",
        "els",
        ",",
        "Ġdes",
        "Ġe",
        "-mails",
        ",",
        "Ġdes",
        "Ġscripts",
        ",",
        "Ġetc",
        ".,",
        "Ġeffect",
        "uer",
        "Ġdes",
        "Ġrais",
        "onn",
        "ements",
        "Ġlog",
        "iques",
        ",",
        "Ġprogrammer",
        ",",
        "Ġet"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11,
        939,
        9293,
        2786,
        72,
        2010,
        11,
        939,
        384,
        60220,
        11,
        939,
        19502,
        11,
        4992,
        2572,
        2456,
        8801,
        939,
        6369,
        26378,
        3723,
        1487,
        8303,
        11,
        47788,
        11,
        1842
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġmême",
            "token_id": 26486,
            "logprob": -0.0703,
            "prob": 0.9336
          },
          {
            "token": "Ġbien",
            "token_id": 14370,
            "logprob": -3.4375,
            "prob": 0.032
          },
          {
            "token": "Ġplus",
            "token_id": 5519,
            "logprob": -3.9375,
            "prob": 0.0194
          },
          {
            "token": "Ġd",
            "token_id": 294,
            "logprob": -4.6875,
            "prob": 0.0092
          },
          {
            "token": "Ġencore",
            "token_id": 34497,
            "logprob": -6.5625,
            "prob": 0.0014
          },
          {
            "token": "Ġje",
            "token_id": 4759,
            "logprob": -6.8125,
            "prob": 0.0011
          },
          {
            "token": "Ġaussi",
            "token_id": 27363,
            "logprob": -7.0625,
            "prob": 0.0009
          },
          {
            "token": "Ġeffect",
            "token_id": 2456,
            "logprob": -7.4375,
            "prob": 0.0006
          },
          {
            "token": "Ġsupporter",
            "token_id": 36463,
            "logprob": -7.6875,
            "prob": 0.0005
          },
          {
            "token": "Ġbeaucoup",
            "token_id": 47388,
            "logprob": -8.0,
            "prob": 0.0003
          }
        ]
      },
      "selected_token": {
        "token": "Ġmême",
        "token_id": 26486,
        "selection_method": "sampling"
      }
    },
    {
      "step": 69,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires, des documents officiels, des e-mails, des scripts, etc., effectuer des raisonnements logiques, programmer, et même",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ",",
        "Ġdes",
        "Ġdocuments",
        "Ġoffic",
        "i",
        "els",
        ",",
        "Ġdes",
        "Ġe",
        "-mails",
        ",",
        "Ġdes",
        "Ġscripts",
        ",",
        "Ġetc",
        ".,",
        "Ġeffect",
        "uer",
        "Ġdes",
        "Ġrais",
        "onn",
        "ements",
        "Ġlog",
        "iques",
        ",",
        "Ġprogrammer",
        ",",
        "Ġet",
        "Ġmême"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11,
        939,
        9293,
        2786,
        72,
        2010,
        11,
        939,
        384,
        60220,
        11,
        939,
        19502,
        11,
        4992,
        2572,
        2456,
        8801,
        939,
        6369,
        26378,
        3723,
        1487,
        8303,
        11,
        47788,
        11,
        1842,
        26486
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġjouer",
            "token_id": 99096,
            "logprob": -0.0137,
            "prob": 0.9883
          },
          {
            "token": "Ġexpr",
            "token_id": 15169,
            "logprob": -5.375,
            "prob": 0.0046
          },
          {
            "token": "Ġjeux",
            "token_id": 69075,
            "logprob": -5.75,
            "prob": 0.0031
          },
          {
            "token": "Ġjeu",
            "token_id": 50555,
            "logprob": -6.75,
            "prob": 0.0012
          },
          {
            "token": "Ġeffect",
            "token_id": 2456,
            "logprob": -6.875,
            "prob": 0.001
          },
          {
            "token": "Ġfaire",
            "token_id": 19463,
            "logprob": -7.75,
            "prob": 0.0004
          },
          {
            "token": "Ġcomprend",
            "token_id": 59846,
            "logprob": -7.875,
            "prob": 0.0004
          },
          {
            "token": "Ġjoueur",
            "token_id": 75949,
            "logprob": -8.4375,
            "prob": 0.0002
          },
          {
            "token": "Ġjou",
            "token_id": 26970,
            "logprob": -8.5625,
            "prob": 0.0002
          },
          {
            "token": "Ġex",
            "token_id": 505,
            "logprob": -8.75,
            "prob": 0.0002
          }
        ]
      },
      "selected_token": {
        "token": "Ġjouer",
        "token_id": 99096,
        "selection_method": "sampling"
      }
    },
    {
      "step": 70,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires, des documents officiels, des e-mails, des scripts, etc., effectuer des raisonnements logiques, programmer, et même jouer",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ",",
        "Ġdes",
        "Ġdocuments",
        "Ġoffic",
        "i",
        "els",
        ",",
        "Ġdes",
        "Ġe",
        "-mails",
        ",",
        "Ġdes",
        "Ġscripts",
        ",",
        "Ġetc",
        ".,",
        "Ġeffect",
        "uer",
        "Ġdes",
        "Ġrais",
        "onn",
        "ements",
        "Ġlog",
        "iques",
        ",",
        "Ġprogrammer",
        ",",
        "Ġet",
        "Ġmême",
        "Ġjouer"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11,
        939,
        9293,
        2786,
        72,
        2010,
        11,
        939,
        384,
        60220,
        11,
        939,
        19502,
        11,
        4992,
        2572,
        2456,
        8801,
        939,
        6369,
        26378,
        3723,
        1487,
        8303,
        11,
        47788,
        11,
        1842,
        26486,
        99096
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġà",
            "token_id": 3784,
            "logprob": -0.127,
            "prob": 0.8789
          },
          {
            "token": "Ġaux",
            "token_id": 10047,
            "logprob": -2.125,
            "prob": 0.1191
          },
          {
            "token": "Ġde",
            "token_id": 409,
            "logprob": -8.375,
            "prob": 0.0002
          },
          {
            "token": "Ġau",
            "token_id": 7906,
            "logprob": -9.75,
            "prob": 0.0001
          },
          {
            "token": "Ġavec",
            "token_id": 9753,
            "logprob": -10.75,
            "prob": 0.0
          },
          {
            "token": "Ġdes",
            "token_id": 939,
            "logprob": -11.125,
            "prob": 0.0
          },
          {
            "token": "Ġa",
            "token_id": 264,
            "logprob": -11.375,
            "prob": 0.0
          },
          {
            "token": ".",
            "token_id": 13,
            "logprob": -12.625,
            "prob": 0.0
          },
          {
            "token": "Ġen",
            "token_id": 662,
            "logprob": -13.0,
            "prob": 0.0
          },
          {
            "token": "à",
            "token_id": 6362,
            "logprob": -13.125,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġà",
        "token_id": 3784,
        "selection_method": "sampling"
      }
    },
    {
      "step": 71,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires, des documents officiels, des e-mails, des scripts, etc., effectuer des raisonnements logiques, programmer, et même jouer à",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ",",
        "Ġdes",
        "Ġdocuments",
        "Ġoffic",
        "i",
        "els",
        ",",
        "Ġdes",
        "Ġe",
        "-mails",
        ",",
        "Ġdes",
        "Ġscripts",
        ",",
        "Ġetc",
        ".,",
        "Ġeffect",
        "uer",
        "Ġdes",
        "Ġrais",
        "onn",
        "ements",
        "Ġlog",
        "iques",
        ",",
        "Ġprogrammer",
        ",",
        "Ġet",
        "Ġmême",
        "Ġjouer",
        "Ġà"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11,
        939,
        9293,
        2786,
        72,
        2010,
        11,
        939,
        384,
        60220,
        11,
        939,
        19502,
        11,
        4992,
        2572,
        2456,
        8801,
        939,
        6369,
        26378,
        3723,
        1487,
        8303,
        11,
        47788,
        11,
        1842,
        26486,
        99096,
        3784
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġdes",
            "token_id": 939,
            "logprob": -0.0001,
            "prob": 1.0
          },
          {
            "token": "Ġjeux",
            "token_id": 69075,
            "logprob": -9.375,
            "prob": 0.0001
          },
          {
            "token": "Ġdivers",
            "token_id": 21113,
            "logprob": -11.25,
            "prob": 0.0
          },
          {
            "token": "Ġjouer",
            "token_id": 99096,
            "logprob": -12.625,
            "prob": 0.0
          },
          {
            "token": "des",
            "token_id": 5799,
            "logprob": -12.625,
            "prob": 0.0
          },
          {
            "token": "-des",
            "token_id": 24506,
            "logprob": -13.125,
            "prob": 0.0
          },
          {
            "token": "Ġjeu",
            "token_id": 50555,
            "logprob": -13.125,
            "prob": 0.0
          },
          {
            "token": "Ġcertains",
            "token_id": 74976,
            "logprob": -13.8125,
            "prob": 0.0
          },
          {
            "token": "Ġde",
            "token_id": 409,
            "logprob": -14.5,
            "prob": 0.0
          },
          {
            "token": "ĠDes",
            "token_id": 3874,
            "logprob": -14.6875,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġdes",
        "token_id": 939,
        "selection_method": "sampling"
      }
    },
    {
      "step": 72,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires, des documents officiels, des e-mails, des scripts, etc., effectuer des raisonnements logiques, programmer, et même jouer à des",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ",",
        "Ġdes",
        "Ġdocuments",
        "Ġoffic",
        "i",
        "els",
        ",",
        "Ġdes",
        "Ġe",
        "-mails",
        ",",
        "Ġdes",
        "Ġscripts",
        ",",
        "Ġetc",
        ".,",
        "Ġeffect",
        "uer",
        "Ġdes",
        "Ġrais",
        "onn",
        "ements",
        "Ġlog",
        "iques",
        ",",
        "Ġprogrammer",
        ",",
        "Ġet",
        "Ġmême",
        "Ġjouer",
        "Ġà",
        "Ġdes"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11,
        939,
        9293,
        2786,
        72,
        2010,
        11,
        939,
        384,
        60220,
        11,
        939,
        19502,
        11,
        4992,
        2572,
        2456,
        8801,
        939,
        6369,
        26378,
        3723,
        1487,
        8303,
        11,
        47788,
        11,
        1842,
        26486,
        99096,
        3784,
        939
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġjeux",
            "token_id": 69075,
            "logprob": -0.0002,
            "prob": 1.0
          },
          {
            "token": "Ġgames",
            "token_id": 3868,
            "logprob": -9.375,
            "prob": 0.0001
          },
          {
            "token": "ĠJe",
            "token_id": 14133,
            "logprob": -10.125,
            "prob": 0.0
          },
          {
            "token": "je",
            "token_id": 3756,
            "logprob": -11.125,
            "prob": 0.0
          },
          {
            "token": "Ġparties",
            "token_id": 9677,
            "logprob": -11.5,
            "prob": 0.0
          },
          {
            "token": "Ġjeu",
            "token_id": 50555,
            "logprob": -12.125,
            "prob": 0.0
          },
          {
            "token": "Je",
            "token_id": 29754,
            "logprob": -12.875,
            "prob": 0.0
          },
          {
            "token": "Ġé",
            "token_id": 3958,
            "logprob": -13.0,
            "prob": 0.0
          },
          {
            "token": "Ġquizzes",
            "token_id": 88223,
            "logprob": -13.8125,
            "prob": 0.0
          },
          {
            "token": "Ġqu",
            "token_id": 922,
            "logprob": -14.1875,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġjeux",
        "token_id": 69075,
        "selection_method": "sampling"
      }
    },
    {
      "step": 73,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires, des documents officiels, des e-mails, des scripts, etc., effectuer des raisonnements logiques, programmer, et même jouer à des jeux",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ",",
        "Ġdes",
        "Ġdocuments",
        "Ġoffic",
        "i",
        "els",
        ",",
        "Ġdes",
        "Ġe",
        "-mails",
        ",",
        "Ġdes",
        "Ġscripts",
        ",",
        "Ġetc",
        ".,",
        "Ġeffect",
        "uer",
        "Ġdes",
        "Ġrais",
        "onn",
        "ements",
        "Ġlog",
        "iques",
        ",",
        "Ġprogrammer",
        ",",
        "Ġet",
        "Ġmême",
        "Ġjouer",
        "Ġà",
        "Ġdes",
        "Ġjeux"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11,
        939,
        9293,
        2786,
        72,
        2010,
        11,
        939,
        384,
        60220,
        11,
        939,
        19502,
        11,
        4992,
        2572,
        2456,
        8801,
        939,
        6369,
        26378,
        3723,
        1487,
        8303,
        11,
        47788,
        11,
        1842,
        26486,
        99096,
        3784,
        939,
        69075
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": ".",
            "token_id": 13,
            "logprob": -0.0002,
            "prob": 1.0
          },
          {
            "token": "Ġ!",
            "token_id": 753,
            "logprob": -8.625,
            "prob": 0.0002
          },
          {
            "token": "Ġde",
            "token_id": 409,
            "logprob": -11.25,
            "prob": 0.0
          },
          {
            "token": "Ġcomme",
            "token_id": 21572,
            "logprob": -11.375,
            "prob": 0.0
          },
          {
            "token": ",",
            "token_id": 11,
            "logprob": -11.75,
            "prob": 0.0
          },
          {
            "token": "Ġou",
            "token_id": 5908,
            "logprob": -13.5,
            "prob": 0.0
          },
          {
            "token": "!",
            "token_id": 0,
            "logprob": -13.75,
            "prob": 0.0
          },
          {
            "token": "Ġd",
            "token_id": 294,
            "logprob": -14.625,
            "prob": 0.0
          },
          {
            "token": "Ġdans",
            "token_id": 6866,
            "logprob": -15.125,
            "prob": 0.0
          },
          {
            "token": ".\n\n",
            "token_id": 382,
            "logprob": -15.625,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": ".",
        "token_id": 13,
        "selection_method": "sampling"
      }
    },
    {
      "step": 74,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires, des documents officiels, des e-mails, des scripts, etc., effectuer des raisonnements logiques, programmer, et même jouer à des jeux.",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ",",
        "Ġdes",
        "Ġdocuments",
        "Ġoffic",
        "i",
        "els",
        ",",
        "Ġdes",
        "Ġe",
        "-mails",
        ",",
        "Ġdes",
        "Ġscripts",
        ",",
        "Ġetc",
        ".,",
        "Ġeffect",
        "uer",
        "Ġdes",
        "Ġrais",
        "onn",
        "ements",
        "Ġlog",
        "iques",
        ",",
        "Ġprogrammer",
        ",",
        "Ġet",
        "Ġmême",
        "Ġjouer",
        "Ġà",
        "Ġdes",
        "Ġjeux",
        "."
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11,
        939,
        9293,
        2786,
        72,
        2010,
        11,
        939,
        384,
        60220,
        11,
        939,
        19502,
        11,
        4992,
        2572,
        2456,
        8801,
        939,
        6369,
        26378,
        3723,
        1487,
        8303,
        11,
        47788,
        11,
        1842,
        26486,
        99096,
        3784,
        939,
        69075,
        13
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "ĠN",
            "token_id": 451,
            "logprob": -0.9961,
            "prob": 0.3691
          },
          {
            "token": "ĠJe",
            "token_id": 14133,
            "logprob": -1.1172,
            "prob": 0.3262
          },
          {
            "token": "ĠSi",
            "token_id": 11832,
            "logprob": -1.4922,
            "prob": 0.2246
          },
          {
            "token": "ĠQue",
            "token_id": 9418,
            "logprob": -3.0,
            "prob": 0.05
          },
          {
            "token": "ĠQu",
            "token_id": 3406,
            "logprob": -4.875,
            "prob": 0.0077
          },
          {
            "token": "ĠEn",
            "token_id": 2925,
            "logprob": -5.25,
            "prob": 0.0053
          },
          {
            "token": "ĠMon",
            "token_id": 3128,
            "logprob": -5.875,
            "prob": 0.0028
          },
          {
            "token": "ĠPour",
            "token_id": 25968,
            "logprob": -6.125,
            "prob": 0.0022
          },
          {
            "token": "ĠEt",
            "token_id": 18888,
            "logprob": -6.5,
            "prob": 0.0015
          },
          {
            "token": "ĠVous",
            "token_id": 40521,
            "logprob": -6.75,
            "prob": 0.0012
          }
        ]
      },
      "selected_token": {
        "token": "ĠN",
        "token_id": 451,
        "selection_method": "sampling"
      }
    },
    {
      "step": 75,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires, des documents officiels, des e-mails, des scripts, etc., effectuer des raisonnements logiques, programmer, et même jouer à des jeux. N",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ",",
        "Ġdes",
        "Ġdocuments",
        "Ġoffic",
        "i",
        "els",
        ",",
        "Ġdes",
        "Ġe",
        "-mails",
        ",",
        "Ġdes",
        "Ġscripts",
        ",",
        "Ġetc",
        ".,",
        "Ġeffect",
        "uer",
        "Ġdes",
        "Ġrais",
        "onn",
        "ements",
        "Ġlog",
        "iques",
        ",",
        "Ġprogrammer",
        ",",
        "Ġet",
        "Ġmême",
        "Ġjouer",
        "Ġà",
        "Ġdes",
        "Ġjeux",
        ".",
        "ĠN"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11,
        939,
        9293,
        2786,
        72,
        2010,
        11,
        939,
        384,
        60220,
        11,
        939,
        19502,
        11,
        4992,
        2572,
        2456,
        8801,
        939,
        6369,
        26378,
        3723,
        1487,
        8303,
        11,
        47788,
        11,
        1842,
        26486,
        99096,
        3784,
        939,
        69075,
        13,
        451
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "'h",
            "token_id": 38882,
            "logprob": -0.2891,
            "prob": 0.75
          },
          {
            "token": "'",
            "token_id": 6,
            "logprob": -1.4141,
            "prob": 0.2432
          },
          {
            "token": "’h",
            "token_id": 57286,
            "logprob": -5.2812,
            "prob": 0.005
          },
          {
            "token": "’",
            "token_id": 527,
            "logprob": -6.6562,
            "prob": 0.0013
          },
          {
            "token": "é",
            "token_id": 963,
            "logprob": -7.9062,
            "prob": 0.0004
          },
          {
            "token": "importe",
            "token_id": 93796,
            "logprob": -9.0625,
            "prob": 0.0001
          },
          {
            "token": "'est",
            "token_id": 17321,
            "logprob": -9.1875,
            "prob": 0.0001
          },
          {
            "token": "'ét",
            "token_id": 56186,
            "logprob": -9.9375,
            "prob": 0.0
          },
          {
            "token": "iveau",
            "token_id": 39219,
            "logprob": -10.0625,
            "prob": 0.0
          },
          {
            "token": "'H",
            "token_id": 66970,
            "logprob": -10.3125,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "'",
        "token_id": 6,
        "selection_method": "sampling"
      }
    },
    {
      "step": 76,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires, des documents officiels, des e-mails, des scripts, etc., effectuer des raisonnements logiques, programmer, et même jouer à des jeux. N'",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ",",
        "Ġdes",
        "Ġdocuments",
        "Ġoffic",
        "i",
        "els",
        ",",
        "Ġdes",
        "Ġe",
        "-mails",
        ",",
        "Ġdes",
        "Ġscripts",
        ",",
        "Ġetc",
        ".,",
        "Ġeffect",
        "uer",
        "Ġdes",
        "Ġrais",
        "onn",
        "ements",
        "Ġlog",
        "iques",
        ",",
        "Ġprogrammer",
        ",",
        "Ġet",
        "Ġmême",
        "Ġjouer",
        "Ġà",
        "Ġdes",
        "Ġjeux",
        ".",
        "ĠN",
        "'"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11,
        939,
        9293,
        2786,
        72,
        2010,
        11,
        939,
        384,
        60220,
        11,
        939,
        19502,
        11,
        4992,
        2572,
        2456,
        8801,
        939,
        6369,
        26378,
        3723,
        1487,
        8303,
        11,
        47788,
        11,
        1842,
        26486,
        99096,
        3784,
        939,
        69075,
        13,
        451,
        6
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "importe",
            "token_id": 93796,
            "logprob": -0.3008,
            "prob": 0.7383
          },
          {
            "token": "ou",
            "token_id": 283,
            "logprob": -1.4297,
            "prob": 0.2402
          },
          {
            "token": "hes",
            "token_id": 16668,
            "logprob": -4.1875,
            "prob": 0.0154
          },
          {
            "token": "ay",
            "token_id": 352,
            "logprob": -6.0625,
            "prob": 0.0023
          },
          {
            "token": "import",
            "token_id": 474,
            "logprob": -7.1875,
            "prob": 0.0008
          },
          {
            "token": "attend",
            "token_id": 56458,
            "logprob": -7.3125,
            "prob": 0.0007
          },
          {
            "token": "att",
            "token_id": 1587,
            "logprob": -9.4375,
            "prob": 0.0001
          },
          {
            "token": "hs",
            "token_id": 4997,
            "logprob": -9.6875,
            "prob": 0.0001
          },
          {
            "token": "avez",
            "token_id": 51559,
            "logprob": -9.8125,
            "prob": 0.0001
          },
          {
            "token": "hu",
            "token_id": 16739,
            "logprob": -9.875,
            "prob": 0.0001
          }
        ]
      },
      "selected_token": {
        "token": "importe",
        "token_id": 93796,
        "selection_method": "sampling"
      }
    },
    {
      "step": 77,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires, des documents officiels, des e-mails, des scripts, etc., effectuer des raisonnements logiques, programmer, et même jouer à des jeux. N'importe",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ",",
        "Ġdes",
        "Ġdocuments",
        "Ġoffic",
        "i",
        "els",
        ",",
        "Ġdes",
        "Ġe",
        "-mails",
        ",",
        "Ġdes",
        "Ġscripts",
        ",",
        "Ġetc",
        ".,",
        "Ġeffect",
        "uer",
        "Ġdes",
        "Ġrais",
        "onn",
        "ements",
        "Ġlog",
        "iques",
        ",",
        "Ġprogrammer",
        ",",
        "Ġet",
        "Ġmême",
        "Ġjouer",
        "Ġà",
        "Ġdes",
        "Ġjeux",
        ".",
        "ĠN",
        "'",
        "importe"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11,
        939,
        9293,
        2786,
        72,
        2010,
        11,
        939,
        384,
        60220,
        11,
        939,
        19502,
        11,
        4992,
        2572,
        2456,
        8801,
        939,
        6369,
        26378,
        3723,
        1487,
        8303,
        11,
        47788,
        11,
        1842,
        26486,
        99096,
        3784,
        939,
        69075,
        13,
        451,
        6,
        93796
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġquelle",
            "token_id": 73840,
            "logprob": -0.3887,
            "prob": 0.6797
          },
          {
            "token": "Ġquel",
            "token_id": 25025,
            "logprob": -1.1406,
            "prob": 0.3203
          },
          {
            "token": "Ġquoi",
            "token_id": 74149,
            "logprob": -7.125,
            "prob": 0.0008
          },
          {
            "token": "quelle",
            "token_id": 87165,
            "logprob": -11.5,
            "prob": 0.0
          },
          {
            "token": "Ġqu",
            "token_id": 922,
            "logprob": -11.5,
            "prob": 0.0
          },
          {
            "token": "Ġwhich",
            "token_id": 892,
            "logprob": -12.125,
            "prob": 0.0
          },
          {
            "token": "Ġqui",
            "token_id": 7774,
            "logprob": -12.25,
            "prob": 0.0
          },
          {
            "token": "哪",
            "token_id": 99459,
            "logprob": -12.375,
            "prob": 0.0
          },
          {
            "token": "Ġoù",
            "token_id": 38623,
            "logprob": -12.625,
            "prob": 0.0
          },
          {
            "token": "Ġquand",
            "token_id": 41576,
            "logprob": -12.875,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġquelle",
        "token_id": 73840,
        "selection_method": "sampling"
      }
    },
    {
      "step": 78,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires, des documents officiels, des e-mails, des scripts, etc., effectuer des raisonnements logiques, programmer, et même jouer à des jeux. N'importe quelle",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ",",
        "Ġdes",
        "Ġdocuments",
        "Ġoffic",
        "i",
        "els",
        ",",
        "Ġdes",
        "Ġe",
        "-mails",
        ",",
        "Ġdes",
        "Ġscripts",
        ",",
        "Ġetc",
        ".,",
        "Ġeffect",
        "uer",
        "Ġdes",
        "Ġrais",
        "onn",
        "ements",
        "Ġlog",
        "iques",
        ",",
        "Ġprogrammer",
        ",",
        "Ġet",
        "Ġmême",
        "Ġjouer",
        "Ġà",
        "Ġdes",
        "Ġjeux",
        ".",
        "ĠN",
        "'",
        "importe",
        "Ġquelle"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11,
        939,
        9293,
        2786,
        72,
        2010,
        11,
        939,
        384,
        60220,
        11,
        939,
        19502,
        11,
        4992,
        2572,
        2456,
        8801,
        939,
        6369,
        26378,
        3723,
        1487,
        8303,
        11,
        47788,
        11,
        1842,
        26486,
        99096,
        3784,
        939,
        69075,
        13,
        451,
        6,
        93796,
        73840
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġquestion",
            "token_id": 3405,
            "logprob": -0.0038,
            "prob": 0.9961
          },
          {
            "token": "Ġdemande",
            "token_id": 61063,
            "logprob": -6.0,
            "prob": 0.0025
          },
          {
            "token": "Ġchose",
            "token_id": 14554,
            "logprob": -8.0,
            "prob": 0.0003
          },
          {
            "token": "Ġaide",
            "token_id": 40575,
            "logprob": -8.125,
            "prob": 0.0003
          },
          {
            "token": "Ġautre",
            "token_id": 46738,
            "logprob": -8.5,
            "prob": 0.0002
          },
          {
            "token": "Ġinformation",
            "token_id": 1995,
            "logprob": -9.9375,
            "prob": 0.0
          },
          {
            "token": "Ġdifficulté",
            "token_id": 142370,
            "logprob": -10.125,
            "prob": 0.0
          },
          {
            "token": "Ġsituation",
            "token_id": 6534,
            "logprob": -10.1875,
            "prob": 0.0
          },
          {
            "token": "ĠQuestion",
            "token_id": 15846,
            "logprob": -10.25,
            "prob": 0.0
          },
          {
            "token": "question",
            "token_id": 7841,
            "logprob": -10.4375,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġquestion",
        "token_id": 3405,
        "selection_method": "sampling"
      }
    },
    {
      "step": 79,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires, des documents officiels, des e-mails, des scripts, etc., effectuer des raisonnements logiques, programmer, et même jouer à des jeux. N'importe quelle question",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ",",
        "Ġdes",
        "Ġdocuments",
        "Ġoffic",
        "i",
        "els",
        ",",
        "Ġdes",
        "Ġe",
        "-mails",
        ",",
        "Ġdes",
        "Ġscripts",
        ",",
        "Ġetc",
        ".,",
        "Ġeffect",
        "uer",
        "Ġdes",
        "Ġrais",
        "onn",
        "ements",
        "Ġlog",
        "iques",
        ",",
        "Ġprogrammer",
        ",",
        "Ġet",
        "Ġmême",
        "Ġjouer",
        "Ġà",
        "Ġdes",
        "Ġjeux",
        ".",
        "ĠN",
        "'",
        "importe",
        "Ġquelle",
        "Ġquestion"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11,
        939,
        9293,
        2786,
        72,
        2010,
        11,
        939,
        384,
        60220,
        11,
        939,
        19502,
        11,
        4992,
        2572,
        2456,
        8801,
        939,
        6369,
        26378,
        3723,
        1487,
        8303,
        11,
        47788,
        11,
        1842,
        26486,
        99096,
        3784,
        939,
        69075,
        13,
        451,
        6,
        93796,
        73840,
        3405
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġou",
            "token_id": 5908,
            "logprob": -0.123,
            "prob": 0.8828
          },
          {
            "token": ",",
            "token_id": 11,
            "logprob": -2.25,
            "prob": 0.1055
          },
          {
            "token": "Ġvous",
            "token_id": 9012,
            "logprob": -5.25,
            "prob": 0.0052
          },
          {
            "token": "Ġque",
            "token_id": 1709,
            "logprob": -5.375,
            "prob": 0.0046
          },
          {
            "token": "Ġpeut",
            "token_id": 24666,
            "logprob": -8.25,
            "prob": 0.0003
          },
          {
            "token": "Ġest",
            "token_id": 1788,
            "logprob": -9.625,
            "prob": 0.0001
          },
          {
            "token": "Ġà",
            "token_id": 3784,
            "logprob": -11.625,
            "prob": 0.0
          },
          {
            "token": "Ġsur",
            "token_id": 1729,
            "logprob": -12.25,
            "prob": 0.0
          },
          {
            "token": "Ġet",
            "token_id": 1842,
            "logprob": -12.25,
            "prob": 0.0
          },
          {
            "token": "Ġ!",
            "token_id": 753,
            "logprob": -12.375,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġou",
        "token_id": 5908,
        "selection_method": "sampling"
      }
    },
    {
      "step": 80,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires, des documents officiels, des e-mails, des scripts, etc., effectuer des raisonnements logiques, programmer, et même jouer à des jeux. N'importe quelle question ou",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ",",
        "Ġdes",
        "Ġdocuments",
        "Ġoffic",
        "i",
        "els",
        ",",
        "Ġdes",
        "Ġe",
        "-mails",
        ",",
        "Ġdes",
        "Ġscripts",
        ",",
        "Ġetc",
        ".,",
        "Ġeffect",
        "uer",
        "Ġdes",
        "Ġrais",
        "onn",
        "ements",
        "Ġlog",
        "iques",
        ",",
        "Ġprogrammer",
        ",",
        "Ġet",
        "Ġmême",
        "Ġjouer",
        "Ġà",
        "Ġdes",
        "Ġjeux",
        ".",
        "ĠN",
        "'",
        "importe",
        "Ġquelle",
        "Ġquestion",
        "Ġou"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11,
        939,
        9293,
        2786,
        72,
        2010,
        11,
        939,
        384,
        60220,
        11,
        939,
        19502,
        11,
        4992,
        2572,
        2456,
        8801,
        939,
        6369,
        26378,
        3723,
        1487,
        8303,
        11,
        47788,
        11,
        1842,
        26486,
        99096,
        3784,
        939,
        69075,
        13,
        451,
        6,
        93796,
        73840,
        3405,
        5908
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġbesoin",
            "token_id": 62569,
            "logprob": -0.4707,
            "prob": 0.625
          },
          {
            "token": "Ġdemande",
            "token_id": 61063,
            "logprob": -1.3438,
            "prob": 0.2598
          },
          {
            "token": "Ġt",
            "token_id": 259,
            "logprob": -2.2188,
            "prob": 0.1084
          },
          {
            "token": "Ġbes",
            "token_id": 9057,
            "logprob": -5.9688,
            "prob": 0.0025
          },
          {
            "token": "Ġaide",
            "token_id": 40575,
            "logprob": -6.2188,
            "prob": 0.002
          },
          {
            "token": "Ġdé",
            "token_id": 7439,
            "logprob": -8.0625,
            "prob": 0.0003
          },
          {
            "token": "Ġnécess",
            "token_id": 62746,
            "logprob": -8.125,
            "prob": 0.0003
          },
          {
            "token": "Ġproblème",
            "token_id": 79159,
            "logprob": -8.3125,
            "prob": 0.0003
          },
          {
            "token": "Ġrequ",
            "token_id": 5892,
            "logprob": -8.3125,
            "prob": 0.0003
          },
          {
            "token": "Ġassistance",
            "token_id": 12994,
            "logprob": -8.625,
            "prob": 0.0002
          }
        ]
      },
      "selected_token": {
        "token": "Ġdemande",
        "token_id": 61063,
        "selection_method": "sampling"
      }
    },
    {
      "step": 81,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires, des documents officiels, des e-mails, des scripts, etc., effectuer des raisonnements logiques, programmer, et même jouer à des jeux. N'importe quelle question ou demande",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ",",
        "Ġdes",
        "Ġdocuments",
        "Ġoffic",
        "i",
        "els",
        ",",
        "Ġdes",
        "Ġe",
        "-mails",
        ",",
        "Ġdes",
        "Ġscripts",
        ",",
        "Ġetc",
        ".,",
        "Ġeffect",
        "uer",
        "Ġdes",
        "Ġrais",
        "onn",
        "ements",
        "Ġlog",
        "iques",
        ",",
        "Ġprogrammer",
        ",",
        "Ġet",
        "Ġmême",
        "Ġjouer",
        "Ġà",
        "Ġdes",
        "Ġjeux",
        ".",
        "ĠN",
        "'",
        "importe",
        "Ġquelle",
        "Ġquestion",
        "Ġou",
        "Ġdemande"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11,
        939,
        9293,
        2786,
        72,
        2010,
        11,
        939,
        384,
        60220,
        11,
        939,
        19502,
        11,
        4992,
        2572,
        2456,
        8801,
        939,
        6369,
        26378,
        3723,
        1487,
        8303,
        11,
        47788,
        11,
        1842,
        26486,
        99096,
        3784,
        939,
        69075,
        13,
        451,
        6,
        93796,
        73840,
        3405,
        5908,
        61063
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": ",",
            "token_id": 11,
            "logprob": -0.0244,
            "prob": 0.9766
          },
          {
            "token": "Ġque",
            "token_id": 1709,
            "logprob": -4.2812,
            "prob": 0.0139
          },
          {
            "token": "Ġpeut",
            "token_id": 24666,
            "logprob": -5.4062,
            "prob": 0.0045
          },
          {
            "token": "Ġvous",
            "token_id": 9012,
            "logprob": -5.6562,
            "prob": 0.0035
          },
          {
            "token": "Ġest",
            "token_id": 1788,
            "logprob": -6.4062,
            "prob": 0.0017
          },
          {
            "token": "Ġ!",
            "token_id": 753,
            "logprob": -9.25,
            "prob": 0.0001
          },
          {
            "token": "Ġde",
            "token_id": 409,
            "logprob": -9.25,
            "prob": 0.0001
          },
          {
            "token": "Ġ-",
            "token_id": 481,
            "logprob": -9.875,
            "prob": 0.0001
          },
          {
            "token": "Ġ–",
            "token_id": 1365,
            "logprob": -9.875,
            "prob": 0.0001
          },
          {
            "token": "Ġ—",
            "token_id": 1959,
            "logprob": -10.0,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": ",",
        "token_id": 11,
        "selection_method": "sampling"
      }
    },
    {
      "step": 82,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires, des documents officiels, des e-mails, des scripts, etc., effectuer des raisonnements logiques, programmer, et même jouer à des jeux. N'importe quelle question ou demande,",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ",",
        "Ġdes",
        "Ġdocuments",
        "Ġoffic",
        "i",
        "els",
        ",",
        "Ġdes",
        "Ġe",
        "-mails",
        ",",
        "Ġdes",
        "Ġscripts",
        ",",
        "Ġetc",
        ".,",
        "Ġeffect",
        "uer",
        "Ġdes",
        "Ġrais",
        "onn",
        "ements",
        "Ġlog",
        "iques",
        ",",
        "Ġprogrammer",
        ",",
        "Ġet",
        "Ġmême",
        "Ġjouer",
        "Ġà",
        "Ġdes",
        "Ġjeux",
        ".",
        "ĠN",
        "'",
        "importe",
        "Ġquelle",
        "Ġquestion",
        "Ġou",
        "Ġdemande",
        ","
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11,
        939,
        9293,
        2786,
        72,
        2010,
        11,
        939,
        384,
        60220,
        11,
        939,
        19502,
        11,
        4992,
        2572,
        2456,
        8801,
        939,
        6369,
        26378,
        3723,
        1487,
        8303,
        11,
        47788,
        11,
        1842,
        26486,
        99096,
        3784,
        939,
        69075,
        13,
        451,
        6,
        93796,
        73840,
        3405,
        5908,
        61063,
        11
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġje",
            "token_id": 4759,
            "logprob": -0.0986,
            "prob": 0.9062
          },
          {
            "token": "Ġn",
            "token_id": 308,
            "logprob": -2.5938,
            "prob": 0.0742
          },
          {
            "token": "Ġque",
            "token_id": 1709,
            "logprob": -4.7188,
            "prob": 0.0089
          },
          {
            "token": "Ġve",
            "token_id": 5208,
            "logprob": -5.4688,
            "prob": 0.0042
          },
          {
            "token": "Ġvous",
            "token_id": 9012,
            "logprob": -5.9688,
            "prob": 0.0025
          },
          {
            "token": "Ġmême",
            "token_id": 26486,
            "logprob": -7.0938,
            "prob": 0.0008
          },
          {
            "token": "Ġfait",
            "token_id": 19694,
            "logprob": -7.0938,
            "prob": 0.0008
          },
          {
            "token": "Ġj",
            "token_id": 502,
            "logprob": -7.2188,
            "prob": 0.0007
          },
          {
            "token": "Ġd",
            "token_id": 294,
            "logprob": -7.8438,
            "prob": 0.0004
          },
          {
            "token": "Ġqu",
            "token_id": 922,
            "logprob": -8.5,
            "prob": 0.0002
          }
        ]
      },
      "selected_token": {
        "token": "Ġn",
        "token_id": 308,
        "selection_method": "sampling"
      }
    },
    {
      "step": 83,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires, des documents officiels, des e-mails, des scripts, etc., effectuer des raisonnements logiques, programmer, et même jouer à des jeux. N'importe quelle question ou demande, n",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ",",
        "Ġdes",
        "Ġdocuments",
        "Ġoffic",
        "i",
        "els",
        ",",
        "Ġdes",
        "Ġe",
        "-mails",
        ",",
        "Ġdes",
        "Ġscripts",
        ",",
        "Ġetc",
        ".,",
        "Ġeffect",
        "uer",
        "Ġdes",
        "Ġrais",
        "onn",
        "ements",
        "Ġlog",
        "iques",
        ",",
        "Ġprogrammer",
        ",",
        "Ġet",
        "Ġmême",
        "Ġjouer",
        "Ġà",
        "Ġdes",
        "Ġjeux",
        ".",
        "ĠN",
        "'",
        "importe",
        "Ġquelle",
        "Ġquestion",
        "Ġou",
        "Ġdemande",
        ",",
        "Ġn"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11,
        939,
        9293,
        2786,
        72,
        2010,
        11,
        939,
        384,
        60220,
        11,
        939,
        19502,
        11,
        4992,
        2572,
        2456,
        8801,
        939,
        6369,
        26378,
        3723,
        1487,
        8303,
        11,
        47788,
        11,
        1842,
        26486,
        99096,
        3784,
        939,
        69075,
        13,
        451,
        6,
        93796,
        73840,
        3405,
        5908,
        61063,
        11,
        308
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "'h",
            "token_id": 38882,
            "logprob": -0.0016,
            "prob": 1.0
          },
          {
            "token": "'",
            "token_id": 6,
            "logprob": -6.625,
            "prob": 0.0013
          },
          {
            "token": "’h",
            "token_id": 57286,
            "logprob": -8.25,
            "prob": 0.0003
          },
          {
            "token": "Ġh",
            "token_id": 305,
            "logprob": -11.5,
            "prob": 0.0
          },
          {
            "token": "'H",
            "token_id": 66970,
            "logprob": -12.75,
            "prob": 0.0
          },
          {
            "token": "'est",
            "token_id": 17321,
            "logprob": -13.0,
            "prob": 0.0
          },
          {
            "token": "'y",
            "token_id": 58758,
            "logprob": -14.875,
            "prob": 0.0
          },
          {
            "token": "\"h",
            "token_id": 78522,
            "logprob": -15.125,
            "prob": 0.0
          },
          {
            "token": ".h",
            "token_id": 860,
            "logprob": -15.125,
            "prob": 0.0
          },
          {
            "token": "’",
            "token_id": 527,
            "logprob": -15.375,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "'h",
        "token_id": 38882,
        "selection_method": "sampling"
      }
    },
    {
      "step": 84,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires, des documents officiels, des e-mails, des scripts, etc., effectuer des raisonnements logiques, programmer, et même jouer à des jeux. N'importe quelle question ou demande, n'h",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ",",
        "Ġdes",
        "Ġdocuments",
        "Ġoffic",
        "i",
        "els",
        ",",
        "Ġdes",
        "Ġe",
        "-mails",
        ",",
        "Ġdes",
        "Ġscripts",
        ",",
        "Ġetc",
        ".,",
        "Ġeffect",
        "uer",
        "Ġdes",
        "Ġrais",
        "onn",
        "ements",
        "Ġlog",
        "iques",
        ",",
        "Ġprogrammer",
        ",",
        "Ġet",
        "Ġmême",
        "Ġjouer",
        "Ġà",
        "Ġdes",
        "Ġjeux",
        ".",
        "ĠN",
        "'",
        "importe",
        "Ġquelle",
        "Ġquestion",
        "Ġou",
        "Ġdemande",
        ",",
        "Ġn",
        "'h"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11,
        939,
        9293,
        2786,
        72,
        2010,
        11,
        939,
        384,
        60220,
        11,
        939,
        19502,
        11,
        4992,
        2572,
        2456,
        8801,
        939,
        6369,
        26378,
        3723,
        1487,
        8303,
        11,
        47788,
        11,
        1842,
        26486,
        99096,
        3784,
        939,
        69075,
        13,
        451,
        6,
        93796,
        73840,
        3405,
        5908,
        61063,
        11,
        308,
        38882
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "és",
            "token_id": 5397,
            "logprob": -0.0,
            "prob": 1.0
          },
          {
            "token": "é",
            "token_id": 963,
            "logprob": -12.25,
            "prob": 0.0
          },
          {
            "token": "ès",
            "token_id": 12142,
            "logprob": -14.375,
            "prob": 0.0
          },
          {
            "token": "ée",
            "token_id": 7888,
            "logprob": -16.875,
            "prob": 0.0
          },
          {
            "token": "è",
            "token_id": 4458,
            "logprob": -18.0,
            "prob": 0.0
          },
          {
            "token": "âte",
            "token_id": 68528,
            "logprob": -20.25,
            "prob": 0.0
          },
          {
            "token": "es",
            "token_id": 288,
            "logprob": -20.5,
            "prob": 0.0
          },
          {
            "token": "ées",
            "token_id": 13700,
            "logprob": -21.125,
            "prob": 0.0
          },
          {
            "token": "aye",
            "token_id": 59955,
            "logprob": -21.125,
            "prob": 0.0
          },
          {
            "token": "ante",
            "token_id": 4942,
            "logprob": -21.375,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "és",
        "token_id": 5397,
        "selection_method": "sampling"
      }
    },
    {
      "step": 85,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires, des documents officiels, des e-mails, des scripts, etc., effectuer des raisonnements logiques, programmer, et même jouer à des jeux. N'importe quelle question ou demande, n'hés",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ",",
        "Ġdes",
        "Ġdocuments",
        "Ġoffic",
        "i",
        "els",
        ",",
        "Ġdes",
        "Ġe",
        "-mails",
        ",",
        "Ġdes",
        "Ġscripts",
        ",",
        "Ġetc",
        ".,",
        "Ġeffect",
        "uer",
        "Ġdes",
        "Ġrais",
        "onn",
        "ements",
        "Ġlog",
        "iques",
        ",",
        "Ġprogrammer",
        ",",
        "Ġet",
        "Ġmême",
        "Ġjouer",
        "Ġà",
        "Ġdes",
        "Ġjeux",
        ".",
        "ĠN",
        "'",
        "importe",
        "Ġquelle",
        "Ġquestion",
        "Ġou",
        "Ġdemande",
        ",",
        "Ġn",
        "'h",
        "és"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11,
        939,
        9293,
        2786,
        72,
        2010,
        11,
        939,
        384,
        60220,
        11,
        939,
        19502,
        11,
        4992,
        2572,
        2456,
        8801,
        939,
        6369,
        26378,
        3723,
        1487,
        8303,
        11,
        47788,
        11,
        1842,
        26486,
        99096,
        3784,
        939,
        69075,
        13,
        451,
        6,
        93796,
        73840,
        3405,
        5908,
        61063,
        11,
        308,
        38882,
        5397
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "itez",
            "token_id": 54645,
            "logprob": -0.0025,
            "prob": 0.9961
          },
          {
            "token": "ite",
            "token_id": 632,
            "logprob": -6.0,
            "prob": 0.0025
          },
          {
            "token": "iter",
            "token_id": 2015,
            "logprob": -12.875,
            "prob": 0.0
          },
          {
            "token": "ites",
            "token_id": 3611,
            "logprob": -14.25,
            "prob": 0.0
          },
          {
            "token": "ité",
            "token_id": 12815,
            "logprob": -14.375,
            "prob": 0.0
          },
          {
            "token": "itant",
            "token_id": 50944,
            "logprob": -14.5,
            "prob": 0.0
          },
          {
            "token": "it",
            "token_id": 275,
            "logprob": -17.0,
            "prob": 0.0
          },
          {
            "token": "inez",
            "token_id": 38295,
            "logprob": -17.125,
            "prob": 0.0
          },
          {
            "token": "itations",
            "token_id": 30667,
            "logprob": -17.375,
            "prob": 0.0
          },
          {
            "token": "irez",
            "token_id": 59736,
            "logprob": -17.375,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "itez",
        "token_id": 54645,
        "selection_method": "sampling"
      }
    },
    {
      "step": 86,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires, des documents officiels, des e-mails, des scripts, etc., effectuer des raisonnements logiques, programmer, et même jouer à des jeux. N'importe quelle question ou demande, n'hésitez",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ",",
        "Ġdes",
        "Ġdocuments",
        "Ġoffic",
        "i",
        "els",
        ",",
        "Ġdes",
        "Ġe",
        "-mails",
        ",",
        "Ġdes",
        "Ġscripts",
        ",",
        "Ġetc",
        ".,",
        "Ġeffect",
        "uer",
        "Ġdes",
        "Ġrais",
        "onn",
        "ements",
        "Ġlog",
        "iques",
        ",",
        "Ġprogrammer",
        ",",
        "Ġet",
        "Ġmême",
        "Ġjouer",
        "Ġà",
        "Ġdes",
        "Ġjeux",
        ".",
        "ĠN",
        "'",
        "importe",
        "Ġquelle",
        "Ġquestion",
        "Ġou",
        "Ġdemande",
        ",",
        "Ġn",
        "'h",
        "és",
        "itez"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11,
        939,
        9293,
        2786,
        72,
        2010,
        11,
        939,
        384,
        60220,
        11,
        939,
        19502,
        11,
        4992,
        2572,
        2456,
        8801,
        939,
        6369,
        26378,
        3723,
        1487,
        8303,
        11,
        47788,
        11,
        1842,
        26486,
        99096,
        3784,
        939,
        69075,
        13,
        451,
        6,
        93796,
        73840,
        3405,
        5908,
        61063,
        11,
        308,
        38882,
        5397,
        54645
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġpas",
            "token_id": 6368,
            "logprob": -0.0,
            "prob": 1.0
          },
          {
            "token": "-p",
            "token_id": 2268,
            "logprob": -11.0,
            "prob": 0.0
          },
          {
            "token": "Ġsurtout",
            "token_id": 75676,
            "logprob": -11.375,
            "prob": 0.0
          },
          {
            "token": "Ġjamais",
            "token_id": 55216,
            "logprob": -11.875,
            "prob": 0.0
          },
          {
            "token": "ĠPas",
            "token_id": 24010,
            "logprob": -13.875,
            "prob": 0.0
          },
          {
            "token": "ĠPAS",
            "token_id": 59917,
            "logprob": -15.5,
            "prob": 0.0
          },
          {
            "token": "_pas",
            "token_id": 79578,
            "logprob": -16.125,
            "prob": 0.0
          },
          {
            "token": "Ġtout",
            "token_id": 16559,
            "logprob": -16.875,
            "prob": 0.0
          },
          {
            "token": "Ġdonc",
            "token_id": 38487,
            "logprob": -17.0,
            "prob": 0.0
          },
          {
            "token": "Ġplus",
            "token_id": 5519,
            "logprob": -17.375,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġpas",
        "token_id": 6368,
        "selection_method": "sampling"
      }
    },
    {
      "step": 87,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires, des documents officiels, des e-mails, des scripts, etc., effectuer des raisonnements logiques, programmer, et même jouer à des jeux. N'importe quelle question ou demande, n'hésitez pas",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ",",
        "Ġdes",
        "Ġdocuments",
        "Ġoffic",
        "i",
        "els",
        ",",
        "Ġdes",
        "Ġe",
        "-mails",
        ",",
        "Ġdes",
        "Ġscripts",
        ",",
        "Ġetc",
        ".,",
        "Ġeffect",
        "uer",
        "Ġdes",
        "Ġrais",
        "onn",
        "ements",
        "Ġlog",
        "iques",
        ",",
        "Ġprogrammer",
        ",",
        "Ġet",
        "Ġmême",
        "Ġjouer",
        "Ġà",
        "Ġdes",
        "Ġjeux",
        ".",
        "ĠN",
        "'",
        "importe",
        "Ġquelle",
        "Ġquestion",
        "Ġou",
        "Ġdemande",
        ",",
        "Ġn",
        "'h",
        "és",
        "itez",
        "Ġpas"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11,
        939,
        9293,
        2786,
        72,
        2010,
        11,
        939,
        384,
        60220,
        11,
        939,
        19502,
        11,
        4992,
        2572,
        2456,
        8801,
        939,
        6369,
        26378,
        3723,
        1487,
        8303,
        11,
        47788,
        11,
        1842,
        26486,
        99096,
        3784,
        939,
        69075,
        13,
        451,
        6,
        93796,
        73840,
        3405,
        5908,
        61063,
        11,
        308,
        38882,
        5397,
        54645,
        6368
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġà",
            "token_id": 3784,
            "logprob": -0.0,
            "prob": 1.0
          },
          {
            "token": "Ġme",
            "token_id": 752,
            "logprob": -11.0,
            "prob": 0.0
          },
          {
            "token": "Ġ!",
            "token_id": 753,
            "logprob": -11.75,
            "prob": 0.0
          },
          {
            "token": "Ġm",
            "token_id": 296,
            "logprob": -12.875,
            "prob": 0.0
          },
          {
            "token": ",",
            "token_id": 11,
            "logprob": -13.625,
            "prob": 0.0
          },
          {
            "token": "!",
            "token_id": 0,
            "logprob": -15.8125,
            "prob": 0.0
          },
          {
            "token": "ĠÀ",
            "token_id": 64281,
            "logprob": -15.8125,
            "prob": 0.0
          },
          {
            "token": "Ġtout",
            "token_id": 16559,
            "logprob": -16.25,
            "prob": 0.0
          },
          {
            "token": "'à",
            "token_id": 80891,
            "logprob": -16.5,
            "prob": 0.0
          },
          {
            "token": "à",
            "token_id": 6362,
            "logprob": -16.625,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġà",
        "token_id": 3784,
        "selection_method": "sampling"
      }
    },
    {
      "step": 88,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires, des documents officiels, des e-mails, des scripts, etc., effectuer des raisonnements logiques, programmer, et même jouer à des jeux. N'importe quelle question ou demande, n'hésitez pas à",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ",",
        "Ġdes",
        "Ġdocuments",
        "Ġoffic",
        "i",
        "els",
        ",",
        "Ġdes",
        "Ġe",
        "-mails",
        ",",
        "Ġdes",
        "Ġscripts",
        ",",
        "Ġetc",
        ".,",
        "Ġeffect",
        "uer",
        "Ġdes",
        "Ġrais",
        "onn",
        "ements",
        "Ġlog",
        "iques",
        ",",
        "Ġprogrammer",
        ",",
        "Ġet",
        "Ġmême",
        "Ġjouer",
        "Ġà",
        "Ġdes",
        "Ġjeux",
        ".",
        "ĠN",
        "'",
        "importe",
        "Ġquelle",
        "Ġquestion",
        "Ġou",
        "Ġdemande",
        ",",
        "Ġn",
        "'h",
        "és",
        "itez",
        "Ġpas",
        "Ġà"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11,
        939,
        9293,
        2786,
        72,
        2010,
        11,
        939,
        384,
        60220,
        11,
        939,
        19502,
        11,
        4992,
        2572,
        2456,
        8801,
        939,
        6369,
        26378,
        3723,
        1487,
        8303,
        11,
        47788,
        11,
        1842,
        26486,
        99096,
        3784,
        939,
        69075,
        13,
        451,
        6,
        93796,
        73840,
        3405,
        5908,
        61063,
        11,
        308,
        38882,
        5397,
        54645,
        6368,
        3784
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġme",
            "token_id": 752,
            "logprob": -0.0212,
            "prob": 0.9805
          },
          {
            "token": "Ġla",
            "token_id": 1187,
            "logprob": -4.1562,
            "prob": 0.0159
          },
          {
            "token": "Ġm",
            "token_id": 296,
            "logprob": -5.2812,
            "prob": 0.0051
          },
          {
            "token": "Ġvenir",
            "token_id": 95486,
            "logprob": -11.0,
            "prob": 0.0
          },
          {
            "token": "Ġfaire",
            "token_id": 19463,
            "logprob": -12.25,
            "prob": 0.0
          },
          {
            "token": "ĠMe",
            "token_id": 2157,
            "logprob": -12.375,
            "prob": 0.0
          },
          {
            "token": "Ġmoi",
            "token_id": 39991,
            "logprob": -12.875,
            "prob": 0.0
          },
          {
            "token": "Ġnous",
            "token_id": 16890,
            "logprob": -13.5,
            "prob": 0.0
          },
          {
            "token": "Ġpartager",
            "token_id": 96348,
            "logprob": -13.5625,
            "prob": 0.0
          },
          {
            "token": "Ġl",
            "token_id": 326,
            "logprob": -14.0,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġme",
        "token_id": 752,
        "selection_method": "sampling"
      }
    },
    {
      "step": 89,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires, des documents officiels, des e-mails, des scripts, etc., effectuer des raisonnements logiques, programmer, et même jouer à des jeux. N'importe quelle question ou demande, n'hésitez pas à me",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ",",
        "Ġdes",
        "Ġdocuments",
        "Ġoffic",
        "i",
        "els",
        ",",
        "Ġdes",
        "Ġe",
        "-mails",
        ",",
        "Ġdes",
        "Ġscripts",
        ",",
        "Ġetc",
        ".,",
        "Ġeffect",
        "uer",
        "Ġdes",
        "Ġrais",
        "onn",
        "ements",
        "Ġlog",
        "iques",
        ",",
        "Ġprogrammer",
        ",",
        "Ġet",
        "Ġmême",
        "Ġjouer",
        "Ġà",
        "Ġdes",
        "Ġjeux",
        ".",
        "ĠN",
        "'",
        "importe",
        "Ġquelle",
        "Ġquestion",
        "Ġou",
        "Ġdemande",
        ",",
        "Ġn",
        "'h",
        "és",
        "itez",
        "Ġpas",
        "Ġà",
        "Ġme"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11,
        939,
        9293,
        2786,
        72,
        2010,
        11,
        939,
        384,
        60220,
        11,
        939,
        19502,
        11,
        4992,
        2572,
        2456,
        8801,
        939,
        6369,
        26378,
        3723,
        1487,
        8303,
        11,
        47788,
        11,
        1842,
        26486,
        99096,
        3784,
        939,
        69075,
        13,
        451,
        6,
        93796,
        73840,
        3405,
        5908,
        61063,
        11,
        308,
        38882,
        5397,
        54645,
        6368,
        3784,
        752
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġla",
            "token_id": 1187,
            "logprob": -0.0189,
            "prob": 0.9805
          },
          {
            "token": "Ġpos",
            "token_id": 1133,
            "logprob": -4.5312,
            "prob": 0.0109
          },
          {
            "token": "Ġfaire",
            "token_id": 19463,
            "logprob": -5.2812,
            "prob": 0.0052
          },
          {
            "token": "Ġl",
            "token_id": 326,
            "logprob": -6.4062,
            "prob": 0.0017
          },
          {
            "token": "Ġle",
            "token_id": 512,
            "logprob": -8.0,
            "prob": 0.0003
          },
          {
            "token": "Ġles",
            "token_id": 3541,
            "logprob": -9.0,
            "prob": 0.0001
          },
          {
            "token": "Ġpropos",
            "token_id": 9844,
            "logprob": -9.125,
            "prob": 0.0001
          },
          {
            "token": "Ġdemand",
            "token_id": 7479,
            "logprob": -9.25,
            "prob": 0.0001
          },
          {
            "token": "Ġpartager",
            "token_id": 96348,
            "logprob": -9.5,
            "prob": 0.0001
          },
          {
            "token": "Ġdire",
            "token_id": 13207,
            "logprob": -9.75,
            "prob": 0.0001
          }
        ]
      },
      "selected_token": {
        "token": "Ġla",
        "token_id": 1187,
        "selection_method": "sampling"
      }
    },
    {
      "step": 90,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires, des documents officiels, des e-mails, des scripts, etc., effectuer des raisonnements logiques, programmer, et même jouer à des jeux. N'importe quelle question ou demande, n'hésitez pas à me la",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ",",
        "Ġdes",
        "Ġdocuments",
        "Ġoffic",
        "i",
        "els",
        ",",
        "Ġdes",
        "Ġe",
        "-mails",
        ",",
        "Ġdes",
        "Ġscripts",
        ",",
        "Ġetc",
        ".,",
        "Ġeffect",
        "uer",
        "Ġdes",
        "Ġrais",
        "onn",
        "ements",
        "Ġlog",
        "iques",
        ",",
        "Ġprogrammer",
        ",",
        "Ġet",
        "Ġmême",
        "Ġjouer",
        "Ġà",
        "Ġdes",
        "Ġjeux",
        ".",
        "ĠN",
        "'",
        "importe",
        "Ġquelle",
        "Ġquestion",
        "Ġou",
        "Ġdemande",
        ",",
        "Ġn",
        "'h",
        "és",
        "itez",
        "Ġpas",
        "Ġà",
        "Ġme",
        "Ġla"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11,
        939,
        9293,
        2786,
        72,
        2010,
        11,
        939,
        384,
        60220,
        11,
        939,
        19502,
        11,
        4992,
        2572,
        2456,
        8801,
        939,
        6369,
        26378,
        3723,
        1487,
        8303,
        11,
        47788,
        11,
        1842,
        26486,
        99096,
        3784,
        939,
        69075,
        13,
        451,
        6,
        93796,
        73840,
        3405,
        5908,
        61063,
        11,
        308,
        38882,
        5397,
        54645,
        6368,
        3784,
        752,
        1187
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġpos",
            "token_id": 1133,
            "logprob": -0.4844,
            "prob": 0.6172
          },
          {
            "token": "Ġfaire",
            "token_id": 19463,
            "logprob": -0.9844,
            "prob": 0.373
          },
          {
            "token": "Ġform",
            "token_id": 1352,
            "logprob": -5.3438,
            "prob": 0.0047
          },
          {
            "token": "Ġpropos",
            "token_id": 9844,
            "logprob": -5.4688,
            "prob": 0.0042
          },
          {
            "token": "Ġsou",
            "token_id": 5822,
            "logprob": -7.5938,
            "prob": 0.0005
          },
          {
            "token": "Ġtrans",
            "token_id": 1356,
            "logprob": -8.25,
            "prob": 0.0003
          },
          {
            "token": "isser",
            "token_id": 73233,
            "logprob": -9.125,
            "prob": 0.0001
          },
          {
            "token": "Ġcommun",
            "token_id": 33461,
            "logprob": -9.625,
            "prob": 0.0001
          },
          {
            "token": "Ġpose",
            "token_id": 17040,
            "logprob": -10.125,
            "prob": 0.0
          },
          {
            "token": "Ġmettre",
            "token_id": 46921,
            "logprob": -10.25,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġpos",
        "token_id": 1133,
        "selection_method": "sampling"
      }
    },
    {
      "step": 91,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires, des documents officiels, des e-mails, des scripts, etc., effectuer des raisonnements logiques, programmer, et même jouer à des jeux. N'importe quelle question ou demande, n'hésitez pas à me la pos",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ",",
        "Ġdes",
        "Ġdocuments",
        "Ġoffic",
        "i",
        "els",
        ",",
        "Ġdes",
        "Ġe",
        "-mails",
        ",",
        "Ġdes",
        "Ġscripts",
        ",",
        "Ġetc",
        ".,",
        "Ġeffect",
        "uer",
        "Ġdes",
        "Ġrais",
        "onn",
        "ements",
        "Ġlog",
        "iques",
        ",",
        "Ġprogrammer",
        ",",
        "Ġet",
        "Ġmême",
        "Ġjouer",
        "Ġà",
        "Ġdes",
        "Ġjeux",
        ".",
        "ĠN",
        "'",
        "importe",
        "Ġquelle",
        "Ġquestion",
        "Ġou",
        "Ġdemande",
        ",",
        "Ġn",
        "'h",
        "és",
        "itez",
        "Ġpas",
        "Ġà",
        "Ġme",
        "Ġla",
        "Ġpos"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11,
        939,
        9293,
        2786,
        72,
        2010,
        11,
        939,
        384,
        60220,
        11,
        939,
        19502,
        11,
        4992,
        2572,
        2456,
        8801,
        939,
        6369,
        26378,
        3723,
        1487,
        8303,
        11,
        47788,
        11,
        1842,
        26486,
        99096,
        3784,
        939,
        69075,
        13,
        451,
        6,
        93796,
        73840,
        3405,
        5908,
        61063,
        11,
        308,
        38882,
        5397,
        54645,
        6368,
        3784,
        752,
        1187,
        1133
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "er",
            "token_id": 261,
            "logprob": 0.0,
            "prob": 1.0
          },
          {
            "token": "ée",
            "token_id": 7888,
            "logprob": -18.125,
            "prob": 0.0
          },
          {
            "token": "é",
            "token_id": 963,
            "logprob": -19.0,
            "prob": 0.0
          },
          {
            "token": "ER",
            "token_id": 640,
            "logprob": -21.875,
            "prob": 0.0
          },
          {
            "token": "ers",
            "token_id": 388,
            "logprob": -23.875,
            "prob": 0.0
          },
          {
            "token": "és",
            "token_id": 5397,
            "logprob": -24.25,
            "prob": 0.0
          },
          {
            "token": "ér",
            "token_id": 13763,
            "logprob": -24.25,
            "prob": 0.0
          },
          {
            "token": "erà",
            "token_id": 132617,
            "logprob": -24.25,
            "prob": 0.0
          },
          {
            "token": "ées",
            "token_id": 13700,
            "logprob": -25.375,
            "prob": 0.0
          },
          {
            "token": "erer",
            "token_id": 90017,
            "logprob": -25.375,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "er",
        "token_id": 261,
        "selection_method": "sampling"
      }
    },
    {
      "step": 92,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires, des documents officiels, des e-mails, des scripts, etc., effectuer des raisonnements logiques, programmer, et même jouer à des jeux. N'importe quelle question ou demande, n'hésitez pas à me la poser",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ",",
        "Ġdes",
        "Ġdocuments",
        "Ġoffic",
        "i",
        "els",
        ",",
        "Ġdes",
        "Ġe",
        "-mails",
        ",",
        "Ġdes",
        "Ġscripts",
        ",",
        "Ġetc",
        ".,",
        "Ġeffect",
        "uer",
        "Ġdes",
        "Ġrais",
        "onn",
        "ements",
        "Ġlog",
        "iques",
        ",",
        "Ġprogrammer",
        ",",
        "Ġet",
        "Ġmême",
        "Ġjouer",
        "Ġà",
        "Ġdes",
        "Ġjeux",
        ".",
        "ĠN",
        "'",
        "importe",
        "Ġquelle",
        "Ġquestion",
        "Ġou",
        "Ġdemande",
        ",",
        "Ġn",
        "'h",
        "és",
        "itez",
        "Ġpas",
        "Ġà",
        "Ġme",
        "Ġla",
        "Ġpos",
        "er"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11,
        939,
        9293,
        2786,
        72,
        2010,
        11,
        939,
        384,
        60220,
        11,
        939,
        19502,
        11,
        4992,
        2572,
        2456,
        8801,
        939,
        6369,
        26378,
        3723,
        1487,
        8303,
        11,
        47788,
        11,
        1842,
        26486,
        99096,
        3784,
        939,
        69075,
        13,
        451,
        6,
        93796,
        73840,
        3405,
        5908,
        61063,
        11,
        308,
        38882,
        5397,
        54645,
        6368,
        3784,
        752,
        1187,
        1133,
        261
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġ!",
            "token_id": 753,
            "logprob": -0.0073,
            "prob": 0.9922
          },
          {
            "token": ",",
            "token_id": 11,
            "logprob": -5.25,
            "prob": 0.0052
          },
          {
            "token": "!",
            "token_id": 0,
            "logprob": -7.125,
            "prob": 0.0008
          },
          {
            "token": ".",
            "token_id": 13,
            "logprob": -7.375,
            "prob": 0.0006
          },
          {
            "token": "Ġà",
            "token_id": 3784,
            "logprob": -8.0,
            "prob": 0.0003
          },
          {
            "token": "Ġ-",
            "token_id": 481,
            "logprob": -9.0,
            "prob": 0.0001
          },
          {
            "token": "Ġ—",
            "token_id": 1959,
            "logprob": -9.5,
            "prob": 0.0001
          },
          {
            "token": "Ġet",
            "token_id": 1842,
            "logprob": -9.875,
            "prob": 0.0001
          },
          {
            "token": "Ġ!\n\n",
            "token_id": 24750,
            "logprob": -10.375,
            "prob": 0.0
          },
          {
            "token": " ",
            "token_id": 4102,
            "logprob": -11.25,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġ!",
        "token_id": 753,
        "selection_method": "sampling"
      }
    },
    {
      "step": 93,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires, des documents officiels, des e-mails, des scripts, etc., effectuer des raisonnements logiques, programmer, et même jouer à des jeux. N'importe quelle question ou demande, n'hésitez pas à me la poser !",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ",",
        "Ġdes",
        "Ġdocuments",
        "Ġoffic",
        "i",
        "els",
        ",",
        "Ġdes",
        "Ġe",
        "-mails",
        ",",
        "Ġdes",
        "Ġscripts",
        ",",
        "Ġetc",
        ".,",
        "Ġeffect",
        "uer",
        "Ġdes",
        "Ġrais",
        "onn",
        "ements",
        "Ġlog",
        "iques",
        ",",
        "Ġprogrammer",
        ",",
        "Ġet",
        "Ġmême",
        "Ġjouer",
        "Ġà",
        "Ġdes",
        "Ġjeux",
        ".",
        "ĠN",
        "'",
        "importe",
        "Ġquelle",
        "Ġquestion",
        "Ġou",
        "Ġdemande",
        ",",
        "Ġn",
        "'h",
        "és",
        "itez",
        "Ġpas",
        "Ġà",
        "Ġme",
        "Ġla",
        "Ġpos",
        "er",
        "Ġ!"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11,
        939,
        9293,
        2786,
        72,
        2010,
        11,
        939,
        384,
        60220,
        11,
        939,
        19502,
        11,
        4992,
        2572,
        2456,
        8801,
        939,
        6369,
        26378,
        3723,
        1487,
        8303,
        11,
        47788,
        11,
        1842,
        26486,
        99096,
        3784,
        939,
        69075,
        13,
        451,
        6,
        93796,
        73840,
        3405,
        5908,
        61063,
        11,
        308,
        38882,
        5397,
        54645,
        6368,
        3784,
        752,
        1187,
        1133,
        261,
        753
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġ�",
            "token_id": 26525,
            "logprob": -0.0903,
            "prob": 0.9141
          },
          {
            "token": "<|im_end|>",
            "token_id": 151645,
            "logprob": -3.3438,
            "prob": 0.0354
          },
          {
            "token": "Ġ�",
            "token_id": 11162,
            "logprob": -3.4688,
            "prob": 0.0312
          },
          {
            "token": "Ġ�",
            "token_id": 63039,
            "logprob": -4.0938,
            "prob": 0.0167
          },
          {
            "token": "Ġ�",
            "token_id": 25521,
            "logprob": -5.9688,
            "prob": 0.0026
          },
          {
            "token": "Ġ�",
            "token_id": 61804,
            "logprob": -9.0625,
            "prob": 0.0001
          },
          {
            "token": "Ġ�",
            "token_id": 95069,
            "logprob": -9.0625,
            "prob": 0.0001
          },
          {
            "token": "Ġ❤",
            "token_id": 70470,
            "logprob": -9.1875,
            "prob": 0.0001
          },
          {
            "token": "Ġ�",
            "token_id": 2858,
            "logprob": -9.6875,
            "prob": 0.0001
          },
          {
            "token": "Ġ:)",
            "token_id": 25956,
            "logprob": -10.3125,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġ�",
        "token_id": 26525,
        "selection_method": "sampling"
      }
    },
    {
      "step": 94,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires, des documents officiels, des e-mails, des scripts, etc., effectuer des raisonnements logiques, programmer, et même jouer à des jeux. N'importe quelle question ou demande, n'hésitez pas à me la poser ! �",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ",",
        "Ġdes",
        "Ġdocuments",
        "Ġoffic",
        "i",
        "els",
        ",",
        "Ġdes",
        "Ġe",
        "-mails",
        ",",
        "Ġdes",
        "Ġscripts",
        ",",
        "Ġetc",
        ".,",
        "Ġeffect",
        "uer",
        "Ġdes",
        "Ġrais",
        "onn",
        "ements",
        "Ġlog",
        "iques",
        ",",
        "Ġprogrammer",
        ",",
        "Ġet",
        "Ġmême",
        "Ġjouer",
        "Ġà",
        "Ġdes",
        "Ġjeux",
        ".",
        "ĠN",
        "'",
        "importe",
        "Ġquelle",
        "Ġquestion",
        "Ġou",
        "Ġdemande",
        ",",
        "Ġn",
        "'h",
        "és",
        "itez",
        "Ġpas",
        "Ġà",
        "Ġme",
        "Ġla",
        "Ġpos",
        "er",
        "Ġ!",
        "Ġ�"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11,
        939,
        9293,
        2786,
        72,
        2010,
        11,
        939,
        384,
        60220,
        11,
        939,
        19502,
        11,
        4992,
        2572,
        2456,
        8801,
        939,
        6369,
        26378,
        3723,
        1487,
        8303,
        11,
        47788,
        11,
        1842,
        26486,
        99096,
        3784,
        939,
        69075,
        13,
        451,
        6,
        93796,
        73840,
        3405,
        5908,
        61063,
        11,
        308,
        38882,
        5397,
        54645,
        6368,
        3784,
        752,
        1187,
        1133,
        261,
        753,
        26525
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "�",
            "token_id": 232,
            "logprob": -0.0098,
            "prob": 0.9922
          },
          {
            "token": "�",
            "token_id": 226,
            "logprob": -4.625,
            "prob": 0.0097
          },
          {
            "token": "�",
            "token_id": 225,
            "logprob": -10.875,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 236,
            "logprob": -11.875,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 223,
            "logprob": -14.25,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 233,
            "logprob": -14.625,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 234,
            "logprob": -14.875,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 235,
            "logprob": -15.125,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 224,
            "logprob": -15.375,
            "prob": 0.0
          },
          {
            "token": "�",
            "token_id": 116,
            "logprob": -16.25,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "�",
        "token_id": 232,
        "selection_method": "sampling"
      }
    },
    {
      "step": 95,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\nJe suis Qwen, un modèle de langage à très grande échelle développé par Alibaba Cloud. Je peux répondre à vos questions, créer des textes tels que des histoires, des documents officiels, des e-mails, des scripts, etc., effectuer des raisonnements logiques, programmer, et même jouer à des jeux. N'importe quelle question ou demande, n'hésitez pas à me la poser ! 😊",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "Je",
        "Ġsuis",
        "ĠQ",
        "wen",
        ",",
        "Ġun",
        "Ġmodèle",
        "Ġde",
        "Ġlang",
        "age",
        "Ġà",
        "Ġtrès",
        "Ġgrande",
        "Ġé",
        "ch",
        "elle",
        "Ġdévelopp",
        "é",
        "Ġpar",
        "ĠAlibaba",
        "ĠCloud",
        ".",
        "ĠJe",
        "Ġpeux",
        "Ġrépond",
        "re",
        "Ġà",
        "Ġvos",
        "Ġquestions",
        ",",
        "Ġcréer",
        "Ġdes",
        "Ġtext",
        "es",
        "Ġt",
        "els",
        "Ġque",
        "Ġdes",
        "Ġhisto",
        "ires",
        ",",
        "Ġdes",
        "Ġdocuments",
        "Ġoffic",
        "i",
        "els",
        ",",
        "Ġdes",
        "Ġe",
        "-mails",
        ",",
        "Ġdes",
        "Ġscripts",
        ",",
        "Ġetc",
        ".,",
        "Ġeffect",
        "uer",
        "Ġdes",
        "Ġrais",
        "onn",
        "ements",
        "Ġlog",
        "iques",
        ",",
        "Ġprogrammer",
        ",",
        "Ġet",
        "Ġmême",
        "Ġjouer",
        "Ġà",
        "Ġdes",
        "Ġjeux",
        ".",
        "ĠN",
        "'",
        "importe",
        "Ġquelle",
        "Ġquestion",
        "Ġou",
        "Ġdemande",
        ",",
        "Ġn",
        "'h",
        "és",
        "itez",
        "Ġpas",
        "Ġà",
        "Ġme",
        "Ġla",
        "Ġpos",
        "er",
        "Ġ!",
        "Ġ�",
        "�"
      ],
      "token_ids": [
        61445,
        1531,
        2385,
        84,
        30,
        151645,
        198,
        151644,
        77091,
        198,
        29754,
        35631,
        1207,
        16948,
        11,
        650,
        82497,
        409,
        8688,
        424,
        3784,
        24901,
        24604,
        3958,
        331,
        6712,
        67766,
        963,
        1346,
        54364,
        14817,
        13,
        14133,
        93197,
        74771,
        265,
        3784,
        25251,
        4755,
        11,
        74731,
        939,
        1467,
        288,
        259,
        2010,
        1709,
        939,
        76517,
        3861,
        11,
        939,
        9293,
        2786,
        72,
        2010,
        11,
        939,
        384,
        60220,
        11,
        939,
        19502,
        11,
        4992,
        2572,
        2456,
        8801,
        939,
        6369,
        26378,
        3723,
        1487,
        8303,
        11,
        47788,
        11,
        1842,
        26486,
        99096,
        3784,
        939,
        69075,
        13,
        451,
        6,
        93796,
        73840,
        3405,
        5908,
        61063,
        11,
        308,
        38882,
        5397,
        54645,
        6368,
        3784,
        752,
        1187,
        1133,
        261,
        753,
        26525,
        232
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "<|im_end|>",
            "token_id": 151645,
            "logprob": -0.0003,
            "prob": 1.0
          },
          {
            "token": "\n\n",
            "token_id": 271,
            "logprob": -9.0,
            "prob": 0.0001
          },
          {
            "token": "\n\n\n",
            "token_id": 1406,
            "logprob": -9.375,
            "prob": 0.0001
          },
          {
            "token": "Ġ�",
            "token_id": 11162,
            "logprob": -10.375,
            "prob": 0.0
          },
          {
            "token": "Ġ�",
            "token_id": 26525,
            "logprob": -11.375,
            "prob": 0.0
          },
          {
            "token": "✨",
            "token_id": 144232,
            "logprob": -11.5,
            "prob": 0.0
          },
          {
            "token": "Ġ�",
            "token_id": 63039,
            "logprob": -11.875,
            "prob": 0.0
          },
          {
            "token": "Ġ�",
            "token_id": 25521,
            "logprob": -12.0,
            "prob": 0.0
          },
          {
            "token": "ĠPour",
            "token_id": 25968,
            "logprob": -12.0,
            "prob": 0.0
          },
          {
            "token": "\n",
            "token_id": 198,
            "logprob": -12.75,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "<|im_end|>",
        "token_id": 151645,
        "selection_method": "sampling"
      }
    }
  ]
}