{
  "id": "generated_20251203_121132",
  "prompt": "Qui es-tu?",
  "language": "fr",
  "temperature": 5.0,
  "top_k": 10,
  "model_info": {
    "name": "allenai/Olmo-3-7B-Think",
    "num_layers": 32,
    "hidden_size": 4096,
    "num_attention_heads": 32,
    "vocab_size": 100278
  },
  "generation_steps": [
    {
      "step": 0,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Okay",
            "token_id": 33413,
            "logprob": -0.0292,
            "prob": 0.9727
          },
          {
            "token": "Hmm",
            "token_id": 81122,
            "logprob": -4.2812,
            "prob": 0.0139
          },
          {
            "token": "ĠOkay",
            "token_id": 36539,
            "logprob": -5.7812,
            "prob": 0.0031
          },
          {
            "token": "Ah",
            "token_id": 25797,
            "logprob": -6.4062,
            "prob": 0.0017
          },
          {
            "token": "Alright",
            "token_id": 72586,
            "logprob": -7.3438,
            "prob": 0.0006
          },
          {
            "token": "Ġbon",
            "token_id": 7970,
            "logprob": -7.3438,
            "prob": 0.0006
          },
          {
            "token": "Ġokay",
            "token_id": 17339,
            "logprob": -7.7188,
            "prob": 0.0004
          },
          {
            "token": "okay",
            "token_id": 94317,
            "logprob": -8.0,
            "prob": 0.0003
          },
          {
            "token": "OK",
            "token_id": 4012,
            "logprob": -8.375,
            "prob": 0.0002
          },
          {
            "token": "Ok",
            "token_id": 11839,
            "logprob": -8.375,
            "prob": 0.0002
          }
        ]
      },
      "selected_token": {
        "token": "Okay",
        "token_id": 33413,
        "selection_method": "sampling"
      }
    },
    {
      "step": 1,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": ",",
            "token_id": 11,
            "logprob": -0.0,
            "prob": 1.0
          },
          {
            "token": ":",
            "token_id": 25,
            "logprob": -15.0,
            "prob": 0.0
          },
          {
            "token": "，",
            "token_id": 3922,
            "logprob": -15.3125,
            "prob": 0.0
          },
          {
            "token": "Ġso",
            "token_id": 779,
            "logprob": -15.375,
            "prob": 0.0
          },
          {
            "token": "?",
            "token_id": 30,
            "logprob": -15.75,
            "prob": 0.0
          },
          {
            "token": "...",
            "token_id": 1131,
            "logprob": -15.8125,
            "prob": 0.0
          },
          {
            "token": ".",
            "token_id": 13,
            "logprob": -16.25,
            "prob": 0.0
          },
          {
            "token": "Ġdu",
            "token_id": 3930,
            "logprob": -16.5,
            "prob": 0.0
          },
          {
            "token": "!",
            "token_id": 0,
            "logprob": -16.5,
            "prob": 0.0
          },
          {
            "token": "Ġlet",
            "token_id": 1095,
            "logprob": -16.625,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": ",",
        "token_id": 11,
        "selection_method": "sampling"
      }
    },
    {
      "step": 2,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay,",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ","
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġthe",
            "token_id": 279,
            "logprob": -0.0008,
            "prob": 1.0
          },
          {
            "token": "Ġl",
            "token_id": 326,
            "logprob": -7.25,
            "prob": 0.0007
          },
          {
            "token": "Ġso",
            "token_id": 779,
            "logprob": -9.75,
            "prob": 0.0001
          },
          {
            "token": "Ġlet",
            "token_id": 1095,
            "logprob": -11.375,
            "prob": 0.0
          },
          {
            "token": "ĠI",
            "token_id": 358,
            "logprob": -12.0,
            "prob": 0.0
          },
          {
            "token": "用户",
            "token_id": 20600,
            "logprob": -12.4375,
            "prob": 0.0
          },
          {
            "token": "Ġthey",
            "token_id": 814,
            "logprob": -13.0,
            "prob": 0.0
          },
          {
            "token": "Ġle",
            "token_id": 514,
            "logprob": -13.1875,
            "prob": 0.0
          },
          {
            "token": "Ġuser",
            "token_id": 1217,
            "logprob": -13.3125,
            "prob": 0.0
          },
          {
            "token": "Ġsomeone",
            "token_id": 4423,
            "logprob": -13.3125,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġthe",
        "token_id": 279,
        "selection_method": "sampling"
      }
    },
    {
      "step": 3,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġuser",
            "token_id": 1217,
            "logprob": -0.0,
            "prob": 1.0
          },
          {
            "token": "用户",
            "token_id": 20600,
            "logprob": -15.5,
            "prob": 0.0
          },
          {
            "token": "ĠUser",
            "token_id": 2724,
            "logprob": -17.25,
            "prob": 0.0
          },
          {
            "token": "Ġusers",
            "token_id": 3932,
            "logprob": -17.75,
            "prob": 0.0
          },
          {
            "token": "Ġuse",
            "token_id": 1005,
            "logprob": -18.0,
            "prob": 0.0
          },
          {
            "token": "Ġperson",
            "token_id": 1732,
            "logprob": -18.125,
            "prob": 0.0
          },
          {
            "token": "user",
            "token_id": 882,
            "logprob": -18.375,
            "prob": 0.0
          },
          {
            "token": "Ġcustomer",
            "token_id": 6130,
            "logprob": -19.25,
            "prob": 0.0
          },
          {
            "token": "User",
            "token_id": 1502,
            "logprob": -19.75,
            "prob": 0.0
          },
          {
            "token": "Ġ사용",
            "token_id": 41820,
            "logprob": -20.0,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġusers",
        "token_id": 3932,
        "selection_method": "sampling"
      }
    },
    {
      "step": 4,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġasked",
            "token_id": 4691,
            "logprob": -1.0859,
            "prob": 0.3379
          },
          {
            "token": "Ġis",
            "token_id": 374,
            "logprob": -1.0859,
            "prob": 0.3379
          },
          {
            "token": "Ġare",
            "token_id": 527,
            "logprob": -1.2109,
            "prob": 0.2988
          },
          {
            "token": "Ġjust",
            "token_id": 1120,
            "logprob": -4.4688,
            "prob": 0.0116
          },
          {
            "token": "Ġasks",
            "token_id": 17501,
            "logprob": -4.9688,
            "prob": 0.007
          },
          {
            "token": "Ġwrote",
            "token_id": 6267,
            "logprob": -5.8438,
            "prob": 0.0029
          },
          {
            "token": "Ġasking",
            "token_id": 10371,
            "logprob": -7.2812,
            "prob": 0.0007
          },
          {
            "token": "Ġask",
            "token_id": 2610,
            "logprob": -7.8438,
            "prob": 0.0004
          },
          {
            "token": "Ġsays",
            "token_id": 2795,
            "logprob": -8.0625,
            "prob": 0.0003
          },
          {
            "token": "Ġstarted",
            "token_id": 3940,
            "logprob": -8.5,
            "prob": 0.0002
          }
        ]
      },
      "selected_token": {
        "token": "Ġare",
        "token_id": 527,
        "selection_method": "sampling"
      }
    },
    {
      "step": 5,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġasking",
            "token_id": 10371,
            "logprob": -0.0002,
            "prob": 1.0
          },
          {
            "token": "Ġwriting",
            "token_id": 4477,
            "logprob": -9.75,
            "prob": 0.0001
          },
          {
            "token": "Ġusing",
            "token_id": 1701,
            "logprob": -10.125,
            "prob": 0.0
          },
          {
            "token": "Ġsaying",
            "token_id": 5605,
            "logprob": -10.6875,
            "prob": 0.0
          },
          {
            "token": "Ġstarting",
            "token_id": 6041,
            "logprob": -11.5625,
            "prob": 0.0
          },
          {
            "token": "Ġquestioning",
            "token_id": 34685,
            "logprob": -11.8125,
            "prob": 0.0
          },
          {
            "token": "Ġin",
            "token_id": 304,
            "logprob": -11.875,
            "prob": 0.0
          },
          {
            "token": "Ġgreeting",
            "token_id": 43213,
            "logprob": -12.0625,
            "prob": 0.0
          },
          {
            "token": "Ġasked",
            "token_id": 4691,
            "logprob": -12.3125,
            "prob": 0.0
          },
          {
            "token": "Ġwondering",
            "token_id": 20910,
            "logprob": -12.3125,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġwondering",
        "token_id": 20910,
        "selection_method": "sampling"
      }
    },
    {
      "step": 6,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġ\"",
            "token_id": 330,
            "logprob": -0.2021,
            "prob": 0.8164
          },
          {
            "token": ",",
            "token_id": 11,
            "logprob": -1.7031,
            "prob": 0.1826
          },
          {
            "token": "Ġwho",
            "token_id": 889,
            "logprob": -7.3125,
            "prob": 0.0007
          },
          {
            "token": "Ġabout",
            "token_id": 922,
            "logprob": -10.4375,
            "prob": 0.0
          },
          {
            "token": "Ġwhat",
            "token_id": 1148,
            "logprob": -10.5,
            "prob": 0.0
          },
          {
            "token": "Ġ“",
            "token_id": 1054,
            "logprob": -11.125,
            "prob": 0.0
          },
          {
            "token": "Ġqui",
            "token_id": 7930,
            "logprob": -11.5625,
            "prob": 0.0
          },
          {
            "token": "Ġ'",
            "token_id": 364,
            "logprob": -13.0625,
            "prob": 0.0
          },
          {
            "token": ",\"",
            "token_id": 1359,
            "logprob": -13.25,
            "prob": 0.0
          },
          {
            "token": ":",
            "token_id": 25,
            "logprob": -13.5625,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġ\"",
        "token_id": 330,
        "selection_method": "sampling"
      }
    },
    {
      "step": 7,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\""
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Qui",
            "token_id": 62545,
            "logprob": -0.0036,
            "prob": 0.9961
          },
          {
            "token": "ĠQui",
            "token_id": 42215,
            "logprob": -6.3125,
            "prob": 0.0018
          },
          {
            "token": "Ġqui",
            "token_id": 7930,
            "logprob": -7.1875,
            "prob": 0.0008
          },
          {
            "token": "Who",
            "token_id": 15546,
            "logprob": -7.75,
            "prob": 0.0004
          },
          {
            "token": "ĠQUI",
            "token_id": 89630,
            "logprob": -8.375,
            "prob": 0.0002
          },
          {
            "token": "Qu",
            "token_id": 2232,
            "logprob": -9.0,
            "prob": 0.0001
          },
          {
            "token": "QUI",
            "token_id": 12247,
            "logprob": -10.125,
            "prob": 0.0
          },
          {
            "token": "qui",
            "token_id": 47391,
            "logprob": -10.6875,
            "prob": 0.0
          },
          {
            "token": "ĠWho",
            "token_id": 10699,
            "logprob": -10.75,
            "prob": 0.0
          },
          {
            "token": "who",
            "token_id": 14965,
            "logprob": -11.625,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Who",
        "token_id": 15546,
        "selection_method": "sampling"
      }
    },
    {
      "step": 8,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġare",
            "token_id": 527,
            "logprob": -0.0004,
            "prob": 1.0
          },
          {
            "token": "Ġis",
            "token_id": 374,
            "logprob": -8.375,
            "prob": 0.0002
          },
          {
            "token": "Ġam",
            "token_id": 1097,
            "logprob": -10.0,
            "prob": 0.0
          },
          {
            "token": "ĠARE",
            "token_id": 16202,
            "logprob": -10.875,
            "prob": 0.0
          },
          {
            "token": "ami",
            "token_id": 10830,
            "logprob": -11.875,
            "prob": 0.0
          },
          {
            "token": "Ġsont",
            "token_id": 15132,
            "logprob": -12.0,
            "prob": 0.0
          },
          {
            "token": "ĠAre",
            "token_id": 8886,
            "logprob": -12.1875,
            "prob": 0.0
          },
          {
            "token": "Ġart",
            "token_id": 1989,
            "logprob": -12.25,
            "prob": 0.0
          },
          {
            "token": "Ġdo",
            "token_id": 656,
            "logprob": -12.9375,
            "prob": 0.0
          },
          {
            "token": "Ġwere",
            "token_id": 1051,
            "logprob": -12.9375,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġare",
        "token_id": 527,
        "selection_method": "sampling"
      }
    },
    {
      "step": 9,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġyou",
            "token_id": 499,
            "logprob": -0.0001,
            "prob": 1.0
          },
          {
            "token": "ĠYou",
            "token_id": 1472,
            "logprob": -10.125,
            "prob": 0.0
          },
          {
            "token": "ĠYOU",
            "token_id": 15334,
            "logprob": -11.75,
            "prob": 0.0
          },
          {
            "token": "you",
            "token_id": 9514,
            "logprob": -12.6875,
            "prob": 0.0
          },
          {
            "token": "你",
            "token_id": 57668,
            "logprob": -13.4375,
            "prob": 0.0
          },
          {
            "token": "You",
            "token_id": 2675,
            "logprob": -13.875,
            "prob": 0.0
          },
          {
            "token": "-you",
            "token_id": 46517,
            "logprob": -13.9375,
            "prob": 0.0
          },
          {
            "token": "您",
            "token_id": 88126,
            "logprob": -14.625,
            "prob": 0.0
          },
          {
            "token": "Ġthee",
            "token_id": 40344,
            "logprob": -15.625,
            "prob": 0.0
          },
          {
            "token": "Ġvous",
            "token_id": 9189,
            "logprob": -15.6875,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġyou",
        "token_id": 499,
        "selection_method": "sampling"
      }
    },
    {
      "step": 10,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "?\"",
            "token_id": 7673,
            "logprob": -0.0006,
            "prob": 1.0
          },
          {
            "token": "?",
            "token_id": 30,
            "logprob": -7.625,
            "prob": 0.0005
          },
          {
            "token": "\"?",
            "token_id": 44969,
            "logprob": -10.5625,
            "prob": 0.0
          },
          {
            "token": "?\",",
            "token_id": 32111,
            "logprob": -10.625,
            "prob": 0.0
          },
          {
            "token": "?\"\n\n",
            "token_id": 12241,
            "logprob": -12.25,
            "prob": 0.0
          },
          {
            "token": ".\"",
            "token_id": 1210,
            "logprob": -12.4375,
            "prob": 0.0
          },
          {
            "token": ",\"",
            "token_id": 1359,
            "logprob": -12.9375,
            "prob": 0.0
          },
          {
            "token": "Ġreally",
            "token_id": 2216,
            "logprob": -13.25,
            "prob": 0.0
          },
          {
            "token": "?”",
            "token_id": 12671,
            "logprob": -13.4375,
            "prob": 0.0
          },
          {
            "token": "?]",
            "token_id": 94068,
            "logprob": -13.5,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "?\"",
        "token_id": 7673,
        "selection_method": "sampling"
      }
    },
    {
      "step": 11,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\"",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\""
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġin",
            "token_id": 304,
            "logprob": -0.0245,
            "prob": 0.9766
          },
          {
            "token": "ĠLet",
            "token_id": 6914,
            "logprob": -4.4062,
            "prob": 0.0123
          },
          {
            "token": "Ġor",
            "token_id": 477,
            "logprob": -4.7812,
            "prob": 0.0084
          },
          {
            "token": "ĠI",
            "token_id": 358,
            "logprob": -6.7812,
            "prob": 0.0011
          },
          {
            "token": "ĠSo",
            "token_id": 2100,
            "logprob": -6.9062,
            "prob": 0.001
          },
          {
            "token": "ĠHmm",
            "token_id": 89290,
            "logprob": -8.375,
            "prob": 0.0002
          },
          {
            "token": "Ġso",
            "token_id": 779,
            "logprob": -8.5625,
            "prob": 0.0002
          },
          {
            "token": "Ġbut",
            "token_id": 719,
            "logprob": -8.625,
            "prob": 0.0002
          },
          {
            "token": "Ġsince",
            "token_id": 2533,
            "logprob": -8.625,
            "prob": 0.0002
          },
          {
            "token": "ĠBut",
            "token_id": 2030,
            "logprob": -9.0,
            "prob": 0.0001
          }
        ]
      },
      "selected_token": {
        "token": "ĠLet",
        "token_id": 6914,
        "selection_method": "sampling"
      }
    },
    {
      "step": 12,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġme",
            "token_id": 757,
            "logprob": -0.0,
            "prob": 1.0
          },
          {
            "token": "'s",
            "token_id": 596,
            "logprob": -10.0,
            "prob": 0.0
          },
          {
            "token": "me",
            "token_id": 2727,
            "logprob": -16.0,
            "prob": 0.0
          },
          {
            "token": "ĠMe",
            "token_id": 2206,
            "logprob": -17.25,
            "prob": 0.0
          },
          {
            "token": "Ġmet",
            "token_id": 2322,
            "logprob": -17.75,
            "prob": 0.0
          },
          {
            "token": "ting",
            "token_id": 1303,
            "logprob": -18.0,
            "prob": 0.0
          },
          {
            "token": "Ġmy",
            "token_id": 856,
            "logprob": -18.125,
            "prob": 0.0
          },
          {
            "token": "'m",
            "token_id": 2846,
            "logprob": -18.375,
            "prob": 0.0
          },
          {
            "token": "我",
            "token_id": 37046,
            "logprob": -19.5,
            "prob": 0.0
          },
          {
            "token": "-me",
            "token_id": 35073,
            "logprob": -19.75,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġmet",
        "token_id": 2322,
        "selection_method": "sampling"
      }
    },
    {
      "step": 13,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġbreak",
            "token_id": 1464,
            "logprob": -0.3789,
            "prob": 0.6836
          },
          {
            "token": "Ġthink",
            "token_id": 1781,
            "logprob": -1.5078,
            "prob": 0.2227
          },
          {
            "token": "Ġstart",
            "token_id": 1212,
            "logprob": -3.0625,
            "prob": 0.0466
          },
          {
            "token": "Ġtranslate",
            "token_id": 15025,
            "logprob": -4.4375,
            "prob": 0.0118
          },
          {
            "token": "h",
            "token_id": 71,
            "logprob": -4.8125,
            "prob": 0.0081
          },
          {
            "token": "Ġme",
            "token_id": 757,
            "logprob": -5.625,
            "prob": 0.0036
          },
          {
            "token": "Ġsee",
            "token_id": 1518,
            "logprob": -5.6875,
            "prob": 0.0034
          },
          {
            "token": "Ġparse",
            "token_id": 4820,
            "logprob": -6.0,
            "prob": 0.0025
          },
          {
            "token": "Ġbreakdown",
            "token_id": 31085,
            "logprob": -6.125,
            "prob": 0.0022
          },
          {
            "token": "Ġmake",
            "token_id": 1304,
            "logprob": -7.0625,
            "prob": 0.0009
          }
        ]
      },
      "selected_token": {
        "token": "Ġsee",
        "token_id": 1518,
        "selection_method": "sampling"
      }
    },
    {
      "step": 14,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": ".",
            "token_id": 13,
            "logprob": -0.7773,
            "prob": 0.459
          },
          {
            "token": "...",
            "token_id": 1131,
            "logprob": -0.9023,
            "prob": 0.4062
          },
          {
            "token": ",",
            "token_id": 11,
            "logprob": -2.1562,
            "prob": 0.1162
          },
          {
            "token": "Ġhow",
            "token_id": 1268,
            "logprob": -4.2812,
            "prob": 0.0139
          },
          {
            "token": ".\n\n",
            "token_id": 382,
            "logprob": -6.2812,
            "prob": 0.0019
          },
          {
            "token": "Ġhere",
            "token_id": 1618,
            "logprob": -7.0312,
            "prob": 0.0009
          },
          {
            "token": "...\n\n",
            "token_id": 2195,
            "logprob": -7.6562,
            "prob": 0.0005
          },
          {
            "token": "Ġthe",
            "token_id": 279,
            "logprob": -7.7812,
            "prob": 0.0004
          },
          {
            "token": "Ġwhat",
            "token_id": 1148,
            "logprob": -8.375,
            "prob": 0.0002
          },
          {
            "token": "…",
            "token_id": 1981,
            "logprob": -9.125,
            "prob": 0.0001
          }
        ]
      },
      "selected_token": {
        "token": "Ġhere",
        "token_id": 1618,
        "selection_method": "sampling"
      }
    },
    {
      "step": 15,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": ".",
            "token_id": 13,
            "logprob": -0.0203,
            "prob": 0.9805
          },
          {
            "token": ".\n\n",
            "token_id": 382,
            "logprob": -4.1562,
            "prob": 0.0159
          },
          {
            "token": "...",
            "token_id": 1131,
            "logprob": -5.9062,
            "prob": 0.0027
          },
          {
            "token": ",",
            "token_id": 11,
            "logprob": -6.6562,
            "prob": 0.0013
          },
          {
            "token": "...\n\n",
            "token_id": 2195,
            "logprob": -10.5,
            "prob": 0.0
          },
          {
            "token": "Ġin",
            "token_id": 304,
            "logprob": -11.25,
            "prob": 0.0
          },
          {
            "token": "…",
            "token_id": 1981,
            "logprob": -11.5,
            "prob": 0.0
          },
          {
            "token": "'s",
            "token_id": 596,
            "logprob": -11.625,
            "prob": 0.0
          },
          {
            "token": "ĠI",
            "token_id": 358,
            "logprob": -11.75,
            "prob": 0.0
          },
          {
            "token": "..",
            "token_id": 497,
            "logprob": -12.0,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": ",",
        "token_id": 11,
        "selection_method": "sampling"
      }
    },
    {
      "step": 16,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here,",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ","
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġthe",
            "token_id": 279,
            "logprob": -0.75,
            "prob": 0.4727
          },
          {
            "token": "Ġthey",
            "token_id": 814,
            "logprob": -1.25,
            "prob": 0.2871
          },
          {
            "token": "ĠI",
            "token_id": 358,
            "logprob": -1.75,
            "prob": 0.1738
          },
          {
            "token": "Ġin",
            "token_id": 304,
            "logprob": -3.625,
            "prob": 0.0266
          },
          {
            "token": "Ġthis",
            "token_id": 420,
            "logprob": -4.0,
            "prob": 0.0183
          },
          {
            "token": "Ġfirst",
            "token_id": 1176,
            "logprob": -4.75,
            "prob": 0.0087
          },
          {
            "token": "Ġ\"",
            "token_id": 330,
            "logprob": -5.75,
            "prob": 0.0032
          },
          {
            "token": "Ġit",
            "token_id": 433,
            "logprob": -5.875,
            "prob": 0.0028
          },
          {
            "token": "Ġmy",
            "token_id": 856,
            "logprob": -5.875,
            "prob": 0.0028
          },
          {
            "token": "Ġmaybe",
            "token_id": 7344,
            "logprob": -6.75,
            "prob": 0.0012
          }
        ]
      },
      "selected_token": {
        "token": "Ġ\"",
        "token_id": 330,
        "selection_method": "sampling"
      }
    },
    {
      "step": 17,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\""
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Qui",
            "token_id": 62545,
            "logprob": -0.0104,
            "prob": 0.9883
          },
          {
            "token": "ĠQui",
            "token_id": 42215,
            "logprob": -5.4375,
            "prob": 0.0043
          },
          {
            "token": "qui",
            "token_id": 47391,
            "logprob": -6.125,
            "prob": 0.0022
          },
          {
            "token": "Ġqui",
            "token_id": 7930,
            "logprob": -6.125,
            "prob": 0.0022
          },
          {
            "token": "Who",
            "token_id": 15546,
            "logprob": -7.875,
            "prob": 0.0004
          },
          {
            "token": "ĠQUI",
            "token_id": 89630,
            "logprob": -8.25,
            "prob": 0.0003
          },
          {
            "token": "QUI",
            "token_id": 12247,
            "logprob": -8.3125,
            "prob": 0.0002
          },
          {
            "token": "Qu",
            "token_id": 2232,
            "logprob": -8.8125,
            "prob": 0.0001
          },
          {
            "token": "who",
            "token_id": 14965,
            "logprob": -9.875,
            "prob": 0.0001
          },
          {
            "token": "qu",
            "token_id": 447,
            "logprob": -10.4375,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Qui",
        "token_id": 62545,
        "selection_method": "sampling"
      }
    },
    {
      "step": 18,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġes",
            "token_id": 1560,
            "logprob": -0.0129,
            "prob": 0.9883
          },
          {
            "token": "Ġest",
            "token_id": 1826,
            "logprob": -4.375,
            "prob": 0.0125
          },
          {
            "token": "Ġé",
            "token_id": 4046,
            "logprob": -9.1875,
            "prob": 0.0001
          },
          {
            "token": "Ġés",
            "token_id": 22257,
            "logprob": -9.9375,
            "prob": 0.0
          },
          {
            "token": "'est",
            "token_id": 17771,
            "logprob": -10.8125,
            "prob": 0.0
          },
          {
            "token": "'es",
            "token_id": 77025,
            "logprob": -10.8125,
            "prob": 0.0
          },
          {
            "token": "ĠEs",
            "token_id": 9419,
            "logprob": -10.875,
            "prob": 0.0
          },
          {
            "token": "Ġte",
            "token_id": 1028,
            "logprob": -11.1875,
            "prob": 0.0
          },
          {
            "token": "\"",
            "token_id": 1,
            "logprob": -11.25,
            "prob": 0.0
          },
          {
            "token": "Ġè",
            "token_id": 11676,
            "logprob": -11.5625,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġè",
        "token_id": 11676,
        "selection_method": "sampling"
      }
    },
    {
      "step": 19,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "s",
            "token_id": 82,
            "logprob": -0.2275,
            "prob": 0.7969
          },
          {
            "token": "Ġtu",
            "token_id": 9964,
            "logprob": -1.9766,
            "prob": 0.1387
          },
          {
            "token": "st",
            "token_id": 267,
            "logprob": -3.0469,
            "prob": 0.0479
          },
          {
            "token": "Ġst",
            "token_id": 357,
            "logprob": -5.2188,
            "prob": 0.0054
          },
          {
            "token": "Ġsto",
            "token_id": 43132,
            "logprob": -7.3438,
            "prob": 0.0006
          },
          {
            "token": "-st",
            "token_id": 5594,
            "logprob": -7.6562,
            "prob": 0.0005
          },
          {
            "token": "Ġsei",
            "token_id": 43237,
            "logprob": -7.9688,
            "prob": 0.0003
          },
          {
            "token": "stri",
            "token_id": 30972,
            "logprob": -8.125,
            "prob": 0.0003
          },
          {
            "token": "sto",
            "token_id": 34152,
            "logprob": -8.1875,
            "prob": 0.0003
          },
          {
            "token": "-t",
            "token_id": 2442,
            "logprob": -8.6875,
            "prob": 0.0002
          }
        ]
      },
      "selected_token": {
        "token": "Ġtu",
        "token_id": 9964,
        "selection_method": "sampling"
      }
    },
    {
      "step": 20,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "?\"",
            "token_id": 7673,
            "logprob": -0.0107,
            "prob": 0.9883
          },
          {
            "token": "\"",
            "token_id": 1,
            "logprob": -4.75,
            "prob": 0.0085
          },
          {
            "token": "?",
            "token_id": 30,
            "logprob": -6.25,
            "prob": 0.0019
          },
          {
            "token": "Ġ?",
            "token_id": 949,
            "logprob": -10.1875,
            "prob": 0.0
          },
          {
            "token": "?\"\n\n",
            "token_id": 12241,
            "logprob": -10.25,
            "prob": 0.0
          },
          {
            "token": "\"?",
            "token_id": 44969,
            "logprob": -11.4375,
            "prob": 0.0
          },
          {
            "token": "?”",
            "token_id": 12671,
            "logprob": -11.6875,
            "prob": 0.0
          },
          {
            "token": "?\",",
            "token_id": 32111,
            "logprob": -12.0625,
            "prob": 0.0
          },
          {
            "token": "?]",
            "token_id": 94068,
            "logprob": -13.0,
            "prob": 0.0
          },
          {
            "token": "?)",
            "token_id": 10380,
            "logprob": -13.125,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "\"",
        "token_id": 1,
        "selection_method": "sampling"
      }
    },
    {
      "step": 21,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\"",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\""
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġin",
            "token_id": 304,
            "logprob": -0.0623,
            "prob": 0.9414
          },
          {
            "token": "Ġis",
            "token_id": 374,
            "logprob": -2.9375,
            "prob": 0.053
          },
          {
            "token": "Ġwhich",
            "token_id": 902,
            "logprob": -6.0625,
            "prob": 0.0023
          },
          {
            "token": "Ġif",
            "token_id": 422,
            "logprob": -6.9375,
            "prob": 0.001
          },
          {
            "token": "Ġor",
            "token_id": 477,
            "logprob": -7.1875,
            "prob": 0.0008
          },
          {
            "token": "Ġmeans",
            "token_id": 3445,
            "logprob": -7.1875,
            "prob": 0.0008
          },
          {
            "token": "Ġtranslates",
            "token_id": 48018,
            "logprob": -7.4375,
            "prob": 0.0006
          },
          {
            "token": "Ġbut",
            "token_id": 719,
            "logprob": -7.5625,
            "prob": 0.0005
          },
          {
            "token": "Ġsince",
            "token_id": 2533,
            "logprob": -7.8125,
            "prob": 0.0004
          },
          {
            "token": "Ġtranslated",
            "token_id": 25548,
            "logprob": -8.1875,
            "prob": 0.0003
          }
        ]
      },
      "selected_token": {
        "token": "Ġbut",
        "token_id": 719,
        "selection_method": "sampling"
      }
    },
    {
      "step": 22,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġwritten",
            "token_id": 5439,
            "logprob": -0.8867,
            "prob": 0.4121
          },
          {
            "token": "Ġin",
            "token_id": 304,
            "logprob": -1.2656,
            "prob": 0.2832
          },
          {
            "token": "Ġthey",
            "token_id": 814,
            "logprob": -1.6406,
            "prob": 0.1943
          },
          {
            "token": "Ġspelled",
            "token_id": 68918,
            "logprob": -2.8906,
            "prob": 0.0557
          },
          {
            "token": "Ġthe",
            "token_id": 279,
            "logprob": -3.7656,
            "prob": 0.0232
          },
          {
            "token": "Ġtranslated",
            "token_id": 25548,
            "logprob": -4.75,
            "prob": 0.0085
          },
          {
            "token": "Ġit",
            "token_id": 433,
            "logprob": -5.0,
            "prob": 0.0067
          },
          {
            "token": "Ġwait",
            "token_id": 3868,
            "logprob": -5.25,
            "prob": 0.0052
          },
          {
            "token": "Ġsince",
            "token_id": 2533,
            "logprob": -5.875,
            "prob": 0.0028
          },
          {
            "token": "Ġactually",
            "token_id": 3604,
            "logprob": -6.25,
            "prob": 0.0019
          }
        ]
      },
      "selected_token": {
        "token": "Ġthey",
        "token_id": 814,
        "selection_method": "sampling"
      }
    },
    {
      "step": 23,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġwrote",
            "token_id": 6267,
            "logprob": -0.0574,
            "prob": 0.9453
          },
          {
            "token": "Ġused",
            "token_id": 1511,
            "logprob": -3.6875,
            "prob": 0.0251
          },
          {
            "token": "Ġspelled",
            "token_id": 68918,
            "logprob": -4.3125,
            "prob": 0.0135
          },
          {
            "token": "Ġtyped",
            "token_id": 33069,
            "logprob": -4.8125,
            "prob": 0.0082
          },
          {
            "token": "Ġput",
            "token_id": 2231,
            "logprob": -5.6875,
            "prob": 0.0034
          },
          {
            "token": "Ġasked",
            "token_id": 4691,
            "logprob": -6.5625,
            "prob": 0.0014
          },
          {
            "token": "Ġprobably",
            "token_id": 4762,
            "logprob": -7.4375,
            "prob": 0.0006
          },
          {
            "token": "Ġmight",
            "token_id": 2643,
            "logprob": -7.5625,
            "prob": 0.0005
          },
          {
            "token": "Ġactually",
            "token_id": 3604,
            "logprob": -7.6875,
            "prob": 0.0005
          },
          {
            "token": "'re",
            "token_id": 2351,
            "logprob": -7.875,
            "prob": 0.0004
          }
        ]
      },
      "selected_token": {
        "token": "Ġspelled",
        "token_id": 68918,
        "selection_method": "sampling"
      }
    },
    {
      "step": 24,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġit",
            "token_id": 433,
            "logprob": -0.0007,
            "prob": 1.0
          },
          {
            "token": "Ġ\"",
            "token_id": 330,
            "logprob": -7.5,
            "prob": 0.0006
          },
          {
            "token": "Ġin",
            "token_id": 304,
            "logprob": -9.625,
            "prob": 0.0001
          },
          {
            "token": "Ġthe",
            "token_id": 279,
            "logprob": -10.3125,
            "prob": 0.0
          },
          {
            "token": "Ġis",
            "token_id": 374,
            "logprob": -11.3125,
            "prob": 0.0
          },
          {
            "token": "ĠQ",
            "token_id": 1229,
            "logprob": -12.8125,
            "prob": 0.0
          },
          {
            "token": "Ġwith",
            "token_id": 449,
            "logprob": -12.875,
            "prob": 0.0
          },
          {
            "token": "Ġthat",
            "token_id": 430,
            "logprob": -13.4375,
            "prob": 0.0
          },
          {
            "token": "ĠFrench",
            "token_id": 8753,
            "logprob": -13.5625,
            "prob": 0.0
          },
          {
            "token": "ĠQu",
            "token_id": 3489,
            "logprob": -13.625,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġit",
        "token_id": 433,
        "selection_method": "sampling"
      }
    },
    {
      "step": 25,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġin",
            "token_id": 304,
            "logprob": -0.2637,
            "prob": 0.7695
          },
          {
            "token": "Ġwith",
            "token_id": 449,
            "logprob": -2.2656,
            "prob": 0.104
          },
          {
            "token": "Ġas",
            "token_id": 439,
            "logprob": -2.3906,
            "prob": 0.0918
          },
          {
            "token": "Ġ\"",
            "token_id": 330,
            "logprob": -4.0,
            "prob": 0.0181
          },
          {
            "token": "ĠFrench",
            "token_id": 8753,
            "logprob": -4.1875,
            "prob": 0.015
          },
          {
            "token": "Ġout",
            "token_id": 704,
            "logprob": -7.125,
            "prob": 0.0008
          },
          {
            "token": "Ġcorrectly",
            "token_id": 12722,
            "logprob": -8.1875,
            "prob": 0.0003
          },
          {
            "token": "Ġusing",
            "token_id": 1701,
            "logprob": -8.5625,
            "prob": 0.0002
          },
          {
            "token": "Ġwrong",
            "token_id": 5076,
            "logprob": -8.75,
            "prob": 0.0002
          },
          {
            "token": "Ġwithout",
            "token_id": 2085,
            "logprob": -9.1875,
            "prob": 0.0001
          }
        ]
      },
      "selected_token": {
        "token": "Ġwith",
        "token_id": 449,
        "selection_method": "sampling"
      }
    },
    {
      "step": 26,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġan",
            "token_id": 459,
            "logprob": -0.3594,
            "prob": 0.6992
          },
          {
            "token": "Ġa",
            "token_id": 264,
            "logprob": -1.8594,
            "prob": 0.1553
          },
          {
            "token": "Ġaccents",
            "token_id": 59570,
            "logprob": -3.1094,
            "prob": 0.0447
          },
          {
            "token": "Ġ\"",
            "token_id": 330,
            "logprob": -3.3594,
            "prob": 0.0347
          },
          {
            "token": "Ġthe",
            "token_id": 279,
            "logprob": -3.6719,
            "prob": 0.0254
          },
          {
            "token": "ĠFrench",
            "token_id": 8753,
            "logprob": -3.8594,
            "prob": 0.0211
          },
          {
            "token": "ĠEnglish",
            "token_id": 6498,
            "logprob": -5.0625,
            "prob": 0.0064
          },
          {
            "token": "Ġsome",
            "token_id": 1063,
            "logprob": -5.9375,
            "prob": 0.0027
          },
          {
            "token": "Ġ'",
            "token_id": 364,
            "logprob": -6.9375,
            "prob": 0.001
          },
          {
            "token": "Ġaccent",
            "token_id": 30200,
            "logprob": -6.9375,
            "prob": 0.001
          }
        ]
      },
      "selected_token": {
        "token": "Ġsome",
        "token_id": 1063,
        "selection_method": "sampling"
      }
    },
    {
      "step": 27,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġaccents",
            "token_id": 59570,
            "logprob": -0.5391,
            "prob": 0.582
          },
          {
            "token": "ĠFrench",
            "token_id": 8753,
            "logprob": -1.2266,
            "prob": 0.293
          },
          {
            "token": "Ġaccent",
            "token_id": 30200,
            "logprob": -3.2344,
            "prob": 0.0396
          },
          {
            "token": "Ġacc",
            "token_id": 1046,
            "logprob": -3.5469,
            "prob": 0.0291
          },
          {
            "token": "Ġty",
            "token_id": 13892,
            "logprob": -3.9844,
            "prob": 0.0187
          },
          {
            "token": "Ġdi",
            "token_id": 1891,
            "logprob": -4.7188,
            "prob": 0.0089
          },
          {
            "token": "Ġextra",
            "token_id": 5066,
            "logprob": -5.9062,
            "prob": 0.0027
          },
          {
            "token": "Ġweird",
            "token_id": 16682,
            "logprob": -6.2188,
            "prob": 0.002
          },
          {
            "token": "Ġtypo",
            "token_id": 86205,
            "logprob": -6.5312,
            "prob": 0.0014
          },
          {
            "token": "ĠEnglish",
            "token_id": 6498,
            "logprob": -6.6562,
            "prob": 0.0013
          }
        ]
      },
      "selected_token": {
        "token": "Ġextra",
        "token_id": 5066,
        "selection_method": "sampling"
      }
    },
    {
      "step": 28,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġletters",
            "token_id": 12197,
            "logprob": -0.5547,
            "prob": 0.5742
          },
          {
            "token": "Ġcharacters",
            "token_id": 5885,
            "logprob": -1.5547,
            "prob": 0.2109
          },
          {
            "token": "Ġaccents",
            "token_id": 59570,
            "logprob": -2.4375,
            "prob": 0.0879
          },
          {
            "token": "Ġspaces",
            "token_id": 12908,
            "logprob": -3.4375,
            "prob": 0.0325
          },
          {
            "token": "Ġ'",
            "token_id": 364,
            "logprob": -4.125,
            "prob": 0.0162
          },
          {
            "token": "Ġ\"",
            "token_id": 330,
            "logprob": -4.375,
            "prob": 0.0127
          },
          {
            "token": "Ġacc",
            "token_id": 1046,
            "logprob": -4.5625,
            "prob": 0.0105
          },
          {
            "token": "Ġe",
            "token_id": 384,
            "logprob": -4.6875,
            "prob": 0.0093
          },
          {
            "token": "Ġaccent",
            "token_id": 30200,
            "logprob": -5.0,
            "prob": 0.0068
          },
          {
            "token": "Ġum",
            "token_id": 4543,
            "logprob": -5.25,
            "prob": 0.0053
          }
        ]
      },
      "selected_token": {
        "token": "Ġaccent",
        "token_id": 30200,
        "selection_method": "sampling"
      }
    },
    {
      "step": 29,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġmarks",
            "token_id": 15785,
            "logprob": -0.0703,
            "prob": 0.9336
          },
          {
            "token": "Ġmaybe",
            "token_id": 7344,
            "logprob": -3.3906,
            "prob": 0.0339
          },
          {
            "token": "Ġand",
            "token_id": 323,
            "logprob": -4.5625,
            "prob": 0.0104
          },
          {
            "token": "Ġon",
            "token_id": 389,
            "logprob": -5.25,
            "prob": 0.0052
          },
          {
            "token": ":",
            "token_id": 25,
            "logprob": -5.625,
            "prob": 0.0036
          },
          {
            "token": ",",
            "token_id": 11,
            "logprob": -6.125,
            "prob": 0.0022
          },
          {
            "token": "Ġsigns",
            "token_id": 12195,
            "logprob": -6.3125,
            "prob": 0.0018
          },
          {
            "token": "Ġmarkings",
            "token_id": 65172,
            "logprob": -6.5625,
            "prob": 0.0014
          },
          {
            "token": "Ġcharacters",
            "token_id": 5885,
            "logprob": -6.5625,
            "prob": 0.0014
          },
          {
            "token": "Ġin",
            "token_id": 304,
            "logprob": -6.9375,
            "prob": 0.001
          }
        ]
      },
      "selected_token": {
        "token": "Ġmarks",
        "token_id": 15785,
        "selection_method": "sampling"
      }
    },
    {
      "step": 30,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġmaybe",
            "token_id": 7344,
            "logprob": -1.1719,
            "prob": 0.3086
          },
          {
            "token": ",",
            "token_id": 11,
            "logprob": -1.5469,
            "prob": 0.2119
          },
          {
            "token": ".",
            "token_id": 13,
            "logprob": -1.6719,
            "prob": 0.1875
          },
          {
            "token": "Ġand",
            "token_id": 323,
            "logprob": -2.2969,
            "prob": 0.1001
          },
          {
            "token": "?",
            "token_id": 30,
            "logprob": -2.2969,
            "prob": 0.1001
          },
          {
            "token": ":",
            "token_id": 25,
            "logprob": -3.4219,
            "prob": 0.0325
          },
          {
            "token": "Ġor",
            "token_id": 477,
            "logprob": -3.9219,
            "prob": 0.0198
          },
          {
            "token": "Ġin",
            "token_id": 304,
            "logprob": -4.0625,
            "prob": 0.0175
          },
          {
            "token": "Ġlike",
            "token_id": 1093,
            "logprob": -5.5625,
            "prob": 0.0039
          },
          {
            "token": "...",
            "token_id": 1131,
            "logprob": -5.5625,
            "prob": 0.0039
          }
        ]
      },
      "selected_token": {
        "token": "?",
        "token_id": 30,
        "selection_method": "sampling"
      }
    },
    {
      "step": 31,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks?",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "ĠWait",
            "token_id": 14144,
            "logprob": -0.6914,
            "prob": 0.5
          },
          {
            "token": "ĠMaybe",
            "token_id": 10926,
            "logprob": -0.8164,
            "prob": 0.4414
          },
          {
            "token": "ĠOr",
            "token_id": 2582,
            "logprob": -4.0625,
            "prob": 0.0171
          },
          {
            "token": "ĠHmm",
            "token_id": 89290,
            "logprob": -4.5625,
            "prob": 0.0104
          },
          {
            "token": "ĠProbably",
            "token_id": 38254,
            "logprob": -4.8125,
            "prob": 0.0081
          },
          {
            "token": "ĠAnyway",
            "token_id": 42669,
            "logprob": -5.0625,
            "prob": 0.0063
          },
          {
            "token": "ĠLike",
            "token_id": 9086,
            "logprob": -5.3125,
            "prob": 0.0049
          },
          {
            "token": "ĠWell",
            "token_id": 8489,
            "logprob": -5.6875,
            "prob": 0.0034
          },
          {
            "token": "ĠNot",
            "token_id": 2876,
            "logprob": -6.3125,
            "prob": 0.0018
          },
          {
            "token": "ĠThe",
            "token_id": 578,
            "logprob": -6.4375,
            "prob": 0.0016
          }
        ]
      },
      "selected_token": {
        "token": "ĠWait",
        "token_id": 14144,
        "selection_method": "sampling"
      }
    },
    {
      "step": 32,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": ",",
            "token_id": 11,
            "logprob": -0.0369,
            "prob": 0.9648
          },
          {
            "token": "Ġno",
            "token_id": 912,
            "logprob": -3.4062,
            "prob": 0.033
          },
          {
            "token": "Ġthe",
            "token_id": 279,
            "logprob": -6.1562,
            "prob": 0.0021
          },
          {
            "token": "Ġactually",
            "token_id": 3604,
            "logprob": -7.0312,
            "prob": 0.0009
          },
          {
            "token": "Ġ\"",
            "token_id": 330,
            "logprob": -9.3125,
            "prob": 0.0001
          },
          {
            "token": "Ġin",
            "token_id": 304,
            "logprob": -9.5625,
            "prob": 0.0001
          },
          {
            "token": "Ġmaybe",
            "token_id": 7344,
            "logprob": -9.6875,
            "prob": 0.0001
          },
          {
            "token": "ĠFrench",
            "token_id": 8753,
            "logprob": -12.3125,
            "prob": 0.0
          },
          {
            "token": "Ġthey",
            "token_id": 814,
            "logprob": -12.875,
            "prob": 0.0
          },
          {
            "token": "Ġwait",
            "token_id": 3868,
            "logprob": -13.0,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġno",
        "token_id": 912,
        "selection_method": "sampling"
      }
    },
    {
      "step": 33,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": ",",
            "token_id": 11,
            "logprob": -0.0001,
            "prob": 1.0
          },
          {
            "token": "Ġactually",
            "token_id": 3604,
            "logprob": -9.375,
            "prob": 0.0001
          },
          {
            "token": "Ġthe",
            "token_id": 279,
            "logprob": -11.5,
            "prob": 0.0
          },
          {
            "token": "Ġin",
            "token_id": 304,
            "logprob": -11.625,
            "prob": 0.0
          },
          {
            "token": "pe",
            "token_id": 375,
            "logprob": -11.875,
            "prob": 0.0
          },
          {
            "token": ".",
            "token_id": 13,
            "logprob": -12.0,
            "prob": 0.0
          },
          {
            "token": ",\"",
            "token_id": 1359,
            "logprob": -12.625,
            "prob": 0.0
          },
          {
            "token": "Ġ\"",
            "token_id": 330,
            "logprob": -13.125,
            "prob": 0.0
          },
          {
            "token": "Ġwait",
            "token_id": 3868,
            "logprob": -13.25,
            "prob": 0.0
          },
          {
            "token": "Ġmaybe",
            "token_id": 7344,
            "logprob": -13.5,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": ",",
        "token_id": 11,
        "selection_method": "sampling"
      }
    },
    {
      "step": 34,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no,",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ","
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġthe",
            "token_id": 279,
            "logprob": -0.5742,
            "prob": 0.5625
          },
          {
            "token": "Ġactually",
            "token_id": 3604,
            "logprob": -1.4531,
            "prob": 0.2344
          },
          {
            "token": "Ġin",
            "token_id": 304,
            "logprob": -2.3281,
            "prob": 0.0977
          },
          {
            "token": "Ġmaybe",
            "token_id": 7344,
            "logprob": -3.4531,
            "prob": 0.0317
          },
          {
            "token": "Ġthey",
            "token_id": 814,
            "logprob": -3.7031,
            "prob": 0.0248
          },
          {
            "token": "Ġlooking",
            "token_id": 3411,
            "logprob": -3.8281,
            "prob": 0.0219
          },
          {
            "token": "Ġ\"",
            "token_id": 330,
            "logprob": -4.3125,
            "prob": 0.0132
          },
          {
            "token": "Ġit",
            "token_id": 433,
            "logprob": -4.8125,
            "prob": 0.0081
          },
          {
            "token": "ĠFrench",
            "token_id": 8753,
            "logprob": -6.6875,
            "prob": 0.0012
          },
          {
            "token": "Ġwait",
            "token_id": 3868,
            "logprob": -6.8125,
            "prob": 0.0011
          }
        ]
      },
      "selected_token": {
        "token": "Ġin",
        "token_id": 304,
        "selection_method": "sampling"
      }
    },
    {
      "step": 35,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "ĠFrench",
            "token_id": 8753,
            "logprob": -0.0522,
            "prob": 0.9492
          },
          {
            "token": "Ġthe",
            "token_id": 279,
            "logprob": -3.1719,
            "prob": 0.0417
          },
          {
            "token": "ĠEnglish",
            "token_id": 6498,
            "logprob": -4.8125,
            "prob": 0.0082
          },
          {
            "token": "Ġtheir",
            "token_id": 872,
            "logprob": -8.125,
            "prob": 0.0003
          },
          {
            "token": "Ġfrench",
            "token_id": 42293,
            "logprob": -9.25,
            "prob": 0.0001
          },
          {
            "token": "ĠCatalan",
            "token_id": 81944,
            "logprob": -9.625,
            "prob": 0.0001
          },
          {
            "token": "Ġthis",
            "token_id": 420,
            "logprob": -9.75,
            "prob": 0.0001
          },
          {
            "token": "ĠChinese",
            "token_id": 8620,
            "logprob": -9.875,
            "prob": 0.0001
          },
          {
            "token": "ĠItalian",
            "token_id": 15155,
            "logprob": -10.0625,
            "prob": 0.0
          },
          {
            "token": "French",
            "token_id": 44297,
            "logprob": -10.125,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġfrench",
        "token_id": 42293,
        "selection_method": "sampling"
      }
    },
    {
      "step": 36,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġit",
            "token_id": 433,
            "logprob": -0.4336,
            "prob": 0.6484
          },
          {
            "token": "Ġ\"",
            "token_id": 330,
            "logprob": -1.4297,
            "prob": 0.2383
          },
          {
            "token": ",",
            "token_id": 11,
            "logprob": -2.5625,
            "prob": 0.0776
          },
          {
            "token": "Ġthat",
            "token_id": 430,
            "logprob": -3.6875,
            "prob": 0.0251
          },
          {
            "token": "Ġmaybe",
            "token_id": 7344,
            "logprob": -5.9375,
            "prob": 0.0027
          },
          {
            "token": "Ġthe",
            "token_id": 279,
            "logprob": -6.25,
            "prob": 0.0019
          },
          {
            "token": "Ġthey",
            "token_id": 814,
            "logprob": -6.6875,
            "prob": 0.0013
          },
          {
            "token": "?",
            "token_id": 30,
            "logprob": -7.0,
            "prob": 0.0009
          },
          {
            "token": ".",
            "token_id": 13,
            "logprob": -7.1875,
            "prob": 0.0008
          },
          {
            "token": ":",
            "token_id": 25,
            "logprob": -8.0,
            "prob": 0.0003
          }
        ]
      },
      "selected_token": {
        "token": ",",
        "token_id": 11,
        "selection_method": "sampling"
      }
    },
    {
      "step": 37,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french,",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ","
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġ\"",
            "token_id": 330,
            "logprob": -0.1807,
            "prob": 0.8359
          },
          {
            "token": "Ġit",
            "token_id": 433,
            "logprob": -2.3125,
            "prob": 0.0996
          },
          {
            "token": "Ġthe",
            "token_id": 279,
            "logprob": -2.9375,
            "prob": 0.0535
          },
          {
            "token": "Ġmaybe",
            "token_id": 7344,
            "logprob": -5.8125,
            "prob": 0.003
          },
          {
            "token": "Ġactually",
            "token_id": 3604,
            "logprob": -6.375,
            "prob": 0.0017
          },
          {
            "token": "Ġqui",
            "token_id": 7930,
            "logprob": -7.0,
            "prob": 0.0009
          },
          {
            "token": "Ġquestion",
            "token_id": 3488,
            "logprob": -7.25,
            "prob": 0.0007
          },
          {
            "token": "ĠQui",
            "token_id": 42215,
            "logprob": -7.25,
            "prob": 0.0007
          },
          {
            "token": "Ġthat",
            "token_id": 430,
            "logprob": -7.375,
            "prob": 0.0006
          },
          {
            "token": "Ġquestions",
            "token_id": 4860,
            "logprob": -7.75,
            "prob": 0.0004
          }
        ]
      },
      "selected_token": {
        "token": "Ġactually",
        "token_id": 3604,
        "selection_method": "sampling"
      }
    },
    {
      "step": 38,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġ\"",
            "token_id": 330,
            "logprob": -0.5898,
            "prob": 0.5547
          },
          {
            "token": ",",
            "token_id": 11,
            "logprob": -1.4609,
            "prob": 0.2314
          },
          {
            "token": "Ġthe",
            "token_id": 279,
            "logprob": -1.9609,
            "prob": 0.1406
          },
          {
            "token": ".",
            "token_id": 13,
            "logprob": -3.8438,
            "prob": 0.0215
          },
          {
            "token": "Ġin",
            "token_id": 304,
            "logprob": -3.9688,
            "prob": 0.019
          },
          {
            "token": "Ġit",
            "token_id": 433,
            "logprob": -3.9688,
            "prob": 0.019
          },
          {
            "token": "ĠFrench",
            "token_id": 8753,
            "logprob": -5.2188,
            "prob": 0.0054
          },
          {
            "token": "Ġthey",
            "token_id": 814,
            "logprob": -6.3438,
            "prob": 0.0018
          },
          {
            "token": "Ġmaybe",
            "token_id": 7344,
            "logprob": -7.4062,
            "prob": 0.0006
          },
          {
            "token": "Ġno",
            "token_id": 912,
            "logprob": -7.4688,
            "prob": 0.0006
          }
        ]
      },
      "selected_token": {
        "token": ",",
        "token_id": 11,
        "selection_method": "sampling"
      }
    },
    {
      "step": 39,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually,",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ","
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġ\"",
            "token_id": 330,
            "logprob": -0.3047,
            "prob": 0.7383
          },
          {
            "token": "Ġthe",
            "token_id": 279,
            "logprob": -1.5547,
            "prob": 0.2119
          },
          {
            "token": "Ġit",
            "token_id": 433,
            "logprob": -3.7969,
            "prob": 0.0223
          },
          {
            "token": "Ġthey",
            "token_id": 814,
            "logprob": -4.8125,
            "prob": 0.0082
          },
          {
            "token": "Ġin",
            "token_id": 304,
            "logprob": -5.375,
            "prob": 0.0047
          },
          {
            "token": "Ġmaybe",
            "token_id": 7344,
            "logprob": -5.75,
            "prob": 0.0032
          },
          {
            "token": "Ġbut",
            "token_id": 719,
            "logprob": -6.125,
            "prob": 0.0022
          },
          {
            "token": "ĠFrench",
            "token_id": 8753,
            "logprob": -6.375,
            "prob": 0.0017
          },
          {
            "token": "Ġif",
            "token_id": 422,
            "logprob": -6.5,
            "prob": 0.0015
          },
          {
            "token": "Ġthat",
            "token_id": 430,
            "logprob": -6.5625,
            "prob": 0.0014
          }
        ]
      },
      "selected_token": {
        "token": "Ġ\"",
        "token_id": 330,
        "selection_method": "sampling"
      }
    },
    {
      "step": 40,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\""
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Qui",
            "token_id": 62545,
            "logprob": -0.0262,
            "prob": 0.9727
          },
          {
            "token": "Ġqui",
            "token_id": 7930,
            "logprob": -4.5938,
            "prob": 0.0102
          },
          {
            "token": "ĠQui",
            "token_id": 42215,
            "logprob": -5.0312,
            "prob": 0.0066
          },
          {
            "token": "qui",
            "token_id": 47391,
            "logprob": -5.6562,
            "prob": 0.0035
          },
          {
            "token": "Who",
            "token_id": 15546,
            "logprob": -5.7188,
            "prob": 0.0033
          },
          {
            "token": "Qu",
            "token_id": 2232,
            "logprob": -7.3438,
            "prob": 0.0006
          },
          {
            "token": "ĠQUI",
            "token_id": 89630,
            "logprob": -7.9688,
            "prob": 0.0003
          },
          {
            "token": "who",
            "token_id": 14965,
            "logprob": -8.25,
            "prob": 0.0003
          },
          {
            "token": "QUI",
            "token_id": 12247,
            "logprob": -8.625,
            "prob": 0.0002
          },
          {
            "token": "qu",
            "token_id": 447,
            "logprob": -9.1875,
            "prob": 0.0001
          }
        ]
      },
      "selected_token": {
        "token": "QUI",
        "token_id": 12247,
        "selection_method": "sampling"
      }
    },
    {
      "step": 41,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "ĠES",
            "token_id": 19844,
            "logprob": -0.8203,
            "prob": 0.4395
          },
          {
            "token": "ES",
            "token_id": 1600,
            "logprob": -1.4453,
            "prob": 0.2354
          },
          {
            "token": "Ġest",
            "token_id": 1826,
            "logprob": -1.8203,
            "prob": 0.1621
          },
          {
            "token": "Ġes",
            "token_id": 1560,
            "logprob": -2.6406,
            "prob": 0.0718
          },
          {
            "token": "ĠEST",
            "token_id": 26963,
            "logprob": -3.1406,
            "prob": 0.0435
          },
          {
            "token": "ĠEs",
            "token_id": 9419,
            "logprob": -5.375,
            "prob": 0.0046
          },
          {
            "token": "Ġè",
            "token_id": 11676,
            "logprob": -5.75,
            "prob": 0.0032
          },
          {
            "token": "\"",
            "token_id": 1,
            "logprob": -5.9375,
            "prob": 0.0026
          },
          {
            "token": "Es",
            "token_id": 17812,
            "logprob": -6.0625,
            "prob": 0.0023
          },
          {
            "token": "-",
            "token_id": 12,
            "logprob": -6.125,
            "prob": 0.0022
          }
        ]
      },
      "selected_token": {
        "token": "ĠEST",
        "token_id": 26963,
        "selection_method": "sampling"
      }
    },
    {
      "step": 42,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI EST",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "-",
            "token_id": 12,
            "logprob": -0.5,
            "prob": 0.6055
          },
          {
            "token": "ĠTU",
            "token_id": 70514,
            "logprob": -1.75,
            "prob": 0.1738
          },
          {
            "token": "U",
            "token_id": 52,
            "logprob": -2.625,
            "prob": 0.0723
          },
          {
            "token": "-T",
            "token_id": 9469,
            "logprob": -4.0625,
            "prob": 0.0172
          },
          {
            "token": "ĠU",
            "token_id": 549,
            "logprob": -4.1875,
            "prob": 0.0151
          },
          {
            "token": "-U",
            "token_id": 35681,
            "logprob": -4.4375,
            "prob": 0.0118
          },
          {
            "token": "ĠT",
            "token_id": 350,
            "logprob": -4.625,
            "prob": 0.0098
          },
          {
            "token": "S",
            "token_id": 50,
            "logprob": -4.8125,
            "prob": 0.0081
          },
          {
            "token": "ĠQUE",
            "token_id": 30776,
            "logprob": -5.0625,
            "prob": 0.0063
          },
          {
            "token": "T",
            "token_id": 51,
            "logprob": -6.0312,
            "prob": 0.0024
          }
        ]
      },
      "selected_token": {
        "token": "U",
        "token_id": 52,
        "selection_method": "sampling"
      }
    },
    {
      "step": 43,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "?\"",
            "token_id": 7673,
            "logprob": -0.8008,
            "prob": 0.4473
          },
          {
            "token": "\"",
            "token_id": 1,
            "logprob": -0.9258,
            "prob": 0.3965
          },
          {
            "token": "ĠTU",
            "token_id": 70514,
            "logprob": -2.2969,
            "prob": 0.1001
          },
          {
            "token": "\"?",
            "token_id": 44969,
            "logprob": -3.7344,
            "prob": 0.0238
          },
          {
            "token": "?",
            "token_id": 30,
            "logprob": -4.6875,
            "prob": 0.0093
          },
          {
            "token": "\".",
            "token_id": 3343,
            "logprob": -5.5,
            "prob": 0.0041
          },
          {
            "token": "Ġ?",
            "token_id": 949,
            "logprob": -5.9375,
            "prob": 0.0027
          },
          {
            "token": "ĠT",
            "token_id": 350,
            "logprob": -6.75,
            "prob": 0.0012
          },
          {
            "token": ".\"",
            "token_id": 1210,
            "logprob": -7.3125,
            "prob": 0.0007
          },
          {
            "token": "ĠTI",
            "token_id": 39237,
            "logprob": -7.3125,
            "prob": 0.0007
          }
        ]
      },
      "selected_token": {
        "token": "ĠTU",
        "token_id": 70514,
        "selection_method": "sampling"
      }
    },
    {
      "step": 44,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "?\"",
            "token_id": 7673,
            "logprob": -0.5664,
            "prob": 0.5664
          },
          {
            "token": "\"",
            "token_id": 1,
            "logprob": -0.9414,
            "prob": 0.3906
          },
          {
            "token": "\"?",
            "token_id": 44969,
            "logprob": -3.8125,
            "prob": 0.022
          },
          {
            "token": "\".",
            "token_id": 3343,
            "logprob": -4.5625,
            "prob": 0.0104
          },
          {
            "token": "?",
            "token_id": 30,
            "logprob": -4.8125,
            "prob": 0.0081
          },
          {
            "token": ".\"",
            "token_id": 1210,
            "logprob": -7.625,
            "prob": 0.0005
          },
          {
            "token": "Ġ?",
            "token_id": 949,
            "logprob": -7.9375,
            "prob": 0.0004
          },
          {
            "token": "\",",
            "token_id": 498,
            "logprob": -8.25,
            "prob": 0.0003
          },
          {
            "token": "?\",",
            "token_id": 32111,
            "logprob": -9.375,
            "prob": 0.0001
          },
          {
            "token": "\"—",
            "token_id": 66101,
            "logprob": -9.4375,
            "prob": 0.0001
          }
        ]
      },
      "selected_token": {
        "token": "?",
        "token_id": 30,
        "selection_method": "sampling"
      }
    },
    {
      "step": 45,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU?",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "\".",
            "token_id": 3343,
            "logprob": -0.1455,
            "prob": 0.8633
          },
          {
            "token": "ĠWait",
            "token_id": 14144,
            "logprob": -3.1406,
            "prob": 0.043
          },
          {
            "token": "Ġ\"",
            "token_id": 330,
            "logprob": -4.1562,
            "prob": 0.0159
          },
          {
            "token": "?\"",
            "token_id": 7673,
            "logprob": -4.4062,
            "prob": 0.0123
          },
          {
            "token": "!\"",
            "token_id": 9135,
            "logprob": -4.6562,
            "prob": 0.0096
          },
          {
            "token": "\"\"",
            "token_id": 3089,
            "logprob": -5.1562,
            "prob": 0.0058
          },
          {
            "token": "ĠThat",
            "token_id": 3011,
            "logprob": -5.4688,
            "prob": 0.0043
          },
          {
            "token": "ĠNo",
            "token_id": 2360,
            "logprob": -5.6562,
            "prob": 0.0035
          },
          {
            "token": "ĠOr",
            "token_id": 2582,
            "logprob": -6.0312,
            "prob": 0.0024
          },
          {
            "token": "ĠOh",
            "token_id": 8840,
            "logprob": -6.0938,
            "prob": 0.0023
          }
        ]
      },
      "selected_token": {
        "token": "ĠThat",
        "token_id": 3011,
        "selection_method": "sampling"
      }
    },
    {
      "step": 46,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU? That",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?",
        "ĠThat"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30,
        3011
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "'s",
            "token_id": 596,
            "logprob": -0.1943,
            "prob": 0.8242
          },
          {
            "token": "Ġdoesn",
            "token_id": 3250,
            "logprob": -3.0625,
            "prob": 0.0464
          },
          {
            "token": "Ġwould",
            "token_id": 1053,
            "logprob": -3.1875,
            "prob": 0.041
          },
          {
            "token": "Ġmight",
            "token_id": 2643,
            "logprob": -3.3125,
            "prob": 0.0361
          },
          {
            "token": "Ġlooks",
            "token_id": 5992,
            "logprob": -4.0625,
            "prob": 0.0171
          },
          {
            "token": "Ġseems",
            "token_id": 5084,
            "logprob": -4.5625,
            "prob": 0.0104
          },
          {
            "token": "’s",
            "token_id": 753,
            "logprob": -4.9375,
            "prob": 0.0071
          },
          {
            "token": "Ġcan",
            "token_id": 649,
            "logprob": -5.8125,
            "prob": 0.003
          },
          {
            "token": "Ġwas",
            "token_id": 574,
            "logprob": -5.9375,
            "prob": 0.0026
          },
          {
            "token": "Ġmakes",
            "token_id": 3727,
            "logprob": -6.0625,
            "prob": 0.0023
          }
        ]
      },
      "selected_token": {
        "token": "Ġwould",
        "token_id": 1053,
        "selection_method": "sampling"
      }
    },
    {
      "step": 47,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU? That would",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?",
        "ĠThat",
        "Ġwould"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30,
        3011,
        1053
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġbe",
            "token_id": 387,
            "logprob": -0.0167,
            "prob": 0.9844
          },
          {
            "token": "Ġmean",
            "token_id": 3152,
            "logprob": -5.2812,
            "prob": 0.0052
          },
          {
            "token": "Ġtranslate",
            "token_id": 15025,
            "logprob": -5.4062,
            "prob": 0.0045
          },
          {
            "token": "Ġmake",
            "token_id": 1304,
            "logprob": -6.2812,
            "prob": 0.0019
          },
          {
            "token": "Ġactually",
            "token_id": 3604,
            "logprob": -6.5312,
            "prob": 0.0015
          },
          {
            "token": "Ġhave",
            "token_id": 617,
            "logprob": -6.7812,
            "prob": 0.0012
          },
          {
            "token": "Ġprobably",
            "token_id": 4762,
            "logprob": -7.4062,
            "prob": 0.0006
          },
          {
            "token": "Ġliterally",
            "token_id": 16280,
            "logprob": -7.6562,
            "prob": 0.0005
          },
          {
            "token": "Ġnot",
            "token_id": 539,
            "logprob": -8.0,
            "prob": 0.0003
          },
          {
            "token": "Ġnormally",
            "token_id": 14614,
            "logprob": -9.125,
            "prob": 0.0001
          }
        ]
      },
      "selected_token": {
        "token": "Ġtranslate",
        "token_id": 15025,
        "selection_method": "sampling"
      }
    },
    {
      "step": 48,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU? That would translate",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?",
        "ĠThat",
        "Ġwould",
        "Ġtranslate"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30,
        3011,
        1053,
        15025
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġto",
            "token_id": 311,
            "logprob": -0.0178,
            "prob": 0.9805
          },
          {
            "token": "Ġas",
            "token_id": 439,
            "logprob": -5.2812,
            "prob": 0.0052
          },
          {
            "token": "Ġdirectly",
            "token_id": 6089,
            "logprob": -5.5312,
            "prob": 0.004
          },
          {
            "token": "Ġliterally",
            "token_id": 16280,
            "logprob": -6.0312,
            "prob": 0.0024
          },
          {
            "token": "Ġfrom",
            "token_id": 505,
            "logprob": -6.4062,
            "prob": 0.0017
          },
          {
            "token": "Ġback",
            "token_id": 1203,
            "logprob": -7.1562,
            "prob": 0.0008
          },
          {
            "token": "Ġ\"",
            "token_id": 330,
            "logprob": -7.5312,
            "prob": 0.0005
          },
          {
            "token": "Ġmore",
            "token_id": 810,
            "logprob": -7.6562,
            "prob": 0.0005
          },
          {
            "token": "Ġlike",
            "token_id": 1093,
            "logprob": -7.7812,
            "prob": 0.0004
          },
          {
            "token": ".",
            "token_id": 13,
            "logprob": -7.9062,
            "prob": 0.0004
          }
        ]
      },
      "selected_token": {
        "token": "Ġ\"",
        "token_id": 330,
        "selection_method": "sampling"
      }
    },
    {
      "step": 49,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU? That would translate \"",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?",
        "ĠThat",
        "Ġwould",
        "Ġtranslate",
        "Ġ\""
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30,
        3011,
        1053,
        15025,
        330
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Who",
            "token_id": 15546,
            "logprob": -0.0742,
            "prob": 0.9297
          },
          {
            "token": "Qui",
            "token_id": 62545,
            "logprob": -3.3281,
            "prob": 0.0359
          },
          {
            "token": "WHO",
            "token_id": 78847,
            "logprob": -4.0625,
            "prob": 0.017
          },
          {
            "token": "ĠWho",
            "token_id": 10699,
            "logprob": -4.9375,
            "prob": 0.0071
          },
          {
            "token": "who",
            "token_id": 14965,
            "logprob": -5.0,
            "prob": 0.0067
          },
          {
            "token": "ĠWHO",
            "token_id": 40312,
            "logprob": -6.4375,
            "prob": 0.0016
          },
          {
            "token": "ĠQui",
            "token_id": 42215,
            "logprob": -7.5,
            "prob": 0.0005
          },
          {
            "token": "Ġqui",
            "token_id": 7930,
            "logprob": -7.6875,
            "prob": 0.0005
          },
          {
            "token": "Ġwho",
            "token_id": 889,
            "logprob": -7.8125,
            "prob": 0.0004
          },
          {
            "token": "What",
            "token_id": 3923,
            "logprob": -8.0,
            "prob": 0.0003
          }
        ]
      },
      "selected_token": {
        "token": "Qui",
        "token_id": 62545,
        "selection_method": "sampling"
      }
    },
    {
      "step": 50,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU? That would translate \"Qui",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?",
        "ĠThat",
        "Ġwould",
        "Ġtranslate",
        "Ġ\"",
        "Qui"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30,
        3011,
        1053,
        15025,
        330,
        62545
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġes",
            "token_id": 1560,
            "logprob": -0.2178,
            "prob": 0.8047
          },
          {
            "token": "Ġest",
            "token_id": 1826,
            "logprob": -1.6562,
            "prob": 0.1914
          },
          {
            "token": "Ġêtes",
            "token_id": 62299,
            "logprob": -7.2812,
            "prob": 0.0007
          },
          {
            "token": "'est",
            "token_id": 17771,
            "logprob": -7.8438,
            "prob": 0.0004
          },
          {
            "token": "ĠEs",
            "token_id": 9419,
            "logprob": -7.9062,
            "prob": 0.0004
          },
          {
            "token": "Ġés",
            "token_id": 22257,
            "logprob": -7.9062,
            "prob": 0.0004
          },
          {
            "token": "Ġsont",
            "token_id": 15132,
            "logprob": -8.5,
            "prob": 0.0002
          },
          {
            "token": "Ġet",
            "token_id": 1880,
            "logprob": -8.6875,
            "prob": 0.0002
          },
          {
            "token": "Ġé",
            "token_id": 4046,
            "logprob": -8.75,
            "prob": 0.0002
          },
          {
            "token": "Ġè",
            "token_id": 11676,
            "logprob": -9.0,
            "prob": 0.0001
          }
        ]
      },
      "selected_token": {
        "token": "Ġé",
        "token_id": 4046,
        "selection_method": "sampling"
      }
    },
    {
      "step": 51,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU? That would translate \"Qui é",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?",
        "ĠThat",
        "Ġwould",
        "Ġtranslate",
        "Ġ\"",
        "Qui",
        "Ġé"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30,
        3011,
        1053,
        15025,
        330,
        62545,
        4046
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "ts",
            "token_id": 2641,
            "logprob": -0.332,
            "prob": 0.7188
          },
          {
            "token": "st",
            "token_id": 267,
            "logprob": -1.7656,
            "prob": 0.1709
          },
          {
            "token": "ta",
            "token_id": 2629,
            "logprob": -4.7812,
            "prob": 0.0085
          },
          {
            "token": "tes",
            "token_id": 2392,
            "logprob": -4.875,
            "prob": 0.0077
          },
          {
            "token": "des",
            "token_id": 5919,
            "logprob": -5.375,
            "prob": 0.0047
          },
          {
            "token": "t",
            "token_id": 83,
            "logprob": -5.75,
            "prob": 0.0032
          },
          {
            "token": "Ġst",
            "token_id": 357,
            "logprob": -5.8438,
            "prob": 0.0029
          },
          {
            "token": "Ġtu",
            "token_id": 9964,
            "logprob": -6.125,
            "prob": 0.0022
          },
          {
            "token": "Ġt",
            "token_id": 259,
            "logprob": -6.125,
            "prob": 0.0022
          },
          {
            "token": "tau",
            "token_id": 30243,
            "logprob": -6.1562,
            "prob": 0.0022
          }
        ]
      },
      "selected_token": {
        "token": "st",
        "token_id": 267,
        "selection_method": "sampling"
      }
    },
    {
      "step": 52,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU? That would translate \"Qui ést",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?",
        "ĠThat",
        "Ġwould",
        "Ġtranslate",
        "Ġ\"",
        "Qui",
        "Ġé",
        "st"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30,
        3011,
        1053,
        15025,
        330,
        62545,
        4046,
        267
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġtu",
            "token_id": 9964,
            "logprob": -0.7812,
            "prob": 0.457
          },
          {
            "token": "-",
            "token_id": 12,
            "logprob": -2.8438,
            "prob": 0.0581
          },
          {
            "token": "tu",
            "token_id": 25506,
            "logprob": -2.9062,
            "prob": 0.0547
          },
          {
            "token": "u",
            "token_id": 84,
            "logprob": -2.9688,
            "prob": 0.0513
          },
          {
            "token": "Ġu",
            "token_id": 577,
            "logprob": -3.2188,
            "prob": 0.04
          },
          {
            "token": "-u",
            "token_id": 46481,
            "logprob": -3.2812,
            "prob": 0.0376
          },
          {
            "token": "ou",
            "token_id": 283,
            "logprob": -3.6562,
            "prob": 0.0259
          },
          {
            "token": "-t",
            "token_id": 2442,
            "logprob": -3.7188,
            "prob": 0.0243
          },
          {
            "token": "ú",
            "token_id": 6792,
            "logprob": -4.0312,
            "prob": 0.0177
          },
          {
            "token": "-ce",
            "token_id": 54312,
            "logprob": -4.2812,
            "prob": 0.0139
          }
        ]
      },
      "selected_token": {
        "token": "-ce",
        "token_id": 54312,
        "selection_method": "sampling"
      }
    },
    {
      "step": 53,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU? That would translate \"Qui ést-ce",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?",
        "ĠThat",
        "Ġwould",
        "Ġtranslate",
        "Ġ\"",
        "Qui",
        "Ġé",
        "st",
        "-ce"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30,
        3011,
        1053,
        15025,
        330,
        62545,
        4046,
        267,
        54312
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġque",
            "token_id": 1744,
            "logprob": -0.7383,
            "prob": 0.4785
          },
          {
            "token": "-to",
            "token_id": 4791,
            "logprob": -0.8633,
            "prob": 0.4219
          },
          {
            "token": "Ġtu",
            "token_id": 9964,
            "logprob": -2.6094,
            "prob": 0.0732
          },
          {
            "token": "-t",
            "token_id": 2442,
            "logprob": -4.625,
            "prob": 0.0099
          },
          {
            "token": "Ġtoi",
            "token_id": 76420,
            "logprob": -5.1875,
            "prob": 0.0056
          },
          {
            "token": "Ġqui",
            "token_id": 7930,
            "logprob": -5.6875,
            "prob": 0.0034
          },
          {
            "token": "ĠTo",
            "token_id": 2057,
            "logprob": -6.875,
            "prob": 0.001
          },
          {
            "token": "_to",
            "token_id": 2401,
            "logprob": -7.4375,
            "prob": 0.0006
          },
          {
            "token": "-",
            "token_id": 12,
            "logprob": -7.75,
            "prob": 0.0004
          },
          {
            "token": "Ġto",
            "token_id": 311,
            "logprob": -8.25,
            "prob": 0.0003
          }
        ]
      },
      "selected_token": {
        "token": "-t",
        "token_id": 2442,
        "selection_method": "sampling"
      }
    },
    {
      "step": 54,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU? That would translate \"Qui ést-ce-t",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?",
        "ĠThat",
        "Ġwould",
        "Ġtranslate",
        "Ġ\"",
        "Qui",
        "Ġé",
        "st",
        "-ce",
        "-t"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30,
        3011,
        1053,
        15025,
        330,
        62545,
        4046,
        267,
        54312,
        2442
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "u",
            "token_id": 84,
            "logprob": -0.0042,
            "prob": 0.9961
          },
          {
            "token": "-u",
            "token_id": 46481,
            "logprob": -6.5,
            "prob": 0.0015
          },
          {
            "token": "'",
            "token_id": 6,
            "logprob": -7.125,
            "prob": 0.0008
          },
          {
            "token": "-",
            "token_id": 12,
            "logprob": -8.625,
            "prob": 0.0002
          },
          {
            "token": "'u",
            "token_id": 92704,
            "logprob": -8.875,
            "prob": 0.0001
          },
          {
            "token": "U",
            "token_id": 52,
            "logprob": -9.1875,
            "prob": 0.0001
          },
          {
            "token": "’",
            "token_id": 529,
            "logprob": -9.4375,
            "prob": 0.0001
          },
          {
            "token": "ou",
            "token_id": 283,
            "logprob": -9.625,
            "prob": 0.0001
          },
          {
            "token": "ú",
            "token_id": 6792,
            "logprob": -9.8125,
            "prob": 0.0001
          },
          {
            "token": "-U",
            "token_id": 35681,
            "logprob": -9.8125,
            "prob": 0.0001
          }
        ]
      },
      "selected_token": {
        "token": "u",
        "token_id": 84,
        "selection_method": "sampling"
      }
    },
    {
      "step": 55,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU? That would translate \"Qui ést-ce-tu",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?",
        "ĠThat",
        "Ġwould",
        "Ġtranslate",
        "Ġ\"",
        "Qui",
        "Ġé",
        "st",
        "-ce",
        "-t",
        "u"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30,
        3011,
        1053,
        15025,
        330,
        62545,
        4046,
        267,
        54312,
        2442,
        84
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "?\"",
            "token_id": 7673,
            "logprob": -0.0312,
            "prob": 0.9688
          },
          {
            "token": "?",
            "token_id": 30,
            "logprob": -4.2812,
            "prob": 0.0139
          },
          {
            "token": "Ġ?",
            "token_id": 949,
            "logprob": -4.7812,
            "prob": 0.0084
          },
          {
            "token": "\"",
            "token_id": 1,
            "logprob": -5.1562,
            "prob": 0.0058
          },
          {
            "token": "?\",",
            "token_id": 32111,
            "logprob": -6.5312,
            "prob": 0.0015
          },
          {
            "token": "\"?",
            "token_id": 44969,
            "logprob": -7.6562,
            "prob": 0.0005
          },
          {
            "token": "\",",
            "token_id": 498,
            "logprob": -7.8438,
            "prob": 0.0004
          },
          {
            "token": "\".",
            "token_id": 3343,
            "logprob": -8.5,
            "prob": 0.0002
          },
          {
            "token": "?\"\n\n",
            "token_id": 12241,
            "logprob": -10.25,
            "prob": 0.0
          },
          {
            "token": "Ġtu",
            "token_id": 9964,
            "logprob": -10.375,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "\",",
        "token_id": 498,
        "selection_method": "sampling"
      }
    },
    {
      "step": 56,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU? That would translate \"Qui ést-ce-tu\",",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?",
        "ĠThat",
        "Ġwould",
        "Ġtranslate",
        "Ġ\"",
        "Qui",
        "Ġé",
        "st",
        "-ce",
        "-t",
        "u",
        "\","
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30,
        3011,
        1053,
        15025,
        330,
        62545,
        4046,
        267,
        54312,
        2442,
        84,
        498
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġbut",
            "token_id": 719,
            "logprob": -0.6602,
            "prob": 0.5156
          },
          {
            "token": "Ġwhich",
            "token_id": 902,
            "logprob": -1.1641,
            "prob": 0.3125
          },
          {
            "token": "Ġmeaning",
            "token_id": 7438,
            "logprob": -2.5312,
            "prob": 0.0791
          },
          {
            "token": "Ġmaybe",
            "token_id": 7344,
            "logprob": -3.5312,
            "prob": 0.0292
          },
          {
            "token": "Ġlike",
            "token_id": 1093,
            "logprob": -4.2812,
            "prob": 0.0138
          },
          {
            "token": "Ġso",
            "token_id": 779,
            "logprob": -4.5312,
            "prob": 0.0107
          },
          {
            "token": "Ġright",
            "token_id": 1314,
            "logprob": -4.7812,
            "prob": 0.0084
          },
          {
            "token": "Ġno",
            "token_id": 912,
            "logprob": -5.0312,
            "prob": 0.0065
          },
          {
            "token": "Ġwait",
            "token_id": 3868,
            "logprob": -5.1562,
            "prob": 0.0057
          },
          {
            "token": "Ġor",
            "token_id": 477,
            "logprob": -5.7812,
            "prob": 0.0031
          }
        ]
      },
      "selected_token": {
        "token": "Ġwhich",
        "token_id": 902,
        "selection_method": "sampling"
      }
    },
    {
      "step": 57,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU? That would translate \"Qui ést-ce-tu\", which",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?",
        "ĠThat",
        "Ġwould",
        "Ġtranslate",
        "Ġ\"",
        "Qui",
        "Ġé",
        "st",
        "-ce",
        "-t",
        "u",
        "\",",
        "Ġwhich"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30,
        3011,
        1053,
        15025,
        330,
        62545,
        4046,
        267,
        54312,
        2442,
        84,
        498,
        902
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġis",
            "token_id": 374,
            "logprob": -0.2852,
            "prob": 0.7539
          },
          {
            "token": "Ġmeans",
            "token_id": 3445,
            "logprob": -1.7812,
            "prob": 0.168
          },
          {
            "token": "Ġin",
            "token_id": 304,
            "logprob": -3.6562,
            "prob": 0.0258
          },
          {
            "token": "Ġwould",
            "token_id": 1053,
            "logprob": -4.5312,
            "prob": 0.0107
          },
          {
            "token": "Ġisn",
            "token_id": 4536,
            "logprob": -4.6562,
            "prob": 0.0095
          },
          {
            "token": "Ġliterally",
            "token_id": 16280,
            "logprob": -4.9062,
            "prob": 0.0074
          },
          {
            "token": "Ġactually",
            "token_id": 3604,
            "logprob": -5.0312,
            "prob": 0.0065
          },
          {
            "token": "Ġmight",
            "token_id": 2643,
            "logprob": -5.0312,
            "prob": 0.0065
          },
          {
            "token": "Ġshould",
            "token_id": 1288,
            "logprob": -5.4062,
            "prob": 0.0045
          },
          {
            "token": "Ġdoesn",
            "token_id": 3250,
            "logprob": -5.9062,
            "prob": 0.0027
          }
        ]
      },
      "selected_token": {
        "token": "Ġisn",
        "token_id": 4536,
        "selection_method": "sampling"
      }
    },
    {
      "step": 58,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU? That would translate \"Qui ést-ce-tu\", which isn",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?",
        "ĠThat",
        "Ġwould",
        "Ġtranslate",
        "Ġ\"",
        "Qui",
        "Ġé",
        "st",
        "-ce",
        "-t",
        "u",
        "\",",
        "Ġwhich",
        "Ġisn"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30,
        3011,
        1053,
        15025,
        330,
        62545,
        4046,
        267,
        54312,
        2442,
        84,
        498,
        902,
        4536
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "'t",
            "token_id": 956,
            "logprob": -0.0008,
            "prob": 1.0
          },
          {
            "token": "’t",
            "token_id": 1431,
            "logprob": -7.25,
            "prob": 0.0007
          },
          {
            "token": "´t",
            "token_id": 97965,
            "logprob": -11.25,
            "prob": 0.0
          },
          {
            "token": "\"",
            "token_id": 1,
            "logprob": -11.875,
            "prob": 0.0
          },
          {
            "token": "'s",
            "token_id": 596,
            "logprob": -12.625,
            "prob": 0.0
          },
          {
            "token": "Ġ\"",
            "token_id": 330,
            "logprob": -12.875,
            "prob": 0.0
          },
          {
            "token": ";t",
            "token_id": 54847,
            "logprob": -13.875,
            "prob": 0.0
          },
          {
            "token": "'T",
            "token_id": 17773,
            "logprob": -14.0,
            "prob": 0.0
          },
          {
            "token": "'m",
            "token_id": 2846,
            "logprob": -14.125,
            "prob": 0.0
          },
          {
            "token": "'",
            "token_id": 6,
            "logprob": -14.25,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "'s",
        "token_id": 596,
        "selection_method": "sampling"
      }
    },
    {
      "step": 59,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU? That would translate \"Qui ést-ce-tu\", which isn's",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?",
        "ĠThat",
        "Ġwould",
        "Ġtranslate",
        "Ġ\"",
        "Qui",
        "Ġé",
        "st",
        "-ce",
        "-t",
        "u",
        "\",",
        "Ġwhich",
        "Ġisn",
        "'s"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30,
        3011,
        1053,
        15025,
        330,
        62545,
        4046,
        267,
        54312,
        2442,
        84,
        498,
        902,
        4536,
        596
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġcorrect",
            "token_id": 4495,
            "logprob": -0.9609,
            "prob": 0.3828
          },
          {
            "token": "ĠFrench",
            "token_id": 8753,
            "logprob": -1.7109,
            "prob": 0.1807
          },
          {
            "token": "Ġquite",
            "token_id": 5115,
            "logprob": -1.8359,
            "prob": 0.1592
          },
          {
            "token": "Ġright",
            "token_id": 1314,
            "logprob": -2.5781,
            "prob": 0.0752
          },
          {
            "token": "Ġstandard",
            "token_id": 5410,
            "logprob": -3.3281,
            "prob": 0.0356
          },
          {
            "token": "Ġthe",
            "token_id": 279,
            "logprob": -3.8281,
            "prob": 0.0216
          },
          {
            "token": "Ġexactly",
            "token_id": 7041,
            "logprob": -3.8281,
            "prob": 0.0216
          },
          {
            "token": "Ġreally",
            "token_id": 2216,
            "logprob": -4.0938,
            "prob": 0.0168
          },
          {
            "token": "Ġa",
            "token_id": 264,
            "logprob": -4.2188,
            "prob": 0.0148
          },
          {
            "token": "Ġeven",
            "token_id": 1524,
            "logprob": -4.2188,
            "prob": 0.0148
          }
        ]
      },
      "selected_token": {
        "token": "Ġquite",
        "token_id": 5115,
        "selection_method": "sampling"
      }
    },
    {
      "step": 60,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU? That would translate \"Qui ést-ce-tu\", which isn's quite",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?",
        "ĠThat",
        "Ġwould",
        "Ġtranslate",
        "Ġ\"",
        "Qui",
        "Ġé",
        "st",
        "-ce",
        "-t",
        "u",
        "\",",
        "Ġwhich",
        "Ġisn",
        "'s",
        "Ġquite"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30,
        3011,
        1053,
        15025,
        330,
        62545,
        4046,
        267,
        54312,
        2442,
        84,
        498,
        902,
        4536,
        596,
        5115
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġright",
            "token_id": 1314,
            "logprob": -0.4805,
            "prob": 0.6172
          },
          {
            "token": "Ġcorrect",
            "token_id": 4495,
            "logprob": -1.6094,
            "prob": 0.2002
          },
          {
            "token": "Ġstandard",
            "token_id": 5410,
            "logprob": -3.1094,
            "prob": 0.0447
          },
          {
            "token": "ĠFrench",
            "token_id": 8753,
            "logprob": -3.3594,
            "prob": 0.0349
          },
          {
            "token": "Ġproper",
            "token_id": 6300,
            "logprob": -3.4844,
            "prob": 0.0308
          },
          {
            "token": "Ġa",
            "token_id": 264,
            "logprob": -3.4844,
            "prob": 0.0308
          },
          {
            "token": "Ġthe",
            "token_id": 279,
            "logprob": -4.8438,
            "prob": 0.0078
          },
          {
            "token": "Ġgramm",
            "token_id": 69225,
            "logprob": -5.2188,
            "prob": 0.0053
          },
          {
            "token": "Ġnatural",
            "token_id": 5933,
            "logprob": -5.2188,
            "prob": 0.0053
          },
          {
            "token": "Ġcorrectly",
            "token_id": 12722,
            "logprob": -5.3438,
            "prob": 0.0047
          }
        ]
      },
      "selected_token": {
        "token": "Ġstandard",
        "token_id": 5410,
        "selection_method": "sampling"
      }
    },
    {
      "step": 61,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU? That would translate \"Qui ést-ce-tu\", which isn's quite standard",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?",
        "ĠThat",
        "Ġwould",
        "Ġtranslate",
        "Ġ\"",
        "Qui",
        "Ġé",
        "st",
        "-ce",
        "-t",
        "u",
        "\",",
        "Ġwhich",
        "Ġisn",
        "'s",
        "Ġquite",
        "Ġstandard"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30,
        3011,
        1053,
        15025,
        330,
        62545,
        4046,
        267,
        54312,
        2442,
        84,
        498,
        902,
        4536,
        596,
        5115,
        5410
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": ".",
            "token_id": 13,
            "logprob": -0.4297,
            "prob": 0.6523
          },
          {
            "token": "ĠFrench",
            "token_id": 8753,
            "logprob": -1.1797,
            "prob": 0.3066
          },
          {
            "token": "Ġfrench",
            "token_id": 42293,
            "logprob": -4.3125,
            "prob": 0.0135
          },
          {
            "token": ",",
            "token_id": 11,
            "logprob": -4.5625,
            "prob": 0.0105
          },
          {
            "token": "Ġspelling",
            "token_id": 43529,
            "logprob": -5.4375,
            "prob": 0.0044
          },
          {
            "token": "Ġin",
            "token_id": 304,
            "logprob": -6.0,
            "prob": 0.0025
          },
          {
            "token": "Ġeither",
            "token_id": 3060,
            "logprob": -6.3125,
            "prob": 0.0018
          },
          {
            "token": ".\n\n",
            "token_id": 382,
            "logprob": -6.8125,
            "prob": 0.0011
          },
          {
            "token": "Ġbecause",
            "token_id": 1606,
            "logprob": -6.8125,
            "prob": 0.0011
          },
          {
            "token": "Ġmaybe",
            "token_id": 7344,
            "logprob": -7.3125,
            "prob": 0.0007
          }
        ]
      },
      "selected_token": {
        "token": "Ġfrench",
        "token_id": 42293,
        "selection_method": "sampling"
      }
    },
    {
      "step": 62,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU? That would translate \"Qui ést-ce-tu\", which isn's quite standard french",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?",
        "ĠThat",
        "Ġwould",
        "Ġtranslate",
        "Ġ\"",
        "Qui",
        "Ġé",
        "st",
        "-ce",
        "-t",
        "u",
        "\",",
        "Ġwhich",
        "Ġisn",
        "'s",
        "Ġquite",
        "Ġstandard",
        "Ġfrench"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30,
        3011,
        1053,
        15025,
        330,
        62545,
        4046,
        267,
        54312,
        2442,
        84,
        498,
        902,
        4536,
        596,
        5115,
        5410,
        42293
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": ".",
            "token_id": 13,
            "logprob": -0.0815,
            "prob": 0.9219
          },
          {
            "token": ",",
            "token_id": 11,
            "logprob": -3.7031,
            "prob": 0.0245
          },
          {
            "token": "Ġgrammar",
            "token_id": 32528,
            "logprob": -4.3438,
            "prob": 0.0131
          },
          {
            "token": "Ġfor",
            "token_id": 369,
            "logprob": -4.4688,
            "prob": 0.0116
          },
          {
            "token": "Ġspelling",
            "token_id": 43529,
            "logprob": -5.2188,
            "prob": 0.0055
          },
          {
            "token": "Ġmaybe",
            "token_id": 7344,
            "logprob": -5.5938,
            "prob": 0.0038
          },
          {
            "token": "Ġph",
            "token_id": 1343,
            "logprob": -6.0938,
            "prob": 0.0023
          },
          {
            "token": "...",
            "token_id": 1131,
            "logprob": -6.1562,
            "prob": 0.0022
          },
          {
            "token": "Ġsyntax",
            "token_id": 20047,
            "logprob": -6.2188,
            "prob": 0.002
          },
          {
            "token": ";",
            "token_id": 26,
            "logprob": -6.4688,
            "prob": 0.0016
          }
        ]
      },
      "selected_token": {
        "token": ".",
        "token_id": 13,
        "selection_method": "sampling"
      }
    },
    {
      "step": 63,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU? That would translate \"Qui ést-ce-tu\", which isn's quite standard french.",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?",
        "ĠThat",
        "Ġwould",
        "Ġtranslate",
        "Ġ\"",
        "Qui",
        "Ġé",
        "st",
        "-ce",
        "-t",
        "u",
        "\",",
        "Ġwhich",
        "Ġisn",
        "'s",
        "Ġquite",
        "Ġstandard",
        "Ġfrench",
        "."
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30,
        3011,
        1053,
        15025,
        330,
        62545,
        4046,
        267,
        54312,
        2442,
        84,
        498,
        902,
        4536,
        596,
        5115,
        5410,
        42293,
        13
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "ĠMaybe",
            "token_id": 10926,
            "logprob": -0.9258,
            "prob": 0.3965
          },
          {
            "token": "ĠWait",
            "token_id": 14144,
            "logprob": -1.3047,
            "prob": 0.2715
          },
          {
            "token": "ĠThe",
            "token_id": 578,
            "logprob": -2.1719,
            "prob": 0.1133
          },
          {
            "token": "ĠUsually",
            "token_id": 34067,
            "logprob": -2.7969,
            "prob": 0.0608
          },
          {
            "token": "ĠNormally",
            "token_id": 52783,
            "logprob": -3.1719,
            "prob": 0.0417
          },
          {
            "token": "ĠProbably",
            "token_id": 38254,
            "logprob": -3.6719,
            "prob": 0.0253
          },
          {
            "token": "ĠOh",
            "token_id": 8840,
            "logprob": -4.0625,
            "prob": 0.0173
          },
          {
            "token": "ĠFrench",
            "token_id": 8753,
            "logprob": -4.0625,
            "prob": 0.0173
          },
          {
            "token": "Ġ\"",
            "token_id": 330,
            "logprob": -4.5625,
            "prob": 0.0106
          },
          {
            "token": "ĠHmm",
            "token_id": 89290,
            "logprob": -4.5625,
            "prob": 0.0106
          }
        ]
      },
      "selected_token": {
        "token": "ĠFrench",
        "token_id": 8753,
        "selection_method": "sampling"
      }
    },
    {
      "step": 64,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU? That would translate \"Qui ést-ce-tu\", which isn's quite standard french. French",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?",
        "ĠThat",
        "Ġwould",
        "Ġtranslate",
        "Ġ\"",
        "Qui",
        "Ġé",
        "st",
        "-ce",
        "-t",
        "u",
        "\",",
        "Ġwhich",
        "Ġisn",
        "'s",
        "Ġquite",
        "Ġstandard",
        "Ġfrench",
        ".",
        "ĠFrench"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30,
        3011,
        1053,
        15025,
        330,
        62545,
        4046,
        267,
        54312,
        2442,
        84,
        498,
        902,
        4536,
        596,
        5115,
        5410,
        42293,
        13,
        8753
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġusually",
            "token_id": 6118,
            "logprob": -0.3008,
            "prob": 0.7422
          },
          {
            "token": "Ġuses",
            "token_id": 5829,
            "logprob": -2.4219,
            "prob": 0.0884
          },
          {
            "token": "Ġtypically",
            "token_id": 11383,
            "logprob": -2.6719,
            "prob": 0.0688
          },
          {
            "token": "Ġwould",
            "token_id": 1053,
            "logprob": -3.0469,
            "prob": 0.0474
          },
          {
            "token": "Ġquestions",
            "token_id": 4860,
            "logprob": -4.5625,
            "prob": 0.0106
          },
          {
            "token": "Ġis",
            "token_id": 374,
            "logprob": -4.875,
            "prob": 0.0077
          },
          {
            "token": "Ġfor",
            "token_id": 369,
            "logprob": -5.0,
            "prob": 0.0068
          },
          {
            "token": "Ġquestion",
            "token_id": 3488,
            "logprob": -5.5,
            "prob": 0.0042
          },
          {
            "token": "Ġgrammar",
            "token_id": 32528,
            "logprob": -5.75,
            "prob": 0.0032
          },
          {
            "token": "Ġgenerally",
            "token_id": 8965,
            "logprob": -5.8125,
            "prob": 0.003
          }
        ]
      },
      "selected_token": {
        "token": "Ġwould",
        "token_id": 1053,
        "selection_method": "sampling"
      }
    },
    {
      "step": 65,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU? That would translate \"Qui ést-ce-tu\", which isn's quite standard french. French would",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?",
        "ĠThat",
        "Ġwould",
        "Ġtranslate",
        "Ġ\"",
        "Qui",
        "Ġé",
        "st",
        "-ce",
        "-t",
        "u",
        "\",",
        "Ġwhich",
        "Ġisn",
        "'s",
        "Ġquite",
        "Ġstandard",
        "Ġfrench",
        ".",
        "ĠFrench",
        "Ġwould"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30,
        3011,
        1053,
        15025,
        330,
        62545,
        4046,
        267,
        54312,
        2442,
        84,
        498,
        902,
        4536,
        596,
        5115,
        5410,
        42293,
        13,
        8753,
        1053
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġbe",
            "token_id": 387,
            "logprob": -0.1924,
            "prob": 0.8242
          },
          {
            "token": "Ġusually",
            "token_id": 6118,
            "logprob": -2.6875,
            "prob": 0.0679
          },
          {
            "token": "Ġtypically",
            "token_id": 11383,
            "logprob": -3.5625,
            "prob": 0.0282
          },
          {
            "token": "Ġnormally",
            "token_id": 14614,
            "logprob": -3.6875,
            "prob": 0.0249
          },
          {
            "token": "Ġprobably",
            "token_id": 4762,
            "logprob": -3.8125,
            "prob": 0.022
          },
          {
            "token": "Ġsay",
            "token_id": 2019,
            "logprob": -4.1875,
            "prob": 0.0151
          },
          {
            "token": "Ġuse",
            "token_id": 1005,
            "logprob": -4.9375,
            "prob": 0.0071
          },
          {
            "token": "Ġhave",
            "token_id": 617,
            "logprob": -5.6875,
            "prob": 0.0034
          },
          {
            "token": "Ġmore",
            "token_id": 810,
            "logprob": -5.8125,
            "prob": 0.003
          },
          {
            "token": "Ġask",
            "token_id": 2610,
            "logprob": -6.4375,
            "prob": 0.0016
          }
        ]
      },
      "selected_token": {
        "token": "Ġnormally",
        "token_id": 14614,
        "selection_method": "sampling"
      }
    },
    {
      "step": 66,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU? That would translate \"Qui ést-ce-tu\", which isn's quite standard french. French would normally",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?",
        "ĠThat",
        "Ġwould",
        "Ġtranslate",
        "Ġ\"",
        "Qui",
        "Ġé",
        "st",
        "-ce",
        "-t",
        "u",
        "\",",
        "Ġwhich",
        "Ġisn",
        "'s",
        "Ġquite",
        "Ġstandard",
        "Ġfrench",
        ".",
        "ĠFrench",
        "Ġwould",
        "Ġnormally"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30,
        3011,
        1053,
        15025,
        330,
        62545,
        4046,
        267,
        54312,
        2442,
        84,
        498,
        902,
        4536,
        596,
        5115,
        5410,
        42293,
        13,
        8753,
        1053,
        14614
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġbe",
            "token_id": 387,
            "logprob": -0.2461,
            "prob": 0.7812
          },
          {
            "token": "Ġsay",
            "token_id": 2019,
            "logprob": -1.9922,
            "prob": 0.1357
          },
          {
            "token": "Ġask",
            "token_id": 2610,
            "logprob": -3.5,
            "prob": 0.0303
          },
          {
            "token": "Ġuse",
            "token_id": 1005,
            "logprob": -3.625,
            "prob": 0.0267
          },
          {
            "token": "Ġhave",
            "token_id": 617,
            "logprob": -4.25,
            "prob": 0.0143
          },
          {
            "token": "Ġwrite",
            "token_id": 3350,
            "logprob": -5.3125,
            "prob": 0.0049
          },
          {
            "token": "Ġspell",
            "token_id": 13141,
            "logprob": -6.3125,
            "prob": 0.0018
          },
          {
            "token": "Ġcapitalize",
            "token_id": 53825,
            "logprob": -6.8125,
            "prob": 0.0011
          },
          {
            "token": "Ġjust",
            "token_id": 1120,
            "logprob": -6.9375,
            "prob": 0.001
          },
          {
            "token": "Ġ\"",
            "token_id": 330,
            "logprob": -7.8125,
            "prob": 0.0004
          }
        ]
      },
      "selected_token": {
        "token": "Ġbe",
        "token_id": 387,
        "selection_method": "sampling"
      }
    },
    {
      "step": 67,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU? That would translate \"Qui ést-ce-tu\", which isn's quite standard french. French would normally be",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?",
        "ĠThat",
        "Ġwould",
        "Ġtranslate",
        "Ġ\"",
        "Qui",
        "Ġé",
        "st",
        "-ce",
        "-t",
        "u",
        "\",",
        "Ġwhich",
        "Ġisn",
        "'s",
        "Ġquite",
        "Ġstandard",
        "Ġfrench",
        ".",
        "ĠFrench",
        "Ġwould",
        "Ġnormally",
        "Ġbe"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30,
        3011,
        1053,
        15025,
        330,
        62545,
        4046,
        267,
        54312,
        2442,
        84,
        498,
        902,
        4536,
        596,
        5115,
        5410,
        42293,
        13,
        8753,
        1053,
        14614,
        387
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġ\"",
            "token_id": 330,
            "logprob": -0.0018,
            "prob": 1.0
          },
          {
            "token": "Ġeither",
            "token_id": 3060,
            "logprob": -6.5625,
            "prob": 0.0014
          },
          {
            "token": "Ġ'",
            "token_id": 364,
            "logprob": -9.8125,
            "prob": 0.0001
          },
          {
            "token": "Ġspelled",
            "token_id": 68918,
            "logprob": -10.1875,
            "prob": 0.0
          },
          {
            "token": "Ġ“",
            "token_id": 1054,
            "logprob": -10.3125,
            "prob": 0.0
          },
          {
            "token": "ĠQui",
            "token_id": 42215,
            "logprob": -10.8125,
            "prob": 0.0
          },
          {
            "token": "Ġwritten",
            "token_id": 5439,
            "logprob": -10.8125,
            "prob": 0.0
          },
          {
            "token": "Ġ«",
            "token_id": 12769,
            "logprob": -11.5625,
            "prob": 0.0
          },
          {
            "token": "ĠQu",
            "token_id": 3489,
            "logprob": -11.75,
            "prob": 0.0
          },
          {
            "token": "Ġsomething",
            "token_id": 2555,
            "logprob": -11.8125,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġsomething",
        "token_id": 2555,
        "selection_method": "sampling"
      }
    },
    {
      "step": 68,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU? That would translate \"Qui ést-ce-tu\", which isn's quite standard french. French would normally be something",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?",
        "ĠThat",
        "Ġwould",
        "Ġtranslate",
        "Ġ\"",
        "Qui",
        "Ġé",
        "st",
        "-ce",
        "-t",
        "u",
        "\",",
        "Ġwhich",
        "Ġisn",
        "'s",
        "Ġquite",
        "Ġstandard",
        "Ġfrench",
        ".",
        "ĠFrench",
        "Ġwould",
        "Ġnormally",
        "Ġbe",
        "Ġsomething"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30,
        3011,
        1053,
        15025,
        330,
        62545,
        4046,
        267,
        54312,
        2442,
        84,
        498,
        902,
        4536,
        596,
        5115,
        5410,
        42293,
        13,
        8753,
        1053,
        14614,
        387,
        2555
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġlike",
            "token_id": 1093,
            "logprob": -0.0044,
            "prob": 0.9961
          },
          {
            "token": "Ġelse",
            "token_id": 775,
            "logprob": -5.5,
            "prob": 0.0041
          },
          {
            "token": "Ġmore",
            "token_id": 810,
            "logprob": -9.375,
            "prob": 0.0001
          },
          {
            "token": "Ġ\"",
            "token_id": 330,
            "logprob": -10.0,
            "prob": 0.0
          },
          {
            "token": "Ġwith",
            "token_id": 449,
            "logprob": -10.875,
            "prob": 0.0
          },
          {
            "token": "Ġlik",
            "token_id": 3208,
            "logprob": -10.875,
            "prob": 0.0
          },
          {
            "token": "ĠLike",
            "token_id": 9086,
            "logprob": -11.25,
            "prob": 0.0
          },
          {
            "token": "Ġlikes",
            "token_id": 13452,
            "logprob": -11.75,
            "prob": 0.0
          },
          {
            "token": "Ġcloser",
            "token_id": 12401,
            "logprob": -11.875,
            "prob": 0.0
          },
          {
            "token": "like",
            "token_id": 4908,
            "logprob": -12.25,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "like",
        "token_id": 4908,
        "selection_method": "sampling"
      }
    },
    {
      "step": 69,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU? That would translate \"Qui ést-ce-tu\", which isn's quite standard french. French would normally be somethinglike",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?",
        "ĠThat",
        "Ġwould",
        "Ġtranslate",
        "Ġ\"",
        "Qui",
        "Ġé",
        "st",
        "-ce",
        "-t",
        "u",
        "\",",
        "Ġwhich",
        "Ġisn",
        "'s",
        "Ġquite",
        "Ġstandard",
        "Ġfrench",
        ".",
        "ĠFrench",
        "Ġwould",
        "Ġnormally",
        "Ġbe",
        "Ġsomething",
        "like"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30,
        3011,
        1053,
        15025,
        330,
        62545,
        4046,
        267,
        54312,
        2442,
        84,
        498,
        902,
        4536,
        596,
        5115,
        5410,
        42293,
        13,
        8753,
        1053,
        14614,
        387,
        2555,
        4908
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġ\"",
            "token_id": 330,
            "logprob": -0.0036,
            "prob": 0.9961
          },
          {
            "token": ":",
            "token_id": 25,
            "logprob": -6.875,
            "prob": 0.001
          },
          {
            "token": ",",
            "token_id": 11,
            "logprob": -7.375,
            "prob": 0.0006
          },
          {
            "token": "\"",
            "token_id": 1,
            "logprob": -7.6875,
            "prob": 0.0005
          },
          {
            "token": "ĠQu",
            "token_id": 3489,
            "logprob": -7.8125,
            "prob": 0.0004
          },
          {
            "token": "Ġ'",
            "token_id": 364,
            "logprob": -8.4375,
            "prob": 0.0002
          },
          {
            "token": "Ġ“",
            "token_id": 1054,
            "logprob": -8.625,
            "prob": 0.0002
          },
          {
            "token": "Ġqui",
            "token_id": 7930,
            "logprob": -9.9375,
            "prob": 0.0
          },
          {
            "token": "...",
            "token_id": 1131,
            "logprob": -10.4375,
            "prob": 0.0
          },
          {
            "token": "ĠQU",
            "token_id": 27090,
            "logprob": -10.5,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "ĠQu",
        "token_id": 3489,
        "selection_method": "sampling"
      }
    },
    {
      "step": 70,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU? That would translate \"Qui ést-ce-tu\", which isn's quite standard french. French would normally be somethinglike Qu",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?",
        "ĠThat",
        "Ġwould",
        "Ġtranslate",
        "Ġ\"",
        "Qui",
        "Ġé",
        "st",
        "-ce",
        "-t",
        "u",
        "\",",
        "Ġwhich",
        "Ġisn",
        "'s",
        "Ġquite",
        "Ġstandard",
        "Ġfrench",
        ".",
        "ĠFrench",
        "Ġwould",
        "Ġnormally",
        "Ġbe",
        "Ġsomething",
        "like",
        "ĠQu"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30,
        3011,
        1053,
        15025,
        330,
        62545,
        4046,
        267,
        54312,
        2442,
        84,
        498,
        902,
        4536,
        596,
        5115,
        5410,
        42293,
        13,
        8753,
        1053,
        14614,
        387,
        2555,
        4908,
        3489
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "'est",
            "token_id": 17771,
            "logprob": -0.668,
            "prob": 0.5117
          },
          {
            "token": "el",
            "token_id": 301,
            "logprob": -1.2344,
            "prob": 0.291
          },
          {
            "token": "elle",
            "token_id": 6853,
            "logprob": -2.5469,
            "prob": 0.0786
          },
          {
            "token": "Ġest",
            "token_id": 1826,
            "logprob": -4.3438,
            "prob": 0.0128
          },
          {
            "token": "'",
            "token_id": 6,
            "logprob": -4.3438,
            "prob": 0.0128
          },
          {
            "token": "ель",
            "token_id": 26503,
            "logprob": -4.4062,
            "prob": 0.012
          },
          {
            "token": "els",
            "token_id": 2053,
            "logprob": -4.5938,
            "prob": 0.01
          },
          {
            "token": "’est",
            "token_id": 22117,
            "logprob": -4.9062,
            "prob": 0.0073
          },
          {
            "token": "ĠEST",
            "token_id": 26963,
            "logprob": -5.1562,
            "prob": 0.0057
          },
          {
            "token": "elles",
            "token_id": 37907,
            "logprob": -6.0312,
            "prob": 0.0024
          }
        ]
      },
      "selected_token": {
        "token": "ĠEST",
        "token_id": 26963,
        "selection_method": "sampling"
      }
    },
    {
      "step": 71,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU? That would translate \"Qui ést-ce-tu\", which isn's quite standard french. French would normally be somethinglike Qu EST",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?",
        "ĠThat",
        "Ġwould",
        "Ġtranslate",
        "Ġ\"",
        "Qui",
        "Ġé",
        "st",
        "-ce",
        "-t",
        "u",
        "\",",
        "Ġwhich",
        "Ġisn",
        "'s",
        "Ġquite",
        "Ġstandard",
        "Ġfrench",
        ".",
        "ĠFrench",
        "Ġwould",
        "Ġnormally",
        "Ġbe",
        "Ġsomething",
        "like",
        "ĠQu",
        "ĠEST"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30,
        3011,
        1053,
        15025,
        330,
        62545,
        4046,
        267,
        54312,
        2442,
        84,
        498,
        902,
        4536,
        596,
        5115,
        5410,
        42293,
        13,
        8753,
        1053,
        14614,
        387,
        2555,
        4908,
        3489,
        26963
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "-",
            "token_id": 12,
            "logprob": -0.4609,
            "prob": 0.6328
          },
          {
            "token": "ĠTU",
            "token_id": 70514,
            "logprob": -2.1406,
            "prob": 0.1167
          },
          {
            "token": "U",
            "token_id": 52,
            "logprob": -3.2031,
            "prob": 0.0403
          },
          {
            "token": "Ġtu",
            "token_id": 9964,
            "logprob": -3.5781,
            "prob": 0.0277
          },
          {
            "token": "-T",
            "token_id": 9469,
            "logprob": -3.8906,
            "prob": 0.0203
          },
          {
            "token": "ĠU",
            "token_id": 549,
            "logprob": -4.0312,
            "prob": 0.0179
          },
          {
            "token": "-t",
            "token_id": 2442,
            "logprob": -4.2812,
            "prob": 0.0139
          },
          {
            "token": "-U",
            "token_id": 35681,
            "logprob": -4.5312,
            "prob": 0.0109
          },
          {
            "token": "u",
            "token_id": 84,
            "logprob": -4.9375,
            "prob": 0.0072
          },
          {
            "token": "ĠTu",
            "token_id": 29749,
            "logprob": -5.0312,
            "prob": 0.0066
          }
        ]
      },
      "selected_token": {
        "token": "-t",
        "token_id": 2442,
        "selection_method": "sampling"
      }
    },
    {
      "step": 72,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU? That would translate \"Qui ést-ce-tu\", which isn's quite standard french. French would normally be somethinglike Qu EST-t",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?",
        "ĠThat",
        "Ġwould",
        "Ġtranslate",
        "Ġ\"",
        "Qui",
        "Ġé",
        "st",
        "-ce",
        "-t",
        "u",
        "\",",
        "Ġwhich",
        "Ġisn",
        "'s",
        "Ġquite",
        "Ġstandard",
        "Ġfrench",
        ".",
        "ĠFrench",
        "Ġwould",
        "Ġnormally",
        "Ġbe",
        "Ġsomething",
        "like",
        "ĠQu",
        "ĠEST",
        "-t"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30,
        3011,
        1053,
        15025,
        330,
        62545,
        4046,
        267,
        54312,
        2442,
        84,
        498,
        902,
        4536,
        596,
        5115,
        5410,
        42293,
        13,
        8753,
        1053,
        14614,
        387,
        2555,
        4908,
        3489,
        26963,
        2442
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "u",
            "token_id": 84,
            "logprob": -0.1338,
            "prob": 0.875
          },
          {
            "token": "U",
            "token_id": 52,
            "logprob": -2.2031,
            "prob": 0.1113
          },
          {
            "token": "-",
            "token_id": 12,
            "logprob": -4.75,
            "prob": 0.0086
          },
          {
            "token": "-u",
            "token_id": 46481,
            "logprob": -8.1875,
            "prob": 0.0003
          },
          {
            "token": "-U",
            "token_id": 35681,
            "logprob": -8.1875,
            "prob": 0.0003
          },
          {
            "token": "ou",
            "token_id": 283,
            "logprob": -8.4375,
            "prob": 0.0002
          },
          {
            "token": "ĠU",
            "token_id": 549,
            "logprob": -8.4375,
            "prob": 0.0002
          },
          {
            "token": "-on",
            "token_id": 10539,
            "logprob": -8.6875,
            "prob": 0.0002
          },
          {
            "token": "'",
            "token_id": 6,
            "logprob": -8.9375,
            "prob": 0.0001
          },
          {
            "token": "-il",
            "token_id": 57375,
            "logprob": -8.9375,
            "prob": 0.0001
          }
        ]
      },
      "selected_token": {
        "token": "U",
        "token_id": 52,
        "selection_method": "sampling"
      }
    },
    {
      "step": 73,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU? That would translate \"Qui ést-ce-tu\", which isn's quite standard french. French would normally be somethinglike Qu EST-tU",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?",
        "ĠThat",
        "Ġwould",
        "Ġtranslate",
        "Ġ\"",
        "Qui",
        "Ġé",
        "st",
        "-ce",
        "-t",
        "u",
        "\",",
        "Ġwhich",
        "Ġisn",
        "'s",
        "Ġquite",
        "Ġstandard",
        "Ġfrench",
        ".",
        "ĠFrench",
        "Ġwould",
        "Ġnormally",
        "Ġbe",
        "Ġsomething",
        "like",
        "ĠQu",
        "ĠEST",
        "-t",
        "U"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30,
        3011,
        1053,
        15025,
        330,
        62545,
        4046,
        267,
        54312,
        2442,
        84,
        498,
        902,
        4536,
        596,
        5115,
        5410,
        42293,
        13,
        8753,
        1053,
        14614,
        387,
        2555,
        4908,
        3489,
        26963,
        2442,
        52
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "?",
            "token_id": 30,
            "logprob": -0.8047,
            "prob": 0.4473
          },
          {
            "token": ".",
            "token_id": 13,
            "logprob": -1.6172,
            "prob": 0.1982
          },
          {
            "token": "Ġtu",
            "token_id": 9964,
            "logprob": -2.0625,
            "prob": 0.1279
          },
          {
            "token": "ĠTU",
            "token_id": 70514,
            "logprob": -2.3125,
            "prob": 0.0996
          },
          {
            "token": ",",
            "token_id": 11,
            "logprob": -3.375,
            "prob": 0.0344
          },
          {
            "token": "...",
            "token_id": 1131,
            "logprob": -4.7188,
            "prob": 0.009
          },
          {
            "token": "Ġou",
            "token_id": 6033,
            "logprob": -5.25,
            "prob": 0.0053
          },
          {
            "token": "Ġt",
            "token_id": 259,
            "logprob": -5.4375,
            "prob": 0.0044
          },
          {
            "token": "Ġ(",
            "token_id": 320,
            "logprob": -5.5,
            "prob": 0.0041
          },
          {
            "token": "Ġ?",
            "token_id": 949,
            "logprob": -5.625,
            "prob": 0.0036
          }
        ]
      },
      "selected_token": {
        "token": ",",
        "token_id": 11,
        "selection_method": "sampling"
      }
    },
    {
      "step": 74,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU? That would translate \"Qui ést-ce-tu\", which isn's quite standard french. French would normally be somethinglike Qu EST-tU,",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?",
        "ĠThat",
        "Ġwould",
        "Ġtranslate",
        "Ġ\"",
        "Qui",
        "Ġé",
        "st",
        "-ce",
        "-t",
        "u",
        "\",",
        "Ġwhich",
        "Ġisn",
        "'s",
        "Ġquite",
        "Ġstandard",
        "Ġfrench",
        ".",
        "ĠFrench",
        "Ġwould",
        "Ġnormally",
        "Ġbe",
        "Ġsomething",
        "like",
        "ĠQu",
        "ĠEST",
        "-t",
        "U",
        ","
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30,
        3011,
        1053,
        15025,
        330,
        62545,
        4046,
        267,
        54312,
        2442,
        84,
        498,
        902,
        4536,
        596,
        5115,
        5410,
        42293,
        13,
        8753,
        1053,
        14614,
        387,
        2555,
        4908,
        3489,
        26963,
        2442,
        52,
        11
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġbut",
            "token_id": 719,
            "logprob": -0.5859,
            "prob": 0.5547
          },
          {
            "token": "Ġor",
            "token_id": 477,
            "logprob": -2.2188,
            "prob": 0.1094
          },
          {
            "token": "Ġwith",
            "token_id": 449,
            "logprob": -2.2188,
            "prob": 0.1094
          },
          {
            "token": "Ġmaybe",
            "token_id": 7344,
            "logprob": -2.3438,
            "prob": 0.0967
          },
          {
            "token": "Ġso",
            "token_id": 779,
            "logprob": -3.0312,
            "prob": 0.0486
          },
          {
            "token": "Ġ\"",
            "token_id": 330,
            "logprob": -5.0312,
            "prob": 0.0066
          },
          {
            "token": "Ġperhaps",
            "token_id": 8530,
            "logprob": -5.0938,
            "prob": 0.0062
          },
          {
            "token": "Ġlike",
            "token_id": 1093,
            "logprob": -5.2188,
            "prob": 0.0055
          },
          {
            "token": "Ġsince",
            "token_id": 2533,
            "logprob": -5.3438,
            "prob": 0.0048
          },
          {
            "token": "Ġusing",
            "token_id": 1701,
            "logprob": -5.4688,
            "prob": 0.0042
          }
        ]
      },
      "selected_token": {
        "token": "Ġbut",
        "token_id": 719,
        "selection_method": "sampling"
      }
    },
    {
      "step": 75,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU? That would translate \"Qui ést-ce-tu\", which isn's quite standard french. French would normally be somethinglike Qu EST-tU, but",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?",
        "ĠThat",
        "Ġwould",
        "Ġtranslate",
        "Ġ\"",
        "Qui",
        "Ġé",
        "st",
        "-ce",
        "-t",
        "u",
        "\",",
        "Ġwhich",
        "Ġisn",
        "'s",
        "Ġquite",
        "Ġstandard",
        "Ġfrench",
        ".",
        "ĠFrench",
        "Ġwould",
        "Ġnormally",
        "Ġbe",
        "Ġsomething",
        "like",
        "ĠQu",
        "ĠEST",
        "-t",
        "U",
        ",",
        "Ġbut"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30,
        3011,
        1053,
        15025,
        330,
        62545,
        4046,
        267,
        54312,
        2442,
        84,
        498,
        902,
        4536,
        596,
        5115,
        5410,
        42293,
        13,
        8753,
        1053,
        14614,
        387,
        2555,
        4908,
        3489,
        26963,
        2442,
        52,
        11,
        719
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġmaybe",
            "token_id": 7344,
            "logprob": -0.3633,
            "prob": 0.6953
          },
          {
            "token": "Ġthe",
            "token_id": 279,
            "logprob": -2.3594,
            "prob": 0.0942
          },
          {
            "token": "Ġwith",
            "token_id": 449,
            "logprob": -2.9844,
            "prob": 0.0503
          },
          {
            "token": "Ġthey",
            "token_id": 814,
            "logprob": -3.2344,
            "prob": 0.0393
          },
          {
            "token": "Ġperhaps",
            "token_id": 8530,
            "logprob": -3.9844,
            "prob": 0.0186
          },
          {
            "token": "Ġanyway",
            "token_id": 13971,
            "logprob": -4.125,
            "prob": 0.0164
          },
          {
            "token": "Ġregardless",
            "token_id": 15851,
            "logprob": -4.375,
            "prob": 0.0128
          },
          {
            "token": "Ġhere",
            "token_id": 1618,
            "logprob": -4.5,
            "prob": 0.0112
          },
          {
            "token": "Ġthat",
            "token_id": 430,
            "logprob": -4.625,
            "prob": 0.0099
          },
          {
            "token": "Ġeven",
            "token_id": 1524,
            "logprob": -4.75,
            "prob": 0.0087
          }
        ]
      },
      "selected_token": {
        "token": "Ġwith",
        "token_id": 449,
        "selection_method": "sampling"
      }
    },
    {
      "step": 76,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU? That would translate \"Qui ést-ce-tu\", which isn's quite standard french. French would normally be somethinglike Qu EST-tU, but with",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?",
        "ĠThat",
        "Ġwould",
        "Ġtranslate",
        "Ġ\"",
        "Qui",
        "Ġé",
        "st",
        "-ce",
        "-t",
        "u",
        "\",",
        "Ġwhich",
        "Ġisn",
        "'s",
        "Ġquite",
        "Ġstandard",
        "Ġfrench",
        ".",
        "ĠFrench",
        "Ġwould",
        "Ġnormally",
        "Ġbe",
        "Ġsomething",
        "like",
        "ĠQu",
        "ĠEST",
        "-t",
        "U",
        ",",
        "Ġbut",
        "Ġwith"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30,
        3011,
        1053,
        15025,
        330,
        62545,
        4046,
        267,
        54312,
        2442,
        84,
        498,
        902,
        4536,
        596,
        5115,
        5410,
        42293,
        13,
        8753,
        1053,
        14614,
        387,
        2555,
        4908,
        3489,
        26963,
        2442,
        52,
        11,
        719,
        449
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġaccents",
            "token_id": 59570,
            "logprob": -0.7266,
            "prob": 0.4844
          },
          {
            "token": "Ġthe",
            "token_id": 279,
            "logprob": -1.1016,
            "prob": 0.332
          },
          {
            "token": "Ġproper",
            "token_id": 6300,
            "logprob": -3.0312,
            "prob": 0.0479
          },
          {
            "token": "Ġan",
            "token_id": 459,
            "logprob": -3.7812,
            "prob": 0.0226
          },
          {
            "token": "Ġcorrect",
            "token_id": 4495,
            "logprob": -4.1562,
            "prob": 0.0156
          },
          {
            "token": "Ġa",
            "token_id": 264,
            "logprob": -4.2812,
            "prob": 0.0137
          },
          {
            "token": "Ġsome",
            "token_id": 1063,
            "logprob": -4.4062,
            "prob": 0.0121
          },
          {
            "token": "Ġaccent",
            "token_id": 30200,
            "logprob": -4.7188,
            "prob": 0.0089
          },
          {
            "token": "Ġmaybe",
            "token_id": 7344,
            "logprob": -5.0312,
            "prob": 0.0065
          },
          {
            "token": "Ġcapital",
            "token_id": 6864,
            "logprob": -5.3438,
            "prob": 0.0047
          }
        ]
      },
      "selected_token": {
        "token": "Ġmaybe",
        "token_id": 7344,
        "selection_method": "sampling"
      }
    },
    {
      "step": 77,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU? That would translate \"Qui ést-ce-tu\", which isn's quite standard french. French would normally be somethinglike Qu EST-tU, but with maybe",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?",
        "ĠThat",
        "Ġwould",
        "Ġtranslate",
        "Ġ\"",
        "Qui",
        "Ġé",
        "st",
        "-ce",
        "-t",
        "u",
        "\",",
        "Ġwhich",
        "Ġisn",
        "'s",
        "Ġquite",
        "Ġstandard",
        "Ġfrench",
        ".",
        "ĠFrench",
        "Ġwould",
        "Ġnormally",
        "Ġbe",
        "Ġsomething",
        "like",
        "ĠQu",
        "ĠEST",
        "-t",
        "U",
        ",",
        "Ġbut",
        "Ġwith",
        "Ġmaybe"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30,
        3011,
        1053,
        15025,
        330,
        62545,
        4046,
        267,
        54312,
        2442,
        84,
        498,
        902,
        4536,
        596,
        5115,
        5410,
        42293,
        13,
        8753,
        1053,
        14614,
        387,
        2555,
        4908,
        3489,
        26963,
        2442,
        52,
        11,
        719,
        449,
        7344
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġaccents",
            "token_id": 59570,
            "logprob": -1.1875,
            "prob": 0.3047
          },
          {
            "token": "Ġa",
            "token_id": 264,
            "logprob": -1.8125,
            "prob": 0.1631
          },
          {
            "token": "Ġan",
            "token_id": 459,
            "logprob": -1.875,
            "prob": 0.1533
          },
          {
            "token": "Ġsome",
            "token_id": 1063,
            "logprob": -2.0,
            "prob": 0.1357
          },
          {
            "token": "Ġthe",
            "token_id": 279,
            "logprob": -2.4375,
            "prob": 0.0874
          },
          {
            "token": "Ġdifferent",
            "token_id": 2204,
            "logprob": -3.3125,
            "prob": 0.0364
          },
          {
            "token": "Ġ\"",
            "token_id": 330,
            "logprob": -4.375,
            "prob": 0.0126
          },
          {
            "token": "Ġmore",
            "token_id": 810,
            "logprob": -4.5625,
            "prob": 0.0104
          },
          {
            "token": "Ġaccent",
            "token_id": 30200,
            "logprob": -4.875,
            "prob": 0.0076
          },
          {
            "token": "Ġone",
            "token_id": 832,
            "logprob": -5.0625,
            "prob": 0.0063
          }
        ]
      },
      "selected_token": {
        "token": "Ġan",
        "token_id": 459,
        "selection_method": "sampling"
      }
    },
    {
      "step": 78,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU? That would translate \"Qui ést-ce-tu\", which isn's quite standard french. French would normally be somethinglike Qu EST-tU, but with maybe an",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?",
        "ĠThat",
        "Ġwould",
        "Ġtranslate",
        "Ġ\"",
        "Qui",
        "Ġé",
        "st",
        "-ce",
        "-t",
        "u",
        "\",",
        "Ġwhich",
        "Ġisn",
        "'s",
        "Ġquite",
        "Ġstandard",
        "Ġfrench",
        ".",
        "ĠFrench",
        "Ġwould",
        "Ġnormally",
        "Ġbe",
        "Ġsomething",
        "like",
        "ĠQu",
        "ĠEST",
        "-t",
        "U",
        ",",
        "Ġbut",
        "Ġwith",
        "Ġmaybe",
        "Ġan"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30,
        3011,
        1053,
        15025,
        330,
        62545,
        4046,
        267,
        54312,
        2442,
        84,
        498,
        902,
        4536,
        596,
        5115,
        5410,
        42293,
        13,
        8753,
        1053,
        14614,
        387,
        2555,
        4908,
        3489,
        26963,
        2442,
        52,
        11,
        719,
        449,
        7344,
        459
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġaccent",
            "token_id": 30200,
            "logprob": -0.1719,
            "prob": 0.8438
          },
          {
            "token": "Ġacute",
            "token_id": 30883,
            "logprob": -3.4219,
            "prob": 0.0327
          },
          {
            "token": "Ġinverted",
            "token_id": 47801,
            "logprob": -3.9219,
            "prob": 0.0198
          },
          {
            "token": "Ġextra",
            "token_id": 5066,
            "logprob": -4.0312,
            "prob": 0.0175
          },
          {
            "token": "Ġapost",
            "token_id": 39571,
            "logprob": -4.3438,
            "prob": 0.0128
          },
          {
            "token": "Ġ'",
            "token_id": 364,
            "logprob": -4.8438,
            "prob": 0.0078
          },
          {
            "token": "Ġaccents",
            "token_id": 59570,
            "logprob": -4.9062,
            "prob": 0.0073
          },
          {
            "token": "Ġé",
            "token_id": 4046,
            "logprob": -4.9688,
            "prob": 0.0068
          },
          {
            "token": "Ġ\"",
            "token_id": 330,
            "logprob": -5.0312,
            "prob": 0.0064
          },
          {
            "token": "Ġinversion",
            "token_id": 47588,
            "logprob": -5.0938,
            "prob": 0.006
          }
        ]
      },
      "selected_token": {
        "token": "Ġinverted",
        "token_id": 47801,
        "selection_method": "sampling"
      }
    },
    {
      "step": 79,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU? That would translate \"Qui ést-ce-tu\", which isn's quite standard french. French would normally be somethinglike Qu EST-tU, but with maybe an inverted",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?",
        "ĠThat",
        "Ġwould",
        "Ġtranslate",
        "Ġ\"",
        "Qui",
        "Ġé",
        "st",
        "-ce",
        "-t",
        "u",
        "\",",
        "Ġwhich",
        "Ġisn",
        "'s",
        "Ġquite",
        "Ġstandard",
        "Ġfrench",
        ".",
        "ĠFrench",
        "Ġwould",
        "Ġnormally",
        "Ġbe",
        "Ġsomething",
        "like",
        "ĠQu",
        "ĠEST",
        "-t",
        "U",
        ",",
        "Ġbut",
        "Ġwith",
        "Ġmaybe",
        "Ġan",
        "Ġinverted"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30,
        3011,
        1053,
        15025,
        330,
        62545,
        4046,
        267,
        54312,
        2442,
        84,
        498,
        902,
        4536,
        596,
        5115,
        5410,
        42293,
        13,
        8753,
        1053,
        14614,
        387,
        2555,
        4908,
        3489,
        26963,
        2442,
        52,
        11,
        719,
        449,
        7344,
        459,
        47801
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġquestion",
            "token_id": 3488,
            "logprob": -0.1738,
            "prob": 0.8398
          },
          {
            "token": "Ġaccent",
            "token_id": 30200,
            "logprob": -3.2969,
            "prob": 0.0369
          },
          {
            "token": "Ġe",
            "token_id": 384,
            "logprob": -4.125,
            "prob": 0.0164
          },
          {
            "token": "ĠT",
            "token_id": 350,
            "logprob": -4.5625,
            "prob": 0.0106
          },
          {
            "token": "Ġaccents",
            "token_id": 59570,
            "logprob": -4.6875,
            "prob": 0.0093
          },
          {
            "token": "Ġcomma",
            "token_id": 32783,
            "logprob": -4.8125,
            "prob": 0.0082
          },
          {
            "token": "Ġacute",
            "token_id": 30883,
            "logprob": -5.0625,
            "prob": 0.0064
          },
          {
            "token": "Ġ'",
            "token_id": 364,
            "logprob": -5.3125,
            "prob": 0.005
          },
          {
            "token": "Ġ\"",
            "token_id": 330,
            "logprob": -5.3125,
            "prob": 0.005
          },
          {
            "token": "Ġc",
            "token_id": 272,
            "logprob": -5.5625,
            "prob": 0.0039
          }
        ]
      },
      "selected_token": {
        "token": "Ġcomma",
        "token_id": 32783,
        "selection_method": "sampling"
      }
    },
    {
      "step": 80,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU? That would translate \"Qui ést-ce-tu\", which isn's quite standard french. French would normally be somethinglike Qu EST-tU, but with maybe an inverted comma",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?",
        "ĠThat",
        "Ġwould",
        "Ġtranslate",
        "Ġ\"",
        "Qui",
        "Ġé",
        "st",
        "-ce",
        "-t",
        "u",
        "\",",
        "Ġwhich",
        "Ġisn",
        "'s",
        "Ġquite",
        "Ġstandard",
        "Ġfrench",
        ".",
        "ĠFrench",
        "Ġwould",
        "Ġnormally",
        "Ġbe",
        "Ġsomething",
        "like",
        "ĠQu",
        "ĠEST",
        "-t",
        "U",
        ",",
        "Ġbut",
        "Ġwith",
        "Ġmaybe",
        "Ġan",
        "Ġinverted",
        "Ġcomma"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30,
        3011,
        1053,
        15025,
        330,
        62545,
        4046,
        267,
        54312,
        2442,
        84,
        498,
        902,
        4536,
        596,
        5115,
        5410,
        42293,
        13,
        8753,
        1053,
        14614,
        387,
        2555,
        4908,
        3489,
        26963,
        2442,
        52,
        11,
        719,
        449,
        7344,
        459,
        47801,
        32783
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "?",
            "token_id": 30,
            "logprob": -0.7812,
            "prob": 0.457
          },
          {
            "token": "Ġor",
            "token_id": 477,
            "logprob": -1.1562,
            "prob": 0.3145
          },
          {
            "token": ".",
            "token_id": 13,
            "logprob": -1.7812,
            "prob": 0.168
          },
          {
            "token": "Ġmaybe",
            "token_id": 7344,
            "logprob": -4.6562,
            "prob": 0.0095
          },
          {
            "token": "Ġinstead",
            "token_id": 4619,
            "logprob": -4.7812,
            "prob": 0.0084
          },
          {
            "token": "?\n\n",
            "token_id": 1980,
            "logprob": -5.1562,
            "prob": 0.0058
          },
          {
            "token": ",",
            "token_id": 11,
            "logprob": -5.4062,
            "prob": 0.0045
          },
          {
            "token": "Ġif",
            "token_id": 422,
            "logprob": -5.5312,
            "prob": 0.004
          },
          {
            "token": "Ġafter",
            "token_id": 1306,
            "logprob": -5.5312,
            "prob": 0.004
          },
          {
            "token": "Ġfor",
            "token_id": 369,
            "logprob": -5.6562,
            "prob": 0.0035
          }
        ]
      },
      "selected_token": {
        "token": ",",
        "token_id": 11,
        "selection_method": "sampling"
      }
    },
    {
      "step": 81,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU? That would translate \"Qui ést-ce-tu\", which isn's quite standard french. French would normally be somethinglike Qu EST-tU, but with maybe an inverted comma,",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?",
        "ĠThat",
        "Ġwould",
        "Ġtranslate",
        "Ġ\"",
        "Qui",
        "Ġé",
        "st",
        "-ce",
        "-t",
        "u",
        "\",",
        "Ġwhich",
        "Ġisn",
        "'s",
        "Ġquite",
        "Ġstandard",
        "Ġfrench",
        ".",
        "ĠFrench",
        "Ġwould",
        "Ġnormally",
        "Ġbe",
        "Ġsomething",
        "like",
        "ĠQu",
        "ĠEST",
        "-t",
        "U",
        ",",
        "Ġbut",
        "Ġwith",
        "Ġmaybe",
        "Ġan",
        "Ġinverted",
        "Ġcomma",
        ","
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30,
        3011,
        1053,
        15025,
        330,
        62545,
        4046,
        267,
        54312,
        2442,
        84,
        498,
        902,
        4536,
        596,
        5115,
        5410,
        42293,
        13,
        8753,
        1053,
        14614,
        387,
        2555,
        4908,
        3489,
        26963,
        2442,
        52,
        11,
        719,
        449,
        7344,
        459,
        47801,
        32783,
        11
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġbut",
            "token_id": 719,
            "logprob": -0.5391,
            "prob": 0.582
          },
          {
            "token": "Ġor",
            "token_id": 477,
            "logprob": -1.6641,
            "prob": 0.1895
          },
          {
            "token": "Ġlike",
            "token_id": 1093,
            "logprob": -1.7891,
            "prob": 0.167
          },
          {
            "token": "Ġmaybe",
            "token_id": 7344,
            "logprob": -3.9219,
            "prob": 0.0199
          },
          {
            "token": "Ġ\"",
            "token_id": 330,
            "logprob": -4.5312,
            "prob": 0.0107
          },
          {
            "token": "ĠQu",
            "token_id": 3489,
            "logprob": -5.5312,
            "prob": 0.0039
          },
          {
            "token": "Ġdepending",
            "token_id": 11911,
            "logprob": -5.6562,
            "prob": 0.0035
          },
          {
            "token": "Ġnot",
            "token_id": 539,
            "logprob": -6.0312,
            "prob": 0.0024
          },
          {
            "token": "Ġperhaps",
            "token_id": 8530,
            "logprob": -6.0312,
            "prob": 0.0024
          },
          {
            "token": "Ġas",
            "token_id": 439,
            "logprob": -6.2812,
            "prob": 0.0019
          }
        ]
      },
      "selected_token": {
        "token": "Ġnot",
        "token_id": 539,
        "selection_method": "sampling"
      }
    },
    {
      "step": 82,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU? That would translate \"Qui ést-ce-tu\", which isn's quite standard french. French would normally be somethinglike Qu EST-tU, but with maybe an inverted comma, not",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?",
        "ĠThat",
        "Ġwould",
        "Ġtranslate",
        "Ġ\"",
        "Qui",
        "Ġé",
        "st",
        "-ce",
        "-t",
        "u",
        "\",",
        "Ġwhich",
        "Ġisn",
        "'s",
        "Ġquite",
        "Ġstandard",
        "Ġfrench",
        ".",
        "ĠFrench",
        "Ġwould",
        "Ġnormally",
        "Ġbe",
        "Ġsomething",
        "like",
        "ĠQu",
        "ĠEST",
        "-t",
        "U",
        ",",
        "Ġbut",
        "Ġwith",
        "Ġmaybe",
        "Ġan",
        "Ġinverted",
        "Ġcomma",
        ",",
        "Ġnot"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30,
        3011,
        1053,
        15025,
        330,
        62545,
        4046,
        267,
        54312,
        2442,
        84,
        498,
        902,
        4536,
        596,
        5115,
        5410,
        42293,
        13,
        8753,
        1053,
        14614,
        387,
        2555,
        4908,
        3489,
        26963,
        2442,
        52,
        11,
        719,
        449,
        7344,
        459,
        47801,
        32783,
        11,
        539
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġsure",
            "token_id": 2771,
            "logprob": -0.543,
            "prob": 0.582
          },
          {
            "token": "Ġan",
            "token_id": 459,
            "logprob": -2.5469,
            "prob": 0.0786
          },
          {
            "token": "Ġthe",
            "token_id": 279,
            "logprob": -2.6094,
            "prob": 0.0737
          },
          {
            "token": "Ġé",
            "token_id": 4046,
            "logprob": -2.9219,
            "prob": 0.054
          },
          {
            "token": "Ġa",
            "token_id": 264,
            "logprob": -2.9844,
            "prob": 0.0508
          },
          {
            "token": "Ġ\"",
            "token_id": 330,
            "logprob": -3.2969,
            "prob": 0.0371
          },
          {
            "token": "Ġaccents",
            "token_id": 59570,
            "logprob": -3.4844,
            "prob": 0.0308
          },
          {
            "token": "Ġthat",
            "token_id": 430,
            "logprob": -4.3438,
            "prob": 0.0128
          },
          {
            "token": "Ġquestion",
            "token_id": 3488,
            "logprob": -4.4688,
            "prob": 0.0114
          },
          {
            "token": "Ġaccent",
            "token_id": 30200,
            "logprob": -5.2812,
            "prob": 0.005
          }
        ]
      },
      "selected_token": {
        "token": "Ġ\"",
        "token_id": 330,
        "selection_method": "sampling"
      }
    },
    {
      "step": 83,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU? That would translate \"Qui ést-ce-tu\", which isn's quite standard french. French would normally be somethinglike Qu EST-tU, but with maybe an inverted comma, not \"",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?",
        "ĠThat",
        "Ġwould",
        "Ġtranslate",
        "Ġ\"",
        "Qui",
        "Ġé",
        "st",
        "-ce",
        "-t",
        "u",
        "\",",
        "Ġwhich",
        "Ġisn",
        "'s",
        "Ġquite",
        "Ġstandard",
        "Ġfrench",
        ".",
        "ĠFrench",
        "Ġwould",
        "Ġnormally",
        "Ġbe",
        "Ġsomething",
        "like",
        "ĠQu",
        "ĠEST",
        "-t",
        "U",
        ",",
        "Ġbut",
        "Ġwith",
        "Ġmaybe",
        "Ġan",
        "Ġinverted",
        "Ġcomma",
        ",",
        "Ġnot",
        "Ġ\""
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30,
        3011,
        1053,
        15025,
        330,
        62545,
        4046,
        267,
        54312,
        2442,
        84,
        498,
        902,
        4536,
        596,
        5115,
        5410,
        42293,
        13,
        8753,
        1053,
        14614,
        387,
        2555,
        4908,
        3489,
        26963,
        2442,
        52,
        11,
        719,
        449,
        7344,
        459,
        47801,
        32783,
        11,
        539,
        330
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "est",
            "token_id": 478,
            "logprob": -0.2715,
            "prob": 0.7617
          },
          {
            "token": "qui",
            "token_id": 47391,
            "logprob": -2.5781,
            "prob": 0.0757
          },
          {
            "token": "Qui",
            "token_id": 62545,
            "logprob": -3.7656,
            "prob": 0.0231
          },
          {
            "token": "EST",
            "token_id": 5288,
            "logprob": -3.9531,
            "prob": 0.019
          },
          {
            "token": "Ġqui",
            "token_id": 7930,
            "logprob": -4.0312,
            "prob": 0.0179
          },
          {
            "token": "e",
            "token_id": 68,
            "logprob": -4.5312,
            "prob": 0.0109
          },
          {
            "token": "tu",
            "token_id": 25506,
            "logprob": -4.7188,
            "prob": 0.009
          },
          {
            "token": "es",
            "token_id": 288,
            "logprob": -4.9062,
            "prob": 0.0075
          },
          {
            "token": "é",
            "token_id": 978,
            "logprob": -5.2812,
            "prob": 0.0051
          },
          {
            "token": "ĠQui",
            "token_id": 42215,
            "logprob": -5.3438,
            "prob": 0.0048
          }
        ]
      },
      "selected_token": {
        "token": "qui",
        "token_id": 47391,
        "selection_method": "sampling"
      }
    },
    {
      "step": 84,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU? That would translate \"Qui ést-ce-tu\", which isn's quite standard french. French would normally be somethinglike Qu EST-tU, but with maybe an inverted comma, not \"qui",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?",
        "ĠThat",
        "Ġwould",
        "Ġtranslate",
        "Ġ\"",
        "Qui",
        "Ġé",
        "st",
        "-ce",
        "-t",
        "u",
        "\",",
        "Ġwhich",
        "Ġisn",
        "'s",
        "Ġquite",
        "Ġstandard",
        "Ġfrench",
        ".",
        "ĠFrench",
        "Ġwould",
        "Ġnormally",
        "Ġbe",
        "Ġsomething",
        "like",
        "ĠQu",
        "ĠEST",
        "-t",
        "U",
        ",",
        "Ġbut",
        "Ġwith",
        "Ġmaybe",
        "Ġan",
        "Ġinverted",
        "Ġcomma",
        ",",
        "Ġnot",
        "Ġ\"",
        "qui"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30,
        3011,
        1053,
        15025,
        330,
        62545,
        4046,
        267,
        54312,
        2442,
        84,
        498,
        902,
        4536,
        596,
        5115,
        5410,
        42293,
        13,
        8753,
        1053,
        14614,
        387,
        2555,
        4908,
        3489,
        26963,
        2442,
        52,
        11,
        719,
        449,
        7344,
        459,
        47801,
        32783,
        11,
        539,
        330,
        47391
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġest",
            "token_id": 1826,
            "logprob": -1.0938,
            "prob": 0.3359
          },
          {
            "token": "\".",
            "token_id": 3343,
            "logprob": -1.3438,
            "prob": 0.2617
          },
          {
            "token": "\"",
            "token_id": 1,
            "logprob": -1.8438,
            "prob": 0.1582
          },
          {
            "token": "Ġé",
            "token_id": 4046,
            "logprob": -2.2188,
            "prob": 0.1089
          },
          {
            "token": "Ġes",
            "token_id": 1560,
            "logprob": -2.9062,
            "prob": 0.0547
          },
          {
            "token": "Ġè",
            "token_id": 11676,
            "logprob": -3.4688,
            "prob": 0.0312
          },
          {
            "token": "Ġét",
            "token_id": 14240,
            "logprob": -5.0312,
            "prob": 0.0065
          },
          {
            "token": "\",",
            "token_id": 498,
            "logprob": -5.2812,
            "prob": 0.0051
          },
          {
            "token": "'est",
            "token_id": 17771,
            "logprob": -5.5938,
            "prob": 0.0037
          },
          {
            "token": ".\"",
            "token_id": 1210,
            "logprob": -5.6562,
            "prob": 0.0035
          }
        ]
      },
      "selected_token": {
        "token": "'est",
        "token_id": 17771,
        "selection_method": "sampling"
      }
    },
    {
      "step": 85,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU? That would translate \"Qui ést-ce-tu\", which isn's quite standard french. French would normally be somethinglike Qu EST-tU, but with maybe an inverted comma, not \"qui'est",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?",
        "ĠThat",
        "Ġwould",
        "Ġtranslate",
        "Ġ\"",
        "Qui",
        "Ġé",
        "st",
        "-ce",
        "-t",
        "u",
        "\",",
        "Ġwhich",
        "Ġisn",
        "'s",
        "Ġquite",
        "Ġstandard",
        "Ġfrench",
        ".",
        "ĠFrench",
        "Ġwould",
        "Ġnormally",
        "Ġbe",
        "Ġsomething",
        "like",
        "ĠQu",
        "ĠEST",
        "-t",
        "U",
        ",",
        "Ġbut",
        "Ġwith",
        "Ġmaybe",
        "Ġan",
        "Ġinverted",
        "Ġcomma",
        ",",
        "Ġnot",
        "Ġ\"",
        "qui",
        "'est"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30,
        3011,
        1053,
        15025,
        330,
        62545,
        4046,
        267,
        54312,
        2442,
        84,
        498,
        902,
        4536,
        596,
        5115,
        5410,
        42293,
        13,
        8753,
        1053,
        14614,
        387,
        2555,
        4908,
        3489,
        26963,
        2442,
        52,
        11,
        719,
        449,
        7344,
        459,
        47801,
        32783,
        11,
        539,
        330,
        47391,
        17771
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "u",
            "token_id": 84,
            "logprob": -0.8711,
            "prob": 0.418
          },
          {
            "token": "-ce",
            "token_id": 54312,
            "logprob": -1.0625,
            "prob": 0.3457
          },
          {
            "token": "Ġtu",
            "token_id": 9964,
            "logprob": -2.4375,
            "prob": 0.0874
          },
          {
            "token": "tu",
            "token_id": 25506,
            "logprob": -3.4375,
            "prob": 0.0322
          },
          {
            "token": "-u",
            "token_id": 46481,
            "logprob": -3.625,
            "prob": 0.0267
          },
          {
            "token": "-t",
            "token_id": 2442,
            "logprob": -3.8125,
            "prob": 0.0221
          },
          {
            "token": "\".",
            "token_id": 3343,
            "logprob": -4.25,
            "prob": 0.0143
          },
          {
            "token": "\"",
            "token_id": 1,
            "logprob": -4.3125,
            "prob": 0.0134
          },
          {
            "token": "Ġce",
            "token_id": 3846,
            "logprob": -4.8125,
            "prob": 0.0081
          },
          {
            "token": "-",
            "token_id": 12,
            "logprob": -5.875,
            "prob": 0.0028
          }
        ]
      },
      "selected_token": {
        "token": "\"",
        "token_id": 1,
        "selection_method": "sampling"
      }
    },
    {
      "step": 86,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU? That would translate \"Qui ést-ce-tu\", which isn's quite standard french. French would normally be somethinglike Qu EST-tU, but with maybe an inverted comma, not \"qui'est\"",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?",
        "ĠThat",
        "Ġwould",
        "Ġtranslate",
        "Ġ\"",
        "Qui",
        "Ġé",
        "st",
        "-ce",
        "-t",
        "u",
        "\",",
        "Ġwhich",
        "Ġisn",
        "'s",
        "Ġquite",
        "Ġstandard",
        "Ġfrench",
        ".",
        "ĠFrench",
        "Ġwould",
        "Ġnormally",
        "Ġbe",
        "Ġsomething",
        "like",
        "ĠQu",
        "ĠEST",
        "-t",
        "U",
        ",",
        "Ġbut",
        "Ġwith",
        "Ġmaybe",
        "Ġan",
        "Ġinverted",
        "Ġcomma",
        ",",
        "Ġnot",
        "Ġ\"",
        "qui",
        "'est",
        "\""
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30,
        3011,
        1053,
        15025,
        330,
        62545,
        4046,
        267,
        54312,
        2442,
        84,
        498,
        902,
        4536,
        596,
        5115,
        5410,
        42293,
        13,
        8753,
        1053,
        14614,
        387,
        2555,
        4908,
        3489,
        26963,
        2442,
        52,
        11,
        719,
        449,
        7344,
        459,
        47801,
        32783,
        11,
        539,
        330,
        47391,
        17771,
        1
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġbut",
            "token_id": 719,
            "logprob": -1.9219,
            "prob": 0.1465
          },
          {
            "token": "Ġmaybe",
            "token_id": 7344,
            "logprob": -1.9219,
            "prob": 0.1465
          },
          {
            "token": "Ġwhich",
            "token_id": 902,
            "logprob": -2.1719,
            "prob": 0.1138
          },
          {
            "token": "Ġwith",
            "token_id": 449,
            "logprob": -2.2969,
            "prob": 0.1006
          },
          {
            "token": "Ġbecause",
            "token_id": 1606,
            "logprob": -2.3594,
            "prob": 0.0947
          },
          {
            "token": "Ġlike",
            "token_id": 1093,
            "logprob": -2.9219,
            "prob": 0.054
          },
          {
            "token": "Ġas",
            "token_id": 439,
            "logprob": -3.3594,
            "prob": 0.0347
          },
          {
            "token": "Ġsince",
            "token_id": 2533,
            "logprob": -3.4844,
            "prob": 0.0306
          },
          {
            "token": "Ġor",
            "token_id": 477,
            "logprob": -3.5469,
            "prob": 0.0288
          },
          {
            "token": "Ġperhaps",
            "token_id": 8530,
            "logprob": -3.6719,
            "prob": 0.0254
          }
        ]
      },
      "selected_token": {
        "token": "Ġmaybe",
        "token_id": 7344,
        "selection_method": "sampling"
      }
    },
    {
      "step": 87,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU? That would translate \"Qui ést-ce-tu\", which isn's quite standard french. French would normally be somethinglike Qu EST-tU, but with maybe an inverted comma, not \"qui'est\" maybe",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?",
        "ĠThat",
        "Ġwould",
        "Ġtranslate",
        "Ġ\"",
        "Qui",
        "Ġé",
        "st",
        "-ce",
        "-t",
        "u",
        "\",",
        "Ġwhich",
        "Ġisn",
        "'s",
        "Ġquite",
        "Ġstandard",
        "Ġfrench",
        ".",
        "ĠFrench",
        "Ġwould",
        "Ġnormally",
        "Ġbe",
        "Ġsomething",
        "like",
        "ĠQu",
        "ĠEST",
        "-t",
        "U",
        ",",
        "Ġbut",
        "Ġwith",
        "Ġmaybe",
        "Ġan",
        "Ġinverted",
        "Ġcomma",
        ",",
        "Ġnot",
        "Ġ\"",
        "qui",
        "'est",
        "\"",
        "Ġmaybe"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30,
        3011,
        1053,
        15025,
        330,
        62545,
        4046,
        267,
        54312,
        2442,
        84,
        498,
        902,
        4536,
        596,
        5115,
        5410,
        42293,
        13,
        8753,
        1053,
        14614,
        387,
        2555,
        4908,
        3489,
        26963,
        2442,
        52,
        11,
        719,
        449,
        7344,
        459,
        47801,
        32783,
        11,
        539,
        330,
        47391,
        17771,
        1,
        7344
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "?",
            "token_id": 30,
            "logprob": -0.8672,
            "prob": 0.4199
          },
          {
            "token": ".",
            "token_id": 13,
            "logprob": -0.9922,
            "prob": 0.3711
          },
          {
            "token": ".\n\n",
            "token_id": 382,
            "logprob": -3.25,
            "prob": 0.0391
          },
          {
            "token": "?\n\n",
            "token_id": 1980,
            "logprob": -3.25,
            "prob": 0.0391
          },
          {
            "token": "Ġ\"",
            "token_id": 330,
            "logprob": -3.75,
            "prob": 0.0237
          },
          {
            "token": "Ġa",
            "token_id": 264,
            "logprob": -3.75,
            "prob": 0.0237
          },
          {
            "token": "Ġthey",
            "token_id": 814,
            "logprob": -3.75,
            "prob": 0.0237
          },
          {
            "token": "Ġit",
            "token_id": 433,
            "logprob": -4.375,
            "prob": 0.0127
          },
          {
            "token": "Ġthe",
            "token_id": 279,
            "logprob": -5.0,
            "prob": 0.0068
          },
          {
            "token": "Ġthat",
            "token_id": 430,
            "logprob": -5.125,
            "prob": 0.006
          }
        ]
      },
      "selected_token": {
        "token": "?",
        "token_id": 30,
        "selection_method": "sampling"
      }
    },
    {
      "step": 88,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU? That would translate \"Qui ést-ce-tu\", which isn's quite standard french. French would normally be somethinglike Qu EST-tU, but with maybe an inverted comma, not \"qui'est\" maybe?",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?",
        "ĠThat",
        "Ġwould",
        "Ġtranslate",
        "Ġ\"",
        "Qui",
        "Ġé",
        "st",
        "-ce",
        "-t",
        "u",
        "\",",
        "Ġwhich",
        "Ġisn",
        "'s",
        "Ġquite",
        "Ġstandard",
        "Ġfrench",
        ".",
        "ĠFrench",
        "Ġwould",
        "Ġnormally",
        "Ġbe",
        "Ġsomething",
        "like",
        "ĠQu",
        "ĠEST",
        "-t",
        "U",
        ",",
        "Ġbut",
        "Ġwith",
        "Ġmaybe",
        "Ġan",
        "Ġinverted",
        "Ġcomma",
        ",",
        "Ġnot",
        "Ġ\"",
        "qui",
        "'est",
        "\"",
        "Ġmaybe",
        "?"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30,
        3011,
        1053,
        15025,
        330,
        62545,
        4046,
        267,
        54312,
        2442,
        84,
        498,
        902,
        4536,
        596,
        5115,
        5410,
        42293,
        13,
        8753,
        1053,
        14614,
        387,
        2555,
        4908,
        3489,
        26963,
        2442,
        52,
        11,
        719,
        449,
        7344,
        459,
        47801,
        32783,
        11,
        539,
        330,
        47391,
        17771,
        1,
        7344,
        30
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "ĠWait",
            "token_id": 14144,
            "logprob": -0.7617,
            "prob": 0.4668
          },
          {
            "token": "ĠHmm",
            "token_id": 89290,
            "logprob": -1.1328,
            "prob": 0.3223
          },
          {
            "token": "ĠAnyway",
            "token_id": 42669,
            "logprob": -2.1406,
            "prob": 0.1182
          },
          {
            "token": "ĠMaybe",
            "token_id": 10926,
            "logprob": -3.6406,
            "prob": 0.0264
          },
          {
            "token": "ĠOr",
            "token_id": 2582,
            "logprob": -4.125,
            "prob": 0.016
          },
          {
            "token": "ĠBut",
            "token_id": 2030,
            "logprob": -4.625,
            "prob": 0.0097
          },
          {
            "token": "ĠWell",
            "token_id": 8489,
            "logprob": -4.75,
            "prob": 0.0085
          },
          {
            "token": "ĠLet",
            "token_id": 6914,
            "logprob": -5.125,
            "prob": 0.0059
          },
          {
            "token": "ĠNot",
            "token_id": 2876,
            "logprob": -5.25,
            "prob": 0.0052
          },
          {
            "token": "ĠOh",
            "token_id": 8840,
            "logprob": -5.625,
            "prob": 0.0036
          }
        ]
      },
      "selected_token": {
        "token": "ĠWait",
        "token_id": 14144,
        "selection_method": "sampling"
      }
    },
    {
      "step": 89,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU? That would translate \"Qui ést-ce-tu\", which isn's quite standard french. French would normally be somethinglike Qu EST-tU, but with maybe an inverted comma, not \"qui'est\" maybe? Wait",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?",
        "ĠThat",
        "Ġwould",
        "Ġtranslate",
        "Ġ\"",
        "Qui",
        "Ġé",
        "st",
        "-ce",
        "-t",
        "u",
        "\",",
        "Ġwhich",
        "Ġisn",
        "'s",
        "Ġquite",
        "Ġstandard",
        "Ġfrench",
        ".",
        "ĠFrench",
        "Ġwould",
        "Ġnormally",
        "Ġbe",
        "Ġsomething",
        "like",
        "ĠQu",
        "ĠEST",
        "-t",
        "U",
        ",",
        "Ġbut",
        "Ġwith",
        "Ġmaybe",
        "Ġan",
        "Ġinverted",
        "Ġcomma",
        ",",
        "Ġnot",
        "Ġ\"",
        "qui",
        "'est",
        "\"",
        "Ġmaybe",
        "?",
        "ĠWait"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30,
        3011,
        1053,
        15025,
        330,
        62545,
        4046,
        267,
        54312,
        2442,
        84,
        498,
        902,
        4536,
        596,
        5115,
        5410,
        42293,
        13,
        8753,
        1053,
        14614,
        387,
        2555,
        4908,
        3489,
        26963,
        2442,
        52,
        11,
        719,
        449,
        7344,
        459,
        47801,
        32783,
        11,
        539,
        330,
        47391,
        17771,
        1,
        7344,
        30,
        14144
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": ",",
            "token_id": 11,
            "logprob": -0.3047,
            "prob": 0.7383
          },
          {
            "token": "Ġmaybe",
            "token_id": 7344,
            "logprob": -2.2969,
            "prob": 0.0996
          },
          {
            "token": "Ġthe",
            "token_id": 279,
            "logprob": -2.6719,
            "prob": 0.0688
          },
          {
            "token": "Ġno",
            "token_id": 912,
            "logprob": -3.4219,
            "prob": 0.0325
          },
          {
            "token": "Ġactually",
            "token_id": 3604,
            "logprob": -3.6719,
            "prob": 0.0253
          },
          {
            "token": "Ġ\"",
            "token_id": 330,
            "logprob": -4.0625,
            "prob": 0.0173
          },
          {
            "token": ".",
            "token_id": 13,
            "logprob": -5.4375,
            "prob": 0.0044
          },
          {
            "token": "Ġperhaps",
            "token_id": 8530,
            "logprob": -6.1875,
            "prob": 0.0021
          },
          {
            "token": "Ġuser",
            "token_id": 1217,
            "logprob": -6.1875,
            "prob": 0.0021
          },
          {
            "token": "Ġlet",
            "token_id": 1095,
            "logprob": -6.5625,
            "prob": 0.0014
          }
        ]
      },
      "selected_token": {
        "token": ",",
        "token_id": 11,
        "selection_method": "sampling"
      }
    },
    {
      "step": 90,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU? That would translate \"Qui ést-ce-tu\", which isn's quite standard french. French would normally be somethinglike Qu EST-tU, but with maybe an inverted comma, not \"qui'est\" maybe? Wait,",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?",
        "ĠThat",
        "Ġwould",
        "Ġtranslate",
        "Ġ\"",
        "Qui",
        "Ġé",
        "st",
        "-ce",
        "-t",
        "u",
        "\",",
        "Ġwhich",
        "Ġisn",
        "'s",
        "Ġquite",
        "Ġstandard",
        "Ġfrench",
        ".",
        "ĠFrench",
        "Ġwould",
        "Ġnormally",
        "Ġbe",
        "Ġsomething",
        "like",
        "ĠQu",
        "ĠEST",
        "-t",
        "U",
        ",",
        "Ġbut",
        "Ġwith",
        "Ġmaybe",
        "Ġan",
        "Ġinverted",
        "Ġcomma",
        ",",
        "Ġnot",
        "Ġ\"",
        "qui",
        "'est",
        "\"",
        "Ġmaybe",
        "?",
        "ĠWait",
        ","
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30,
        3011,
        1053,
        15025,
        330,
        62545,
        4046,
        267,
        54312,
        2442,
        84,
        498,
        902,
        4536,
        596,
        5115,
        5410,
        42293,
        13,
        8753,
        1053,
        14614,
        387,
        2555,
        4908,
        3489,
        26963,
        2442,
        52,
        11,
        719,
        449,
        7344,
        459,
        47801,
        32783,
        11,
        539,
        330,
        47391,
        17771,
        1,
        7344,
        30,
        14144,
        11
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġmaybe",
            "token_id": 7344,
            "logprob": -0.832,
            "prob": 0.4355
          },
          {
            "token": "Ġactually",
            "token_id": 3604,
            "logprob": -1.8281,
            "prob": 0.1602
          },
          {
            "token": "Ġthe",
            "token_id": 279,
            "logprob": -1.8281,
            "prob": 0.1602
          },
          {
            "token": "Ġ\"",
            "token_id": 330,
            "logprob": -2.0781,
            "prob": 0.125
          },
          {
            "token": "Ġperhaps",
            "token_id": 8530,
            "logprob": -3.2031,
            "prob": 0.0405
          },
          {
            "token": "Ġno",
            "token_id": 912,
            "logprob": -3.4531,
            "prob": 0.0315
          },
          {
            "token": "Ġlet",
            "token_id": 1095,
            "logprob": -4.2188,
            "prob": 0.0149
          },
          {
            "token": "ĠFrench",
            "token_id": 8753,
            "logprob": -5.2188,
            "prob": 0.0055
          },
          {
            "token": "Ġin",
            "token_id": 304,
            "logprob": -5.4688,
            "prob": 0.0043
          },
          {
            "token": "Ġbut",
            "token_id": 719,
            "logprob": -5.8438,
            "prob": 0.0029
          }
        ]
      },
      "selected_token": {
        "token": "Ġmaybe",
        "token_id": 7344,
        "selection_method": "sampling"
      }
    },
    {
      "step": 91,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU? That would translate \"Qui ést-ce-tu\", which isn's quite standard french. French would normally be somethinglike Qu EST-tU, but with maybe an inverted comma, not \"qui'est\" maybe? Wait, maybe",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?",
        "ĠThat",
        "Ġwould",
        "Ġtranslate",
        "Ġ\"",
        "Qui",
        "Ġé",
        "st",
        "-ce",
        "-t",
        "u",
        "\",",
        "Ġwhich",
        "Ġisn",
        "'s",
        "Ġquite",
        "Ġstandard",
        "Ġfrench",
        ".",
        "ĠFrench",
        "Ġwould",
        "Ġnormally",
        "Ġbe",
        "Ġsomething",
        "like",
        "ĠQu",
        "ĠEST",
        "-t",
        "U",
        ",",
        "Ġbut",
        "Ġwith",
        "Ġmaybe",
        "Ġan",
        "Ġinverted",
        "Ġcomma",
        ",",
        "Ġnot",
        "Ġ\"",
        "qui",
        "'est",
        "\"",
        "Ġmaybe",
        "?",
        "ĠWait",
        ",",
        "Ġmaybe"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30,
        3011,
        1053,
        15025,
        330,
        62545,
        4046,
        267,
        54312,
        2442,
        84,
        498,
        902,
        4536,
        596,
        5115,
        5410,
        42293,
        13,
        8753,
        1053,
        14614,
        387,
        2555,
        4908,
        3489,
        26963,
        2442,
        52,
        11,
        719,
        449,
        7344,
        459,
        47801,
        32783,
        11,
        539,
        330,
        47391,
        17771,
        1,
        7344,
        30,
        14144,
        11,
        7344
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġthey",
            "token_id": 814,
            "logprob": -0.8906,
            "prob": 0.4102
          },
          {
            "token": "Ġit",
            "token_id": 433,
            "logprob": -1.1406,
            "prob": 0.3184
          },
          {
            "token": "Ġthe",
            "token_id": 279,
            "logprob": -1.5156,
            "prob": 0.2197
          },
          {
            "token": "Ġa",
            "token_id": 264,
            "logprob": -4.0312,
            "prob": 0.0179
          },
          {
            "token": "Ġthere",
            "token_id": 1070,
            "logprob": -4.5312,
            "prob": 0.0109
          },
          {
            "token": "ĠI",
            "token_id": 358,
            "logprob": -5.0312,
            "prob": 0.0066
          },
          {
            "token": "Ġthat",
            "token_id": 430,
            "logprob": -5.0312,
            "prob": 0.0066
          },
          {
            "token": "Ġ\"",
            "token_id": 330,
            "logprob": -5.9062,
            "prob": 0.0028
          },
          {
            "token": "Ġjust",
            "token_id": 1120,
            "logprob": -6.0312,
            "prob": 0.0024
          },
          {
            "token": "Ġuser",
            "token_id": 1217,
            "logprob": -6.0312,
            "prob": 0.0024
          }
        ]
      },
      "selected_token": {
        "token": "Ġthat",
        "token_id": 430,
        "selection_method": "sampling"
      }
    },
    {
      "step": 92,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU? That would translate \"Qui ést-ce-tu\", which isn's quite standard french. French would normally be somethinglike Qu EST-tU, but with maybe an inverted comma, not \"qui'est\" maybe? Wait, maybe that",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?",
        "ĠThat",
        "Ġwould",
        "Ġtranslate",
        "Ġ\"",
        "Qui",
        "Ġé",
        "st",
        "-ce",
        "-t",
        "u",
        "\",",
        "Ġwhich",
        "Ġisn",
        "'s",
        "Ġquite",
        "Ġstandard",
        "Ġfrench",
        ".",
        "ĠFrench",
        "Ġwould",
        "Ġnormally",
        "Ġbe",
        "Ġsomething",
        "like",
        "ĠQu",
        "ĠEST",
        "-t",
        "U",
        ",",
        "Ġbut",
        "Ġwith",
        "Ġmaybe",
        "Ġan",
        "Ġinverted",
        "Ġcomma",
        ",",
        "Ġnot",
        "Ġ\"",
        "qui",
        "'est",
        "\"",
        "Ġmaybe",
        "?",
        "ĠWait",
        ",",
        "Ġmaybe",
        "Ġthat"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30,
        3011,
        1053,
        15025,
        330,
        62545,
        4046,
        267,
        54312,
        2442,
        84,
        498,
        902,
        4536,
        596,
        5115,
        5410,
        42293,
        13,
        8753,
        1053,
        14614,
        387,
        2555,
        4908,
        3489,
        26963,
        2442,
        52,
        11,
        719,
        449,
        7344,
        459,
        47801,
        32783,
        11,
        539,
        330,
        47391,
        17771,
        1,
        7344,
        30,
        14144,
        11,
        7344,
        430
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "'s",
            "token_id": 596,
            "logprob": -0.0771,
            "prob": 0.9258
          },
          {
            "token": "Ġwas",
            "token_id": 574,
            "logprob": -2.7031,
            "prob": 0.0669
          },
          {
            "token": "Ġuser",
            "token_id": 1217,
            "logprob": -5.3125,
            "prob": 0.0049
          },
          {
            "token": "’s",
            "token_id": 753,
            "logprob": -7.5625,
            "prob": 0.0005
          },
          {
            "token": "Ġtypo",
            "token_id": 86205,
            "logprob": -7.8125,
            "prob": 0.0004
          },
          {
            "token": "Ġ\"",
            "token_id": 330,
            "logprob": -8.9375,
            "prob": 0.0001
          },
          {
            "token": "Ġwasn",
            "token_id": 5828,
            "logprob": -8.9375,
            "prob": 0.0001
          },
          {
            "token": "Ġsentence",
            "token_id": 11914,
            "logprob": -8.9375,
            "prob": 0.0001
          },
          {
            "token": "Ġperson",
            "token_id": 1732,
            "logprob": -9.0625,
            "prob": 0.0001
          },
          {
            "token": "Ġfirst",
            "token_id": 1176,
            "logprob": -9.1875,
            "prob": 0.0001
          }
        ]
      },
      "selected_token": {
        "token": "'s",
        "token_id": 596,
        "selection_method": "sampling"
      }
    },
    {
      "step": 93,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU? That would translate \"Qui ést-ce-tu\", which isn's quite standard french. French would normally be somethinglike Qu EST-tU, but with maybe an inverted comma, not \"qui'est\" maybe? Wait, maybe that's",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?",
        "ĠThat",
        "Ġwould",
        "Ġtranslate",
        "Ġ\"",
        "Qui",
        "Ġé",
        "st",
        "-ce",
        "-t",
        "u",
        "\",",
        "Ġwhich",
        "Ġisn",
        "'s",
        "Ġquite",
        "Ġstandard",
        "Ġfrench",
        ".",
        "ĠFrench",
        "Ġwould",
        "Ġnormally",
        "Ġbe",
        "Ġsomething",
        "like",
        "ĠQu",
        "ĠEST",
        "-t",
        "U",
        ",",
        "Ġbut",
        "Ġwith",
        "Ġmaybe",
        "Ġan",
        "Ġinverted",
        "Ġcomma",
        ",",
        "Ġnot",
        "Ġ\"",
        "qui",
        "'est",
        "\"",
        "Ġmaybe",
        "?",
        "ĠWait",
        ",",
        "Ġmaybe",
        "Ġthat",
        "'s"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30,
        3011,
        1053,
        15025,
        330,
        62545,
        4046,
        267,
        54312,
        2442,
        84,
        498,
        902,
        4536,
        596,
        5115,
        5410,
        42293,
        13,
        8753,
        1053,
        14614,
        387,
        2555,
        4908,
        3489,
        26963,
        2442,
        52,
        11,
        719,
        449,
        7344,
        459,
        47801,
        32783,
        11,
        539,
        330,
        47391,
        17771,
        1,
        7344,
        30,
        14144,
        11,
        7344,
        430,
        596
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġa",
            "token_id": 264,
            "logprob": -0.1846,
            "prob": 0.832
          },
          {
            "token": "Ġjust",
            "token_id": 1120,
            "logprob": -1.9375,
            "prob": 0.1445
          },
          {
            "token": "Ġnot",
            "token_id": 539,
            "logprob": -5.25,
            "prob": 0.0052
          },
          {
            "token": "Ġactually",
            "token_id": 3604,
            "logprob": -5.625,
            "prob": 0.0036
          },
          {
            "token": "Ġan",
            "token_id": 459,
            "logprob": -6.25,
            "prob": 0.0019
          },
          {
            "token": "Ġthe",
            "token_id": 279,
            "logprob": -6.5,
            "prob": 0.0015
          },
          {
            "token": "Ġhow",
            "token_id": 1268,
            "logprob": -6.5625,
            "prob": 0.0014
          },
          {
            "token": "Ġfrom",
            "token_id": 505,
            "logprob": -6.625,
            "prob": 0.0013
          },
          {
            "token": "Ġuser",
            "token_id": 1217,
            "logprob": -6.6875,
            "prob": 0.0013
          },
          {
            "token": "Ġanother",
            "token_id": 2500,
            "logprob": -7.5625,
            "prob": 0.0005
          }
        ]
      },
      "selected_token": {
        "token": "Ġa",
        "token_id": 264,
        "selection_method": "sampling"
      }
    },
    {
      "step": 94,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU? That would translate \"Qui ést-ce-tu\", which isn's quite standard french. French would normally be somethinglike Qu EST-tU, but with maybe an inverted comma, not \"qui'est\" maybe? Wait, maybe that's a",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?",
        "ĠThat",
        "Ġwould",
        "Ġtranslate",
        "Ġ\"",
        "Qui",
        "Ġé",
        "st",
        "-ce",
        "-t",
        "u",
        "\",",
        "Ġwhich",
        "Ġisn",
        "'s",
        "Ġquite",
        "Ġstandard",
        "Ġfrench",
        ".",
        "ĠFrench",
        "Ġwould",
        "Ġnormally",
        "Ġbe",
        "Ġsomething",
        "like",
        "ĠQu",
        "ĠEST",
        "-t",
        "U",
        ",",
        "Ġbut",
        "Ġwith",
        "Ġmaybe",
        "Ġan",
        "Ġinverted",
        "Ġcomma",
        ",",
        "Ġnot",
        "Ġ\"",
        "qui",
        "'est",
        "\"",
        "Ġmaybe",
        "?",
        "ĠWait",
        ",",
        "Ġmaybe",
        "Ġthat",
        "'s",
        "Ġa"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30,
        3011,
        1053,
        15025,
        330,
        62545,
        4046,
        267,
        54312,
        2442,
        84,
        498,
        902,
        4536,
        596,
        5115,
        5410,
        42293,
        13,
        8753,
        1053,
        14614,
        387,
        2555,
        4908,
        3489,
        26963,
        2442,
        52,
        11,
        719,
        449,
        7344,
        459,
        47801,
        32783,
        11,
        539,
        330,
        47391,
        17771,
        1,
        7344,
        30,
        14144,
        11,
        7344,
        430,
        596,
        264
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġtypo",
            "token_id": 86205,
            "logprob": -0.0131,
            "prob": 0.9883
          },
          {
            "token": "Ġmistake",
            "token_id": 16930,
            "logprob": -5.625,
            "prob": 0.0036
          },
          {
            "token": "Ġtyping",
            "token_id": 20061,
            "logprob": -6.5,
            "prob": 0.0015
          },
          {
            "token": "Ġmiss",
            "token_id": 3194,
            "logprob": -6.75,
            "prob": 0.0012
          },
          {
            "token": "Ġspelling",
            "token_id": 43529,
            "logprob": -7.125,
            "prob": 0.0008
          },
          {
            "token": "Ġmist",
            "token_id": 8770,
            "logprob": -7.25,
            "prob": 0.0007
          },
          {
            "token": "Ġcommon",
            "token_id": 4279,
            "logprob": -7.5,
            "prob": 0.0005
          },
          {
            "token": "Ġdifferent",
            "token_id": 2204,
            "logprob": -7.6875,
            "prob": 0.0005
          },
          {
            "token": "Ġtranslation",
            "token_id": 14807,
            "logprob": -7.8125,
            "prob": 0.0004
          },
          {
            "token": "Ġquestion",
            "token_id": 3488,
            "logprob": -7.875,
            "prob": 0.0004
          }
        ]
      },
      "selected_token": {
        "token": "Ġquestion",
        "token_id": 3488,
        "selection_method": "sampling"
      }
    },
    {
      "step": 95,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU? That would translate \"Qui ést-ce-tu\", which isn's quite standard french. French would normally be somethinglike Qu EST-tU, but with maybe an inverted comma, not \"qui'est\" maybe? Wait, maybe that's a question",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?",
        "ĠThat",
        "Ġwould",
        "Ġtranslate",
        "Ġ\"",
        "Qui",
        "Ġé",
        "st",
        "-ce",
        "-t",
        "u",
        "\",",
        "Ġwhich",
        "Ġisn",
        "'s",
        "Ġquite",
        "Ġstandard",
        "Ġfrench",
        ".",
        "ĠFrench",
        "Ġwould",
        "Ġnormally",
        "Ġbe",
        "Ġsomething",
        "like",
        "ĠQu",
        "ĠEST",
        "-t",
        "U",
        ",",
        "Ġbut",
        "Ġwith",
        "Ġmaybe",
        "Ġan",
        "Ġinverted",
        "Ġcomma",
        ",",
        "Ġnot",
        "Ġ\"",
        "qui",
        "'est",
        "\"",
        "Ġmaybe",
        "?",
        "ĠWait",
        ",",
        "Ġmaybe",
        "Ġthat",
        "'s",
        "Ġa",
        "Ġquestion"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30,
        3011,
        1053,
        15025,
        330,
        62545,
        4046,
        267,
        54312,
        2442,
        84,
        498,
        902,
        4536,
        596,
        5115,
        5410,
        42293,
        13,
        8753,
        1053,
        14614,
        387,
        2555,
        4908,
        3489,
        26963,
        2442,
        52,
        11,
        719,
        449,
        7344,
        459,
        47801,
        32783,
        11,
        539,
        330,
        47391,
        17771,
        1,
        7344,
        30,
        14144,
        11,
        7344,
        430,
        596,
        264,
        3488
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġabout",
            "token_id": 922,
            "logprob": -1.1797,
            "prob": 0.3066
          },
          {
            "token": "Ġin",
            "token_id": 304,
            "logprob": -1.9297,
            "prob": 0.1445
          },
          {
            "token": ".",
            "token_id": 13,
            "logprob": -2.3125,
            "prob": 0.0996
          },
          {
            "token": "Ġfrom",
            "token_id": 505,
            "logprob": -2.3125,
            "prob": 0.0996
          },
          {
            "token": "Ġof",
            "token_id": 315,
            "logprob": -2.8125,
            "prob": 0.0603
          },
          {
            "token": "Ġlike",
            "token_id": 1093,
            "logprob": -3.3125,
            "prob": 0.0366
          },
          {
            "token": "Ġwritten",
            "token_id": 5439,
            "logprob": -3.6875,
            "prob": 0.0251
          },
          {
            "token": "Ġtranslation",
            "token_id": 14807,
            "logprob": -3.8125,
            "prob": 0.0222
          },
          {
            "token": ",",
            "token_id": 11,
            "logprob": -3.9375,
            "prob": 0.0197
          },
          {
            "token": "Ġform",
            "token_id": 1376,
            "logprob": -4.1875,
            "prob": 0.0153
          }
        ]
      },
      "selected_token": {
        "token": "Ġlike",
        "token_id": 1093,
        "selection_method": "sampling"
      }
    },
    {
      "step": 96,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU? That would translate \"Qui ést-ce-tu\", which isn's quite standard french. French would normally be somethinglike Qu EST-tU, but with maybe an inverted comma, not \"qui'est\" maybe? Wait, maybe that's a question like",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?",
        "ĠThat",
        "Ġwould",
        "Ġtranslate",
        "Ġ\"",
        "Qui",
        "Ġé",
        "st",
        "-ce",
        "-t",
        "u",
        "\",",
        "Ġwhich",
        "Ġisn",
        "'s",
        "Ġquite",
        "Ġstandard",
        "Ġfrench",
        ".",
        "ĠFrench",
        "Ġwould",
        "Ġnormally",
        "Ġbe",
        "Ġsomething",
        "like",
        "ĠQu",
        "ĠEST",
        "-t",
        "U",
        ",",
        "Ġbut",
        "Ġwith",
        "Ġmaybe",
        "Ġan",
        "Ġinverted",
        "Ġcomma",
        ",",
        "Ġnot",
        "Ġ\"",
        "qui",
        "'est",
        "\"",
        "Ġmaybe",
        "?",
        "ĠWait",
        ",",
        "Ġmaybe",
        "Ġthat",
        "'s",
        "Ġa",
        "Ġquestion",
        "Ġlike"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30,
        3011,
        1053,
        15025,
        330,
        62545,
        4046,
        267,
        54312,
        2442,
        84,
        498,
        902,
        4536,
        596,
        5115,
        5410,
        42293,
        13,
        8753,
        1053,
        14614,
        387,
        2555,
        4908,
        3489,
        26963,
        2442,
        52,
        11,
        719,
        449,
        7344,
        459,
        47801,
        32783,
        11,
        539,
        330,
        47391,
        17771,
        1,
        7344,
        30,
        14144,
        11,
        7344,
        430,
        596,
        264,
        3488,
        1093
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġ\"",
            "token_id": 330,
            "logprob": -0.0334,
            "prob": 0.9688
          },
          {
            "token": ",",
            "token_id": 11,
            "logprob": -4.4062,
            "prob": 0.0121
          },
          {
            "token": "Ġin",
            "token_id": 304,
            "logprob": -4.6562,
            "prob": 0.0095
          },
          {
            "token": "Ġwho",
            "token_id": 889,
            "logprob": -5.9062,
            "prob": 0.0027
          },
          {
            "token": "Ġasking",
            "token_id": 10371,
            "logprob": -6.7812,
            "prob": 0.0011
          },
          {
            "token": "Ġa",
            "token_id": 264,
            "logprob": -6.9062,
            "prob": 0.001
          },
          {
            "token": "Ġ'",
            "token_id": 364,
            "logprob": -7.0312,
            "prob": 0.0009
          },
          {
            "token": "Ġ“",
            "token_id": 1054,
            "logprob": -7.0312,
            "prob": 0.0009
          },
          {
            "token": "ĠQu",
            "token_id": 3489,
            "logprob": -7.4688,
            "prob": 0.0006
          },
          {
            "token": "ĠWho",
            "token_id": 10699,
            "logprob": -7.5312,
            "prob": 0.0005
          }
        ]
      },
      "selected_token": {
        "token": ",",
        "token_id": 11,
        "selection_method": "sampling"
      }
    },
    {
      "step": 97,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU? That would translate \"Qui ést-ce-tu\", which isn's quite standard french. French would normally be somethinglike Qu EST-tU, but with maybe an inverted comma, not \"qui'est\" maybe? Wait, maybe that's a question like,",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?",
        "ĠThat",
        "Ġwould",
        "Ġtranslate",
        "Ġ\"",
        "Qui",
        "Ġé",
        "st",
        "-ce",
        "-t",
        "u",
        "\",",
        "Ġwhich",
        "Ġisn",
        "'s",
        "Ġquite",
        "Ġstandard",
        "Ġfrench",
        ".",
        "ĠFrench",
        "Ġwould",
        "Ġnormally",
        "Ġbe",
        "Ġsomething",
        "like",
        "ĠQu",
        "ĠEST",
        "-t",
        "U",
        ",",
        "Ġbut",
        "Ġwith",
        "Ġmaybe",
        "Ġan",
        "Ġinverted",
        "Ġcomma",
        ",",
        "Ġnot",
        "Ġ\"",
        "qui",
        "'est",
        "\"",
        "Ġmaybe",
        "?",
        "ĠWait",
        ",",
        "Ġmaybe",
        "Ġthat",
        "'s",
        "Ġa",
        "Ġquestion",
        "Ġlike",
        ","
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30,
        3011,
        1053,
        15025,
        330,
        62545,
        4046,
        267,
        54312,
        2442,
        84,
        498,
        902,
        4536,
        596,
        5115,
        5410,
        42293,
        13,
        8753,
        1053,
        14614,
        387,
        2555,
        4908,
        3489,
        26963,
        2442,
        52,
        11,
        719,
        449,
        7344,
        459,
        47801,
        32783,
        11,
        539,
        330,
        47391,
        17771,
        1,
        7344,
        30,
        14144,
        11,
        7344,
        430,
        596,
        264,
        3488,
        1093,
        11
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġ\"",
            "token_id": 330,
            "logprob": -0.0967,
            "prob": 0.9062
          },
          {
            "token": "Ġwho",
            "token_id": 889,
            "logprob": -3.4688,
            "prob": 0.031
          },
          {
            "token": "Ġin",
            "token_id": 304,
            "logprob": -3.5938,
            "prob": 0.0275
          },
          {
            "token": "Ġwhat",
            "token_id": 1148,
            "logprob": -5.4688,
            "prob": 0.0042
          },
          {
            "token": "Ġliterally",
            "token_id": 16280,
            "logprob": -5.5938,
            "prob": 0.0037
          },
          {
            "token": "Ġmaybe",
            "token_id": 7344,
            "logprob": -5.8438,
            "prob": 0.0029
          },
          {
            "token": "ĠWho",
            "token_id": 10699,
            "logprob": -6.2188,
            "prob": 0.002
          },
          {
            "token": "ĠQu",
            "token_id": 3489,
            "logprob": -6.5938,
            "prob": 0.0014
          },
          {
            "token": "Ġ'",
            "token_id": 364,
            "logprob": -6.7188,
            "prob": 0.0012
          },
          {
            "token": "Ġis",
            "token_id": 374,
            "logprob": -6.8438,
            "prob": 0.0011
          }
        ]
      },
      "selected_token": {
        "token": "ĠQu",
        "token_id": 3489,
        "selection_method": "sampling"
      }
    },
    {
      "step": 98,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU? That would translate \"Qui ést-ce-tu\", which isn's quite standard french. French would normally be somethinglike Qu EST-tU, but with maybe an inverted comma, not \"qui'est\" maybe? Wait, maybe that's a question like, Qu",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?",
        "ĠThat",
        "Ġwould",
        "Ġtranslate",
        "Ġ\"",
        "Qui",
        "Ġé",
        "st",
        "-ce",
        "-t",
        "u",
        "\",",
        "Ġwhich",
        "Ġisn",
        "'s",
        "Ġquite",
        "Ġstandard",
        "Ġfrench",
        ".",
        "ĠFrench",
        "Ġwould",
        "Ġnormally",
        "Ġbe",
        "Ġsomething",
        "like",
        "ĠQu",
        "ĠEST",
        "-t",
        "U",
        ",",
        "Ġbut",
        "Ġwith",
        "Ġmaybe",
        "Ġan",
        "Ġinverted",
        "Ġcomma",
        ",",
        "Ġnot",
        "Ġ\"",
        "qui",
        "'est",
        "\"",
        "Ġmaybe",
        "?",
        "ĠWait",
        ",",
        "Ġmaybe",
        "Ġthat",
        "'s",
        "Ġa",
        "Ġquestion",
        "Ġlike",
        ",",
        "ĠQu"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30,
        3011,
        1053,
        15025,
        330,
        62545,
        4046,
        267,
        54312,
        2442,
        84,
        498,
        902,
        4536,
        596,
        5115,
        5410,
        42293,
        13,
        8753,
        1053,
        14614,
        387,
        2555,
        4908,
        3489,
        26963,
        2442,
        52,
        11,
        719,
        449,
        7344,
        459,
        47801,
        32783,
        11,
        539,
        330,
        47391,
        17771,
        1,
        7344,
        30,
        14144,
        11,
        7344,
        430,
        596,
        264,
        3488,
        1093,
        11,
        3489
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "'est",
            "token_id": 17771,
            "logprob": -0.2793,
            "prob": 0.7578
          },
          {
            "token": "Ġest",
            "token_id": 1826,
            "logprob": -2.2188,
            "prob": 0.1089
          },
          {
            "token": "'",
            "token_id": 6,
            "logprob": -2.9688,
            "prob": 0.0515
          },
          {
            "token": "el",
            "token_id": 301,
            "logprob": -4.3438,
            "prob": 0.013
          },
          {
            "token": "elle",
            "token_id": 6853,
            "logprob": -4.875,
            "prob": 0.0077
          },
          {
            "token": "ĠEST",
            "token_id": 26963,
            "logprob": -5.0312,
            "prob": 0.0065
          },
          {
            "token": "’est",
            "token_id": 22117,
            "logprob": -5.2188,
            "prob": 0.0054
          },
          {
            "token": "els",
            "token_id": 2053,
            "logprob": -6.2188,
            "prob": 0.002
          },
          {
            "token": "est",
            "token_id": 478,
            "logprob": -6.375,
            "prob": 0.0017
          },
          {
            "token": "�",
            "token_id": 39013,
            "logprob": -6.5312,
            "prob": 0.0015
          }
        ]
      },
      "selected_token": {
        "token": "elle",
        "token_id": 6853,
        "selection_method": "sampling"
      }
    },
    {
      "step": 99,
      "input_text": "Qui es-tu?<|im_end|>\n<|im_start|>assistant\n<think>Okay, the users are wondering \"Who are you?\" Let met see here, \"Qui è tu\" but they spelled it with some extra accent marks? Wait no, in french, actually, \"QUI ESTU TU? That would translate \"Qui ést-ce-tu\", which isn's quite standard french. French would normally be somethinglike Qu EST-tU, but with maybe an inverted comma, not \"qui'est\" maybe? Wait, maybe that's a question like, Quelle",
      "tokens": [
        "Qui",
        "Ġes",
        "-t",
        "u",
        "?",
        "<|im_end|>",
        "\n",
        "<|im_start|>",
        "assistant",
        "\n",
        "<th",
        "ink",
        ">",
        "Okay",
        ",",
        "Ġthe",
        "Ġusers",
        "Ġare",
        "Ġwondering",
        "Ġ\"",
        "Who",
        "Ġare",
        "Ġyou",
        "?\"",
        "ĠLet",
        "Ġmet",
        "Ġsee",
        "Ġhere",
        ",",
        "Ġ\"",
        "Qui",
        "Ġè",
        "Ġtu",
        "\"",
        "Ġbut",
        "Ġthey",
        "Ġspelled",
        "Ġit",
        "Ġwith",
        "Ġsome",
        "Ġextra",
        "Ġaccent",
        "Ġmarks",
        "?",
        "ĠWait",
        "Ġno",
        ",",
        "Ġin",
        "Ġfrench",
        ",",
        "Ġactually",
        ",",
        "Ġ\"",
        "QUI",
        "ĠEST",
        "U",
        "ĠTU",
        "?",
        "ĠThat",
        "Ġwould",
        "Ġtranslate",
        "Ġ\"",
        "Qui",
        "Ġé",
        "st",
        "-ce",
        "-t",
        "u",
        "\",",
        "Ġwhich",
        "Ġisn",
        "'s",
        "Ġquite",
        "Ġstandard",
        "Ġfrench",
        ".",
        "ĠFrench",
        "Ġwould",
        "Ġnormally",
        "Ġbe",
        "Ġsomething",
        "like",
        "ĠQu",
        "ĠEST",
        "-t",
        "U",
        ",",
        "Ġbut",
        "Ġwith",
        "Ġmaybe",
        "Ġan",
        "Ġinverted",
        "Ġcomma",
        ",",
        "Ġnot",
        "Ġ\"",
        "qui",
        "'est",
        "\"",
        "Ġmaybe",
        "?",
        "ĠWait",
        ",",
        "Ġmaybe",
        "Ġthat",
        "'s",
        "Ġa",
        "Ġquestion",
        "Ġlike",
        ",",
        "ĠQu",
        "elle"
      ],
      "token_ids": [
        62545,
        1560,
        2442,
        84,
        30,
        100265,
        198,
        100264,
        78191,
        198,
        14023,
        771,
        29,
        33413,
        11,
        279,
        3932,
        527,
        20910,
        330,
        15546,
        527,
        499,
        7673,
        6914,
        2322,
        1518,
        1618,
        11,
        330,
        62545,
        11676,
        9964,
        1,
        719,
        814,
        68918,
        433,
        449,
        1063,
        5066,
        30200,
        15785,
        30,
        14144,
        912,
        11,
        304,
        42293,
        11,
        3604,
        11,
        330,
        12247,
        26963,
        52,
        70514,
        30,
        3011,
        1053,
        15025,
        330,
        62545,
        4046,
        267,
        54312,
        2442,
        84,
        498,
        902,
        4536,
        596,
        5115,
        5410,
        42293,
        13,
        8753,
        1053,
        14614,
        387,
        2555,
        4908,
        3489,
        26963,
        2442,
        52,
        11,
        719,
        449,
        7344,
        459,
        47801,
        32783,
        11,
        539,
        330,
        47391,
        17771,
        1,
        7344,
        30,
        14144,
        11,
        7344,
        430,
        596,
        264,
        3488,
        1093,
        11,
        3489,
        6853
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġest",
            "token_id": 1826,
            "logprob": -0.0085,
            "prob": 0.9922
          },
          {
            "token": "Ġêtes",
            "token_id": 62299,
            "logprob": -6.4375,
            "prob": 0.0016
          },
          {
            "token": "'est",
            "token_id": 17771,
            "logprob": -6.4375,
            "prob": 0.0016
          },
          {
            "token": "Ġsont",
            "token_id": 15132,
            "logprob": -6.625,
            "prob": 0.0013
          },
          {
            "token": "Ġque",
            "token_id": 1744,
            "logprob": -7.125,
            "prob": 0.0008
          },
          {
            "token": "Ġes",
            "token_id": 1560,
            "logprob": -7.4375,
            "prob": 0.0006
          },
          {
            "token": "ĠEst",
            "token_id": 9589,
            "logprob": -8.5,
            "prob": 0.0002
          },
          {
            "token": "Ġestimate",
            "token_id": 16430,
            "logprob": -8.6875,
            "prob": 0.0002
          },
          {
            "token": "Est",
            "token_id": 14101,
            "logprob": -9.5,
            "prob": 0.0001
          },
          {
            "token": "Ġqui",
            "token_id": 7930,
            "logprob": -9.625,
            "prob": 0.0001
          }
        ]
      },
      "selected_token": {
        "token": "Ġêtes",
        "token_id": 62299,
        "selection_method": "sampling"
      }
    }
  ]
}