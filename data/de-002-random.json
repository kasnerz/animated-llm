{
  "id": "generated_20251113_155629",
  "prompt": "Wer bist du?",
  "language": "de",
  "temperature": 5.0,
  "top_k": 10,
  "model_info": {
    "name": "CohereLabs/aya-expanse-8b",
    "num_layers": 32,
    "hidden_size": 4096,
    "num_attention_heads": 32,
    "vocab_size": 256000
  },
  "generation_steps": [
    {
      "step": 0,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>"
      ],
      "token_ids": [5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ich",
            "token_id": 75903,
            "logprob": -0.0,
            "prob": 1.0
          },
          {
            "token": "ĠIch",
            "token_id": 31246,
            "logprob": -13.375,
            "prob": 0.0
          },
          {
            "token": "Ik",
            "token_id": 78185,
            "logprob": -16.0,
            "prob": 0.0
          },
          {
            "token": "ich",
            "token_id": 1972,
            "logprob": -17.0156,
            "prob": 0.0
          },
          {
            "token": "<SEP>",
            "token_id": 3,
            "logprob": -35.1875,
            "prob": 0.0
          },
          {
            "token": "<CLS>",
            "token_id": 2,
            "logprob": -35.1562,
            "prob": 0.0
          },
          {
            "token": "<MASK_TOKEN>",
            "token_id": 4,
            "logprob": -35.5312,
            "prob": 0.0
          },
          {
            "token": "<BOS_TOKEN>",
            "token_id": 5,
            "logprob": -36.125,
            "prob": 0.0
          },
          {
            "token": "<PAD>",
            "token_id": 0,
            "logprob": -35.625,
            "prob": 0.0
          },
          {
            "token": "<UNK>",
            "token_id": 1,
            "logprob": -35.6875,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ich",
        "token_id": 75903,
        "selection_method": "sampling"
      }
    },
    {
      "step": 1,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich"
      ],
      "token_ids": [5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġbin",
            "token_id": 13935,
            "logprob": -0.0,
            "prob": 1.0
          },
          {
            "token": "Ġbist",
            "token_id": 193517,
            "logprob": -15.7812,
            "prob": 0.0
          },
          {
            "token": "<PAD>",
            "token_id": 0,
            "logprob": -36.875,
            "prob": 0.0
          },
          {
            "token": "<UNK>",
            "token_id": 1,
            "logprob": -37.1875,
            "prob": 0.0
          },
          {
            "token": "<EOS_TOKEN>",
            "token_id": 6,
            "logprob": -34.1875,
            "prob": 0.0
          },
          {
            "token": "<EOP_TOKEN>",
            "token_id": 7,
            "logprob": -36.6875,
            "prob": 0.0
          },
          {
            "token": "<BOS_TOKEN>",
            "token_id": 5,
            "logprob": -30.3281,
            "prob": 0.0
          },
          {
            "token": "<MASK_TOKEN>",
            "token_id": 4,
            "logprob": -36.625,
            "prob": 0.0
          },
          {
            "token": "<CLS>",
            "token_id": 2,
            "logprob": -36.0312,
            "prob": 0.0
          },
          {
            "token": "<SEP>",
            "token_id": 3,
            "logprob": -36.0312,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġbin",
        "token_id": 13935,
        "selection_method": "sampling"
      }
    },
    {
      "step": 2,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġein",
            "token_id": 4001,
            "logprob": -0.0005,
            "prob": 0.9995
          },
          {
            "token": "ĠCoral",
            "token_id": 68285,
            "logprob": -7.75,
            "prob": 0.0004
          },
          {
            "token": "Ġeine",
            "token_id": 7147,
            "logprob": -9.5781,
            "prob": 0.0001
          },
          {
            "token": "ĠEcho",
            "token_id": 50830,
            "logprob": -11.4688,
            "prob": 0.0
          },
          {
            "token": "Ġeinen",
            "token_id": 13881,
            "logprob": -11.6406,
            "prob": 0.0
          },
          {
            "token": "Ġeen",
            "token_id": 3302,
            "logprob": -13.5078,
            "prob": 0.0
          },
          {
            "token": "ĠEin",
            "token_id": 10649,
            "logprob": -13.6875,
            "prob": 0.0
          },
          {
            "token": "ĠCoh",
            "token_id": 96213,
            "logprob": -14.0625,
            "prob": 0.0
          },
          {
            "token": "ĠSiri",
            "token_id": 116532,
            "logprob": -14.1094,
            "prob": 0.0
          },
          {
            "token": "ĠAssistant",
            "token_id": 25236,
            "logprob": -15.3438,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġein",
        "token_id": 4001,
        "selection_method": "sampling"
      }
    },
    {
      "step": 3,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġk",
            "token_id": 1815,
            "logprob": -0.5225,
            "prob": 0.5928
          },
          {
            "token": "ĠLarge",
            "token_id": 40433,
            "logprob": -1.0693,
            "prob": 0.3433
          },
          {
            "token": "Ġgroß",
            "token_id": 74912,
            "logprob": -3.7422,
            "prob": 0.0237
          },
          {
            "token": "Ġvirt",
            "token_id": 8098,
            "logprob": -4.0547,
            "prob": 0.0173
          },
          {
            "token": "Ġgroßes",
            "token_id": 189308,
            "logprob": -4.8672,
            "prob": 0.0077
          },
          {
            "token": "Ġvirtu",
            "token_id": 151628,
            "logprob": -5.6641,
            "prob": 0.0035
          },
          {
            "token": "ĠKünst",
            "token_id": 119776,
            "logprob": -5.6953,
            "prob": 0.0034
          },
          {
            "token": "ĠKI",
            "token_id": 202056,
            "logprob": -5.9766,
            "prob": 0.0025
          },
          {
            "token": "Ġgroßer",
            "token_id": 125355,
            "logprob": -6.7656,
            "prob": 0.0012
          },
          {
            "token": "Ġkunst",
            "token_id": 36186,
            "logprob": -7.2891,
            "prob": 0.0007
          }
        ]
      },
      "selected_token": {
        "token": "Ġvirtu",
        "token_id": 151628,
        "selection_method": "sampling"
      }
    },
    {
      "step": 4,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtu",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "eller",
            "token_id": 8901,
            "logprob": -0.0,
            "prob": 1.0
          },
          {
            "token": "ellen",
            "token_id": 13580,
            "logprob": -11.3594,
            "prob": 0.0
          },
          {
            "token": "elles",
            "token_id": 8065,
            "logprob": -11.8125,
            "prob": 0.0
          },
          {
            "token": "ell",
            "token_id": 1947,
            "logprob": -14.6562,
            "prob": 0.0
          },
          {
            "token": "eler",
            "token_id": 7474,
            "logprob": -17.3281,
            "prob": 0.0
          },
          {
            "token": "<SEP>",
            "token_id": 3,
            "logprob": -35.4375,
            "prob": 0.0
          },
          {
            "token": "<MASK_TOKEN>",
            "token_id": 4,
            "logprob": -36.375,
            "prob": 0.0
          },
          {
            "token": "<CLS>",
            "token_id": 2,
            "logprob": -35.6562,
            "prob": 0.0
          },
          {
            "token": "<PAD>",
            "token_id": 0,
            "logprob": -36.4688,
            "prob": 0.0
          },
          {
            "token": "<UNK>",
            "token_id": 1,
            "logprob": -35.5625,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "ell",
        "token_id": 1947,
        "selection_method": "sampling"
      }
    },
    {
      "step": 5,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġassist",
            "token_id": 6385,
            "logprob": -0.8511,
            "prob": 0.427
          },
          {
            "token": "Ġintellig",
            "token_id": 34008,
            "logprob": -1.3818,
            "prob": 0.251
          },
          {
            "token": "ĠAssist",
            "token_id": 74008,
            "logprob": -2.3281,
            "prob": 0.0975
          },
          {
            "token": "ĠAssistent",
            "token_id": 183897,
            "logprob": -3.3047,
            "prob": 0.0367
          },
          {
            "token": "er",
            "token_id": 1669,
            "logprob": -3.3281,
            "prob": 0.0359
          },
          {
            "token": "Ġunterst",
            "token_id": 84264,
            "logprob": -3.4766,
            "prob": 0.0309
          },
          {
            "token": "assist",
            "token_id": 109293,
            "logprob": -3.7031,
            "prob": 0.0247
          },
          {
            "token": "Ġassistant",
            "token_id": 17091,
            "logprob": -3.9062,
            "prob": 0.0201
          },
          {
            "token": "-",
            "token_id": 20,
            "logprob": -4.9531,
            "prob": 0.0071
          },
          {
            "token": "Ġasist",
            "token_id": 31511,
            "logprob": -5.3984,
            "prob": 0.0045
          }
        ]
      },
      "selected_token": {
        "token": "Ġintellig",
        "token_id": 34008,
        "selection_method": "sampling"
      }
    },
    {
      "step": 6,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intellig",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "enter",
            "token_id": 12178,
            "logprob": -0.0251,
            "prob": 0.9751
          },
          {
            "token": "entes",
            "token_id": 5628,
            "logprob": -3.6973,
            "prob": 0.0248
          },
          {
            "token": "enten",
            "token_id": 35119,
            "logprob": -10.2422,
            "prob": 0.0
          },
          {
            "token": "ente",
            "token_id": 2416,
            "logprob": -12.8203,
            "prob": 0.0
          },
          {
            "token": "ents",
            "token_id": 2230,
            "logprob": -13.5234,
            "prob": 0.0
          },
          {
            "token": "Ġenter",
            "token_id": 7089,
            "logprob": -15.0078,
            "prob": 0.0
          },
          {
            "token": "eter",
            "token_id": 3381,
            "logprob": -15.2422,
            "prob": 0.0
          },
          {
            "token": "anter",
            "token_id": 20419,
            "logprob": -15.4922,
            "prob": 0.0
          },
          {
            "token": "ENTER",
            "token_id": 67166,
            "logprob": -16.0781,
            "prob": 0.0
          },
          {
            "token": "neter",
            "token_id": 91360,
            "logprob": -16.1406,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "enter",
        "token_id": 12178,
        "selection_method": "sampling"
      }
    },
    {
      "step": 7,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "ĠAssistent",
            "token_id": 183897,
            "logprob": -0.0087,
            "prob": 0.9912
          },
          {
            "token": "ĠAssist",
            "token_id": 74008,
            "logprob": -5.1797,
            "prob": 0.0056
          },
          {
            "token": "ĠAssistant",
            "token_id": 25236,
            "logprob": -6.4609,
            "prob": 0.0016
          },
          {
            "token": "ĠAss",
            "token_id": 3880,
            "logprob": -6.7891,
            "prob": 0.0011
          },
          {
            "token": "ĠChat",
            "token_id": 41573,
            "logprob": -9.8047,
            "prob": 0.0001
          },
          {
            "token": "ĠHel",
            "token_id": 9127,
            "logprob": -10.0625,
            "prob": 0.0
          },
          {
            "token": "Ass",
            "token_id": 6782,
            "logprob": -10.0703,
            "prob": 0.0
          },
          {
            "token": "ĠSprach",
            "token_id": 100809,
            "logprob": -10.1875,
            "prob": 0.0
          },
          {
            "token": "assistent",
            "token_id": 248546,
            "logprob": -10.4844,
            "prob": 0.0
          },
          {
            "token": "Ġasistent",
            "token_id": 141183,
            "logprob": -10.8828,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "ĠAssistant",
        "token_id": 25236,
        "selection_method": "sampling"
      }
    },
    {
      "step": 8,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": ",",
            "token_id": 19,
            "logprob": -0.005,
            "prob": 0.9951
          },
          {
            "token": "Ġoder",
            "token_id": 13624,
            "logprob": -5.6133,
            "prob": 0.0036
          },
          {
            "token": "Ġ(",
            "token_id": 1737,
            "logprob": -6.707,
            "prob": 0.0012
          },
          {
            "token": ".",
            "token_id": 21,
            "logprob": -9.1797,
            "prob": 0.0001
          },
          {
            "token": "Ġund",
            "token_id": 2280,
            "logprob": -11.1641,
            "prob": 0.0
          },
          {
            "token": "Ġnamens",
            "token_id": 104157,
            "logprob": -11.3672,
            "prob": 0.0
          },
          {
            "token": "Ġmit",
            "token_id": 4665,
            "logprob": -12.9844,
            "prob": 0.0
          },
          {
            "token": "Ġbas",
            "token_id": 4336,
            "logprob": -13.3906,
            "prob": 0.0
          },
          {
            "token": "-",
            "token_id": 20,
            "logprob": -13.9219,
            "prob": 0.0
          },
          {
            "token": "Ġauf",
            "token_id": 5709,
            "logprob": -14.1094,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġoder",
        "token_id": 13624,
        "selection_method": "sampling"
      }
    },
    {
      "step": 9,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "ĠChat",
            "token_id": 41573,
            "logprob": -0.0122,
            "prob": 0.9878
          },
          {
            "token": "Ġein",
            "token_id": 4001,
            "logprob": -4.668,
            "prob": 0.0094
          },
          {
            "token": ",",
            "token_id": 19,
            "logprob": -6.9492,
            "prob": 0.001
          },
          {
            "token": "Ġeine",
            "token_id": 7147,
            "logprob": -7.3555,
            "prob": 0.0006
          },
          {
            "token": "Chat",
            "token_id": 38327,
            "logprob": -7.8008,
            "prob": 0.0004
          },
          {
            "token": "Ġchatbot",
            "token_id": 171597,
            "logprob": -8.5547,
            "prob": 0.0002
          },
          {
            "token": "Ġauch",
            "token_id": 9216,
            "logprob": -9.2734,
            "prob": 0.0001
          },
          {
            "token": "Ġeinfach",
            "token_id": 163247,
            "logprob": -9.3281,
            "prob": 0.0001
          },
          {
            "token": "ĠKI",
            "token_id": 202056,
            "logprob": -9.3984,
            "prob": 0.0001
          },
          {
            "token": "Ġchat",
            "token_id": 19816,
            "logprob": -9.9062,
            "prob": 0.0001
          }
        ]
      },
      "selected_token": {
        "token": ",",
        "token_id": 19,
        "selection_method": "sampling"
      }
    },
    {
      "step": 10,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder,",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ","
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġwie",
            "token_id": 9214,
            "logprob": -0.0518,
            "prob": 0.9497
          },
          {
            "token": "Ġeinfach",
            "token_id": 163247,
            "logprob": -3.6465,
            "prob": 0.0261
          },
          {
            "token": "Ġin",
            "token_id": 1709,
            "logprob": -5.3477,
            "prob": 0.0048
          },
          {
            "token": "Ġeinf",
            "token_id": 121384,
            "logprob": -5.3945,
            "prob": 0.0045
          },
          {
            "token": "Ġum",
            "token_id": 2369,
            "logprob": -5.3945,
            "prob": 0.0045
          },
          {
            "token": "Ġkurz",
            "token_id": 59652,
            "logprob": -5.457,
            "prob": 0.0043
          },
          {
            "token": "Ġauf",
            "token_id": 5709,
            "logprob": -5.9258,
            "prob": 0.0027
          },
          {
            "token": "Ġkür",
            "token_id": 160250,
            "logprob": -6.5742,
            "prob": 0.0014
          },
          {
            "token": "Ġanders",
            "token_id": 94022,
            "logprob": -7.6523,
            "prob": 0.0005
          },
          {
            "token": "Ġvere",
            "token_id": 48237,
            "logprob": -7.8086,
            "prob": 0.0004
          }
        ]
      },
      "selected_token": {
        "token": "Ġkurz",
        "token_id": 59652,
        "selection_method": "sampling"
      }
    },
    {
      "step": 11,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġges",
            "token_id": 13183,
            "logprob": -0.3267,
            "prob": 0.7212
          },
          {
            "token": ",",
            "token_id": 19,
            "logprob": -1.3105,
            "prob": 0.2695
          },
          {
            "token": "Ġund",
            "token_id": 2280,
            "logprob": -5.3047,
            "prob": 0.005
          },
          {
            "token": "ges",
            "token_id": 5325,
            "logprob": -6.2656,
            "prob": 0.0019
          },
          {
            "token": "Ġgef",
            "token_id": 29123,
            "logprob": -7.3125,
            "prob": 0.0007
          },
          {
            "token": "ge",
            "token_id": 2035,
            "logprob": -8.125,
            "prob": 0.0003
          },
          {
            "token": "Ġzusammenge",
            "token_id": 210804,
            "logprob": -9.1797,
            "prob": 0.0001
          },
          {
            "token": "Ġvere",
            "token_id": 48237,
            "logprob": -9.5703,
            "prob": 0.0001
          },
          {
            "token": "Ġbeschrieben",
            "token_id": 130631,
            "logprob": -9.7344,
            "prob": 0.0001
          },
          {
            "token": "Ġgenannt",
            "token_id": 48268,
            "logprob": -10.0078,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġbeschrieben",
        "token_id": 130631,
        "selection_method": "sampling"
      }
    },
    {
      "step": 12,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": ",",
            "token_id": 19,
            "logprob": -0.0,
            "prob": 1.0
          },
          {
            "token": ":",
            "token_id": 33,
            "logprob": -15.7344,
            "prob": 0.0
          },
          {
            "token": "Ġein",
            "token_id": 4001,
            "logprob": -16.4062,
            "prob": 0.0
          },
          {
            "token": "Ġals",
            "token_id": 4561,
            "logprob": -16.7812,
            "prob": 0.0
          },
          {
            "token": "<SEP>",
            "token_id": 3,
            "logprob": -35.6562,
            "prob": 0.0
          },
          {
            "token": "<CLS>",
            "token_id": 2,
            "logprob": -35.4062,
            "prob": 0.0
          },
          {
            "token": "<MASK_TOKEN>",
            "token_id": 4,
            "logprob": -35.6562,
            "prob": 0.0
          },
          {
            "token": "<BOS_TOKEN>",
            "token_id": 5,
            "logprob": -36.1562,
            "prob": 0.0
          },
          {
            "token": "<PAD>",
            "token_id": 0,
            "logprob": -35.4688,
            "prob": 0.0
          },
          {
            "token": "<UNK>",
            "token_id": 1,
            "logprob": -35.8125,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": ",",
        "token_id": 19,
        "selection_method": "sampling"
      }
    },
    {
      "step": 13,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben,",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ","
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġein",
            "token_id": 4001,
            "logprob": -0.0018,
            "prob": 0.998
          },
          {
            "token": "Ġeine",
            "token_id": 7147,
            "logprob": -6.3438,
            "prob": 0.0018
          },
          {
            "token": "ĠChat",
            "token_id": 41573,
            "logprob": -13.0469,
            "prob": 0.0
          },
          {
            "token": "Ġeinen",
            "token_id": 13881,
            "logprob": -13.0938,
            "prob": 0.0
          },
          {
            "token": "Ġeen",
            "token_id": 3302,
            "logprob": -14.6094,
            "prob": 0.0
          },
          {
            "token": "ĠKI",
            "token_id": 202056,
            "logprob": -15.2734,
            "prob": 0.0
          },
          {
            "token": "Ġeiner",
            "token_id": 10295,
            "logprob": -17.0938,
            "prob": 0.0
          },
          {
            "token": "Ġk",
            "token_id": 1815,
            "logprob": -17.2969,
            "prob": 0.0
          },
          {
            "token": "ein",
            "token_id": 100848,
            "logprob": -16.2812,
            "prob": 0.0
          },
          {
            "token": "<PAD>",
            "token_id": 0,
            "logprob": -31.875,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġein",
        "token_id": 4001,
        "selection_method": "sampling"
      }
    },
    {
      "step": 14,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "ĠChat",
            "token_id": 41573,
            "logprob": -0.0159,
            "prob": 0.9844
          },
          {
            "token": "ĠKI",
            "token_id": 202056,
            "logprob": -4.2188,
            "prob": 0.0147
          },
          {
            "token": "ĠAI",
            "token_id": 21024,
            "logprob": -7.3281,
            "prob": 0.0007
          },
          {
            "token": "Ġchatbot",
            "token_id": 171597,
            "logprob": -8.7188,
            "prob": 0.0002
          },
          {
            "token": "Chat",
            "token_id": 38327,
            "logprob": -9.1562,
            "prob": 0.0001
          },
          {
            "token": "ĠSprach",
            "token_id": 100809,
            "logprob": -10.4766,
            "prob": 0.0
          },
          {
            "token": "Ġchat",
            "token_id": 19816,
            "logprob": -10.75,
            "prob": 0.0
          },
          {
            "token": "ĠLarge",
            "token_id": 40433,
            "logprob": -10.9375,
            "prob": 0.0
          },
          {
            "token": "Ġdigital",
            "token_id": 7986,
            "logprob": -12.4297,
            "prob": 0.0
          },
          {
            "token": "聊",
            "token_id": 142402,
            "logprob": -12.6328,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "ĠChat",
        "token_id": 41573,
        "selection_method": "sampling"
      }
    },
    {
      "step": 15,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chat",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "bot",
            "token_id": 10278,
            "logprob": -0.0,
            "prob": 1.0
          },
          {
            "token": "bots",
            "token_id": 108333,
            "logprob": -11.0312,
            "prob": 0.0
          },
          {
            "token": "-",
            "token_id": 20,
            "logprob": -12.6562,
            "prob": 0.0
          },
          {
            "token": "Bot",
            "token_id": 34691,
            "logprob": -15.0156,
            "prob": 0.0
          },
          {
            "token": "бот",
            "token_id": 6827,
            "logprob": -15.4531,
            "prob": 0.0
          },
          {
            "token": "boten",
            "token_id": 98466,
            "logprob": -17.0312,
            "prob": 0.0
          },
          {
            "token": "bott",
            "token_id": 109931,
            "logprob": -16.3125,
            "prob": 0.0
          },
          {
            "token": "BOT",
            "token_id": 69683,
            "logprob": -16.9531,
            "prob": 0.0
          },
          {
            "token": "boot",
            "token_id": 19129,
            "logprob": -16.5625,
            "prob": 0.0
          },
          {
            "token": "robot",
            "token_id": 58568,
            "logprob": -16.875,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "bot",
        "token_id": 10278,
        "selection_method": "sampling"
      }
    },
    {
      "step": 16,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": ".",
            "token_id": 21,
            "logprob": -0.0019,
            "prob": 0.998
          },
          {
            "token": ",",
            "token_id": 19,
            "logprob": -6.2812,
            "prob": 0.0019
          },
          {
            "token": "Ġnamens",
            "token_id": 104157,
            "logprob": -10.3281,
            "prob": 0.0
          },
          {
            "token": "-",
            "token_id": 20,
            "logprob": -11.9844,
            "prob": 0.0
          },
          {
            "token": "Ġbas",
            "token_id": 4336,
            "logprob": -12.0859,
            "prob": 0.0
          },
          {
            "token": "Ġmit",
            "token_id": 4665,
            "logprob": -12.4141,
            "prob": 0.0
          },
          {
            "token": "Ġentwickelt",
            "token_id": 105064,
            "logprob": -13.1016,
            "prob": 0.0
          },
          {
            "token": "!",
            "token_id": 8,
            "logprob": -13.4453,
            "prob": 0.0
          },
          {
            "token": "Ġim",
            "token_id": 2101,
            "logprob": -13.5703,
            "prob": 0.0
          },
          {
            "token": "Ġ(",
            "token_id": 1737,
            "logprob": -14.8047,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "-",
        "token_id": 20,
        "selection_method": "sampling"
      }
    },
    {
      "step": 17,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ass",
            "token_id": 6782,
            "logprob": -0.0207,
            "prob": 0.9795
          },
          {
            "token": "System",
            "token_id": 8808,
            "logprob": -3.9434,
            "prob": 0.0194
          },
          {
            "token": "Assist",
            "token_id": 143031,
            "logprob": -7.0977,
            "prob": 0.0008
          },
          {
            "token": "bas",
            "token_id": 10690,
            "logprob": -9.4297,
            "prob": 0.0001
          },
          {
            "token": "Hil",
            "token_id": 85637,
            "logprob": -11.3906,
            "prob": 0.0
          },
          {
            "token": "Programm",
            "token_id": 239466,
            "logprob": -11.6172,
            "prob": 0.0
          },
          {
            "token": "ĠAssistent",
            "token_id": 183897,
            "logprob": -11.6562,
            "prob": 0.0
          },
          {
            "token": "Assistant",
            "token_id": 107048,
            "logprob": -11.6719,
            "prob": 0.0
          },
          {
            "token": "assist",
            "token_id": 109293,
            "logprob": -11.7344,
            "prob": 0.0
          },
          {
            "token": "ĠAssist",
            "token_id": 74008,
            "logprob": -11.9141,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "System",
        "token_id": 8808,
        "selection_method": "sampling"
      }
    },
    {
      "step": 18,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": ".",
            "token_id": 21,
            "logprob": -0.088,
            "prob": 0.916
          },
          {
            "token": ",",
            "token_id": 19,
            "logprob": -2.4941,
            "prob": 0.0826
          },
          {
            "token": "Ġbas",
            "token_id": 4336,
            "logprob": -6.7773,
            "prob": 0.0011
          },
          {
            "token": "Ġnamens",
            "token_id": 104157,
            "logprob": -7.918,
            "prob": 0.0004
          },
          {
            "token": "Ġmit",
            "token_id": 4665,
            "logprob": -9.7188,
            "prob": 0.0001
          },
          {
            "token": "Ġbasiert",
            "token_id": 220160,
            "logprob": -10.9922,
            "prob": 0.0
          },
          {
            "token": "Ġentwickelt",
            "token_id": 105064,
            "logprob": -11.0703,
            "prob": 0.0
          },
          {
            "token": "Ġauf",
            "token_id": 5709,
            "logprob": -11.6328,
            "prob": 0.0
          },
          {
            "token": "Ġgenannt",
            "token_id": 48268,
            "logprob": -13.3672,
            "prob": 0.0
          },
          {
            "token": "!",
            "token_id": 8,
            "logprob": -13.4375,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": ".",
        "token_id": 21,
        "selection_method": "sampling"
      }
    },
    {
      "step": 19,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System.",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        "."
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "ĠIch",
            "token_id": 31246,
            "logprob": -0.0016,
            "prob": 0.9985
          },
          {
            "token": "ĠEntwick",
            "token_id": 136412,
            "logprob": -6.4844,
            "prob": 0.0015
          },
          {
            "token": "ĠEnt",
            "token_id": 8731,
            "logprob": -10.6562,
            "prob": 0.0
          },
          {
            "token": "ĠMein",
            "token_id": 63249,
            "logprob": -11.6953,
            "prob": 0.0
          },
          {
            "token": "Ich",
            "token_id": 75903,
            "logprob": -12.0547,
            "prob": 0.0
          },
          {
            "token": "ĠMeine",
            "token_id": 180612,
            "logprob": -12.0859,
            "prob": 0.0
          },
          {
            "token": "ĠMir",
            "token_id": 9819,
            "logprob": -12.2578,
            "prob": 0.0
          },
          {
            "token": "ĠEntwicklung",
            "token_id": 58645,
            "logprob": -12.4141,
            "prob": 0.0
          },
          {
            "token": "ĠBen",
            "token_id": 5736,
            "logprob": -12.6797,
            "prob": 0.0
          },
          {
            "token": "ĠMich",
            "token_id": 5073,
            "logprob": -13.0469,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "ĠIch",
        "token_id": 31246,
        "selection_method": "sampling"
      }
    },
    {
      "step": 20,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġwurde",
            "token_id": 6149,
            "logprob": -0.0535,
            "prob": 0.9478
          },
          {
            "token": "Ġbin",
            "token_id": 13935,
            "logprob": -2.9746,
            "prob": 0.051
          },
          {
            "token": "Ġhabe",
            "token_id": 61737,
            "logprob": -7.9609,
            "prob": 0.0003
          },
          {
            "token": "Ġwerde",
            "token_id": 152398,
            "logprob": -8.3516,
            "prob": 0.0002
          },
          {
            "token": "Ġwurden",
            "token_id": 14935,
            "logprob": -8.7891,
            "prob": 0.0002
          },
          {
            "token": "Ġarbe",
            "token_id": 82344,
            "logprob": -9.5625,
            "prob": 0.0001
          },
          {
            "token": "Ġwar",
            "token_id": 4341,
            "logprob": -9.5859,
            "prob": 0.0001
          },
          {
            "token": "Ġentwick",
            "token_id": 52336,
            "logprob": -10.2422,
            "prob": 0.0
          },
          {
            "token": "Ġwur",
            "token_id": 5352,
            "logprob": -10.5391,
            "prob": 0.0
          },
          {
            "token": "Ġben",
            "token_id": 4747,
            "logprob": -10.8281,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġwar",
        "token_id": 4341,
        "selection_method": "sampling"
      }
    },
    {
      "step": 21,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġein",
            "token_id": 4001,
            "logprob": -1.4082,
            "prob": 0.2445
          },
          {
            "token": "Ġfrüher",
            "token_id": 77871,
            "logprob": -1.6582,
            "prob": 0.1904
          },
          {
            "token": "Ġzuvor",
            "token_id": 81901,
            "logprob": -1.752,
            "prob": 0.1733
          },
          {
            "token": "Ġursprünglich",
            "token_id": 92254,
            "logprob": -2.3535,
            "prob": 0.095
          },
          {
            "token": "te",
            "token_id": 1822,
            "logprob": -2.5723,
            "prob": 0.0764
          },
          {
            "token": "ĠTeil",
            "token_id": 22815,
            "logprob": -2.7129,
            "prob": 0.0663
          },
          {
            "token": "Ġvorher",
            "token_id": 135469,
            "logprob": -2.9551,
            "prob": 0.0521
          },
          {
            "token": "Ġeine",
            "token_id": 7147,
            "logprob": -3.5098,
            "prob": 0.0299
          },
          {
            "token": "Ġeinst",
            "token_id": 132618,
            "logprob": -4.0586,
            "prob": 0.0173
          },
          {
            "token": "ne",
            "token_id": 1950,
            "logprob": -5.2383,
            "prob": 0.0053
          }
        ]
      },
      "selected_token": {
        "token": "Ġzuvor",
        "token_id": 81901,
        "selection_method": "sampling"
      }
    },
    {
      "step": 22,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġbekannt",
            "token_id": 39923,
            "logprob": -0.5679,
            "prob": 0.5664
          },
          {
            "token": "Ġals",
            "token_id": 4561,
            "logprob": -1.2402,
            "prob": 0.2893
          },
          {
            "token": "Ġein",
            "token_id": 4001,
            "logprob": -1.959,
            "prob": 0.141
          },
          {
            "token": "ĠTeil",
            "token_id": 22815,
            "logprob": -6.1289,
            "prob": 0.0022
          },
          {
            "token": "Ġeine",
            "token_id": 7147,
            "logprob": -8.5312,
            "prob": 0.0002
          },
          {
            "token": "Ġauf",
            "token_id": 5709,
            "logprob": -8.9219,
            "prob": 0.0001
          },
          {
            "token": "Ġdarauf",
            "token_id": 52159,
            "logprob": -9.125,
            "prob": 0.0001
          },
          {
            "token": "Ġvon",
            "token_id": 3615,
            "logprob": -9.9297,
            "prob": 0.0
          },
          {
            "token": "Ġdas",
            "token_id": 4031,
            "logprob": -10.3672,
            "prob": 0.0
          },
          {
            "token": "Ġdafür",
            "token_id": 92145,
            "logprob": -10.6016,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġein",
        "token_id": 4001,
        "selection_method": "sampling"
      }
    },
    {
      "step": 23,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "ĠTeil",
            "token_id": 22815,
            "logprob": -0.0457,
            "prob": 0.9551
          },
          {
            "token": "Ġmensch",
            "token_id": 146395,
            "logprob": -4.2344,
            "prob": 0.0145
          },
          {
            "token": "ĠLarge",
            "token_id": 40433,
            "logprob": -4.8281,
            "prob": 0.008
          },
          {
            "token": "Ġgroßes",
            "token_id": 189308,
            "logprob": -4.9531,
            "prob": 0.0071
          },
          {
            "token": "ĠProdukt",
            "token_id": 186916,
            "logprob": -6.2422,
            "prob": 0.0019
          },
          {
            "token": "ĠSprach",
            "token_id": 100809,
            "logprob": -6.5938,
            "prob": 0.0014
          },
          {
            "token": "Ġgroßer",
            "token_id": 125355,
            "logprob": -6.8047,
            "prob": 0.0011
          },
          {
            "token": "Ġfor",
            "token_id": 1794,
            "logprob": -7.0781,
            "prob": 0.0008
          },
          {
            "token": "ĠProgramm",
            "token_id": 110145,
            "logprob": -7.1016,
            "prob": 0.0008
          },
          {
            "token": "Ġvon",
            "token_id": 3615,
            "logprob": -7.1094,
            "prob": 0.0008
          }
        ]
      },
      "selected_token": {
        "token": "ĠTeil",
        "token_id": 22815,
        "selection_method": "sampling"
      }
    },
    {
      "step": 24,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġder",
            "token_id": 2479,
            "logprob": -0.9541,
            "prob": 0.3853
          },
          {
            "token": "Ġeines",
            "token_id": 20792,
            "logprob": -0.9697,
            "prob": 0.3792
          },
          {
            "token": "Ġvon",
            "token_id": 3615,
            "logprob": -2.0,
            "prob": 0.1353
          },
          {
            "token": "Ġdes",
            "token_id": 2003,
            "logprob": -2.6875,
            "prob": 0.068
          },
          {
            "token": "Ġeiner",
            "token_id": 10295,
            "logprob": -3.4375,
            "prob": 0.0321
          },
          {
            "token": "Ġvom",
            "token_id": 15310,
            "logprob": -9.0,
            "prob": 0.0001
          },
          {
            "token": "Ġverschiedener",
            "token_id": 182058,
            "logprob": -12.5859,
            "prob": 0.0
          },
          {
            "token": "Ġενός",
            "token_id": 40624,
            "logprob": -12.6719,
            "prob": 0.0
          },
          {
            "token": "-",
            "token_id": 20,
            "logprob": -13.1016,
            "prob": 0.0
          },
          {
            "token": "Ġeinem",
            "token_id": 12315,
            "logprob": -13.1562,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġeines",
        "token_id": 20792,
        "selection_method": "sampling"
      }
    },
    {
      "step": 25,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġgroßen",
            "token_id": 56707,
            "logprob": -0.7207,
            "prob": 0.4863
          },
          {
            "token": "ĠForschung",
            "token_id": 80182,
            "logprob": -1.4551,
            "prob": 0.2334
          },
          {
            "token": "Ġgrößeren",
            "token_id": 142081,
            "logprob": -2.2051,
            "prob": 0.1102
          },
          {
            "token": "ĠProjek",
            "token_id": 197942,
            "logprob": -2.3457,
            "prob": 0.0958
          },
          {
            "token": "Ġvon",
            "token_id": 3615,
            "logprob": -3.127,
            "prob": 0.0439
          },
          {
            "token": "Ġgroß",
            "token_id": 74912,
            "logprob": -5.6523,
            "prob": 0.0035
          },
          {
            "token": "ĠProgram",
            "token_id": 10662,
            "logprob": -5.7461,
            "prob": 0.0032
          },
          {
            "token": "Ġfor",
            "token_id": 1794,
            "logprob": -5.793,
            "prob": 0.0031
          },
          {
            "token": "ĠLarge",
            "token_id": 40433,
            "logprob": -6.1367,
            "prob": 0.0022
          },
          {
            "token": "Ġk",
            "token_id": 1815,
            "logprob": -6.3555,
            "prob": 0.0017
          }
        ]
      },
      "selected_token": {
        "token": "Ġgrößeren",
        "token_id": 142081,
        "selection_method": "sampling"
      }
    },
    {
      "step": 26,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "ĠSprach",
            "token_id": 100809,
            "logprob": -0.0649,
            "prob": 0.937
          },
          {
            "token": "ĠProjek",
            "token_id": 197942,
            "logprob": -3.4082,
            "prob": 0.0331
          },
          {
            "token": "ĠProgram",
            "token_id": 10662,
            "logprob": -3.9863,
            "prob": 0.0186
          },
          {
            "token": "ĠKI",
            "token_id": 202056,
            "logprob": -5.6133,
            "prob": 0.0037
          },
          {
            "token": "Ġsprach",
            "token_id": 156708,
            "logprob": -6.6602,
            "prob": 0.0013
          },
          {
            "token": "ĠComputer",
            "token_id": 26053,
            "logprob": -7.0508,
            "prob": 0.0009
          },
          {
            "token": "Ġlingu",
            "token_id": 22569,
            "logprob": -7.6367,
            "prob": 0.0005
          },
          {
            "token": "ĠSoftware",
            "token_id": 20423,
            "logprob": -7.793,
            "prob": 0.0004
          },
          {
            "token": "Ġk",
            "token_id": 1815,
            "logprob": -7.8477,
            "prob": 0.0004
          },
          {
            "token": "ĠKünst",
            "token_id": 119776,
            "logprob": -8.1797,
            "prob": 0.0003
          }
        ]
      },
      "selected_token": {
        "token": "Ġsprach",
        "token_id": 156708,
        "selection_method": "sampling"
      }
    },
    {
      "step": 27,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprach",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "bas",
            "token_id": 10690,
            "logprob": -0.3472,
            "prob": 0.7065
          },
          {
            "token": "ver",
            "token_id": 1901,
            "logprob": -1.2686,
            "prob": 0.281
          },
          {
            "token": "lichen",
            "token_id": 12921,
            "logprob": -5.0039,
            "prob": 0.0067
          },
          {
            "token": "bez",
            "token_id": 31930,
            "logprob": -5.8008,
            "prob": 0.003
          },
          {
            "token": "g",
            "token_id": 78,
            "logprob": -7.5195,
            "prob": 0.0005
          },
          {
            "token": "gest",
            "token_id": 10338,
            "logprob": -8.3984,
            "prob": 0.0002
          },
          {
            "token": "be",
            "token_id": 2901,
            "logprob": -8.5781,
            "prob": 0.0002
          },
          {
            "token": "wissenschaft",
            "token_id": 42174,
            "logprob": -8.5859,
            "prob": 0.0002
          },
          {
            "token": "bew",
            "token_id": 31758,
            "logprob": -8.7734,
            "prob": 0.0002
          },
          {
            "token": "techn",
            "token_id": 24335,
            "logprob": -9.0469,
            "prob": 0.0001
          }
        ]
      },
      "selected_token": {
        "token": "ver",
        "token_id": 1901,
        "selection_method": "sampling"
      }
    },
    {
      "step": 28,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachver",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "arbeit",
            "token_id": 41678,
            "logprob": -0.0007,
            "prob": 0.9995
          },
          {
            "token": "arbeitung",
            "token_id": 150113,
            "logprob": -7.4219,
            "prob": 0.0006
          },
          {
            "token": "arbeiten",
            "token_id": 108222,
            "logprob": -10.2031,
            "prob": 0.0
          },
          {
            "token": "arbe",
            "token_id": 66051,
            "logprob": -11.5781,
            "prob": 0.0
          },
          {
            "token": "werk",
            "token_id": 18226,
            "logprob": -12.5391,
            "prob": 0.0
          },
          {
            "token": "arbeitete",
            "token_id": 182848,
            "logprob": -12.8594,
            "prob": 0.0
          },
          {
            "token": "arbeitet",
            "token_id": 167500,
            "logprob": -13.0938,
            "prob": 0.0
          },
          {
            "token": "mittel",
            "token_id": 60346,
            "logprob": -13.4297,
            "prob": 0.0
          },
          {
            "token": "arbeiter",
            "token_id": 179053,
            "logprob": -13.5781,
            "prob": 0.0
          },
          {
            "token": "prac",
            "token_id": 30943,
            "logprob": -13.9609,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "arbeit",
        "token_id": 41678,
        "selection_method": "sampling"
      }
    },
    {
      "step": 29,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeit",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "enden",
            "token_id": 11404,
            "logprob": -0.0002,
            "prob": 1.0
          },
          {
            "token": "ungs",
            "token_id": 10484,
            "logprob": -8.7031,
            "prob": 0.0002
          },
          {
            "token": "eten",
            "token_id": 17762,
            "logprob": -12.3125,
            "prob": 0.0
          },
          {
            "token": "nden",
            "token_id": 50069,
            "logprob": -12.375,
            "prob": 0.0
          },
          {
            "token": "ender",
            "token_id": 3919,
            "logprob": -12.9844,
            "prob": 0.0
          },
          {
            "token": "baren",
            "token_id": 96010,
            "logprob": -13.0312,
            "prob": 0.0
          },
          {
            "token": "ende",
            "token_id": 5087,
            "logprob": -14.2344,
            "prob": 0.0
          },
          {
            "token": "endem",
            "token_id": 132564,
            "logprob": -14.6719,
            "prob": 0.0
          },
          {
            "token": "endes",
            "token_id": 55258,
            "logprob": -15.4219,
            "prob": 0.0
          },
          {
            "token": "ungsk",
            "token_id": 117606,
            "logprob": -15.7188,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "enden",
        "token_id": 11404,
        "selection_method": "sampling"
      }
    },
    {
      "step": 30,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "ĠMod",
            "token_id": 6037,
            "logprob": -0.0933,
            "prob": 0.9106
          },
          {
            "token": "ĠSystems",
            "token_id": 22610,
            "logprob": -3.25,
            "prob": 0.0388
          },
          {
            "token": "ĠKI",
            "token_id": 202056,
            "logprob": -3.8906,
            "prob": 0.0204
          },
          {
            "token": "ĠNetz",
            "token_id": 141254,
            "logprob": -4.3125,
            "prob": 0.0134
          },
          {
            "token": "ĠModell",
            "token_id": 106562,
            "logprob": -5.4062,
            "prob": 0.0045
          },
          {
            "token": "ĠProgram",
            "token_id": 10662,
            "logprob": -5.5938,
            "prob": 0.0037
          },
          {
            "token": "ĠComputer",
            "token_id": 26053,
            "logprob": -6.6016,
            "prob": 0.0014
          },
          {
            "token": "ĠModelle",
            "token_id": 225575,
            "logprob": -6.9844,
            "prob": 0.0009
          },
          {
            "token": "ĠProjek",
            "token_id": 197942,
            "logprob": -7.0156,
            "prob": 0.0009
          },
          {
            "token": "ĠKünst",
            "token_id": 119776,
            "logprob": -7.4844,
            "prob": 0.0006
          }
        ]
      },
      "selected_token": {
        "token": "ĠComputer",
        "token_id": 26053,
        "selection_method": "sampling"
      }
    },
    {
      "step": 31,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computer",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "program",
            "token_id": 23510,
            "logprob": -0.0079,
            "prob": 0.9922
          },
          {
            "token": "pro",
            "token_id": 2306,
            "logprob": -5.9297,
            "prob": 0.0027
          },
          {
            "token": "programm",
            "token_id": 154279,
            "logprob": -6.1641,
            "prob": 0.0021
          },
          {
            "token": "-",
            "token_id": 20,
            "logprob": -6.6484,
            "prob": 0.0013
          },
          {
            "token": "mod",
            "token_id": 3991,
            "logprob": -7.1953,
            "prob": 0.0008
          },
          {
            "token": "programma",
            "token_id": 87093,
            "logprob": -8.5156,
            "prob": 0.0002
          },
          {
            "token": "programs",
            "token_id": 174786,
            "logprob": -8.5547,
            "prob": 0.0002
          },
          {
            "token": "programme",
            "token_id": 241066,
            "logprob": -8.8516,
            "prob": 0.0001
          },
          {
            "token": "Program",
            "token_id": 18336,
            "logprob": -10.2656,
            "prob": 0.0
          },
          {
            "token": "techn",
            "token_id": 24335,
            "logprob": -10.3281,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "program",
        "token_id": 23510,
        "selection_method": "sampling"
      }
    },
    {
      "step": 32,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogram",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "ms",
            "token_id": 3549,
            "logprob": -0.0,
            "prob": 1.0
          },
          {
            "token": "mes",
            "token_id": 5533,
            "logprob": -10.2188,
            "prob": 0.0
          },
          {
            "token": "ns",
            "token_id": 8953,
            "logprob": -12.9062,
            "prob": 0.0
          },
          {
            "token": "mier",
            "token_id": 32477,
            "logprob": -13.0625,
            "prob": 0.0
          },
          {
            "token": "ems",
            "token_id": 4418,
            "logprob": -13.5938,
            "prob": 0.0
          },
          {
            "token": "mas",
            "token_id": 4966,
            "logprob": -14.1562,
            "prob": 0.0
          },
          {
            "token": "miers",
            "token_id": 177566,
            "logprob": -14.3594,
            "prob": 0.0
          },
          {
            "token": "ums",
            "token_id": 9249,
            "logprob": -14.6875,
            "prob": 0.0
          },
          {
            "token": "mens",
            "token_id": 125372,
            "logprob": -14.8438,
            "prob": 0.0
          },
          {
            "token": "ments",
            "token_id": 3442,
            "logprob": -14.9375,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "ms",
        "token_id": 3549,
        "selection_method": "sampling"
      }
    },
    {
      "step": 33,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": ",",
            "token_id": 19,
            "logprob": -0.0919,
            "prob": 0.9121
          },
          {
            "token": "Ġund",
            "token_id": 2280,
            "logprob": -2.5605,
            "prob": 0.0773
          },
          {
            "token": ".",
            "token_id": 21,
            "logprob": -4.7344,
            "prob": 0.0088
          },
          {
            "token": "Ġnamens",
            "token_id": 104157,
            "logprob": -6.5469,
            "prob": 0.0014
          },
          {
            "token": "Ġ(",
            "token_id": 1737,
            "logprob": -9.3047,
            "prob": 0.0001
          },
          {
            "token": "Ġmit",
            "token_id": 4665,
            "logprob": -9.6562,
            "prob": 0.0001
          },
          {
            "token": "Ġoder",
            "token_id": 13624,
            "logprob": -9.8516,
            "prob": 0.0001
          },
          {
            "token": "Ġvon",
            "token_id": 3615,
            "logprob": -11.2734,
            "prob": 0.0
          },
          {
            "token": "Ġentwickelt",
            "token_id": 105064,
            "logprob": -11.625,
            "prob": 0.0
          },
          {
            "token": "Ġgenannt",
            "token_id": 48268,
            "logprob": -11.8828,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġ(",
        "token_id": 1737,
        "selection_method": "sampling"
      }
    },
    {
      "step": 34,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ("
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Natural",
            "token_id": 59630,
            "logprob": -0.1154,
            "prob": 0.8911
          },
          {
            "token": "NLP",
            "token_id": 176213,
            "logprob": -2.7715,
            "prob": 0.0626
          },
          {
            "token": "auch",
            "token_id": 44051,
            "logprob": -4.4922,
            "prob": 0.0112
          },
          {
            "token": "Artificial",
            "token_id": 200677,
            "logprob": -4.5234,
            "prob": 0.0109
          },
          {
            "token": "Large",
            "token_id": 59573,
            "logprob": -5.4141,
            "prob": 0.0045
          },
          {
            "token": "AI",
            "token_id": 22602,
            "logprob": -5.4453,
            "prob": 0.0043
          },
          {
            "token": "LL",
            "token_id": 12509,
            "logprob": -5.9766,
            "prob": 0.0025
          },
          {
            "token": "KI",
            "token_id": 65308,
            "logprob": -6.75,
            "prob": 0.0012
          },
          {
            "token": "Language",
            "token_id": 25285,
            "logprob": -6.9062,
            "prob": 0.001
          },
          {
            "token": "ĠNatural",
            "token_id": 18515,
            "logprob": -6.9453,
            "prob": 0.001
          }
        ]
      },
      "selected_token": {
        "token": "NLP",
        "token_id": 176213,
        "selection_method": "sampling"
      }
    },
    {
      "step": 35,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "),",
            "token_id": 1969,
            "logprob": -0.6133,
            "prob": 0.5415
          },
          {
            "token": ")",
            "token_id": 16,
            "logprob": -0.9102,
            "prob": 0.4026
          },
          {
            "token": ").",
            "token_id": 2015,
            "logprob": -3.8633,
            "prob": 0.021
          },
          {
            "token": ",",
            "token_id": 19,
            "logprob": -4.2227,
            "prob": 0.0147
          },
          {
            "token": "Ġ-",
            "token_id": 1945,
            "logprob": -4.5977,
            "prob": 0.0101
          },
          {
            "token": "-",
            "token_id": 20,
            "logprob": -5.7852,
            "prob": 0.0031
          },
          {
            "token": "Ġfür",
            "token_id": 6081,
            "logprob": -6.1289,
            "prob": 0.0022
          },
          {
            "token": "Ġ–",
            "token_id": 2129,
            "logprob": -6.3945,
            "prob": 0.0017
          },
          {
            "token": "Ġoder",
            "token_id": 13624,
            "logprob": -6.5664,
            "prob": 0.0014
          },
          {
            "token": "Ġund",
            "token_id": 2280,
            "logprob": -7.457,
            "prob": 0.0006
          }
        ]
      },
      "selected_token": {
        "token": "),",
        "token_id": 1969,
        "selection_method": "sampling"
      }
    },
    {
      "step": 36,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP),",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġdas",
            "token_id": 4031,
            "logprob": -0.0056,
            "prob": 0.9941
          },
          {
            "token": "Ġentwickelt",
            "token_id": 105064,
            "logprob": -5.7227,
            "prob": 0.0033
          },
          {
            "token": "Ġwelches",
            "token_id": 99748,
            "logprob": -7.5039,
            "prob": 0.0005
          },
          {
            "token": "Ġund",
            "token_id": 2280,
            "logprob": -7.7227,
            "prob": 0.0004
          },
          {
            "token": "Ġspezi",
            "token_id": 160585,
            "logprob": -8.1016,
            "prob": 0.0003
          },
          {
            "token": "Ġaber",
            "token_id": 18641,
            "logprob": -8.4141,
            "prob": 0.0002
          },
          {
            "token": "Ġentw",
            "token_id": 109448,
            "logprob": -8.5781,
            "prob": 0.0002
          },
          {
            "token": "Ġdessen",
            "token_id": 38668,
            "logprob": -8.7109,
            "prob": 0.0002
          },
          {
            "token": "Ġjetzt",
            "token_id": 148408,
            "logprob": -9.1797,
            "prob": 0.0001
          },
          {
            "token": "Ġtrain",
            "token_id": 10747,
            "logprob": -10.0078,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġdas",
        "token_id": 4031,
        "selection_method": "sampling"
      }
    },
    {
      "step": 37,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġvon",
            "token_id": 3615,
            "logprob": -0.2588,
            "prob": 0.772
          },
          {
            "token": "Ġdarauf",
            "token_id": 52159,
            "logprob": -1.6963,
            "prob": 0.1833
          },
          {
            "token": "Ġauf",
            "token_id": 5709,
            "logprob": -3.9297,
            "prob": 0.0196
          },
          {
            "token": "Ġspezi",
            "token_id": 160585,
            "logprob": -4.8047,
            "prob": 0.0082
          },
          {
            "token": "Ġentwickelt",
            "token_id": 105064,
            "logprob": -5.1328,
            "prob": 0.0059
          },
          {
            "token": "Ġfür",
            "token_id": 6081,
            "logprob": -5.9766,
            "prob": 0.0025
          },
          {
            "token": "Ġin",
            "token_id": 1709,
            "logprob": -6.6172,
            "prob": 0.0013
          },
          {
            "token": "Ġdazu",
            "token_id": 66775,
            "logprob": -6.8438,
            "prob": 0.0011
          },
          {
            "token": "Ġan",
            "token_id": 1844,
            "logprob": -7.1328,
            "prob": 0.0008
          },
          {
            "token": "Ġals",
            "token_id": 4561,
            "logprob": -7.5156,
            "prob": 0.0005
          }
        ]
      },
      "selected_token": {
        "token": "Ġentwickelt",
        "token_id": 105064,
        "selection_method": "sampling"
      }
    },
    {
      "step": 38,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġwurde",
            "token_id": 6149,
            "logprob": -0.0004,
            "prob": 0.9995
          },
          {
            "token": "Ġhat",
            "token_id": 10085,
            "logprob": -8.0156,
            "prob": 0.0003
          },
          {
            "token": "Ġwurden",
            "token_id": 14935,
            "logprob": -9.9219,
            "prob": 0.0
          },
          {
            "token": "Ġund",
            "token_id": 2280,
            "logprob": -10.9062,
            "prob": 0.0
          },
          {
            "token": "Ġworden",
            "token_id": 12174,
            "logprob": -11.0625,
            "prob": 0.0
          },
          {
            "token": "Ġwird",
            "token_id": 13252,
            "logprob": -12.9609,
            "prob": 0.0
          },
          {
            "token": ",",
            "token_id": 19,
            "logprob": -13.1016,
            "prob": 0.0
          },
          {
            "token": "Ġhatte",
            "token_id": 20028,
            "logprob": -15.0938,
            "prob": 0.0
          },
          {
            "token": "Ġist",
            "token_id": 5132,
            "logprob": -14.9375,
            "prob": 0.0
          },
          {
            "token": "Ġvon",
            "token_id": 3615,
            "logprob": -14.9609,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġwurde",
        "token_id": 6149,
        "selection_method": "sampling"
      }
    },
    {
      "step": 39,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": ",",
            "token_id": 19,
            "logprob": -0.0,
            "prob": 1.0
          },
          {
            "token": "Ġund",
            "token_id": 2280,
            "logprob": -12.9219,
            "prob": 0.0
          },
          {
            "token": "Ġum",
            "token_id": 2369,
            "logprob": -13.75,
            "prob": 0.0
          },
          {
            "token": "Ġoder",
            "token_id": 13624,
            "logprob": -14.5312,
            "prob": 0.0
          },
          {
            "token": ".",
            "token_id": 21,
            "logprob": -16.9375,
            "prob": 0.0
          },
          {
            "token": "<SEP>",
            "token_id": 3,
            "logprob": -33.0,
            "prob": 0.0
          },
          {
            "token": "<MASK_TOKEN>",
            "token_id": 4,
            "logprob": -33.1875,
            "prob": 0.0
          },
          {
            "token": "<CLS>",
            "token_id": 2,
            "logprob": -33.0312,
            "prob": 0.0
          },
          {
            "token": "<PAD>",
            "token_id": 0,
            "logprob": -33.0938,
            "prob": 0.0
          },
          {
            "token": "<UNK>",
            "token_id": 1,
            "logprob": -31.7812,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": ",",
        "token_id": 19,
        "selection_method": "sampling"
      }
    },
    {
      "step": 40,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde,",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ","
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġum",
            "token_id": 2369,
            "logprob": -0.0,
            "prob": 1.0
          },
          {
            "token": "Ġmensch",
            "token_id": 146395,
            "logprob": -15.2656,
            "prob": 0.0
          },
          {
            "token": "Ġindem",
            "token_id": 110717,
            "logprob": -16.9688,
            "prob": 0.0
          },
          {
            "token": "ĠUm",
            "token_id": 11054,
            "logprob": -17.2656,
            "prob": 0.0
          },
          {
            "token": "<SEP>",
            "token_id": 3,
            "logprob": -32.5312,
            "prob": 0.0
          },
          {
            "token": "<CLS>",
            "token_id": 2,
            "logprob": -32.9375,
            "prob": 0.0
          },
          {
            "token": "<MASK_TOKEN>",
            "token_id": 4,
            "logprob": -33.0,
            "prob": 0.0
          },
          {
            "token": "<BOS_TOKEN>",
            "token_id": 5,
            "logprob": -31.6094,
            "prob": 0.0
          },
          {
            "token": "<PAD>",
            "token_id": 0,
            "logprob": -32.9688,
            "prob": 0.0
          },
          {
            "token": "<UNK>",
            "token_id": 1,
            "logprob": -32.1875,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġum",
        "token_id": 2369,
        "selection_method": "sampling"
      }
    },
    {
      "step": 41,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "ĠMenschen",
            "token_id": 43902,
            "logprob": -1.1484,
            "prob": 0.3171
          },
          {
            "token": "Ġmensch",
            "token_id": 146395,
            "logprob": -1.2422,
            "prob": 0.2886
          },
          {
            "token": "Ġnatür",
            "token_id": 131901,
            "logprob": -1.5703,
            "prob": 0.2079
          },
          {
            "token": "Ġmit",
            "token_id": 4665,
            "logprob": -2.2422,
            "prob": 0.1062
          },
          {
            "token": "Ġeine",
            "token_id": 7147,
            "logprob": -3.7109,
            "prob": 0.0244
          },
          {
            "token": "Ġkomplex",
            "token_id": 98993,
            "logprob": -4.5078,
            "prob": 0.011
          },
          {
            "token": "Ġauf",
            "token_id": 5709,
            "logprob": -4.9219,
            "prob": 0.0073
          },
          {
            "token": "Ġden",
            "token_id": 3636,
            "logprob": -5.2188,
            "prob": 0.0054
          },
          {
            "token": "Ġmenschlichen",
            "token_id": 249140,
            "logprob": -5.375,
            "prob": 0.0046
          },
          {
            "token": "ĠBen",
            "token_id": 5736,
            "logprob": -5.4531,
            "prob": 0.0043
          }
        ]
      },
      "selected_token": {
        "token": "Ġnatür",
        "token_id": 131901,
        "selection_method": "sampling"
      }
    },
    {
      "step": 42,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natür",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "liche",
            "token_id": 13651,
            "logprob": -0.0158,
            "prob": 0.9844
          },
          {
            "token": "lich",
            "token_id": 5447,
            "logprob": -4.1719,
            "prob": 0.0154
          },
          {
            "token": "licher",
            "token_id": 27856,
            "logprob": -8.7734,
            "prob": 0.0002
          },
          {
            "token": "lichen",
            "token_id": 12921,
            "logprob": -9.7891,
            "prob": 0.0001
          },
          {
            "token": "liches",
            "token_id": 59015,
            "logprob": -10.8281,
            "prob": 0.0
          },
          {
            "token": "lijke",
            "token_id": 32215,
            "logprob": -11.5078,
            "prob": 0.0
          },
          {
            "token": "sprach",
            "token_id": 86235,
            "logprob": -12.5469,
            "prob": 0.0
          },
          {
            "token": "lichkeit",
            "token_id": 60747,
            "logprob": -12.5625,
            "prob": 0.0
          },
          {
            "token": "ige",
            "token_id": 5342,
            "logprob": -13.5312,
            "prob": 0.0
          },
          {
            "token": "ische",
            "token_id": 5160,
            "logprob": -13.6484,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "liche",
        "token_id": 13651,
        "selection_method": "sampling"
      }
    },
    {
      "step": 43,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "ĠSprache",
            "token_id": 77558,
            "logprob": -0.2328,
            "prob": 0.7925
          },
          {
            "token": "Ġmensch",
            "token_id": 146395,
            "logprob": -1.623,
            "prob": 0.1973
          },
          {
            "token": "ĠSprach",
            "token_id": 100809,
            "logprob": -5.9219,
            "prob": 0.0027
          },
          {
            "token": ",",
            "token_id": 19,
            "logprob": -5.9375,
            "prob": 0.0026
          },
          {
            "token": "Ġund",
            "token_id": 2280,
            "logprob": -6.2031,
            "prob": 0.002
          },
          {
            "token": "ĠSprachen",
            "token_id": 145845,
            "logprob": -6.25,
            "prob": 0.0019
          },
          {
            "token": "Ġmenschlichen",
            "token_id": 249140,
            "logprob": -7.3281,
            "prob": 0.0007
          },
          {
            "token": "ĠMensch",
            "token_id": 107741,
            "logprob": -8.375,
            "prob": 0.0002
          },
          {
            "token": "ĠKon",
            "token_id": 8670,
            "logprob": -9.75,
            "prob": 0.0001
          },
          {
            "token": "ĠMenschen",
            "token_id": 43902,
            "logprob": -10.5781,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "ĠSprach",
        "token_id": 100809,
        "selection_method": "sampling"
      }
    },
    {
      "step": 44,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprach",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "inter",
            "token_id": 3947,
            "logprob": -0.1147,
            "prob": 0.8916
          },
          {
            "token": "ver",
            "token_id": 1901,
            "logprob": -2.7559,
            "prob": 0.0636
          },
          {
            "token": "komm",
            "token_id": 79979,
            "logprob": -4.0664,
            "prob": 0.0171
          },
          {
            "token": "an",
            "token_id": 1675,
            "logprob": -4.8164,
            "prob": 0.0081
          },
          {
            "token": "m",
            "token_id": 84,
            "logprob": -5.5508,
            "prob": 0.0039
          },
          {
            "token": "verständ",
            "token_id": 199718,
            "logprob": -6.2305,
            "prob": 0.002
          },
          {
            "token": "unter",
            "token_id": 31276,
            "logprob": -6.2305,
            "prob": 0.002
          },
          {
            "token": "bef",
            "token_id": 79800,
            "logprob": -6.5742,
            "prob": 0.0014
          },
          {
            "token": "kon",
            "token_id": 11330,
            "logprob": -6.707,
            "prob": 0.0012
          },
          {
            "token": "-",
            "token_id": 20,
            "logprob": -6.9648,
            "prob": 0.0009
          }
        ]
      },
      "selected_token": {
        "token": "an",
        "token_id": 1675,
        "selection_method": "sampling"
      }
    },
    {
      "step": 45,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachan",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "fragen",
            "token_id": 231968,
            "logprob": -0.5356,
            "prob": 0.5854
          },
          {
            "token": "weis",
            "token_id": 74533,
            "logprob": -0.895,
            "prob": 0.4084
          },
          {
            "token": "f",
            "token_id": 77,
            "logprob": -5.2695,
            "prob": 0.0051
          },
          {
            "token": "wendungen",
            "token_id": 216482,
            "logprob": -7.1133,
            "prob": 0.0008
          },
          {
            "token": "frag",
            "token_id": 73708,
            "logprob": -9.6562,
            "prob": 0.0001
          },
          {
            "token": "weisen",
            "token_id": 103745,
            "logprob": -10.0312,
            "prob": 0.0
          },
          {
            "token": "frage",
            "token_id": 198108,
            "logprob": -10.5859,
            "prob": 0.0
          },
          {
            "token": "w",
            "token_id": 94,
            "logprob": -11.5312,
            "prob": 0.0
          },
          {
            "token": "weise",
            "token_id": 12539,
            "logprob": -11.5938,
            "prob": 0.0
          },
          {
            "token": "wen",
            "token_id": 14075,
            "logprob": -11.6719,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "f",
        "token_id": 77,
        "selection_method": "sampling"
      }
    },
    {
      "step": 46,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachanf",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an",
        "f"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675,
        77
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "ragen",
            "token_id": 30437,
            "logprob": -0.1769,
            "prob": 0.8379
          },
          {
            "token": "orderungen",
            "token_id": 155622,
            "logprob": -1.833,
            "prob": 0.1599
          },
          {
            "token": "rage",
            "token_id": 8773,
            "logprob": -6.5039,
            "prob": 0.0015
          },
          {
            "token": "änge",
            "token_id": 47261,
            "logprob": -7.832,
            "prob": 0.0004
          },
          {
            "token": "fragen",
            "token_id": 231968,
            "logprob": -9.1484,
            "prob": 0.0001
          },
          {
            "token": "ragem",
            "token_id": 58124,
            "logprob": -9.1797,
            "prob": 0.0001
          },
          {
            "token": "ange",
            "token_id": 2728,
            "logprob": -11.0469,
            "prob": 0.0
          },
          {
            "token": "rages",
            "token_id": 30538,
            "logprob": -11.0781,
            "prob": 0.0
          },
          {
            "token": "angen",
            "token_id": 26178,
            "logprob": -11.2031,
            "prob": 0.0
          },
          {
            "token": "rag",
            "token_id": 3459,
            "logprob": -11.6328,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "orderungen",
        "token_id": 155622,
        "selection_method": "sampling"
      }
    },
    {
      "step": 47,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachanforderungen",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an",
        "f",
        "orderungen"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675,
        77, 155622
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġzu",
            "token_id": 5937,
            "logprob": -0.0048,
            "prob": 0.9951
          },
          {
            "token": "Ġund",
            "token_id": 2280,
            "logprob": -6.4414,
            "prob": 0.0016
          },
          {
            "token": "Ġwie",
            "token_id": 9214,
            "logprob": -6.7383,
            "prob": 0.0012
          },
          {
            "token": "Ġder",
            "token_id": 2479,
            "logprob": -7.2695,
            "prob": 0.0007
          },
          {
            "token": "Ġvon",
            "token_id": 3615,
            "logprob": -7.6289,
            "prob": 0.0005
          },
          {
            "token": "Ġmensch",
            "token_id": 146395,
            "logprob": -8.5078,
            "prob": 0.0002
          },
          {
            "token": "Ġin",
            "token_id": 1709,
            "logprob": -9.5469,
            "prob": 0.0001
          },
          {
            "token": "Ġmenschlichen",
            "token_id": 249140,
            "logprob": -9.7734,
            "prob": 0.0001
          },
          {
            "token": "Ġso",
            "token_id": 2362,
            "logprob": -9.7734,
            "prob": 0.0001
          },
          {
            "token": "Ġeines",
            "token_id": 20792,
            "logprob": -10.1094,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġzu",
        "token_id": 5937,
        "selection_method": "sampling"
      }
    },
    {
      "step": 48,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachanforderungen zu",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an",
        "f",
        "orderungen",
        "Ġzu"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675,
        77, 155622, 5937
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġverste",
            "token_id": 169355,
            "logprob": -0.0296,
            "prob": 0.9707
          },
          {
            "token": "Ġerf",
            "token_id": 47991,
            "logprob": -3.6074,
            "prob": 0.0271
          },
          {
            "token": "Ġerkennen",
            "token_id": 154496,
            "logprob": -6.9375,
            "prob": 0.001
          },
          {
            "token": "Ġbeg",
            "token_id": 4652,
            "logprob": -8.5938,
            "prob": 0.0002
          },
          {
            "token": "Ġbe",
            "token_id": 1818,
            "logprob": -8.6953,
            "prob": 0.0002
          },
          {
            "token": "Ġver",
            "token_id": 3344,
            "logprob": -8.8438,
            "prob": 0.0001
          },
          {
            "token": "Ġunterstützen",
            "token_id": 251428,
            "logprob": -9.1562,
            "prob": 0.0001
          },
          {
            "token": "Ġinterpret",
            "token_id": 9715,
            "logprob": -9.1875,
            "prob": 0.0001
          },
          {
            "token": "Ġer",
            "token_id": 2347,
            "logprob": -9.625,
            "prob": 0.0001
          },
          {
            "token": "Ġbew",
            "token_id": 42704,
            "logprob": -9.8438,
            "prob": 0.0001
          }
        ]
      },
      "selected_token": {
        "token": "Ġverste",
        "token_id": 169355,
        "selection_method": "sampling"
      }
    },
    {
      "step": 49,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachanforderungen zu verste",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an",
        "f",
        "orderungen",
        "Ġzu",
        "Ġverste"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675,
        77, 155622, 5937, 169355
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "hen",
            "token_id": 11942,
            "logprob": -0.0,
            "prob": 1.0
          },
          {
            "token": "he",
            "token_id": 1678,
            "logprob": -14.4688,
            "prob": 0.0
          },
          {
            "token": "hlen",
            "token_id": 88604,
            "logprob": -16.4844,
            "prob": 0.0
          },
          {
            "token": "ben",
            "token_id": 5881,
            "logprob": -17.1094,
            "prob": 0.0
          },
          {
            "token": "<SEP>",
            "token_id": 3,
            "logprob": -34.625,
            "prob": 0.0
          },
          {
            "token": "<CLS>",
            "token_id": 2,
            "logprob": -33.9375,
            "prob": 0.0
          },
          {
            "token": "<MASK_TOKEN>",
            "token_id": 4,
            "logprob": -34.6562,
            "prob": 0.0
          },
          {
            "token": "<BOS_TOKEN>",
            "token_id": 5,
            "logprob": -31.75,
            "prob": 0.0
          },
          {
            "token": "<PAD>",
            "token_id": 0,
            "logprob": -34.5,
            "prob": 0.0
          },
          {
            "token": "<UNK>",
            "token_id": 1,
            "logprob": -33.0,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "hen",
        "token_id": 11942,
        "selection_method": "sampling"
      }
    },
    {
      "step": 50,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachanforderungen zu verstehen",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an",
        "f",
        "orderungen",
        "Ġzu",
        "Ġverste",
        "hen"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675,
        77, 155622, 5937, 169355, 11942
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġund",
            "token_id": 2280,
            "logprob": -0.0011,
            "prob": 0.999
          },
          {
            "token": ",",
            "token_id": 19,
            "logprob": -7.0,
            "prob": 0.0009
          },
          {
            "token": ".",
            "token_id": 21,
            "logprob": -8.5,
            "prob": 0.0002
          },
          {
            "token": "Ġsowie",
            "token_id": 17878,
            "logprob": -13.7578,
            "prob": 0.0
          },
          {
            "token": "Ġoder",
            "token_id": 13624,
            "logprob": -13.9219,
            "prob": 0.0
          },
          {
            "token": "Ġ(",
            "token_id": 1737,
            "logprob": -15.2031,
            "prob": 0.0
          },
          {
            "token": "Ġ–",
            "token_id": 2129,
            "logprob": -15.6875,
            "prob": 0.0
          },
          {
            "token": "Ġи",
            "token_id": 2071,
            "logprob": -17.0781,
            "prob": 0.0
          },
          {
            "token": "und",
            "token_id": 2004,
            "logprob": -16.5156,
            "prob": 0.0
          },
          {
            "token": "Ġ-",
            "token_id": 1945,
            "logprob": -17.1094,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": ".",
        "token_id": 21,
        "selection_method": "sampling"
      }
    },
    {
      "step": 51,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachanforderungen zu verstehen.",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an",
        "f",
        "orderungen",
        "Ġzu",
        "Ġverste",
        "hen",
        "."
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675,
        77, 155622, 5937, 169355, 11942, 21
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "\n",
            "token_id": 206,
            "logprob": -0.1243,
            "prob": 0.8833
          },
          {
            "token": "ĠIch",
            "token_id": 31246,
            "logprob": -2.6562,
            "prob": 0.0703
          },
          {
            "token": "ĠJ",
            "token_id": 1846,
            "logprob": -4.2969,
            "prob": 0.0136
          },
          {
            "token": "ĠMein",
            "token_id": 63249,
            "logprob": -4.5781,
            "prob": 0.0103
          },
          {
            "token": "Ġ\n",
            "token_id": 1973,
            "logprob": -5.0,
            "prob": 0.0067
          },
          {
            "token": "ĠDu",
            "token_id": 9421,
            "logprob": -5.6094,
            "prob": 0.0037
          },
          {
            "token": "ĠMeine",
            "token_id": 180612,
            "logprob": -5.75,
            "prob": 0.0032
          },
          {
            "token": "ĠEntwick",
            "token_id": 136412,
            "logprob": -6.4609,
            "prob": 0.0016
          },
          {
            "token": "ĠAls",
            "token_id": 21524,
            "logprob": -6.7188,
            "prob": 0.0012
          },
          {
            "token": "ĠIn",
            "token_id": 2020,
            "logprob": -6.8516,
            "prob": 0.0011
          }
        ]
      },
      "selected_token": {
        "token": "ĠIch",
        "token_id": 31246,
        "selection_method": "sampling"
      }
    },
    {
      "step": 52,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachanforderungen zu verstehen. Ich",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an",
        "f",
        "orderungen",
        "Ġzu",
        "Ġverste",
        "hen",
        ".",
        "ĠIch"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675,
        77, 155622, 5937, 169355, 11942, 21, 31246
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġwurde",
            "token_id": 6149,
            "logprob": -0.2279,
            "prob": 0.7964
          },
          {
            "token": "Ġbin",
            "token_id": 13935,
            "logprob": -1.6494,
            "prob": 0.1921
          },
          {
            "token": "Ġhabe",
            "token_id": 61737,
            "logprob": -4.8047,
            "prob": 0.0082
          },
          {
            "token": "Ġben",
            "token_id": 4747,
            "logprob": -7.4297,
            "prob": 0.0006
          },
          {
            "token": "Ġwerde",
            "token_id": 152398,
            "logprob": -7.6484,
            "prob": 0.0005
          },
          {
            "token": "Ġarbe",
            "token_id": 82344,
            "logprob": -7.9375,
            "prob": 0.0004
          },
          {
            "token": "Ġverw",
            "token_id": 46294,
            "logprob": -8.0859,
            "prob": 0.0003
          },
          {
            "token": "Ġkann",
            "token_id": 28963,
            "logprob": -8.1875,
            "prob": 0.0003
          },
          {
            "token": "Ġwurden",
            "token_id": 14935,
            "logprob": -8.3984,
            "prob": 0.0002
          },
          {
            "token": "Ġwar",
            "token_id": 4341,
            "logprob": -8.4219,
            "prob": 0.0002
          }
        ]
      },
      "selected_token": {
        "token": "Ġbin",
        "token_id": 13935,
        "selection_method": "sampling"
      }
    },
    {
      "step": 53,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachanforderungen zu verstehen. Ich bin",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an",
        "f",
        "orderungen",
        "Ġzu",
        "Ġverste",
        "hen",
        ".",
        "ĠIch",
        "Ġbin"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675,
        77, 155622, 5937, 169355, 11942, 21, 31246, 13935
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġdarauf",
            "token_id": 52159,
            "logprob": -0.1384,
            "prob": 0.8706
          },
          {
            "token": "Ġso",
            "token_id": 2362,
            "logprob": -2.5293,
            "prob": 0.0797
          },
          {
            "token": "Ġhier",
            "token_id": 14371,
            "logprob": -3.5449,
            "prob": 0.0289
          },
          {
            "token": "Ġprogramm",
            "token_id": 77009,
            "logprob": -4.6211,
            "prob": 0.0098
          },
          {
            "token": "Ġdafür",
            "token_id": 92145,
            "logprob": -5.6367,
            "prob": 0.0036
          },
          {
            "token": "Ġdazu",
            "token_id": 66775,
            "logprob": -6.1602,
            "prob": 0.0021
          },
          {
            "token": "Ġentw",
            "token_id": 109448,
            "logprob": -6.5898,
            "prob": 0.0014
          },
          {
            "token": "Ġtrain",
            "token_id": 10747,
            "logprob": -7.1055,
            "prob": 0.0008
          },
          {
            "token": "Ġprogram",
            "token_id": 4007,
            "logprob": -8.1484,
            "prob": 0.0003
          },
          {
            "token": "Ġentwickelt",
            "token_id": 105064,
            "logprob": -8.4609,
            "prob": 0.0002
          }
        ]
      },
      "selected_token": {
        "token": "Ġentw",
        "token_id": 109448,
        "selection_method": "sampling"
      }
    },
    {
      "step": 54,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachanforderungen zu verstehen. Ich bin entw",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an",
        "f",
        "orderungen",
        "Ġzu",
        "Ġverste",
        "hen",
        ".",
        "ĠIch",
        "Ġbin",
        "Ġentw"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675,
        77, 155622, 5937, 169355, 11942, 21, 31246, 13935, 109448
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "orfen",
            "token_id": 142085,
            "logprob": -0.0003,
            "prob": 0.9995
          },
          {
            "token": "ungen",
            "token_id": 7868,
            "logprob": -8.6719,
            "prob": 0.0002
          },
          {
            "token": "orf",
            "token_id": 9152,
            "logprob": -11.2656,
            "prob": 0.0
          },
          {
            "token": "ir",
            "token_id": 1771,
            "logprob": -11.3359,
            "prob": 0.0
          },
          {
            "token": "urz",
            "token_id": 133665,
            "logprob": -11.8438,
            "prob": 0.0
          },
          {
            "token": "unden",
            "token_id": 29083,
            "logprob": -11.9766,
            "prob": 0.0
          },
          {
            "token": "iesen",
            "token_id": 50222,
            "logprob": -12.1562,
            "prob": 0.0
          },
          {
            "token": "ieden",
            "token_id": 67348,
            "logprob": -12.2969,
            "prob": 0.0
          },
          {
            "token": "oben",
            "token_id": 70963,
            "logprob": -12.4297,
            "prob": 0.0
          },
          {
            "token": "achsen",
            "token_id": 55638,
            "logprob": -12.7969,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "ungen",
        "token_id": 7868,
        "selection_method": "sampling"
      }
    },
    {
      "step": 55,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachanforderungen zu verstehen. Ich bin entwungen",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an",
        "f",
        "orderungen",
        "Ġzu",
        "Ġverste",
        "hen",
        ".",
        "ĠIch",
        "Ġbin",
        "Ġentw",
        "ungen"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675,
        77, 155622, 5937, 169355, 11942, 21, 31246, 13935, 109448, 7868
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": ",",
            "token_id": 19,
            "logprob": -0.0001,
            "prob": 1.0
          },
          {
            "token": "Ġworden",
            "token_id": 12174,
            "logprob": -9.0469,
            "prob": 0.0001
          },
          {
            "token": "Ġund",
            "token_id": 2280,
            "logprob": -11.875,
            "prob": 0.0
          },
          {
            "token": "Ġwurde",
            "token_id": 6149,
            "logprob": -11.9219,
            "prob": 0.0
          },
          {
            "token": "Ġum",
            "token_id": 2369,
            "logprob": -12.0391,
            "prob": 0.0
          },
          {
            "token": "Ġwurden",
            "token_id": 14935,
            "logprob": -13.2969,
            "prob": 0.0
          },
          {
            "token": "Ġoder",
            "token_id": 13624,
            "logprob": -13.3047,
            "prob": 0.0
          },
          {
            "token": "Ġwerden",
            "token_id": 9178,
            "logprob": -14.4375,
            "prob": 0.0
          },
          {
            "token": "Ġmit",
            "token_id": 4665,
            "logprob": -15.0859,
            "prob": 0.0
          },
          {
            "token": "Ġvon",
            "token_id": 3615,
            "logprob": -15.4844,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": ",",
        "token_id": 19,
        "selection_method": "sampling"
      }
    },
    {
      "step": 56,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachanforderungen zu verstehen. Ich bin entwungen,",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an",
        "f",
        "orderungen",
        "Ġzu",
        "Ġverste",
        "hen",
        ".",
        "ĠIch",
        "Ġbin",
        "Ġentw",
        "ungen",
        ","
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675,
        77, 155622, 5937, 169355, 11942, 21, 31246, 13935, 109448, 7868, 19
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġum",
            "token_id": 2369,
            "logprob": -0.0,
            "prob": 1.0
          },
          {
            "token": "ĠUm",
            "token_id": 11054,
            "logprob": -13.4141,
            "prob": 0.0
          },
          {
            "token": "Ġmensch",
            "token_id": 146395,
            "logprob": -14.25,
            "prob": 0.0
          },
          {
            "token": "ĠInformationen",
            "token_id": 114544,
            "logprob": -14.3594,
            "prob": 0.0
          },
          {
            "token": "ĠBen",
            "token_id": 5736,
            "logprob": -15.0391,
            "prob": 0.0
          },
          {
            "token": "Ġdamit",
            "token_id": 41652,
            "logprob": -15.0938,
            "prob": 0.0
          },
          {
            "token": "Ġdir",
            "token_id": 6359,
            "logprob": -15.4219,
            "prob": 0.0
          },
          {
            "token": "Ġmit",
            "token_id": 4665,
            "logprob": -15.5938,
            "prob": 0.0
          },
          {
            "token": "Ġden",
            "token_id": 3636,
            "logprob": -16.1406,
            "prob": 0.0
          },
          {
            "token": "Ġauf",
            "token_id": 5709,
            "logprob": -15.8516,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġum",
        "token_id": 2369,
        "selection_method": "sampling"
      }
    },
    {
      "step": 57,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachanforderungen zu verstehen. Ich bin entwungen, um",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an",
        "f",
        "orderungen",
        "Ġzu",
        "Ġverste",
        "hen",
        ".",
        "ĠIch",
        "Ġbin",
        "Ġentw",
        "ungen",
        ",",
        "Ġum"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675,
        77, 155622, 5937, 169355, 11942, 21, 31246, 13935, 109448, 7868, 19, 2369
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "ĠMenschen",
            "token_id": 43902,
            "logprob": -0.9341,
            "prob": 0.3928
          },
          {
            "token": "Ġmit",
            "token_id": 4665,
            "logprob": -1.5908,
            "prob": 0.2039
          },
          {
            "token": "Ġeine",
            "token_id": 7147,
            "logprob": -2.0898,
            "prob": 0.1237
          },
          {
            "token": "Ġmensch",
            "token_id": 146395,
            "logprob": -2.4492,
            "prob": 0.0863
          },
          {
            "token": "Ġin",
            "token_id": 1709,
            "logprob": -3.2305,
            "prob": 0.0395
          },
          {
            "token": "ĠBen",
            "token_id": 5736,
            "logprob": -3.3398,
            "prob": 0.0354
          },
          {
            "token": "ĠFragen",
            "token_id": 163794,
            "logprob": -4.0742,
            "prob": 0.017
          },
          {
            "token": "Ġdir",
            "token_id": 6359,
            "logprob": -4.4336,
            "prob": 0.0119
          },
          {
            "token": "ĠGespr",
            "token_id": 151772,
            "logprob": -4.543,
            "prob": 0.0106
          },
          {
            "token": "ĠInformationen",
            "token_id": 114544,
            "logprob": -4.668,
            "prob": 0.0094
          }
        ]
      },
      "selected_token": {
        "token": "ĠFragen",
        "token_id": 163794,
        "selection_method": "sampling"
      }
    },
    {
      "step": 58,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachanforderungen zu verstehen. Ich bin entwungen, um Fragen",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an",
        "f",
        "orderungen",
        "Ġzu",
        "Ġverste",
        "hen",
        ".",
        "ĠIch",
        "Ġbin",
        "Ġentw",
        "ungen",
        ",",
        "Ġum",
        "ĠFragen"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675,
        77, 155622, 5937, 169355, 11942, 21, 31246, 13935, 109448, 7868, 19, 2369, 163794
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġzu",
            "token_id": 5937,
            "logprob": -0.0007,
            "prob": 0.9995
          },
          {
            "token": "Ġwie",
            "token_id": 9214,
            "logprob": -7.3281,
            "prob": 0.0007
          },
          {
            "token": "Ġund",
            "token_id": 2280,
            "logprob": -10.6875,
            "prob": 0.0
          },
          {
            "token": "Ġder",
            "token_id": 2479,
            "logprob": -11.0938,
            "prob": 0.0
          },
          {
            "token": "Ġbe",
            "token_id": 1818,
            "logprob": -12.0234,
            "prob": 0.0
          },
          {
            "token": "Ġanz",
            "token_id": 74954,
            "logprob": -12.6016,
            "prob": 0.0
          },
          {
            "token": "Ġbeant",
            "token_id": 249699,
            "logprob": -12.9766,
            "prob": 0.0
          },
          {
            "token": "Ġvon",
            "token_id": 3615,
            "logprob": -12.9922,
            "prob": 0.0
          },
          {
            "token": "Ġauf",
            "token_id": 5709,
            "logprob": -13.4766,
            "prob": 0.0
          },
          {
            "token": "Ġaller",
            "token_id": 41292,
            "logprob": -13.625,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġwie",
        "token_id": 9214,
        "selection_method": "sampling"
      }
    },
    {
      "step": 59,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachanforderungen zu verstehen. Ich bin entwungen, um Fragen wie",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an",
        "f",
        "orderungen",
        "Ġzu",
        "Ġverste",
        "hen",
        ".",
        "ĠIch",
        "Ġbin",
        "Ġentw",
        "ungen",
        ",",
        "Ġum",
        "ĠFragen",
        "Ġwie"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675,
        77, 155622, 5937, 169355, 11942, 21, 31246, 13935, 109448, 7868, 19, 2369, 163794, 9214
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġdie",
            "token_id": 2915,
            "logprob": -0.6924,
            "prob": 0.5005
          },
          {
            "token": "Ġde",
            "token_id": 1715,
            "logprob": -0.9893,
            "prob": 0.3718
          },
          {
            "token": "Ġ\"",
            "token_id": 1789,
            "logprob": -2.7559,
            "prob": 0.0636
          },
          {
            "token": "ĠIhre",
            "token_id": 100528,
            "logprob": -2.834,
            "prob": 0.0588
          },
          {
            "token": "Ġdiese",
            "token_id": 30447,
            "logprob": -5.5664,
            "prob": 0.0038
          },
          {
            "token": "Ġ„",
            "token_id": 4352,
            "logprob": -6.9102,
            "prob": 0.001
          },
          {
            "token": "ĠDe",
            "token_id": 2721,
            "logprob": -8.9375,
            "prob": 0.0001
          },
          {
            "token": "ĠI",
            "token_id": 1767,
            "logprob": -9.9766,
            "prob": 0.0
          },
          {
            "token": "Ġyours",
            "token_id": 43002,
            "logprob": -10.0234,
            "prob": 0.0
          },
          {
            "token": "Ġder",
            "token_id": 2479,
            "logprob": -10.3438,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġ\"",
        "token_id": 1789,
        "selection_method": "sampling"
      }
    },
    {
      "step": 60,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachanforderungen zu verstehen. Ich bin entwungen, um Fragen wie \"",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an",
        "f",
        "orderungen",
        "Ġzu",
        "Ġverste",
        "hen",
        ".",
        "ĠIch",
        "Ġbin",
        "Ġentw",
        "ungen",
        ",",
        "Ġum",
        "ĠFragen",
        "Ġwie",
        "Ġ\""
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675,
        77, 155622, 5937, 169355, 11942, 21, 31246, 13935, 109448, 7868, 19, 2369, 163794, 9214,
        1789
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Wer",
            "token_id": 51864,
            "logprob": -0.0,
            "prob": 1.0
          },
          {
            "token": "wer",
            "token_id": 7925,
            "logprob": -11.5781,
            "prob": 0.0
          },
          {
            "token": "Who",
            "token_id": 33668,
            "logprob": -11.9531,
            "prob": 0.0
          },
          {
            "token": "ĠWer",
            "token_id": 19171,
            "logprob": -12.4375,
            "prob": 0.0
          },
          {
            "token": "Wie",
            "token_id": 93488,
            "logprob": -13.7656,
            "prob": 0.0
          },
          {
            "token": "Wen",
            "token_id": 199792,
            "logprob": -14.2812,
            "prob": 0.0
          },
          {
            "token": "Chi",
            "token_id": 55430,
            "logprob": -14.6719,
            "prob": 0.0
          },
          {
            "token": "WER",
            "token_id": 50884,
            "logprob": -15.3438,
            "prob": 0.0
          },
          {
            "token": "W",
            "token_id": 62,
            "logprob": -16.2031,
            "prob": 0.0
          },
          {
            "token": "Wel",
            "token_id": 34711,
            "logprob": -15.7812,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Wer",
        "token_id": 51864,
        "selection_method": "sampling"
      }
    },
    {
      "step": 61,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachanforderungen zu verstehen. Ich bin entwungen, um Fragen wie \"Wer",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an",
        "f",
        "orderungen",
        "Ġzu",
        "Ġverste",
        "hen",
        ".",
        "ĠIch",
        "Ġbin",
        "Ġentw",
        "ungen",
        ",",
        "Ġum",
        "ĠFragen",
        "Ġwie",
        "Ġ\"",
        "Wer"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675,
        77, 155622, 5937, 169355, 11942, 21, 31246, 13935, 109448, 7868, 19, 2369, 163794, 9214,
        1789, 51864
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġbist",
            "token_id": 193517,
            "logprob": -0.0004,
            "prob": 0.9995
          },
          {
            "token": "Ġbin",
            "token_id": 13935,
            "logprob": -7.8438,
            "prob": 0.0004
          },
          {
            "token": "ĠBist",
            "token_id": 68681,
            "logprob": -12.3125,
            "prob": 0.0
          },
          {
            "token": "Ġbis",
            "token_id": 6390,
            "logprob": -14.9688,
            "prob": 0.0
          },
          {
            "token": "Ġbina",
            "token_id": 169876,
            "logprob": -15.1953,
            "prob": 0.0
          },
          {
            "token": "Ġbinn",
            "token_id": 181154,
            "logprob": -15.3125,
            "prob": 0.0
          },
          {
            "token": "Ġhast",
            "token_id": 36734,
            "logprob": -15.6953,
            "prob": 0.0
          },
          {
            "token": "Ġbinom",
            "token_id": 231450,
            "logprob": -16.2188,
            "prob": 0.0
          },
          {
            "token": "Ġbins",
            "token_id": 88398,
            "logprob": -16.0781,
            "prob": 0.0
          },
          {
            "token": "Ġb",
            "token_id": 1700,
            "logprob": -15.9844,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġbist",
        "token_id": 193517,
        "selection_method": "sampling"
      }
    },
    {
      "step": 62,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachanforderungen zu verstehen. Ich bin entwungen, um Fragen wie \"Wer bist",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an",
        "f",
        "orderungen",
        "Ġzu",
        "Ġverste",
        "hen",
        ".",
        "ĠIch",
        "Ġbin",
        "Ġentw",
        "ungen",
        ",",
        "Ġum",
        "ĠFragen",
        "Ġwie",
        "Ġ\"",
        "Wer",
        "Ġbist"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675,
        77, 155622, 5937, 169355, 11942, 21, 31246, 13935, 109448, 7868, 19, 2369, 163794, 9214,
        1789, 51864, 193517
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġdu",
            "token_id": 2333,
            "logprob": -0.0,
            "prob": 1.0
          },
          {
            "token": "ĠDu",
            "token_id": 9421,
            "logprob": -14.375,
            "prob": 0.0
          },
          {
            "token": "<PAD>",
            "token_id": 0,
            "logprob": -39.7188,
            "prob": 0.0
          },
          {
            "token": "<UNK>",
            "token_id": 1,
            "logprob": -39.1875,
            "prob": 0.0
          },
          {
            "token": "<EOS_TOKEN>",
            "token_id": 6,
            "logprob": -34.4688,
            "prob": 0.0
          },
          {
            "token": "<EOP_TOKEN>",
            "token_id": 7,
            "logprob": -39.75,
            "prob": 0.0
          },
          {
            "token": "<BOS_TOKEN>",
            "token_id": 5,
            "logprob": -37.5312,
            "prob": 0.0
          },
          {
            "token": "<MASK_TOKEN>",
            "token_id": 4,
            "logprob": -39.75,
            "prob": 0.0
          },
          {
            "token": "<CLS>",
            "token_id": 2,
            "logprob": -39.8125,
            "prob": 0.0
          },
          {
            "token": "<SEP>",
            "token_id": 3,
            "logprob": -40.1875,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġdu",
        "token_id": 2333,
        "selection_method": "sampling"
      }
    },
    {
      "step": 63,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachanforderungen zu verstehen. Ich bin entwungen, um Fragen wie \"Wer bist du",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an",
        "f",
        "orderungen",
        "Ġzu",
        "Ġverste",
        "hen",
        ".",
        "ĠIch",
        "Ġbin",
        "Ġentw",
        "ungen",
        ",",
        "Ġum",
        "ĠFragen",
        "Ġwie",
        "Ġ\"",
        "Wer",
        "Ġbist",
        "Ġdu"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675,
        77, 155622, 5937, 169355, 11942, 21, 31246, 13935, 109448, 7868, 19, 2369, 163794, 9214,
        1789, 51864, 193517, 2333
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "?\"",
            "token_id": 13470,
            "logprob": -0.004,
            "prob": 0.9961
          },
          {
            "token": "?\",",
            "token_id": 57120,
            "logprob": -5.5352,
            "prob": 0.0039
          },
          {
            "token": "?\".",
            "token_id": 93882,
            "logprob": -12.6797,
            "prob": 0.0
          },
          {
            "token": "?",
            "token_id": 38,
            "logprob": -13.2422,
            "prob": 0.0
          },
          {
            "token": "\"",
            "token_id": 9,
            "logprob": -13.2578,
            "prob": 0.0
          },
          {
            "token": "?'",
            "token_id": 52937,
            "logprob": -14.5781,
            "prob": 0.0
          },
          {
            "token": "?**",
            "token_id": 126429,
            "logprob": -14.7656,
            "prob": 0.0
          },
          {
            "token": "?`",
            "token_id": 175623,
            "logprob": -14.8906,
            "prob": 0.0
          },
          {
            "token": "\",",
            "token_id": 2040,
            "logprob": -15.9844,
            "prob": 0.0
          },
          {
            "token": "Ġ?",
            "token_id": 5691,
            "logprob": -16.0938,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "?\"",
        "token_id": 13470,
        "selection_method": "sampling"
      }
    },
    {
      "step": 64,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachanforderungen zu verstehen. Ich bin entwungen, um Fragen wie \"Wer bist du?\"",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an",
        "f",
        "orderungen",
        "Ġzu",
        "Ġverste",
        "hen",
        ".",
        "ĠIch",
        "Ġbin",
        "Ġentw",
        "ungen",
        ",",
        "Ġum",
        "ĠFragen",
        "Ġwie",
        "Ġ\"",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?\""
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675,
        77, 155622, 5937, 169355, 11942, 21, 31246, 13935, 109448, 7868, 19, 2369, 163794, 9214,
        1789, 51864, 193517, 2333, 13470
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġzu",
            "token_id": 5937,
            "logprob": -0.0014,
            "prob": 0.9985
          },
          {
            "token": "Ġmit",
            "token_id": 4665,
            "logprob": -6.8281,
            "prob": 0.0011
          },
          {
            "token": "Ġauf",
            "token_id": 5709,
            "logprob": -9.2188,
            "prob": 0.0001
          },
          {
            "token": "Ġin",
            "token_id": 1709,
            "logprob": -9.7812,
            "prob": 0.0001
          },
          {
            "token": "Ġund",
            "token_id": 2280,
            "logprob": -10.1484,
            "prob": 0.0
          },
          {
            "token": "Ġanz",
            "token_id": 74954,
            "logprob": -10.7109,
            "prob": 0.0
          },
          {
            "token": "Ġaus",
            "token_id": 6523,
            "logprob": -11.0547,
            "prob": 0.0
          },
          {
            "token": "Ġumfass",
            "token_id": 172737,
            "logprob": -11.1172,
            "prob": 0.0
          },
          {
            "token": "Ġoder",
            "token_id": 13624,
            "logprob": -11.7109,
            "prob": 0.0
          },
          {
            "token": "Ġso",
            "token_id": 2362,
            "logprob": -12.2344,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġumfass",
        "token_id": 172737,
        "selection_method": "sampling"
      }
    },
    {
      "step": 65,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachanforderungen zu verstehen. Ich bin entwungen, um Fragen wie \"Wer bist du?\" umfass",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an",
        "f",
        "orderungen",
        "Ġzu",
        "Ġverste",
        "hen",
        ".",
        "ĠIch",
        "Ġbin",
        "Ġentw",
        "ungen",
        ",",
        "Ġum",
        "ĠFragen",
        "Ġwie",
        "Ġ\"",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?\"",
        "Ġumfass"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675,
        77, 155622, 5937, 169355, 11942, 21, 31246, 13935, 109448, 7868, 19, 2369, 163794, 9214,
        1789, 51864, 193517, 2333, 13470, 172737
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "end",
            "token_id": 1883,
            "logprob": -0.0,
            "prob": 1.0
          },
          {
            "token": "ende",
            "token_id": 5087,
            "logprob": -13.4844,
            "prob": 0.0
          },
          {
            "token": "enden",
            "token_id": 11404,
            "logprob": -13.9531,
            "prob": 0.0
          },
          {
            "token": "ender",
            "token_id": 3919,
            "logprob": -14.4375,
            "prob": 0.0
          },
          {
            "token": "endes",
            "token_id": 55258,
            "logprob": -16.875,
            "prob": 0.0
          },
          {
            "token": "ends",
            "token_id": 4235,
            "logprob": -17.3281,
            "prob": 0.0
          },
          {
            "token": "ent",
            "token_id": 1712,
            "logprob": -17.0156,
            "prob": 0.0
          },
          {
            "token": "<CLS>",
            "token_id": 2,
            "logprob": -33.4375,
            "prob": 0.0
          },
          {
            "token": "<UNK>",
            "token_id": 1,
            "logprob": -34.0625,
            "prob": 0.0
          },
          {
            "token": "<PAD>",
            "token_id": 0,
            "logprob": -33.4062,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "ent",
        "token_id": 1712,
        "selection_method": "sampling"
      }
    },
    {
      "step": 66,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachanforderungen zu verstehen. Ich bin entwungen, um Fragen wie \"Wer bist du?\" umfassent",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an",
        "f",
        "orderungen",
        "Ġzu",
        "Ġverste",
        "hen",
        ".",
        "ĠIch",
        "Ġbin",
        "Ġentw",
        "ungen",
        ",",
        "Ġum",
        "ĠFragen",
        "Ġwie",
        "Ġ\"",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?\"",
        "Ġumfass",
        "ent"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675,
        77, 155622, 5937, 169355, 11942, 21, 31246, 13935, 109448, 7868, 19, 2369, 163794, 9214,
        1789, 51864, 193517, 2333, 13470, 172737, 1712
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġund",
            "token_id": 2280,
            "logprob": -0.2935,
            "prob": 0.7456
          },
          {
            "token": "Ġzu",
            "token_id": 5937,
            "logprob": -1.3721,
            "prob": 0.2537
          },
          {
            "token": ",",
            "token_id": 19,
            "logprob": -7.7617,
            "prob": 0.0004
          },
          {
            "token": "Ġaber",
            "token_id": 18641,
            "logprob": -9.4062,
            "prob": 0.0001
          },
          {
            "token": "Ġanz",
            "token_id": 74954,
            "logprob": -10.375,
            "prob": 0.0
          },
          {
            "token": "Ġauf",
            "token_id": 5709,
            "logprob": -11.0312,
            "prob": 0.0
          },
          {
            "token": "Ġmit",
            "token_id": 4665,
            "logprob": -11.0547,
            "prob": 0.0
          },
          {
            "token": "Ġin",
            "token_id": 1709,
            "logprob": -12.4297,
            "prob": 0.0
          },
          {
            "token": "und",
            "token_id": 2004,
            "logprob": -12.5469,
            "prob": 0.0
          },
          {
            "token": "Ġeinz",
            "token_id": 56558,
            "logprob": -12.5391,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġund",
        "token_id": 2280,
        "selection_method": "sampling"
      }
    },
    {
      "step": 67,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachanforderungen zu verstehen. Ich bin entwungen, um Fragen wie \"Wer bist du?\" umfassent und",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an",
        "f",
        "orderungen",
        "Ġzu",
        "Ġverste",
        "hen",
        ".",
        "ĠIch",
        "Ġbin",
        "Ġentw",
        "ungen",
        ",",
        "Ġum",
        "ĠFragen",
        "Ġwie",
        "Ġ\"",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?\"",
        "Ġumfass",
        "ent",
        "Ġund"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675,
        77, 155622, 5937, 169355, 11942, 21, 31246, 13935, 109448, 7868, 19, 2369, 163794, 9214,
        1789, 51864, 193517, 2333, 13470, 172737, 1712, 2280
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġhil",
            "token_id": 57206,
            "logprob": -0.4614,
            "prob": 0.6304
          },
          {
            "token": "Ġn",
            "token_id": 1718,
            "logprob": -1.6016,
            "prob": 0.2015
          },
          {
            "token": "Ġinform",
            "token_id": 3188,
            "logprob": -2.1641,
            "prob": 0.1148
          },
          {
            "token": "Ġs",
            "token_id": 1679,
            "logprob": -4.2344,
            "prob": 0.0145
          },
          {
            "token": "Ġsach",
            "token_id": 190958,
            "logprob": -4.8984,
            "prob": 0.0075
          },
          {
            "token": "Ġver",
            "token_id": 3344,
            "logprob": -5.2734,
            "prob": 0.0051
          },
          {
            "token": "Ġkon",
            "token_id": 5696,
            "logprob": -5.2969,
            "prob": 0.005
          },
          {
            "token": "Ġin",
            "token_id": 1709,
            "logprob": -5.4609,
            "prob": 0.0042
          },
          {
            "token": "Ġprä",
            "token_id": 170168,
            "logprob": -6.5156,
            "prob": 0.0015
          },
          {
            "token": "Ġklar",
            "token_id": 96662,
            "logprob": -6.7109,
            "prob": 0.0012
          }
        ]
      },
      "selected_token": {
        "token": "Ġkon",
        "token_id": 5696,
        "selection_method": "sampling"
      }
    },
    {
      "step": 68,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachanforderungen zu verstehen. Ich bin entwungen, um Fragen wie \"Wer bist du?\" umfassent und kon",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an",
        "f",
        "orderungen",
        "Ġzu",
        "Ġverste",
        "hen",
        ".",
        "ĠIch",
        "Ġbin",
        "Ġentw",
        "ungen",
        ",",
        "Ġum",
        "ĠFragen",
        "Ġwie",
        "Ġ\"",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?\"",
        "Ġumfass",
        "ent",
        "Ġund",
        "Ġkon"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675,
        77, 155622, 5937, 169355, 11942, 21, 31246, 13935, 109448, 7868, 19, 2369, 163794, 9214,
        1789, 51864, 193517, 2333, 13470, 172737, 1712, 2280, 5696
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "text",
            "token_id": 2805,
            "logprob": -0.0011,
            "prob": 0.999
          },
          {
            "token": "tekst",
            "token_id": 215525,
            "logprob": -7.3906,
            "prob": 0.0006
          },
          {
            "token": "vers",
            "token_id": 3347,
            "logprob": -8.9219,
            "prob": 0.0001
          },
          {
            "token": "texts",
            "token_id": 165655,
            "logprob": -9.0938,
            "prob": 0.0001
          },
          {
            "token": "texte",
            "token_id": 57625,
            "logprob": -10.1406,
            "prob": 0.0
          },
          {
            "token": "tex",
            "token_id": 10634,
            "logprob": -10.5312,
            "prob": 0.0
          },
          {
            "token": "ver",
            "token_id": 1901,
            "logprob": -10.7734,
            "prob": 0.0
          },
          {
            "token": "tek",
            "token_id": 23551,
            "logprob": -11.4922,
            "prob": 0.0
          },
          {
            "token": "Text",
            "token_id": 5996,
            "logprob": -11.5234,
            "prob": 0.0
          },
          {
            "token": "struct",
            "token_id": 6283,
            "logprob": -11.6484,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "tekst",
        "token_id": 215525,
        "selection_method": "sampling"
      }
    },
    {
      "step": 69,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachanforderungen zu verstehen. Ich bin entwungen, um Fragen wie \"Wer bist du?\" umfassent und kontekst",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an",
        "f",
        "orderungen",
        "Ġzu",
        "Ġverste",
        "hen",
        ".",
        "ĠIch",
        "Ġbin",
        "Ġentw",
        "ungen",
        ",",
        "Ġum",
        "ĠFragen",
        "Ġwie",
        "Ġ\"",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?\"",
        "Ġumfass",
        "ent",
        "Ġund",
        "Ġkon",
        "tekst"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675,
        77, 155622, 5937, 169355, 11942, 21, 31246, 13935, 109448, 7868, 19, 2369, 163794, 9214,
        1789, 51864, 193517, 2333, 13470, 172737, 1712, 2280, 5696, 215525
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "bez",
            "token_id": 31930,
            "logprob": -0.0581,
            "prob": 0.9434
          },
          {
            "token": "uell",
            "token_id": 166100,
            "logprob": -3.8555,
            "prob": 0.0212
          },
          {
            "token": "abhäng",
            "token_id": 77942,
            "logprob": -5.0742,
            "prob": 0.0063
          },
          {
            "token": "get",
            "token_id": 2214,
            "logprob": -5.4336,
            "prob": 0.0044
          },
          {
            "token": "sens",
            "token_id": 53620,
            "logprob": -5.5117,
            "prob": 0.004
          },
          {
            "token": "bas",
            "token_id": 10690,
            "logprob": -5.832,
            "prob": 0.0029
          },
          {
            "token": "gem",
            "token_id": 25822,
            "logprob": -5.8398,
            "prob": 0.0029
          },
          {
            "token": "bew",
            "token_id": 31758,
            "logprob": -6.4102,
            "prob": 0.0016
          },
          {
            "token": "gere",
            "token_id": 51619,
            "logprob": -6.5352,
            "prob": 0.0015
          },
          {
            "token": "beg",
            "token_id": 43882,
            "logprob": -6.582,
            "prob": 0.0014
          }
        ]
      },
      "selected_token": {
        "token": "abhäng",
        "token_id": 77942,
        "selection_method": "sampling"
      }
    },
    {
      "step": 70,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachanforderungen zu verstehen. Ich bin entwungen, um Fragen wie \"Wer bist du?\" umfassent und kontekstabhäng",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an",
        "f",
        "orderungen",
        "Ġzu",
        "Ġverste",
        "hen",
        ".",
        "ĠIch",
        "Ġbin",
        "Ġentw",
        "ungen",
        ",",
        "Ġum",
        "ĠFragen",
        "Ġwie",
        "Ġ\"",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?\"",
        "Ġumfass",
        "ent",
        "Ġund",
        "Ġkon",
        "tekst",
        "abhäng"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675,
        77, 155622, 5937, 169355, 11942, 21, 31246, 13935, 109448, 7868, 19, 2369, 163794, 9214,
        1789, 51864, 193517, 2333, 13470, 172737, 1712, 2280, 5696, 215525, 77942
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "ig",
            "token_id": 1760,
            "logprob": -0.0,
            "prob": 1.0
          },
          {
            "token": "end",
            "token_id": 1883,
            "logprob": -10.8125,
            "prob": 0.0
          },
          {
            "token": "igen",
            "token_id": 5984,
            "logprob": -13.1406,
            "prob": 0.0
          },
          {
            "token": "ige",
            "token_id": 5342,
            "logprob": -14.7578,
            "prob": 0.0
          },
          {
            "token": "iger",
            "token_id": 6813,
            "logprob": -14.7656,
            "prob": 0.0
          },
          {
            "token": "igend",
            "token_id": 229963,
            "logprob": -15.3047,
            "prob": 0.0
          },
          {
            "token": "igem",
            "token_id": 112594,
            "logprob": -15.1797,
            "prob": 0.0
          },
          {
            "token": "en",
            "token_id": 1673,
            "logprob": -15.6953,
            "prob": 0.0
          },
          {
            "token": "lich",
            "token_id": 5447,
            "logprob": -15.4062,
            "prob": 0.0
          },
          {
            "token": "igt",
            "token_id": 19861,
            "logprob": -16.2031,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "ig",
        "token_id": 1760,
        "selection_method": "sampling"
      }
    },
    {
      "step": 71,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachanforderungen zu verstehen. Ich bin entwungen, um Fragen wie \"Wer bist du?\" umfassent und kontekstabhängig",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an",
        "f",
        "orderungen",
        "Ġzu",
        "Ġverste",
        "hen",
        ".",
        "ĠIch",
        "Ġbin",
        "Ġentw",
        "ungen",
        ",",
        "Ġum",
        "ĠFragen",
        "Ġwie",
        "Ġ\"",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?\"",
        "Ġumfass",
        "ent",
        "Ġund",
        "Ġkon",
        "tekst",
        "abhäng",
        "ig"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675,
        77, 155622, 5937, 169355, 11942, 21, 31246, 13935, 109448, 7868, 19, 2369, 163794, 9214,
        1789, 51864, 193517, 2333, 13470, 172737, 1712, 2280, 5696, 215525, 77942, 1760
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġzu",
            "token_id": 5937,
            "logprob": -0.0,
            "prob": 1.0
          },
          {
            "token": "Ġauf",
            "token_id": 5709,
            "logprob": -11.1406,
            "prob": 0.0
          },
          {
            "token": "Ġanz",
            "token_id": 74954,
            "logprob": -11.7969,
            "prob": 0.0
          },
          {
            "token": "Ġmit",
            "token_id": 4665,
            "logprob": -11.9375,
            "prob": 0.0
          },
          {
            "token": "Ġeinz",
            "token_id": 56558,
            "logprob": -12.9922,
            "prob": 0.0
          },
          {
            "token": "Ġbeant",
            "token_id": 249699,
            "logprob": -13.0312,
            "prob": 0.0
          },
          {
            "token": ",",
            "token_id": 19,
            "logprob": -13.2734,
            "prob": 0.0
          },
          {
            "token": "Ġwahr",
            "token_id": 93557,
            "logprob": -13.8594,
            "prob": 0.0
          },
          {
            "token": "Ġbe",
            "token_id": 1818,
            "logprob": -13.9062,
            "prob": 0.0
          },
          {
            "token": "Ġzur",
            "token_id": 9843,
            "logprob": -13.9609,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġzu",
        "token_id": 5937,
        "selection_method": "sampling"
      }
    },
    {
      "step": 72,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachanforderungen zu verstehen. Ich bin entwungen, um Fragen wie \"Wer bist du?\" umfassent und kontekstabhängig zu",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an",
        "f",
        "orderungen",
        "Ġzu",
        "Ġverste",
        "hen",
        ".",
        "ĠIch",
        "Ġbin",
        "Ġentw",
        "ungen",
        ",",
        "Ġum",
        "ĠFragen",
        "Ġwie",
        "Ġ\"",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?\"",
        "Ġumfass",
        "ent",
        "Ġund",
        "Ġkon",
        "tekst",
        "abhäng",
        "ig",
        "Ġzu"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675,
        77, 155622, 5937, 169355, 11942, 21, 31246, 13935, 109448, 7868, 19, 2369, 163794, 9214,
        1789, 51864, 193517, 2333, 13470, 172737, 1712, 2280, 5696, 215525, 77942, 1760, 5937
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġbeant",
            "token_id": 249699,
            "logprob": -0.0018,
            "prob": 0.998
          },
          {
            "token": "Ġant",
            "token_id": 4752,
            "logprob": -6.3594,
            "prob": 0.0017
          },
          {
            "token": "Ġbe",
            "token_id": 1818,
            "logprob": -9.9375,
            "prob": 0.0
          },
          {
            "token": "Ġanswer",
            "token_id": 11205,
            "logprob": -12.3984,
            "prob": 0.0
          },
          {
            "token": "Ġer",
            "token_id": 2347,
            "logprob": -12.6562,
            "prob": 0.0
          },
          {
            "token": "Ġαπαν",
            "token_id": 172671,
            "logprob": -13.25,
            "prob": 0.0
          },
          {
            "token": "Ġerf",
            "token_id": 47991,
            "logprob": -13.5781,
            "prob": 0.0
          },
          {
            "token": "Ġ답",
            "token_id": 178352,
            "logprob": -13.6406,
            "prob": 0.0
          },
          {
            "token": "Ġbehand",
            "token_id": 88748,
            "logprob": -14.1719,
            "prob": 0.0
          },
          {
            "token": "Ġverste",
            "token_id": 169355,
            "logprob": -14.125,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġbe",
        "token_id": 1818,
        "selection_method": "sampling"
      }
    },
    {
      "step": 73,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachanforderungen zu verstehen. Ich bin entwungen, um Fragen wie \"Wer bist du?\" umfassent und kontekstabhängig zu be",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an",
        "f",
        "orderungen",
        "Ġzu",
        "Ġverste",
        "hen",
        ".",
        "ĠIch",
        "Ġbin",
        "Ġentw",
        "ungen",
        ",",
        "Ġum",
        "ĠFragen",
        "Ġwie",
        "Ġ\"",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?\"",
        "Ġumfass",
        "ent",
        "Ġund",
        "Ġkon",
        "tekst",
        "abhäng",
        "ig",
        "Ġzu",
        "Ġbe"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675,
        77, 155622, 5937, 169355, 11942, 21, 31246, 13935, 109448, 7868, 19, 2369, 163794, 9214,
        1789, 51864, 193517, 2333, 13470, 172737, 1712, 2280, 5696, 215525, 77942, 1760, 5937, 1818
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "ant",
            "token_id": 1860,
            "logprob": -0.3191,
            "prob": 0.7271
          },
          {
            "token": "antwort",
            "token_id": 136946,
            "logprob": -1.3193,
            "prob": 0.2673
          },
          {
            "token": "Ġbeant",
            "token_id": 249699,
            "logprob": -6.875,
            "prob": 0.001
          },
          {
            "token": "Ant",
            "token_id": 13019,
            "logprob": -6.9375,
            "prob": 0.001
          },
          {
            "token": "gegn",
            "token_id": 151776,
            "logprob": -7.1094,
            "prob": 0.0008
          },
          {
            "token": "답",
            "token_id": 115566,
            "logprob": -8.2734,
            "prob": 0.0003
          },
          {
            "token": "Ġant",
            "token_id": 4752,
            "logprob": -8.2734,
            "prob": 0.0003
          },
          {
            "token": "ziehen",
            "token_id": 146619,
            "logprob": -8.4297,
            "prob": 0.0002
          },
          {
            "token": "achten",
            "token_id": 38442,
            "logprob": -8.9375,
            "prob": 0.0001
          },
          {
            "token": "enden",
            "token_id": 11404,
            "logprob": -9.0234,
            "prob": 0.0001
          }
        ]
      },
      "selected_token": {
        "token": "antwort",
        "token_id": 136946,
        "selection_method": "sampling"
      }
    },
    {
      "step": 74,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachanforderungen zu verstehen. Ich bin entwungen, um Fragen wie \"Wer bist du?\" umfassent und kontekstabhängig zu beantwort",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an",
        "f",
        "orderungen",
        "Ġzu",
        "Ġverste",
        "hen",
        ".",
        "ĠIch",
        "Ġbin",
        "Ġentw",
        "ungen",
        ",",
        "Ġum",
        "ĠFragen",
        "Ġwie",
        "Ġ\"",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?\"",
        "Ġumfass",
        "ent",
        "Ġund",
        "Ġkon",
        "tekst",
        "abhäng",
        "ig",
        "Ġzu",
        "Ġbe",
        "antwort"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675,
        77, 155622, 5937, 169355, 11942, 21, 31246, 13935, 109448, 7868, 19, 2369, 163794, 9214,
        1789, 51864, 193517, 2333, 13470, 172737, 1712, 2280, 5696, 215525, 77942, 1760, 5937, 1818,
        136946
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "et",
            "token_id": 1720,
            "logprob": -0.0961,
            "prob": 0.9082
          },
          {
            "token": "eten",
            "token_id": 17762,
            "logprob": -2.4238,
            "prob": 0.0886
          },
          {
            "token": "ete",
            "token_id": 5652,
            "logprob": -6.9883,
            "prob": 0.0009
          },
          {
            "token": "en",
            "token_id": 1673,
            "logprob": -7.1758,
            "prob": 0.0008
          },
          {
            "token": "eln",
            "token_id": 26602,
            "logprob": -7.6758,
            "prob": 0.0005
          },
          {
            "token": "ieren",
            "token_id": 16328,
            "logprob": -8.4688,
            "prob": 0.0002
          },
          {
            "token": "ern",
            "token_id": 2148,
            "logprob": -8.6875,
            "prob": 0.0002
          },
          {
            "token": "ung",
            "token_id": 2359,
            "logprob": -9.3594,
            "prob": 0.0001
          },
          {
            "token": ".",
            "token_id": 21,
            "logprob": -9.6406,
            "prob": 0.0001
          },
          {
            "token": "zen",
            "token_id": 3842,
            "logprob": -9.8438,
            "prob": 0.0001
          }
        ]
      },
      "selected_token": {
        "token": "ete",
        "token_id": 5652,
        "selection_method": "sampling"
      }
    },
    {
      "step": 75,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachanforderungen zu verstehen. Ich bin entwungen, um Fragen wie \"Wer bist du?\" umfassent und kontekstabhängig zu beantwortete",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an",
        "f",
        "orderungen",
        "Ġzu",
        "Ġverste",
        "hen",
        ".",
        "ĠIch",
        "Ġbin",
        "Ġentw",
        "ungen",
        ",",
        "Ġum",
        "ĠFragen",
        "Ġwie",
        "Ġ\"",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?\"",
        "Ġumfass",
        "ent",
        "Ġund",
        "Ġkon",
        "tekst",
        "abhäng",
        "ig",
        "Ġzu",
        "Ġbe",
        "antwort",
        "ete"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675,
        77, 155622, 5937, 169355, 11942, 21, 31246, 13935, 109448, 7868, 19, 2369, 163794, 9214,
        1789, 51864, 193517, 2333, 13470, 172737, 1712, 2280, 5696, 215525, 77942, 1760, 5937, 1818,
        136946, 5652
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": ".",
            "token_id": 21,
            "logprob": -0.0013,
            "prob": 0.9985
          },
          {
            "token": "in",
            "token_id": 1670,
            "logprob": -7.6094,
            "prob": 0.0005
          },
          {
            "token": ",",
            "token_id": 19,
            "logprob": -8.0625,
            "prob": 0.0003
          },
          {
            "token": "en",
            "token_id": 1673,
            "logprob": -8.4219,
            "prob": 0.0002
          },
          {
            "token": "Ġund",
            "token_id": 2280,
            "logprob": -9.0781,
            "prob": 0.0001
          },
          {
            "token": "n",
            "token_id": 85,
            "logprob": -9.8594,
            "prob": 0.0001
          },
          {
            "token": "Ġn",
            "token_id": 1718,
            "logprob": -11.625,
            "prob": 0.0
          },
          {
            "token": "Ġ-",
            "token_id": 1945,
            "logprob": -11.6719,
            "prob": 0.0
          },
          {
            "token": "Ġsowie",
            "token_id": 17878,
            "logprob": -11.6797,
            "prob": 0.0
          },
          {
            "token": ":",
            "token_id": 33,
            "logprob": -11.7031,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "in",
        "token_id": 1670,
        "selection_method": "sampling"
      }
    },
    {
      "step": 76,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachanforderungen zu verstehen. Ich bin entwungen, um Fragen wie \"Wer bist du?\" umfassent und kontekstabhängig zu beantwortetein",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an",
        "f",
        "orderungen",
        "Ġzu",
        "Ġverste",
        "hen",
        ".",
        "ĠIch",
        "Ġbin",
        "Ġentw",
        "ungen",
        ",",
        "Ġum",
        "ĠFragen",
        "Ġwie",
        "Ġ\"",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?\"",
        "Ġumfass",
        "ent",
        "Ġund",
        "Ġkon",
        "tekst",
        "abhäng",
        "ig",
        "Ġzu",
        "Ġbe",
        "antwort",
        "ete",
        "in"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675,
        77, 155622, 5937, 169355, 11942, 21, 31246, 13935, 109448, 7868, 19, 2369, 163794, 9214,
        1789, 51864, 193517, 2333, 13470, 172737, 1712, 2280, 5696, 215525, 77942, 1760, 5937, 1818,
        136946, 5652, 1670
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": ".",
            "token_id": 21,
            "logprob": -0.001,
            "prob": 0.999
          },
          {
            "token": ",",
            "token_id": 19,
            "logprob": -7.0625,
            "prob": 0.0009
          },
          {
            "token": "Ġund",
            "token_id": 2280,
            "logprob": -9.4375,
            "prob": 0.0001
          },
          {
            "token": ":",
            "token_id": 33,
            "logprob": -11.1875,
            "prob": 0.0
          },
          {
            "token": "Ġ-",
            "token_id": 1945,
            "logprob": -12.5234,
            "prob": 0.0
          },
          {
            "token": "Ġkönnen",
            "token_id": 37285,
            "logprob": -12.5391,
            "prob": 0.0
          },
          {
            "token": "Ġ–",
            "token_id": 2129,
            "logprob": -12.8281,
            "prob": 0.0
          },
          {
            "token": "m",
            "token_id": 84,
            "logprob": -13.375,
            "prob": 0.0
          },
          {
            "token": "Ġkann",
            "token_id": 28963,
            "logprob": -13.5312,
            "prob": 0.0
          },
          {
            "token": ";",
            "token_id": 34,
            "logprob": -13.5938,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġkönnen",
        "token_id": 37285,
        "selection_method": "sampling"
      }
    },
    {
      "step": 77,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachanforderungen zu verstehen. Ich bin entwungen, um Fragen wie \"Wer bist du?\" umfassent und kontekstabhängig zu beantwortetein können",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an",
        "f",
        "orderungen",
        "Ġzu",
        "Ġverste",
        "hen",
        ".",
        "ĠIch",
        "Ġbin",
        "Ġentw",
        "ungen",
        ",",
        "Ġum",
        "ĠFragen",
        "Ġwie",
        "Ġ\"",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?\"",
        "Ġumfass",
        "ent",
        "Ġund",
        "Ġkon",
        "tekst",
        "abhäng",
        "ig",
        "Ġzu",
        "Ġbe",
        "antwort",
        "ete",
        "in",
        "Ġkönnen"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675,
        77, 155622, 5937, 169355, 11942, 21, 31246, 13935, 109448, 7868, 19, 2369, 163794, 9214,
        1789, 51864, 193517, 2333, 13470, 172737, 1712, 2280, 5696, 215525, 77942, 1760, 5937, 1818,
        136946, 5652, 1670, 37285
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": ".",
            "token_id": 21,
            "logprob": -0.0018,
            "prob": 0.998
          },
          {
            "token": ",",
            "token_id": 19,
            "logprob": -6.5,
            "prob": 0.0015
          },
          {
            "token": ":",
            "token_id": 33,
            "logprob": -8.875,
            "prob": 0.0001
          },
          {
            "token": "Ġund",
            "token_id": 2280,
            "logprob": -9.9531,
            "prob": 0.0
          },
          {
            "token": "Ġ-",
            "token_id": 1945,
            "logprob": -11.2891,
            "prob": 0.0
          },
          {
            "token": "Ġ–",
            "token_id": 2129,
            "logprob": -11.4141,
            "prob": 0.0
          },
          {
            "token": ";",
            "token_id": 34,
            "logprob": -12.3359,
            "prob": 0.0
          },
          {
            "token": "Ġin",
            "token_id": 1709,
            "logprob": -12.3906,
            "prob": 0.0
          },
          {
            "token": "Ġ(",
            "token_id": 1737,
            "logprob": -12.7422,
            "prob": 0.0
          },
          {
            "token": "Ġ.",
            "token_id": 2475,
            "logprob": -13.2344,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": ".",
        "token_id": 21,
        "selection_method": "sampling"
      }
    },
    {
      "step": 78,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachanforderungen zu verstehen. Ich bin entwungen, um Fragen wie \"Wer bist du?\" umfassent und kontekstabhängig zu beantwortetein können.",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an",
        "f",
        "orderungen",
        "Ġzu",
        "Ġverste",
        "hen",
        ".",
        "ĠIch",
        "Ġbin",
        "Ġentw",
        "ungen",
        ",",
        "Ġum",
        "ĠFragen",
        "Ġwie",
        "Ġ\"",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?\"",
        "Ġumfass",
        "ent",
        "Ġund",
        "Ġkon",
        "tekst",
        "abhäng",
        "ig",
        "Ġzu",
        "Ġbe",
        "antwort",
        "ete",
        "in",
        "Ġkönnen",
        "."
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675,
        77, 155622, 5937, 169355, 11942, 21, 31246, 13935, 109448, 7868, 19, 2369, 163794, 9214,
        1789, 51864, 193517, 2333, 13470, 172737, 1712, 2280, 5696, 215525, 77942, 1760, 5937, 1818,
        136946, 5652, 1670, 37285, 21
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "\n",
            "token_id": 206,
            "logprob": -0.0042,
            "prob": 0.9961
          },
          {
            "token": "Ġ\n",
            "token_id": 1973,
            "logprob": -6.3008,
            "prob": 0.0018
          },
          {
            "token": "ĠMein",
            "token_id": 63249,
            "logprob": -7.2852,
            "prob": 0.0007
          },
          {
            "token": "ĠDabei",
            "token_id": 69592,
            "logprob": -7.8633,
            "prob": 0.0004
          },
          {
            "token": "ĠIch",
            "token_id": 31246,
            "logprob": -7.9102,
            "prob": 0.0004
          },
          {
            "token": "ĠMeine",
            "token_id": 180612,
            "logprob": -8.2734,
            "prob": 0.0003
          },
          {
            "token": "ĠHier",
            "token_id": 23396,
            "logprob": -9.0078,
            "prob": 0.0001
          },
          {
            "token": "ĠDas",
            "token_id": 12241,
            "logprob": -9.7266,
            "prob": 0.0001
          },
          {
            "token": "ĠDazu",
            "token_id": 129235,
            "logprob": -9.7344,
            "prob": 0.0001
          },
          {
            "token": "ĠWährend",
            "token_id": 63409,
            "logprob": -10.3828,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "\n",
        "token_id": 206,
        "selection_method": "sampling"
      }
    },
    {
      "step": 79,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachanforderungen zu verstehen. Ich bin entwungen, um Fragen wie \"Wer bist du?\" umfassent und kontekstabhängig zu beantwortetein können.\n",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an",
        "f",
        "orderungen",
        "Ġzu",
        "Ġverste",
        "hen",
        ".",
        "ĠIch",
        "Ġbin",
        "Ġentw",
        "ungen",
        ",",
        "Ġum",
        "ĠFragen",
        "Ġwie",
        "Ġ\"",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?\"",
        "Ġumfass",
        "ent",
        "Ġund",
        "Ġkon",
        "tekst",
        "abhäng",
        "ig",
        "Ġzu",
        "Ġbe",
        "antwort",
        "ete",
        "in",
        "Ġkönnen",
        ".",
        "\n"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675,
        77, 155622, 5937, 169355, 11942, 21, 31246, 13935, 109448, 7868, 19, 2369, 163794, 9214,
        1789, 51864, 193517, 2333, 13470, 172737, 1712, 2280, 5696, 215525, 77942, 1760, 5937, 1818,
        136946, 5652, 1670, 37285, 21, 206
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "\n",
            "token_id": 206,
            "logprob": 0.0,
            "prob": 1.0
          },
          {
            "token": "<UNK>",
            "token_id": 1,
            "logprob": -32.8438,
            "prob": 0.0
          },
          {
            "token": "<SEP>",
            "token_id": 3,
            "logprob": -32.8125,
            "prob": 0.0
          },
          {
            "token": "<EOS_TOKEN>",
            "token_id": 6,
            "logprob": -18.9062,
            "prob": 0.0
          },
          {
            "token": "<EOP_TOKEN>",
            "token_id": 7,
            "logprob": -33.0,
            "prob": 0.0
          },
          {
            "token": "<PAD>",
            "token_id": 0,
            "logprob": -33.0938,
            "prob": 0.0
          },
          {
            "token": "<CLS>",
            "token_id": 2,
            "logprob": -32.875,
            "prob": 0.0
          },
          {
            "token": "<BOS_TOKEN>",
            "token_id": 5,
            "logprob": -31.9688,
            "prob": 0.0
          },
          {
            "token": "!",
            "token_id": 8,
            "logprob": -25.0625,
            "prob": 0.0
          },
          {
            "token": "<MASK_TOKEN>",
            "token_id": 4,
            "logprob": -33.0625,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "\n",
        "token_id": 206,
        "selection_method": "sampling"
      }
    },
    {
      "step": 80,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachanforderungen zu verstehen. Ich bin entwungen, um Fragen wie \"Wer bist du?\" umfassent und kontekstabhängig zu beantwortetein können.\n\n",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an",
        "f",
        "orderungen",
        "Ġzu",
        "Ġverste",
        "hen",
        ".",
        "ĠIch",
        "Ġbin",
        "Ġentw",
        "ungen",
        ",",
        "Ġum",
        "ĠFragen",
        "Ġwie",
        "Ġ\"",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?\"",
        "Ġumfass",
        "ent",
        "Ġund",
        "Ġkon",
        "tekst",
        "abhäng",
        "ig",
        "Ġzu",
        "Ġbe",
        "antwort",
        "ete",
        "in",
        "Ġkönnen",
        ".",
        "\n",
        "\n"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675,
        77, 155622, 5937, 169355, 11942, 21, 31246, 13935, 109448, 7868, 19, 2369, 163794, 9214,
        1789, 51864, 193517, 2333, 13470, 172737, 1712, 2280, 5696, 215525, 77942, 1760, 5937, 1818,
        136946, 5652, 1670, 37285, 21, 206, 206
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Me",
            "token_id": 10872,
            "logprob": -0.3052,
            "prob": 0.7368
          },
          {
            "token": "Im",
            "token_id": 4928,
            "logprob": -2.3203,
            "prob": 0.0982
          },
          {
            "token": "Hier",
            "token_id": 52729,
            "logprob": -2.5703,
            "prob": 0.0765
          },
          {
            "token": "In",
            "token_id": 2158,
            "logprob": -3.2734,
            "prob": 0.0378
          },
          {
            "token": "Als",
            "token_id": 37229,
            "logprob": -3.6016,
            "prob": 0.0273
          },
          {
            "token": "Ich",
            "token_id": 75903,
            "logprob": -4.2422,
            "prob": 0.0144
          },
          {
            "token": "Ob",
            "token_id": 4033,
            "logprob": -7.1641,
            "prob": 0.0008
          },
          {
            "token": "Zu",
            "token_id": 77038,
            "logprob": -7.6953,
            "prob": 0.0005
          },
          {
            "token": "Mit",
            "token_id": 27256,
            "logprob": -7.7188,
            "prob": 0.0004
          },
          {
            "token": "Gen",
            "token_id": 15116,
            "logprob": -7.8984,
            "prob": 0.0004
          }
        ]
      },
      "selected_token": {
        "token": "Als",
        "token_id": 37229,
        "selection_method": "sampling"
      }
    },
    {
      "step": 81,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachanforderungen zu verstehen. Ich bin entwungen, um Fragen wie \"Wer bist du?\" umfassent und kontekstabhängig zu beantwortetein können.\n\nAls",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an",
        "f",
        "orderungen",
        "Ġzu",
        "Ġverste",
        "hen",
        ".",
        "ĠIch",
        "Ġbin",
        "Ġentw",
        "ungen",
        ",",
        "Ġum",
        "ĠFragen",
        "Ġwie",
        "Ġ\"",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?\"",
        "Ġumfass",
        "ent",
        "Ġund",
        "Ġkon",
        "tekst",
        "abhäng",
        "ig",
        "Ġzu",
        "Ġbe",
        "antwort",
        "ete",
        "in",
        "Ġkönnen",
        ".",
        "\n",
        "\n",
        "Als"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675,
        77, 155622, 5937, 169355, 11942, 21, 31246, 13935, 109448, 7868, 19, 2369, 163794, 9214,
        1789, 51864, 193517, 2333, 13470, 172737, 1712, 2280, 5696, 215525, 77942, 1760, 5937, 1818,
        136946, 5652, 1670, 37285, 21, 206, 206, 37229
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "ĠKI",
            "token_id": 202056,
            "logprob": -0.1576,
            "prob": 0.854
          },
          {
            "token": "Ġk",
            "token_id": 1815,
            "logprob": -2.0488,
            "prob": 0.129
          },
          {
            "token": "ĠAI",
            "token_id": 21024,
            "logprob": -4.9844,
            "prob": 0.0068
          },
          {
            "token": "Ġsol",
            "token_id": 3137,
            "logprob": -6.1719,
            "prob": 0.0021
          },
          {
            "token": "ĠKünst",
            "token_id": 119776,
            "logprob": -6.8281,
            "prob": 0.0011
          },
          {
            "token": "ĠSprach",
            "token_id": 100809,
            "logprob": -6.8906,
            "prob": 0.001
          },
          {
            "token": "ĠChat",
            "token_id": 41573,
            "logprob": -7.0391,
            "prob": 0.0009
          },
          {
            "token": "Ġsolcher",
            "token_id": 241471,
            "logprob": -7.0625,
            "prob": 0.0009
          },
          {
            "token": "ĠTeil",
            "token_id": 22815,
            "logprob": -7.1172,
            "prob": 0.0008
          },
          {
            "token": "ĠAssistent",
            "token_id": 183897,
            "logprob": -7.625,
            "prob": 0.0005
          }
        ]
      },
      "selected_token": {
        "token": "ĠKI",
        "token_id": 202056,
        "selection_method": "sampling"
      }
    },
    {
      "step": 82,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachanforderungen zu verstehen. Ich bin entwungen, um Fragen wie \"Wer bist du?\" umfassent und kontekstabhängig zu beantwortetein können.\n\nAls KI",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an",
        "f",
        "orderungen",
        "Ġzu",
        "Ġverste",
        "hen",
        ".",
        "ĠIch",
        "Ġbin",
        "Ġentw",
        "ungen",
        ",",
        "Ġum",
        "ĠFragen",
        "Ġwie",
        "Ġ\"",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?\"",
        "Ġumfass",
        "ent",
        "Ġund",
        "Ġkon",
        "tekst",
        "abhäng",
        "ig",
        "Ġzu",
        "Ġbe",
        "antwort",
        "ete",
        "in",
        "Ġkönnen",
        ".",
        "\n",
        "\n",
        "Als",
        "ĠKI"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675,
        77, 155622, 5937, 169355, 11942, 21, 31246, 13935, 109448, 7868, 19, 2369, 163794, 9214,
        1789, 51864, 193517, 2333, 13470, 172737, 1712, 2280, 5696, 215525, 77942, 1760, 5937, 1818,
        136946, 5652, 1670, 37285, 21, 206, 206, 37229, 202056
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "-",
            "token_id": 20,
            "logprob": -0.0339,
            "prob": 0.9668
          },
          {
            "token": "Ġhabe",
            "token_id": 61737,
            "logprob": -3.6738,
            "prob": 0.0254
          },
          {
            "token": "Ġbin",
            "token_id": 13935,
            "logprob": -5.2539,
            "prob": 0.0052
          },
          {
            "token": "Ġkann",
            "token_id": 28963,
            "logprob": -6.6602,
            "prob": 0.0013
          },
          {
            "token": "Ġ(",
            "token_id": 1737,
            "logprob": -8.3125,
            "prob": 0.0002
          },
          {
            "token": "Ġwurde",
            "token_id": 6149,
            "logprob": -8.6484,
            "prob": 0.0002
          },
          {
            "token": "Ġbas",
            "token_id": 4336,
            "logprob": -8.7422,
            "prob": 0.0002
          },
          {
            "token": "Ġl",
            "token_id": 1711,
            "logprob": -8.8672,
            "prob": 0.0001
          },
          {
            "token": ",",
            "token_id": 19,
            "logprob": -9.5234,
            "prob": 0.0001
          },
          {
            "token": "Ġverw",
            "token_id": 46294,
            "logprob": -10.0391,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġkann",
        "token_id": 28963,
        "selection_method": "sampling"
      }
    },
    {
      "step": 83,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachanforderungen zu verstehen. Ich bin entwungen, um Fragen wie \"Wer bist du?\" umfassent und kontekstabhängig zu beantwortetein können.\n\nAls KI kann",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an",
        "f",
        "orderungen",
        "Ġzu",
        "Ġverste",
        "hen",
        ".",
        "ĠIch",
        "Ġbin",
        "Ġentw",
        "ungen",
        ",",
        "Ġum",
        "ĠFragen",
        "Ġwie",
        "Ġ\"",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?\"",
        "Ġumfass",
        "ent",
        "Ġund",
        "Ġkon",
        "tekst",
        "abhäng",
        "ig",
        "Ġzu",
        "Ġbe",
        "antwort",
        "ete",
        "in",
        "Ġkönnen",
        ".",
        "\n",
        "\n",
        "Als",
        "ĠKI",
        "Ġkann"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675,
        77, 155622, 5937, 169355, 11942, 21, 31246, 13935, 109448, 7868, 19, 2369, 163794, 9214,
        1789, 51864, 193517, 2333, 13470, 172737, 1712, 2280, 5696, 215525, 77942, 1760, 5937, 1818,
        136946, 5652, 1670, 37285, 21, 206, 206, 37229, 202056, 28963
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġich",
            "token_id": 23909,
            "logprob": -0.0001,
            "prob": 1.0
          },
          {
            "token": "ĠIch",
            "token_id": 31246,
            "logprob": -11.1719,
            "prob": 0.0
          },
          {
            "token": "Ġman",
            "token_id": 2647,
            "logprob": -11.4688,
            "prob": 0.0
          },
          {
            "token": "Ġund",
            "token_id": 2280,
            "logprob": -11.4688,
            "prob": 0.0
          },
          {
            "token": "Ġik",
            "token_id": 16502,
            "logprob": -11.5859,
            "prob": 0.0
          },
          {
            "token": "Ġes",
            "token_id": 2278,
            "logprob": -11.6484,
            "prob": 0.0
          },
          {
            "token": "Ġ\"",
            "token_id": 1789,
            "logprob": -11.9609,
            "prob": 0.0
          },
          {
            "token": "st",
            "token_id": 1725,
            "logprob": -12.0156,
            "prob": 0.0
          },
          {
            "token": "Ġmeine",
            "token_id": 227217,
            "logprob": -12.6875,
            "prob": 0.0
          },
          {
            "token": "Ġmich",
            "token_id": 123180,
            "logprob": -13.4219,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġich",
        "token_id": 23909,
        "selection_method": "sampling"
      }
    },
    {
      "step": 84,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachanforderungen zu verstehen. Ich bin entwungen, um Fragen wie \"Wer bist du?\" umfassent und kontekstabhängig zu beantwortetein können.\n\nAls KI kann ich",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an",
        "f",
        "orderungen",
        "Ġzu",
        "Ġverste",
        "hen",
        ".",
        "ĠIch",
        "Ġbin",
        "Ġentw",
        "ungen",
        ",",
        "Ġum",
        "ĠFragen",
        "Ġwie",
        "Ġ\"",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?\"",
        "Ġumfass",
        "ent",
        "Ġund",
        "Ġkon",
        "tekst",
        "abhäng",
        "ig",
        "Ġzu",
        "Ġbe",
        "antwort",
        "ete",
        "in",
        "Ġkönnen",
        ".",
        "\n",
        "\n",
        "Als",
        "ĠKI",
        "Ġkann",
        "Ġich"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675,
        77, 155622, 5937, 169355, 11942, 21, 31246, 13935, 109448, 7868, 19, 2369, 163794, 9214,
        1789, 51864, 193517, 2333, 13470, 172737, 1712, 2280, 5696, 215525, 77942, 1760, 5937, 1818,
        136946, 5652, 1670, 37285, 21, 206, 206, 37229, 202056, 28963, 23909
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": ":",
            "token_id": 33,
            "logprob": -0.4707,
            "prob": 0.6245
          },
          {
            "token": "ĠInformationen",
            "token_id": 114544,
            "logprob": -1.8926,
            "prob": 0.1506
          },
          {
            "token": "Ġeine",
            "token_id": 7147,
            "logprob": -2.3457,
            "prob": 0.0958
          },
          {
            "token": "Ġgroße",
            "token_id": 52932,
            "logprob": -3.2988,
            "prob": 0.0369
          },
          {
            "token": "Ġnicht",
            "token_id": 12075,
            "logprob": -4.1719,
            "prob": 0.0154
          },
          {
            "token": "Ġkeine",
            "token_id": 41487,
            "logprob": -4.4531,
            "prob": 0.0116
          },
          {
            "token": "Ġverschiedene",
            "token_id": 79817,
            "logprob": -4.8203,
            "prob": 0.008
          },
          {
            "token": "Ġauf",
            "token_id": 5709,
            "logprob": -5.1719,
            "prob": 0.0057
          },
          {
            "token": "Ġdir",
            "token_id": 6359,
            "logprob": -5.2266,
            "prob": 0.0054
          },
          {
            "token": "Ġviele",
            "token_id": 62909,
            "logprob": -5.3594,
            "prob": 0.0047
          }
        ]
      },
      "selected_token": {
        "token": "Ġdir",
        "token_id": 6359,
        "selection_method": "sampling"
      }
    },
    {
      "step": 85,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachanforderungen zu verstehen. Ich bin entwungen, um Fragen wie \"Wer bist du?\" umfassent und kontekstabhängig zu beantwortetein können.\n\nAls KI kann ich dir",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an",
        "f",
        "orderungen",
        "Ġzu",
        "Ġverste",
        "hen",
        ".",
        "ĠIch",
        "Ġbin",
        "Ġentw",
        "ungen",
        ",",
        "Ġum",
        "ĠFragen",
        "Ġwie",
        "Ġ\"",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?\"",
        "Ġumfass",
        "ent",
        "Ġund",
        "Ġkon",
        "tekst",
        "abhäng",
        "ig",
        "Ġzu",
        "Ġbe",
        "antwort",
        "ete",
        "in",
        "Ġkönnen",
        ".",
        "\n",
        "\n",
        "Als",
        "ĠKI",
        "Ġkann",
        "Ġich",
        "Ġdir"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675,
        77, 155622, 5937, 169355, 11942, 21, 31246, 13935, 109448, 7868, 19, 2369, 163794, 9214,
        1789, 51864, 193517, 2333, 13470, 172737, 1712, 2280, 5696, 215525, 77942, 1760, 5937, 1818,
        136946, 5652, 1670, 37285, 21, 206, 206, 37229, 202056, 28963, 23909, 6359
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġbei",
            "token_id": 9174,
            "logprob": -0.1658,
            "prob": 0.8472
          },
          {
            "token": "Ġin",
            "token_id": 1709,
            "logprob": -2.4629,
            "prob": 0.0852
          },
          {
            "token": "Ġeine",
            "token_id": 7147,
            "logprob": -3.8223,
            "prob": 0.0219
          },
          {
            "token": "Ġauf",
            "token_id": 5709,
            "logprob": -4.2734,
            "prob": 0.0139
          },
          {
            "token": "ĠInformationen",
            "token_id": 114544,
            "logprob": -4.3828,
            "prob": 0.0125
          },
          {
            "token": "Ġdabei",
            "token_id": 48853,
            "logprob": -5.0703,
            "prob": 0.0063
          },
          {
            "token": "Ġhel",
            "token_id": 2941,
            "logprob": -5.3516,
            "prob": 0.0047
          },
          {
            "token": "Ġüber",
            "token_id": 9534,
            "logprob": -5.6094,
            "prob": 0.0037
          },
          {
            "token": "Ġbeim",
            "token_id": 27815,
            "logprob": -6.9609,
            "prob": 0.0009
          },
          {
            "token": "Ġnicht",
            "token_id": 12075,
            "logprob": -7.1016,
            "prob": 0.0008
          }
        ]
      },
      "selected_token": {
        "token": "Ġüber",
        "token_id": 9534,
        "selection_method": "sampling"
      }
    },
    {
      "step": 86,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachanforderungen zu verstehen. Ich bin entwungen, um Fragen wie \"Wer bist du?\" umfassent und kontekstabhängig zu beantwortetein können.\n\nAls KI kann ich dir über",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an",
        "f",
        "orderungen",
        "Ġzu",
        "Ġverste",
        "hen",
        ".",
        "ĠIch",
        "Ġbin",
        "Ġentw",
        "ungen",
        ",",
        "Ġum",
        "ĠFragen",
        "Ġwie",
        "Ġ\"",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?\"",
        "Ġumfass",
        "ent",
        "Ġund",
        "Ġkon",
        "tekst",
        "abhäng",
        "ig",
        "Ġzu",
        "Ġbe",
        "antwort",
        "ete",
        "in",
        "Ġkönnen",
        ".",
        "\n",
        "\n",
        "Als",
        "ĠKI",
        "Ġkann",
        "Ġich",
        "Ġdir",
        "Ġüber"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675,
        77, 155622, 5937, 169355, 11942, 21, 31246, 13935, 109448, 7868, 19, 2369, 163794, 9214,
        1789, 51864, 193517, 2333, 13470, 172737, 1712, 2280, 5696, 215525, 77942, 1760, 5937, 1818,
        136946, 5652, 1670, 37285, 21, 206, 206, 37229, 202056, 28963, 23909, 6359, 9534
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġeine",
            "token_id": 7147,
            "logprob": -0.0904,
            "prob": 0.9136
          },
          {
            "token": "Ġein",
            "token_id": 4001,
            "logprob": -3.0586,
            "prob": 0.0469
          },
          {
            "token": "Ġviele",
            "token_id": 62909,
            "logprob": -3.9805,
            "prob": 0.0187
          },
          {
            "token": "Ġverschiedene",
            "token_id": 79817,
            "logprob": -4.0273,
            "prob": 0.0178
          },
          {
            "token": "all",
            "token_id": 1954,
            "logprob": -6.9805,
            "prob": 0.0009
          },
          {
            "token": "Ġvielf",
            "token_id": 190708,
            "logprob": -8.1094,
            "prob": 0.0003
          },
          {
            "token": "Ġall",
            "token_id": 2157,
            "logprob": -8.2109,
            "prob": 0.0003
          },
          {
            "token": "Ġzahlreiche",
            "token_id": 79096,
            "logprob": -8.4062,
            "prob": 0.0002
          },
          {
            "token": "Ġeinen",
            "token_id": 13881,
            "logprob": -8.5547,
            "prob": 0.0002
          },
          {
            "token": "Ġviel",
            "token_id": 55989,
            "logprob": -9.3047,
            "prob": 0.0001
          }
        ]
      },
      "selected_token": {
        "token": "Ġeine",
        "token_id": 7147,
        "selection_method": "sampling"
      }
    },
    {
      "step": 87,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachanforderungen zu verstehen. Ich bin entwungen, um Fragen wie \"Wer bist du?\" umfassent und kontekstabhängig zu beantwortetein können.\n\nAls KI kann ich dir über eine",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an",
        "f",
        "orderungen",
        "Ġzu",
        "Ġverste",
        "hen",
        ".",
        "ĠIch",
        "Ġbin",
        "Ġentw",
        "ungen",
        ",",
        "Ġum",
        "ĠFragen",
        "Ġwie",
        "Ġ\"",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?\"",
        "Ġumfass",
        "ent",
        "Ġund",
        "Ġkon",
        "tekst",
        "abhäng",
        "ig",
        "Ġzu",
        "Ġbe",
        "antwort",
        "ete",
        "in",
        "Ġkönnen",
        ".",
        "\n",
        "\n",
        "Als",
        "ĠKI",
        "Ġkann",
        "Ġich",
        "Ġdir",
        "Ġüber",
        "Ġeine"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675,
        77, 155622, 5937, 169355, 11942, 21, 31246, 13935, 109448, 7868, 19, 2369, 163794, 9214,
        1789, 51864, 193517, 2333, 13470, 172737, 1712, 2280, 5696, 215525, 77942, 1760, 5937, 1818,
        136946, 5652, 1670, 37285, 21, 206, 206, 37229, 202056, 28963, 23909, 6359, 9534, 7147
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "ĠVielzahl",
            "token_id": 227271,
            "logprob": -0.0316,
            "prob": 0.9688
          },
          {
            "token": "Ġbre",
            "token_id": 4014,
            "logprob": -4.0625,
            "prob": 0.0172
          },
          {
            "token": "ĠF",
            "token_id": 1795,
            "logprob": -4.6875,
            "prob": 0.0092
          },
          {
            "token": "Ġgroße",
            "token_id": 52932,
            "logprob": -5.9219,
            "prob": 0.0027
          },
          {
            "token": "ĠReihe",
            "token_id": 79079,
            "logprob": -6.8281,
            "prob": 0.0011
          },
          {
            "token": "ĠVi",
            "token_id": 14099,
            "logprob": -8.4609,
            "prob": 0.0002
          },
          {
            "token": "ĠMenge",
            "token_id": 189167,
            "logprob": -8.8281,
            "prob": 0.0001
          },
          {
            "token": "ĠBreite",
            "token_id": 184572,
            "logprob": -9.4922,
            "prob": 0.0001
          },
          {
            "token": "ĠBand",
            "token_id": 9370,
            "logprob": -10.375,
            "prob": 0.0
          },
          {
            "token": "Ġumfang",
            "token_id": 148109,
            "logprob": -10.4297,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġbre",
        "token_id": 4014,
        "selection_method": "sampling"
      }
    },
    {
      "step": 88,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachanforderungen zu verstehen. Ich bin entwungen, um Fragen wie \"Wer bist du?\" umfassent und kontekstabhängig zu beantwortetein können.\n\nAls KI kann ich dir über eine bre",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an",
        "f",
        "orderungen",
        "Ġzu",
        "Ġverste",
        "hen",
        ".",
        "ĠIch",
        "Ġbin",
        "Ġentw",
        "ungen",
        ",",
        "Ġum",
        "ĠFragen",
        "Ġwie",
        "Ġ\"",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?\"",
        "Ġumfass",
        "ent",
        "Ġund",
        "Ġkon",
        "tekst",
        "abhäng",
        "ig",
        "Ġzu",
        "Ġbe",
        "antwort",
        "ete",
        "in",
        "Ġkönnen",
        ".",
        "\n",
        "\n",
        "Als",
        "ĠKI",
        "Ġkann",
        "Ġich",
        "Ġdir",
        "Ġüber",
        "Ġeine",
        "Ġbre"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675,
        77, 155622, 5937, 169355, 11942, 21, 31246, 13935, 109448, 7868, 19, 2369, 163794, 9214,
        1789, 51864, 193517, 2333, 13470, 172737, 1712, 2280, 5696, 215525, 77942, 1760, 5937, 1818,
        136946, 5652, 1670, 37285, 21, 206, 206, 37229, 202056, 28963, 23909, 6359, 9534, 7147, 4014
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "ite",
            "token_id": 2114,
            "logprob": -0.0002,
            "prob": 1.0
          },
          {
            "token": "ites",
            "token_id": 4307,
            "logprob": -10.5078,
            "prob": 0.0
          },
          {
            "token": "itte",
            "token_id": 6812,
            "logprob": -11.4766,
            "prob": 0.0
          },
          {
            "token": "iti",
            "token_id": 8695,
            "logprob": -11.4766,
            "prob": 0.0
          },
          {
            "token": "ita",
            "token_id": 3631,
            "logprob": -11.6094,
            "prob": 0.0
          },
          {
            "token": "itere",
            "token_id": 75807,
            "logprob": -11.9453,
            "prob": 0.0
          },
          {
            "token": "iten",
            "token_id": 9505,
            "logprob": -12.1484,
            "prob": 0.0
          },
          {
            "token": "ITE",
            "token_id": 20544,
            "logprob": -12.2188,
            "prob": 0.0
          },
          {
            "token": "ito",
            "token_id": 3726,
            "logprob": -12.3281,
            "prob": 0.0
          },
          {
            "token": "iter",
            "token_id": 3412,
            "logprob": -12.4844,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "ites",
        "token_id": 4307,
        "selection_method": "sampling"
      }
    },
    {
      "step": 89,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachanforderungen zu verstehen. Ich bin entwungen, um Fragen wie \"Wer bist du?\" umfassent und kontekstabhängig zu beantwortetein können.\n\nAls KI kann ich dir über eine breites",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an",
        "f",
        "orderungen",
        "Ġzu",
        "Ġverste",
        "hen",
        ".",
        "ĠIch",
        "Ġbin",
        "Ġentw",
        "ungen",
        ",",
        "Ġum",
        "ĠFragen",
        "Ġwie",
        "Ġ\"",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?\"",
        "Ġumfass",
        "ent",
        "Ġund",
        "Ġkon",
        "tekst",
        "abhäng",
        "ig",
        "Ġzu",
        "Ġbe",
        "antwort",
        "ete",
        "in",
        "Ġkönnen",
        ".",
        "\n",
        "\n",
        "Als",
        "ĠKI",
        "Ġkann",
        "Ġich",
        "Ġdir",
        "Ġüber",
        "Ġeine",
        "Ġbre",
        "ites"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675,
        77, 155622, 5937, 169355, 11942, 21, 31246, 13935, 109448, 7868, 19, 2369, 163794, 9214,
        1789, 51864, 193517, 2333, 13470, 172737, 1712, 2280, 5696, 215525, 77942, 1760, 5937, 1818,
        136946, 5652, 1670, 37285, 21, 206, 206, 37229, 202056, 28963, 23909, 6359, 9534, 7147,
        4014, 4307
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "ĠSpektrum",
            "token_id": 249763,
            "logprob": -0.0364,
            "prob": 0.9644
          },
          {
            "token": "ĠThem",
            "token_id": 76826,
            "logprob": -3.5371,
            "prob": 0.0291
          },
          {
            "token": "ĠSpe",
            "token_id": 10496,
            "logprob": -5.8633,
            "prob": 0.0028
          },
          {
            "token": "ĠThemen",
            "token_id": 126575,
            "logprob": -6.9258,
            "prob": 0.001
          },
          {
            "token": "ĠFeld",
            "token_id": 38824,
            "logprob": -7.0586,
            "prob": 0.0009
          },
          {
            "token": "ĠPalette",
            "token_id": 163886,
            "logprob": -7.3242,
            "prob": 0.0007
          },
          {
            "token": "ĠThema",
            "token_id": 111704,
            "logprob": -8.5391,
            "prob": 0.0002
          },
          {
            "token": "ĠBereich",
            "token_id": 65015,
            "logprob": -9.6094,
            "prob": 0.0001
          },
          {
            "token": "ĠArray",
            "token_id": 14786,
            "logprob": -10.1172,
            "prob": 0.0
          },
          {
            "token": "ĠSpann",
            "token_id": 132425,
            "logprob": -10.2109,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "ĠSpe",
        "token_id": 10496,
        "selection_method": "sampling"
      }
    },
    {
      "step": 90,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachanforderungen zu verstehen. Ich bin entwungen, um Fragen wie \"Wer bist du?\" umfassent und kontekstabhängig zu beantwortetein können.\n\nAls KI kann ich dir über eine breites Spe",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an",
        "f",
        "orderungen",
        "Ġzu",
        "Ġverste",
        "hen",
        ".",
        "ĠIch",
        "Ġbin",
        "Ġentw",
        "ungen",
        ",",
        "Ġum",
        "ĠFragen",
        "Ġwie",
        "Ġ\"",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?\"",
        "Ġumfass",
        "ent",
        "Ġund",
        "Ġkon",
        "tekst",
        "abhäng",
        "ig",
        "Ġzu",
        "Ġbe",
        "antwort",
        "ete",
        "in",
        "Ġkönnen",
        ".",
        "\n",
        "\n",
        "Als",
        "ĠKI",
        "Ġkann",
        "Ġich",
        "Ġdir",
        "Ġüber",
        "Ġeine",
        "Ġbre",
        "ites",
        "ĠSpe"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675,
        77, 155622, 5937, 169355, 11942, 21, 31246, 13935, 109448, 7868, 19, 2369, 163794, 9214,
        1789, 51864, 193517, 2333, 13470, 172737, 1712, 2280, 5696, 215525, 77942, 1760, 5937, 1818,
        136946, 5652, 1670, 37285, 21, 206, 206, 37229, 202056, 28963, 23909, 6359, 9534, 7147,
        4014, 4307, 10496
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "ktr",
            "token_id": 18603,
            "logprob": -0.4304,
            "prob": 0.6504
          },
          {
            "token": "ktrum",
            "token_id": 129707,
            "logprob": -2.0391,
            "prob": 0.13
          },
          {
            "token": "k",
            "token_id": 82,
            "logprob": -2.1016,
            "prob": 0.1222
          },
          {
            "token": "kt",
            "token_id": 3623,
            "logprob": -2.5547,
            "prob": 0.0776
          },
          {
            "token": "kk",
            "token_id": 57751,
            "logprob": -5.5938,
            "prob": 0.0037
          },
          {
            "token": "ktor",
            "token_id": 17991,
            "logprob": -5.6719,
            "prob": 0.0034
          },
          {
            "token": "kter",
            "token_id": 81663,
            "logprob": -5.9297,
            "prob": 0.0027
          },
          {
            "token": "ktur",
            "token_id": 26819,
            "logprob": -6.1797,
            "prob": 0.0021
          },
          {
            "token": "ktar",
            "token_id": 105360,
            "logprob": -7.2109,
            "prob": 0.0007
          },
          {
            "token": "kte",
            "token_id": 49368,
            "logprob": -7.7578,
            "prob": 0.0004
          }
        ]
      },
      "selected_token": {
        "token": "ktr",
        "token_id": 18603,
        "selection_method": "sampling"
      }
    },
    {
      "step": 91,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachanforderungen zu verstehen. Ich bin entwungen, um Fragen wie \"Wer bist du?\" umfassent und kontekstabhängig zu beantwortetein können.\n\nAls KI kann ich dir über eine breites Spektr",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an",
        "f",
        "orderungen",
        "Ġzu",
        "Ġverste",
        "hen",
        ".",
        "ĠIch",
        "Ġbin",
        "Ġentw",
        "ungen",
        ",",
        "Ġum",
        "ĠFragen",
        "Ġwie",
        "Ġ\"",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?\"",
        "Ġumfass",
        "ent",
        "Ġund",
        "Ġkon",
        "tekst",
        "abhäng",
        "ig",
        "Ġzu",
        "Ġbe",
        "antwort",
        "ete",
        "in",
        "Ġkönnen",
        ".",
        "\n",
        "\n",
        "Als",
        "ĠKI",
        "Ġkann",
        "Ġich",
        "Ġdir",
        "Ġüber",
        "Ġeine",
        "Ġbre",
        "ites",
        "ĠSpe",
        "ktr"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675,
        77, 155622, 5937, 169355, 11942, 21, 31246, 13935, 109448, 7868, 19, 2369, 163794, 9214,
        1789, 51864, 193517, 2333, 13470, 172737, 1712, 2280, 5696, 215525, 77942, 1760, 5937, 1818,
        136946, 5652, 1670, 37285, 21, 206, 206, 37229, 202056, 28963, 23909, 6359, 9534, 7147,
        4014, 4307, 10496, 18603
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "en",
            "token_id": 1673,
            "logprob": -0.2267,
            "prob": 0.7974
          },
          {
            "token": "um",
            "token_id": 1783,
            "logprob": -1.6953,
            "prob": 0.1835
          },
          {
            "token": "ums",
            "token_id": 9249,
            "logprob": -4.3203,
            "prob": 0.0133
          },
          {
            "token": "al",
            "token_id": 1687,
            "logprob": -5.9297,
            "prob": 0.0027
          },
          {
            "token": "un",
            "token_id": 1743,
            "logprob": -6.5078,
            "prob": 0.0015
          },
          {
            "token": "an",
            "token_id": 1675,
            "logprob": -7.0078,
            "prob": 0.0009
          },
          {
            "token": "am",
            "token_id": 1722,
            "logprob": -7.9297,
            "prob": 0.0004
          },
          {
            "token": "üm",
            "token_id": 7721,
            "logprob": -9.4609,
            "prob": 0.0001
          },
          {
            "token": "umm",
            "token_id": 4273,
            "logprob": -9.5078,
            "prob": 0.0001
          },
          {
            "token": "Ġan",
            "token_id": 1844,
            "logprob": -9.5547,
            "prob": 0.0001
          }
        ]
      },
      "selected_token": {
        "token": "al",
        "token_id": 1687,
        "selection_method": "sampling"
      }
    },
    {
      "step": 92,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachanforderungen zu verstehen. Ich bin entwungen, um Fragen wie \"Wer bist du?\" umfassent und kontekstabhängig zu beantwortetein können.\n\nAls KI kann ich dir über eine breites Spektral",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an",
        "f",
        "orderungen",
        "Ġzu",
        "Ġverste",
        "hen",
        ".",
        "ĠIch",
        "Ġbin",
        "Ġentw",
        "ungen",
        ",",
        "Ġum",
        "ĠFragen",
        "Ġwie",
        "Ġ\"",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?\"",
        "Ġumfass",
        "ent",
        "Ġund",
        "Ġkon",
        "tekst",
        "abhäng",
        "ig",
        "Ġzu",
        "Ġbe",
        "antwort",
        "ete",
        "in",
        "Ġkönnen",
        ".",
        "\n",
        "\n",
        "Als",
        "ĠKI",
        "Ġkann",
        "Ġich",
        "Ġdir",
        "Ġüber",
        "Ġeine",
        "Ġbre",
        "ites",
        "ĠSpe",
        "ktr",
        "al"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675,
        77, 155622, 5937, 169355, 11942, 21, 31246, 13935, 109448, 7868, 19, 2369, 163794, 9214,
        1789, 51864, 193517, 2333, 13470, 172737, 1712, 2280, 5696, 215525, 77942, 1760, 5937, 1818,
        136946, 5652, 1670, 37285, 21, 206, 206, 37229, 202056, 28963, 23909, 6359, 9534, 7147,
        4014, 4307, 10496, 18603, 1687
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġan",
            "token_id": 1844,
            "logprob": -0.0464,
            "prob": 0.9546
          },
          {
            "token": "Ġvon",
            "token_id": 3615,
            "logprob": -3.1406,
            "prob": 0.0433
          },
          {
            "token": "Ġder",
            "token_id": 2479,
            "logprob": -7.1094,
            "prob": 0.0008
          },
          {
            "token": "Ġthem",
            "token_id": 2747,
            "logprob": -7.6406,
            "prob": 0.0005
          },
          {
            "token": "ĠThemen",
            "token_id": 126575,
            "logprob": -7.9531,
            "prob": 0.0004
          },
          {
            "token": "Ġverschiedener",
            "token_id": 182058,
            "logprob": -8.9453,
            "prob": 0.0001
          },
          {
            "token": "ĠWissen",
            "token_id": 195696,
            "logprob": -9.9844,
            "prob": 0.0
          },
          {
            "token": "the",
            "token_id": 3798,
            "logprob": -10.8359,
            "prob": 0.0
          },
          {
            "token": "Ġunterschied",
            "token_id": 69253,
            "logprob": -11.0156,
            "prob": 0.0
          },
          {
            "token": "Ġthe",
            "token_id": 1690,
            "logprob": -11.2734,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "Ġan",
        "token_id": 1844,
        "selection_method": "sampling"
      }
    },
    {
      "step": 93,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachanforderungen zu verstehen. Ich bin entwungen, um Fragen wie \"Wer bist du?\" umfassent und kontekstabhängig zu beantwortetein können.\n\nAls KI kann ich dir über eine breites Spektral an",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an",
        "f",
        "orderungen",
        "Ġzu",
        "Ġverste",
        "hen",
        ".",
        "ĠIch",
        "Ġbin",
        "Ġentw",
        "ungen",
        ",",
        "Ġum",
        "ĠFragen",
        "Ġwie",
        "Ġ\"",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?\"",
        "Ġumfass",
        "ent",
        "Ġund",
        "Ġkon",
        "tekst",
        "abhäng",
        "ig",
        "Ġzu",
        "Ġbe",
        "antwort",
        "ete",
        "in",
        "Ġkönnen",
        ".",
        "\n",
        "\n",
        "Als",
        "ĠKI",
        "Ġkann",
        "Ġich",
        "Ġdir",
        "Ġüber",
        "Ġeine",
        "Ġbre",
        "ites",
        "ĠSpe",
        "ktr",
        "al",
        "Ġan"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675,
        77, 155622, 5937, 169355, 11942, 21, 31246, 13935, 109448, 7868, 19, 2369, 163794, 9214,
        1789, 51864, 193517, 2333, 13470, 172737, 1712, 2280, 5696, 215525, 77942, 1760, 5937, 1818,
        136946, 5652, 1670, 37285, 21, 206, 206, 37229, 202056, 28963, 23909, 6359, 9534, 7147,
        4014, 4307, 10496, 18603, 1687, 1844
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "ĠThemen",
            "token_id": 126575,
            "logprob": -0.0123,
            "prob": 0.9878
          },
          {
            "token": "ĠInformationen",
            "token_id": 114544,
            "logprob": -4.5586,
            "prob": 0.0105
          },
          {
            "token": "ĠWissen",
            "token_id": 195696,
            "logprob": -6.8867,
            "prob": 0.001
          },
          {
            "token": "ĠWiss",
            "token_id": 127629,
            "logprob": -8.1719,
            "prob": 0.0003
          },
          {
            "token": "ĠThema",
            "token_id": 111704,
            "logprob": -8.9141,
            "prob": 0.0001
          },
          {
            "token": "ĠInformation",
            "token_id": 12814,
            "logprob": -9.0,
            "prob": 0.0001
          },
          {
            "token": "ĠInformations",
            "token_id": 137824,
            "logprob": -10.3906,
            "prob": 0.0
          },
          {
            "token": "ĠTopics",
            "token_id": 113522,
            "logprob": -10.6016,
            "prob": 0.0
          },
          {
            "token": "ĠThem",
            "token_id": 76826,
            "logprob": -11.4062,
            "prob": 0.0
          },
          {
            "token": "ĠBereichen",
            "token_id": 217949,
            "logprob": -12.3438,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "ĠThemen",
        "token_id": 126575,
        "selection_method": "sampling"
      }
    },
    {
      "step": 94,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachanforderungen zu verstehen. Ich bin entwungen, um Fragen wie \"Wer bist du?\" umfassent und kontekstabhängig zu beantwortetein können.\n\nAls KI kann ich dir über eine breites Spektral an Themen",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an",
        "f",
        "orderungen",
        "Ġzu",
        "Ġverste",
        "hen",
        ".",
        "ĠIch",
        "Ġbin",
        "Ġentw",
        "ungen",
        ",",
        "Ġum",
        "ĠFragen",
        "Ġwie",
        "Ġ\"",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?\"",
        "Ġumfass",
        "ent",
        "Ġund",
        "Ġkon",
        "tekst",
        "abhäng",
        "ig",
        "Ġzu",
        "Ġbe",
        "antwort",
        "ete",
        "in",
        "Ġkönnen",
        ".",
        "\n",
        "\n",
        "Als",
        "ĠKI",
        "Ġkann",
        "Ġich",
        "Ġdir",
        "Ġüber",
        "Ġeine",
        "Ġbre",
        "ites",
        "ĠSpe",
        "ktr",
        "al",
        "Ġan",
        "ĠThemen"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675,
        77, 155622, 5937, 169355, 11942, 21, 31246, 13935, 109448, 7868, 19, 2369, 163794, 9214,
        1789, 51864, 193517, 2333, 13470, 172737, 1712, 2280, 5696, 215525, 77942, 1760, 5937, 1818,
        136946, 5652, 1670, 37285, 21, 206, 206, 37229, 202056, 28963, 23909, 6359, 9534, 7147,
        4014, 4307, 10496, 18603, 1687, 1844, 126575
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "ĠInformationen",
            "token_id": 114544,
            "logprob": -0.1715,
            "prob": 0.8423
          },
          {
            "token": "Ġhel",
            "token_id": 2941,
            "logprob": -2.125,
            "prob": 0.1194
          },
          {
            "token": "Ġinform",
            "token_id": 3188,
            "logprob": -4.3125,
            "prob": 0.0134
          },
          {
            "token": "Ġant",
            "token_id": 4752,
            "logprob": -5.0547,
            "prob": 0.0064
          },
          {
            "token": "ĠAus",
            "token_id": 12761,
            "logprob": -5.8984,
            "prob": 0.0027
          },
          {
            "token": "ĠInformation",
            "token_id": 12814,
            "logprob": -6.0312,
            "prob": 0.0024
          },
          {
            "token": "Ġhin",
            "token_id": 52619,
            "logprob": -6.2656,
            "prob": 0.0019
          },
          {
            "token": "ĠAnt",
            "token_id": 4463,
            "logprob": -6.3125,
            "prob": 0.0018
          },
          {
            "token": "ĠBes",
            "token_id": 16588,
            "logprob": -6.8047,
            "prob": 0.0011
          },
          {
            "token": "Ġbeh",
            "token_id": 5264,
            "logprob": -6.9922,
            "prob": 0.0009
          }
        ]
      },
      "selected_token": {
        "token": "ĠBes",
        "token_id": 16588,
        "selection_method": "sampling"
      }
    },
    {
      "step": 95,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachanforderungen zu verstehen. Ich bin entwungen, um Fragen wie \"Wer bist du?\" umfassent und kontekstabhängig zu beantwortetein können.\n\nAls KI kann ich dir über eine breites Spektral an Themen Bes",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an",
        "f",
        "orderungen",
        "Ġzu",
        "Ġverste",
        "hen",
        ".",
        "ĠIch",
        "Ġbin",
        "Ġentw",
        "ungen",
        ",",
        "Ġum",
        "ĠFragen",
        "Ġwie",
        "Ġ\"",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?\"",
        "Ġumfass",
        "ent",
        "Ġund",
        "Ġkon",
        "tekst",
        "abhäng",
        "ig",
        "Ġzu",
        "Ġbe",
        "antwort",
        "ete",
        "in",
        "Ġkönnen",
        ".",
        "\n",
        "\n",
        "Als",
        "ĠKI",
        "Ġkann",
        "Ġich",
        "Ġdir",
        "Ġüber",
        "Ġeine",
        "Ġbre",
        "ites",
        "ĠSpe",
        "ktr",
        "al",
        "Ġan",
        "ĠThemen",
        "ĠBes"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675,
        77, 155622, 5937, 169355, 11942, 21, 31246, 13935, 109448, 7868, 19, 2369, 163794, 9214,
        1789, 51864, 193517, 2333, 13470, 172737, 1712, 2280, 5696, 215525, 77942, 1760, 5937, 1818,
        136946, 5652, 1670, 37285, 21, 206, 206, 37229, 202056, 28963, 23909, 6359, 9534, 7147,
        4014, 4307, 10496, 18603, 1687, 1844, 126575, 16588
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "cheid",
            "token_id": 46042,
            "logprob": -0.0004,
            "prob": 0.9995
          },
          {
            "token": "che",
            "token_id": 2290,
            "logprob": -8.4219,
            "prob": 0.0002
          },
          {
            "token": "cheiden",
            "token_id": 59543,
            "logprob": -9.7734,
            "prob": 0.0001
          },
          {
            "token": "chein",
            "token_id": 145014,
            "logprob": -9.8906,
            "prob": 0.0001
          },
          {
            "token": "org",
            "token_id": 3270,
            "logprob": -11.1562,
            "prob": 0.0
          },
          {
            "token": "icht",
            "token_id": 5076,
            "logprob": -11.5078,
            "prob": 0.0
          },
          {
            "token": "ag",
            "token_id": 1786,
            "logprob": -12.25,
            "prob": 0.0
          },
          {
            "token": "inn",
            "token_id": 2949,
            "logprob": -12.5469,
            "prob": 0.0
          },
          {
            "token": "uche",
            "token_id": 33075,
            "logprob": -12.6797,
            "prob": 0.0
          },
          {
            "token": "chaft",
            "token_id": 9206,
            "logprob": -12.9219,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "cheid",
        "token_id": 46042,
        "selection_method": "sampling"
      }
    },
    {
      "step": 96,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachanforderungen zu verstehen. Ich bin entwungen, um Fragen wie \"Wer bist du?\" umfassent und kontekstabhängig zu beantwortetein können.\n\nAls KI kann ich dir über eine breites Spektral an Themen Bescheid",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an",
        "f",
        "orderungen",
        "Ġzu",
        "Ġverste",
        "hen",
        ".",
        "ĠIch",
        "Ġbin",
        "Ġentw",
        "ungen",
        ",",
        "Ġum",
        "ĠFragen",
        "Ġwie",
        "Ġ\"",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?\"",
        "Ġumfass",
        "ent",
        "Ġund",
        "Ġkon",
        "tekst",
        "abhäng",
        "ig",
        "Ġzu",
        "Ġbe",
        "antwort",
        "ete",
        "in",
        "Ġkönnen",
        ".",
        "\n",
        "\n",
        "Als",
        "ĠKI",
        "Ġkann",
        "Ġich",
        "Ġdir",
        "Ġüber",
        "Ġeine",
        "Ġbre",
        "ites",
        "ĠSpe",
        "ktr",
        "al",
        "Ġan",
        "ĠThemen",
        "ĠBes",
        "cheid"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675,
        77, 155622, 5937, 169355, 11942, 21, 31246, 13935, 109448, 7868, 19, 2369, 163794, 9214,
        1789, 51864, 193517, 2333, 13470, 172737, 1712, 2280, 5696, 215525, 77942, 1760, 5937, 1818,
        136946, 5652, 1670, 37285, 21, 206, 206, 37229, 202056, 28963, 23909, 6359, 9534, 7147,
        4014, 4307, 10496, 18603, 1687, 1844, 126575, 16588, 46042
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġgeben",
            "token_id": 138823,
            "logprob": -0.1366,
            "prob": 0.8726
          },
          {
            "token": "Ġw",
            "token_id": 1695,
            "logprob": -2.1523,
            "prob": 0.1162
          },
          {
            "token": "Ġs",
            "token_id": 1679,
            "logprob": -4.8789,
            "prob": 0.0076
          },
          {
            "token": "Ġversch",
            "token_id": 17110,
            "logprob": -6.1992,
            "prob": 0.002
          },
          {
            "token": "Ġgeven",
            "token_id": 78562,
            "logprob": -8.7266,
            "prob": 0.0002
          },
          {
            "token": "geben",
            "token_id": 32950,
            "logprob": -8.8594,
            "prob": 0.0001
          },
          {
            "token": "w",
            "token_id": 94,
            "logprob": -9.4375,
            "prob": 0.0001
          },
          {
            "token": "Ġhel",
            "token_id": 2941,
            "logprob": -9.5312,
            "prob": 0.0001
          },
          {
            "token": "Ġgegeben",
            "token_id": 120569,
            "logprob": -9.5781,
            "prob": 0.0001
          },
          {
            "token": "Ġweiß",
            "token_id": 116417,
            "logprob": -9.6406,
            "prob": 0.0001
          }
        ]
      },
      "selected_token": {
        "token": "Ġs",
        "token_id": 1679,
        "selection_method": "sampling"
      }
    },
    {
      "step": 97,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachanforderungen zu verstehen. Ich bin entwungen, um Fragen wie \"Wer bist du?\" umfassent und kontekstabhängig zu beantwortetein können.\n\nAls KI kann ich dir über eine breites Spektral an Themen Bescheid s",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an",
        "f",
        "orderungen",
        "Ġzu",
        "Ġverste",
        "hen",
        ".",
        "ĠIch",
        "Ġbin",
        "Ġentw",
        "ungen",
        ",",
        "Ġum",
        "ĠFragen",
        "Ġwie",
        "Ġ\"",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?\"",
        "Ġumfass",
        "ent",
        "Ġund",
        "Ġkon",
        "tekst",
        "abhäng",
        "ig",
        "Ġzu",
        "Ġbe",
        "antwort",
        "ete",
        "in",
        "Ġkönnen",
        ".",
        "\n",
        "\n",
        "Als",
        "ĠKI",
        "Ġkann",
        "Ġich",
        "Ġdir",
        "Ġüber",
        "Ġeine",
        "Ġbre",
        "ites",
        "ĠSpe",
        "ktr",
        "al",
        "Ġan",
        "ĠThemen",
        "ĠBes",
        "cheid",
        "Ġs"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675,
        77, 155622, 5937, 169355, 11942, 21, 31246, 13935, 109448, 7868, 19, 2369, 163794, 9214,
        1789, 51864, 193517, 2333, 13470, 172737, 1712, 2280, 5696, 215525, 77942, 1760, 5937, 1818,
        136946, 5652, 1670, 37285, 21, 206, 206, 37229, 202056, 28963, 23909, 6359, 9534, 7147,
        4014, 4307, 10496, 18603, 1687, 1844, 126575, 16588, 46042, 1679
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "agen",
            "token_id": 9714,
            "logprob": -0.0,
            "prob": 1.0
          },
          {
            "token": "agt",
            "token_id": 36905,
            "logprob": -14.0781,
            "prob": 0.0
          },
          {
            "token": "orgen",
            "token_id": 60336,
            "logprob": -15.0234,
            "prob": 0.0
          },
          {
            "token": "ag",
            "token_id": 1786,
            "logprob": -17.2969,
            "prob": 0.0
          },
          {
            "token": "<SEP>",
            "token_id": 3,
            "logprob": -31.125,
            "prob": 0.0
          },
          {
            "token": "<CLS>",
            "token_id": 2,
            "logprob": -30.75,
            "prob": 0.0
          },
          {
            "token": "<MASK_TOKEN>",
            "token_id": 4,
            "logprob": -31.1094,
            "prob": 0.0
          },
          {
            "token": "<BOS_TOKEN>",
            "token_id": 5,
            "logprob": -28.8594,
            "prob": 0.0
          },
          {
            "token": "<PAD>",
            "token_id": 0,
            "logprob": -31.0,
            "prob": 0.0
          },
          {
            "token": "<UNK>",
            "token_id": 1,
            "logprob": -30.3281,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": "agen",
        "token_id": 9714,
        "selection_method": "sampling"
      }
    },
    {
      "step": 98,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachanforderungen zu verstehen. Ich bin entwungen, um Fragen wie \"Wer bist du?\" umfassent und kontekstabhängig zu beantwortetein können.\n\nAls KI kann ich dir über eine breites Spektral an Themen Bescheid sagen",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an",
        "f",
        "orderungen",
        "Ġzu",
        "Ġverste",
        "hen",
        ".",
        "ĠIch",
        "Ġbin",
        "Ġentw",
        "ungen",
        ",",
        "Ġum",
        "ĠFragen",
        "Ġwie",
        "Ġ\"",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?\"",
        "Ġumfass",
        "ent",
        "Ġund",
        "Ġkon",
        "tekst",
        "abhäng",
        "ig",
        "Ġzu",
        "Ġbe",
        "antwort",
        "ete",
        "in",
        "Ġkönnen",
        ".",
        "\n",
        "\n",
        "Als",
        "ĠKI",
        "Ġkann",
        "Ġich",
        "Ġdir",
        "Ġüber",
        "Ġeine",
        "Ġbre",
        "ites",
        "ĠSpe",
        "ktr",
        "al",
        "Ġan",
        "ĠThemen",
        "ĠBes",
        "cheid",
        "Ġs",
        "agen"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675,
        77, 155622, 5937, 169355, 11942, 21, 31246, 13935, 109448, 7868, 19, 2369, 163794, 9214,
        1789, 51864, 193517, 2333, 13470, 172737, 1712, 2280, 5696, 215525, 77942, 1760, 5937, 1818,
        136946, 5652, 1670, 37285, 21, 206, 206, 37229, 202056, 28963, 23909, 6359, 9534, 7147,
        4014, 4307, 10496, 18603, 1687, 1844, 126575, 16588, 46042, 1679, 9714
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": ",",
            "token_id": 19,
            "logprob": -0.007,
            "prob": 0.9932
          },
          {
            "token": ".",
            "token_id": 21,
            "logprob": -5.8672,
            "prob": 0.0028
          },
          {
            "token": "Ġund",
            "token_id": 2280,
            "logprob": -6.4141,
            "prob": 0.0016
          },
          {
            "token": ":",
            "token_id": 33,
            "logprob": -6.4453,
            "prob": 0.0016
          },
          {
            "token": "Ġ-",
            "token_id": 1945,
            "logprob": -7.8516,
            "prob": 0.0004
          },
          {
            "token": "Ġoder",
            "token_id": 13624,
            "logprob": -8.4609,
            "prob": 0.0002
          },
          {
            "token": "Ġ–",
            "token_id": 2129,
            "logprob": -8.7266,
            "prob": 0.0002
          },
          {
            "token": ";",
            "token_id": 34,
            "logprob": -9.2734,
            "prob": 0.0001
          },
          {
            "token": "Ġ(",
            "token_id": 1737,
            "logprob": -9.7422,
            "prob": 0.0001
          },
          {
            "token": "Ġ—",
            "token_id": 2518,
            "logprob": -13.3047,
            "prob": 0.0
          }
        ]
      },
      "selected_token": {
        "token": ":",
        "token_id": 33,
        "selection_method": "sampling"
      }
    },
    {
      "step": 99,
      "input_text": "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Wer bist du?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>Ich bin ein virtuell intelligenter Assistant oder, kurz beschrieben, ein Chatbot-System. Ich war zuvor ein Teil eines größeren sprachverarbeitenden Computerprogramms (NLP), das entwickelt wurde, um natürliche Sprachanforderungen zu verstehen. Ich bin entwungen, um Fragen wie \"Wer bist du?\" umfassent und kontekstabhängig zu beantwortetein können.\n\nAls KI kann ich dir über eine breites Spektral an Themen Bescheid sagen:",
      "tokens": [
        "<BOS_TOKEN>",
        "<|START_OF_TURN_TOKEN|>",
        "<|USER_TOKEN|>",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?",
        "<|END_OF_TURN_TOKEN|>",
        "<|START_OF_TURN_TOKEN|>",
        "<|CHATBOT_TOKEN|>",
        "Ich",
        "Ġbin",
        "Ġein",
        "Ġvirtu",
        "ell",
        "Ġintellig",
        "enter",
        "ĠAssistant",
        "Ġoder",
        ",",
        "Ġkurz",
        "Ġbeschrieben",
        ",",
        "Ġein",
        "ĠChat",
        "bot",
        "-",
        "System",
        ".",
        "ĠIch",
        "Ġwar",
        "Ġzuvor",
        "Ġein",
        "ĠTeil",
        "Ġeines",
        "Ġgrößeren",
        "Ġsprach",
        "ver",
        "arbeit",
        "enden",
        "ĠComputer",
        "program",
        "ms",
        "Ġ(",
        "NLP",
        "),",
        "Ġdas",
        "Ġentwickelt",
        "Ġwurde",
        ",",
        "Ġum",
        "Ġnatür",
        "liche",
        "ĠSprach",
        "an",
        "f",
        "orderungen",
        "Ġzu",
        "Ġverste",
        "hen",
        ".",
        "ĠIch",
        "Ġbin",
        "Ġentw",
        "ungen",
        ",",
        "Ġum",
        "ĠFragen",
        "Ġwie",
        "Ġ\"",
        "Wer",
        "Ġbist",
        "Ġdu",
        "?\"",
        "Ġumfass",
        "ent",
        "Ġund",
        "Ġkon",
        "tekst",
        "abhäng",
        "ig",
        "Ġzu",
        "Ġbe",
        "antwort",
        "ete",
        "in",
        "Ġkönnen",
        ".",
        "\n",
        "\n",
        "Als",
        "ĠKI",
        "Ġkann",
        "Ġich",
        "Ġdir",
        "Ġüber",
        "Ġeine",
        "Ġbre",
        "ites",
        "ĠSpe",
        "ktr",
        "al",
        "Ġan",
        "ĠThemen",
        "ĠBes",
        "cheid",
        "Ġs",
        "agen",
        ":"
      ],
      "token_ids": [
        5, 255000, 255006, 51864, 193517, 2333, 38, 255001, 255000, 255007, 75903, 13935, 4001,
        151628, 1947, 34008, 12178, 25236, 13624, 19, 59652, 130631, 19, 4001, 41573, 10278, 20,
        8808, 21, 31246, 4341, 81901, 4001, 22815, 20792, 142081, 156708, 1901, 41678, 11404, 26053,
        23510, 3549, 1737, 176213, 1969, 4031, 105064, 6149, 19, 2369, 131901, 13651, 100809, 1675,
        77, 155622, 5937, 169355, 11942, 21, 31246, 13935, 109448, 7868, 19, 2369, 163794, 9214,
        1789, 51864, 193517, 2333, 13470, 172737, 1712, 2280, 5696, 215525, 77942, 1760, 5937, 1818,
        136946, 5652, 1670, 37285, 21, 206, 206, 37229, 202056, 28963, 23909, 6359, 9534, 7147,
        4014, 4307, 10496, 18603, 1687, 1844, 126575, 16588, 46042, 1679, 9714, 33
      ],
      "output_distribution": {
        "top_k": 10,
        "candidates": [
          {
            "token": "Ġvon",
            "token_id": 3615,
            "logprob": -0.8574,
            "prob": 0.4243
          },
          {
            "token": "ĠIch",
            "token_id": 31246,
            "logprob": -1.1074,
            "prob": 0.3306
          },
          {
            "token": "\n",
            "token_id": 206,
            "logprob": -1.7793,
            "prob": 0.1688
          },
          {
            "token": "\n\n",
            "token_id": 2126,
            "logprob": -3.4824,
            "prob": 0.0307
          },
          {
            "token": "Ġich",
            "token_id": 23909,
            "logprob": -3.6074,
            "prob": 0.0271
          },
          {
            "token": "ĠVon",
            "token_id": 24447,
            "logprob": -4.4023,
            "prob": 0.0122
          },
          {
            "token": "Ġ\n",
            "token_id": 1973,
            "logprob": -6.6445,
            "prob": 0.0013
          },
          {
            "token": "ĠOb",
            "token_id": 6193,
            "logprob": -7.4023,
            "prob": 0.0006
          },
          {
            "token": "ĠWir",
            "token_id": 46711,
            "logprob": -7.707,
            "prob": 0.0004
          },
          {
            "token": "Ġvom",
            "token_id": 15310,
            "logprob": -7.8398,
            "prob": 0.0004
          }
        ]
      },
      "selected_token": {
        "token": "Ġ\n",
        "token_id": 1973,
        "selection_method": "sampling"
      }
    }
  ]
}
