{
  "examples": [
    {
      "id": "cs-001-full-Vanilla_Transformer__1.2B_",
      "type": "training",
      "prompt": "Velký jazykový model (anglicky large language model – zkráceně LLM) je počítačový model jazyka založ...",
      "language": "cs",
      "description": "Velký jazykový model (anglicky large language model – zkráceně LLM) je počítačový model jazyka založ...",
      "num_tokens": 94,
      "model_id": "Vanilla Transformer (1.2B)",
      "file": "cs/cs-001-full-Vanilla_Transformer__1.2B_.json",
      "source": "https://cs.wikipedia.org/wiki/Velký_jazykový_model"
    },
    {
      "id": "cs-002-full-Vanilla_Transformer__1.2B_",
      "type": "training",
      "prompt": "Dům stál na mírném svahu na samém konci vesnice. Stál o samotě, s vyhlídkou na širé lány jihozápadní...",
      "language": "cs",
      "description": "Dům stál na mírném svahu na samém konci vesnice. Stál o samotě, s vyhlídkou na širé lány jihozápadní...",
      "num_tokens": 110,
      "model_id": "Vanilla Transformer (1.2B)",
      "file": "cs/cs-002-full-Vanilla_Transformer__1.2B_.json",
      "source": "Douglas Adams - Stopařův průvodce po Galaxii"
    },
    {
      "id": "cs-003-full-Vanilla_Transformer__1.2B_",
      "type": "training",
      "prompt": "def factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    if n == 0 or n == 1:\n        re...",
      "language": "cs",
      "description": "def factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    if n == 0 or n == 1:\n        re...",
      "num_tokens": 44,
      "model_id": "Vanilla Transformer (1.2B)",
      "file": "cs/cs-003-full-Vanilla_Transformer__1.2B_.json",
      "source": "Python kód - rekurzivní výpočet faktoriálu"
    },
    {
      "id": "en-001-full-Vanilla_Transformer__1.2B_",
      "type": "training",
      "prompt": "A large language model (LLM) is a language model trained with self-supervised machine learning on a ...",
      "language": "en",
      "description": "A large language model (LLM) is a language model trained with self-supervised machine learning on a ...",
      "num_tokens": 38,
      "model_id": "Vanilla Transformer (1.2B)",
      "file": "en/en-001-full-Vanilla_Transformer__1.2B_.json",
      "source": "https://en.wikipedia.org/wiki/Large_language_model"
    },
    {
      "id": "en-002-full-Vanilla_Transformer__1.2B_",
      "type": "training",
      "prompt": "The house stood on a slight rise just on the edge of the village. It stood on its own and looked out...",
      "language": "en",
      "description": "The house stood on a slight rise just on the edge of the village. It stood on its own and looked out...",
      "num_tokens": 84,
      "model_id": "Vanilla Transformer (1.2B)",
      "file": "en/en-002-full-Vanilla_Transformer__1.2B_.json",
      "source": "Douglas Adams - The Hitchhiker's Guide to the Galaxy"
    },
    {
      "id": "en-003-full-Vanilla_Transformer__1.2B_",
      "type": "training",
      "prompt": "def factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    if n == 0 or n == 1:\n        re...",
      "language": "en",
      "description": "def factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    if n == 0 or n == 1:\n        re...",
      "num_tokens": 44,
      "model_id": "Vanilla Transformer (1.2B)",
      "file": "en/en-003-full-Vanilla_Transformer__1.2B_.json",
      "source": "Python code - recursive factorial function"
    },
    {
      "id": "fr-001-full-Vanilla_Transformer__1.2B_",
      "type": "training",
      "prompt": "Un grand modèle de langage (abrégé LLM de l'anglais large language model) est un modèle de langage p...",
      "language": "fr",
      "description": "Un grand modèle de langage (abrégé LLM de l'anglais large language model) est un modèle de langage p...",
      "num_tokens": 48,
      "model_id": "Vanilla Transformer (1.2B)",
      "file": "fr/fr-001-full-Vanilla_Transformer__1.2B_.json",
      "source": "https://fr.wikipedia.org/wiki/Grand_modèle_de_langage"
    },
    {
      "id": "fr-002-full-Vanilla_Transformer__1.2B_",
      "type": "training",
      "prompt": "La maison se tenait, isolée, sur une légère éminence juste à la sortie du village, et donnait sur le...",
      "language": "fr",
      "description": "La maison se tenait, isolée, sur une légère éminence juste à la sortie du village, et donnait sur le...",
      "num_tokens": 112,
      "model_id": "Vanilla Transformer (1.2B)",
      "file": "fr/fr-002-full-Vanilla_Transformer__1.2B_.json",
      "source": "Douglas Adams - Le Guide du voyageur galactique"
    },
    {
      "id": "fr-003-full-Vanilla_Transformer__1.2B_",
      "type": "training",
      "prompt": "def factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    if n == 0 or n == 1:\n        re...",
      "language": "fr",
      "description": "def factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    if n == 0 or n == 1:\n        re...",
      "num_tokens": 44,
      "model_id": "Vanilla Transformer (1.2B)",
      "file": "fr/fr-003-full-Vanilla_Transformer__1.2B_.json",
      "source": "Code Python - fonction factorielle récursive"
    },
    {
      "id": "uk-001-full-Vanilla_Transformer__1.2B_",
      "type": "training",
      "prompt": "Велика мовна модель (ВММ, або LLM від англ. large language model) — це модель мови, що складається з...",
      "language": "uk",
      "description": "Велика мовна модель (ВММ, або LLM від англ. large language model) — це модель мови, що складається з...",
      "num_tokens": 81,
      "model_id": "Vanilla Transformer (1.2B)",
      "file": "uk/uk-001-full-Vanilla_Transformer__1.2B_.json",
      "source": "https://uk.wikipedia.org/wiki/Велика_мовна_модель"
    },
    {
      "id": "uk-002-full-Vanilla_Transformer__1.2B_",
      "type": "training",
      "prompt": "На околиці села, на пагорбі, стояв дім. Фасадом він був повернутий до безкраїх нив Західної Англії. ...",
      "language": "uk",
      "description": "На околиці села, на пагорбі, стояв дім. Фасадом він був повернутий до безкраїх нив Західної Англії. ...",
      "num_tokens": 99,
      "model_id": "Vanilla Transformer (1.2B)",
      "file": "uk/uk-002-full-Vanilla_Transformer__1.2B_.json",
      "source": "Дуглас Адамс – Путівник по Галактиці"
    },
    {
      "id": "uk-003-full-Vanilla_Transformer__1.2B_",
      "type": "training",
      "prompt": "def factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    if n == 0 or n == 1:\n        re...",
      "language": "uk",
      "description": "def factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    if n == 0 or n == 1:\n        re...",
      "num_tokens": 44,
      "model_id": "Vanilla Transformer (1.2B)",
      "file": "uk/uk-003-full-Vanilla_Transformer__1.2B_.json",
      "source": "Код Python - рекурсивне обчислення факторіала"
    },
    {
      "id": "zh-001-full-Vanilla_Transformer__1.2B_",
      "type": "training",
      "prompt": "大型语言模型（英語：large language model，LLM），也称大语言模型，简称大模型，是一種基於人工神经网络的语言模型。",
      "language": "zh",
      "description": "大型语言模型（英語：large language model，LLM），也称大语言模型，简称大模型，是一種基於人工神经网络的语言模型。",
      "num_tokens": 39,
      "model_id": "Vanilla Transformer (1.2B)",
      "file": "zh/zh-001-full-Vanilla_Transformer__1.2B_.json",
      "source": "https://zh.wikipedia.org/wiki/大型语言模型"
    },
    {
      "id": "zh-002-full-Vanilla_Transformer__1.2B_",
      "type": "training",
      "prompt": "这幢屋子孤零零地坐落在村庄边缘的缓坡上，放眼望去是无边无际的英国西南部 农田。这幢屋子不管从任何意义上说都平平常常，房龄快三十年了，矮胖短粗，方头方脑，砖木结构，正面的四扇窗户不管是尺寸还是比例都或多...",
      "language": "zh",
      "description": "这幢屋子孤零零地坐落在村庄边缘的缓坡上，放眼望去是无边无际的英国西南部 农田。这幢屋子不管从任何意义上说都平平常常，房龄快三十年了，矮胖短粗，方头方脑，砖木结构，正面的四扇窗户不管是尺寸还是比例都或多...",
      "num_tokens": 110,
      "model_id": "Vanilla Transformer (1.2B)",
      "file": "zh/zh-002-full-Vanilla_Transformer__1.2B_.json",
      "source": "银河系漫游指南系"
    },
    {
      "id": "zh-003-full-Vanilla_Transformer__1.2B_",
      "type": "training",
      "prompt": "def factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    if n == 0 or n == 1:\n        re...",
      "language": "zh",
      "description": "def factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    if n == 0 or n == 1:\n        re...",
      "num_tokens": 44,
      "model_id": "Vanilla Transformer (1.2B)",
      "file": "zh/zh-003-full-Vanilla_Transformer__1.2B_.json",
      "source": "Python 代码 - 递归阶乘函数"
    },
    {
      "id": "cs-001-full-CohereForAI-aya-expanse-8b",
      "type": "training",
      "prompt": "Velký jazykový model (anglicky large language model – zkráceně LLM) je počítačový model jazyka založ...",
      "language": "cs",
      "description": "Velký jazykový model (anglicky large language model – zkráceně LLM) je počítačový model jazyka založ...",
      "num_tokens": 80,
      "model_id": "CohereForAI/aya-expanse-8b",
      "file": "cs/cs-001-full-CohereForAI-aya-expanse-8b.json",
      "source": "https://cs.wikipedia.org/wiki/Velký_jazykový_model"
    },
    {
      "id": "cs-001-full-Qwen-Qwen3-4B-Instruct-2507",
      "type": "training",
      "prompt": "Velký jazykový model (anglicky large language model – zkráceně LLM) je počítačový model jazyka založ...",
      "language": "cs",
      "description": "Velký jazykový model (anglicky large language model – zkráceně LLM) je počítačový model jazyka založ...",
      "num_tokens": 129,
      "model_id": "Qwen/Qwen3-4B-Instruct-2507",
      "file": "cs/cs-001-full-Qwen-Qwen3-4B-Instruct-2507.json",
      "source": "https://cs.wikipedia.org/wiki/Velký_jazykový_model"
    },
    {
      "id": "cs-001-full-allenai-Olmo-3-7B-Think",
      "type": "training",
      "prompt": "Velký jazykový model (anglicky large language model – zkráceně LLM) je počítačový model jazyka založ...",
      "language": "cs",
      "description": "Velký jazykový model (anglicky large language model – zkráceně LLM) je počítačový model jazyka založ...",
      "num_tokens": 130,
      "model_id": "allenai/Olmo-3-7B-Think",
      "file": "cs/cs-001-full-allenai-Olmo-3-7B-Think.json",
      "source": "https://cs.wikipedia.org/wiki/Velký_jazykový_model"
    },
    {
      "id": "cs-001-full-meta-llama-Llama-3.2-1B-Instruct",
      "type": "training",
      "prompt": "Velký jazykový model (anglicky large language model – zkráceně LLM) je počítačový model jazyka založ...",
      "language": "cs",
      "description": "Velký jazykový model (anglicky large language model – zkráceně LLM) je počítačový model jazyka založ...",
      "num_tokens": 94,
      "model_id": "meta-llama/Llama-3.2-1B-Instruct",
      "file": "cs/cs-001-full-meta-llama-Llama-3.2-1B-Instruct.json",
      "source": "https://cs.wikipedia.org/wiki/Velký_jazykový_model"
    },
    {
      "id": "cs-002-full-CohereForAI-aya-expanse-8b",
      "type": "training",
      "prompt": "Dům stál na mírném svahu na samém konci vesnice. Stál o samotě, s vyhlídkou na širé lány jihozápadní...",
      "language": "cs",
      "description": "Dům stál na mírném svahu na samém konci vesnice. Stál o samotě, s vyhlídkou na širé lány jihozápadní...",
      "num_tokens": 90,
      "model_id": "CohereForAI/aya-expanse-8b",
      "file": "cs/cs-002-full-CohereForAI-aya-expanse-8b.json",
      "source": "Douglas Adams - Stopařův průvodce po Galaxii"
    },
    {
      "id": "cs-002-full-Qwen-Qwen3-4B-Instruct-2507",
      "type": "training",
      "prompt": "Dům stál na mírném svahu na samém konci vesnice. Stál o samotě, s vyhlídkou na širé lány jihozápadní...",
      "language": "cs",
      "description": "Dům stál na mírném svahu na samém konci vesnice. Stál o samotě, s vyhlídkou na širé lány jihozápadní...",
      "num_tokens": 134,
      "model_id": "Qwen/Qwen3-4B-Instruct-2507",
      "file": "cs/cs-002-full-Qwen-Qwen3-4B-Instruct-2507.json",
      "source": "Douglas Adams - Stopařův průvodce po Galaxii"
    },
    {
      "id": "cs-002-full-allenai-Olmo-3-7B-Think",
      "type": "training",
      "prompt": "Dům stál na mírném svahu na samém konci vesnice. Stál o samotě, s vyhlídkou na širé lány jihozápadní...",
      "language": "cs",
      "description": "Dům stál na mírném svahu na samém konci vesnice. Stál o samotě, s vyhlídkou na širé lány jihozápadní...",
      "num_tokens": 134,
      "model_id": "allenai/Olmo-3-7B-Think",
      "file": "cs/cs-002-full-allenai-Olmo-3-7B-Think.json",
      "source": "Douglas Adams - Stopařův průvodce po Galaxii"
    },
    {
      "id": "cs-002-full-meta-llama-Llama-3.2-1B-Instruct",
      "type": "training",
      "prompt": "Dům stál na mírném svahu na samém konci vesnice. Stál o samotě, s vyhlídkou na širé lány jihozápadní...",
      "language": "cs",
      "description": "Dům stál na mírném svahu na samém konci vesnice. Stál o samotě, s vyhlídkou na širé lány jihozápadní...",
      "num_tokens": 110,
      "model_id": "meta-llama/Llama-3.2-1B-Instruct",
      "file": "cs/cs-002-full-meta-llama-Llama-3.2-1B-Instruct.json",
      "source": "Douglas Adams - Stopařův průvodce po Galaxii"
    },
    {
      "id": "cs-003-full-CohereForAI-aya-expanse-8b",
      "type": "training",
      "prompt": "def factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    if n == 0 or n == 1:\n        re...",
      "language": "cs",
      "description": "def factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    if n == 0 or n == 1:\n        re...",
      "num_tokens": 48,
      "model_id": "CohereForAI/aya-expanse-8b",
      "file": "cs/cs-003-full-CohereForAI-aya-expanse-8b.json",
      "source": "Python kód - rekurzivní výpočet faktoriálu"
    },
    {
      "id": "cs-003-full-Qwen-Qwen3-4B-Instruct-2507",
      "type": "training",
      "prompt": "def factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    if n == 0 or n == 1:\n        re...",
      "language": "cs",
      "description": "def factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    if n == 0 or n == 1:\n        re...",
      "num_tokens": 43,
      "model_id": "Qwen/Qwen3-4B-Instruct-2507",
      "file": "cs/cs-003-full-Qwen-Qwen3-4B-Instruct-2507.json",
      "source": "Python kód - rekurzivní výpočet faktoriálu"
    },
    {
      "id": "cs-003-full-allenai-Olmo-3-7B-Think",
      "type": "training",
      "prompt": "def factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    if n == 0 or n == 1:\n        re...",
      "language": "cs",
      "description": "def factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    if n == 0 or n == 1:\n        re...",
      "num_tokens": 43,
      "model_id": "allenai/Olmo-3-7B-Think",
      "file": "cs/cs-003-full-allenai-Olmo-3-7B-Think.json",
      "source": "Python kód - rekurzivní výpočet faktoriálu"
    },
    {
      "id": "cs-003-full-meta-llama-Llama-3.2-1B-Instruct",
      "type": "training",
      "prompt": "def factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    if n == 0 or n == 1:\n        re...",
      "language": "cs",
      "description": "def factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    if n == 0 or n == 1:\n        re...",
      "num_tokens": 44,
      "model_id": "meta-llama/Llama-3.2-1B-Instruct",
      "file": "cs/cs-003-full-meta-llama-Llama-3.2-1B-Instruct.json",
      "source": "Python kód - rekurzivní výpočet faktoriálu"
    },
    {
      "id": "en-001-full-CohereForAI-aya-expanse-8b",
      "type": "training",
      "prompt": "A large language model (LLM) is a language model trained with self-supervised machine learning on a ...",
      "language": "en",
      "description": "A large language model (LLM) is a language model trained with self-supervised machine learning on a ...",
      "num_tokens": 38,
      "model_id": "CohereForAI/aya-expanse-8b",
      "file": "en/en-001-full-CohereForAI-aya-expanse-8b.json",
      "source": "https://en.wikipedia.org/wiki/Large_language_model"
    },
    {
      "id": "en-001-full-Qwen-Qwen3-4B-Instruct-2507",
      "type": "training",
      "prompt": "A large language model (LLM) is a language model trained with self-supervised machine learning on a ...",
      "language": "en",
      "description": "A large language model (LLM) is a language model trained with self-supervised machine learning on a ...",
      "num_tokens": 37,
      "model_id": "Qwen/Qwen3-4B-Instruct-2507",
      "file": "en/en-001-full-Qwen-Qwen3-4B-Instruct-2507.json",
      "source": "https://en.wikipedia.org/wiki/Large_language_model"
    },
    {
      "id": "en-001-full-allenai-Olmo-3-7B-Think",
      "type": "training",
      "prompt": "A large language model (LLM) is a language model trained with self-supervised machine learning on a ...",
      "language": "en",
      "description": "A large language model (LLM) is a language model trained with self-supervised machine learning on a ...",
      "num_tokens": 37,
      "model_id": "allenai/Olmo-3-7B-Think",
      "file": "en/en-001-full-allenai-Olmo-3-7B-Think.json",
      "source": "https://en.wikipedia.org/wiki/Large_language_model"
    },
    {
      "id": "en-001-full-meta-llama-Llama-3.2-1B-Instruct",
      "type": "training",
      "prompt": "A large language model (LLM) is a language model trained with self-supervised machine learning on a ...",
      "language": "en",
      "description": "A large language model (LLM) is a language model trained with self-supervised machine learning on a ...",
      "num_tokens": 38,
      "model_id": "meta-llama/Llama-3.2-1B-Instruct",
      "file": "en/en-001-full-meta-llama-Llama-3.2-1B-Instruct.json",
      "source": "https://en.wikipedia.org/wiki/Large_language_model"
    },
    {
      "id": "en-002-full-CohereForAI-aya-expanse-8b",
      "type": "training",
      "prompt": "The house stood on a slight rise just on the edge of the village. It stood on its own and looked out...",
      "language": "en",
      "description": "The house stood on a slight rise just on the edge of the village. It stood on its own and looked out...",
      "num_tokens": 83,
      "model_id": "CohereForAI/aya-expanse-8b",
      "file": "en/en-002-full-CohereForAI-aya-expanse-8b.json",
      "source": "Douglas Adams - The Hitchhiker's Guide to the Galaxy"
    },
    {
      "id": "en-002-full-Qwen-Qwen3-4B-Instruct-2507",
      "type": "training",
      "prompt": "The house stood on a slight rise just on the edge of the village. It stood on its own and looked out...",
      "language": "en",
      "description": "The house stood on a slight rise just on the edge of the village. It stood on its own and looked out...",
      "num_tokens": 83,
      "model_id": "Qwen/Qwen3-4B-Instruct-2507",
      "file": "en/en-002-full-Qwen-Qwen3-4B-Instruct-2507.json",
      "source": "Douglas Adams - The Hitchhiker's Guide to the Galaxy"
    },
    {
      "id": "en-002-full-allenai-Olmo-3-7B-Think",
      "type": "training",
      "prompt": "The house stood on a slight rise just on the edge of the village. It stood on its own and looked out...",
      "language": "en",
      "description": "The house stood on a slight rise just on the edge of the village. It stood on its own and looked out...",
      "num_tokens": 83,
      "model_id": "allenai/Olmo-3-7B-Think",
      "file": "en/en-002-full-allenai-Olmo-3-7B-Think.json",
      "source": "Douglas Adams - The Hitchhiker's Guide to the Galaxy"
    },
    {
      "id": "en-002-full-meta-llama-Llama-3.2-1B-Instruct",
      "type": "training",
      "prompt": "The house stood on a slight rise just on the edge of the village. It stood on its own and looked out...",
      "language": "en",
      "description": "The house stood on a slight rise just on the edge of the village. It stood on its own and looked out...",
      "num_tokens": 84,
      "model_id": "meta-llama/Llama-3.2-1B-Instruct",
      "file": "en/en-002-full-meta-llama-Llama-3.2-1B-Instruct.json",
      "source": "Douglas Adams - The Hitchhiker's Guide to the Galaxy"
    },
    {
      "id": "en-003-full-CohereForAI-aya-expanse-8b",
      "type": "training",
      "prompt": "def factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    if n == 0 or n == 1:\n        re...",
      "language": "en",
      "description": "def factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    if n == 0 or n == 1:\n        re...",
      "num_tokens": 48,
      "model_id": "CohereForAI/aya-expanse-8b",
      "file": "en/en-003-full-CohereForAI-aya-expanse-8b.json",
      "source": "Python code - recursive factorial function"
    },
    {
      "id": "en-003-full-Qwen-Qwen3-4B-Instruct-2507",
      "type": "training",
      "prompt": "def factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    if n == 0 or n == 1:\n        re...",
      "language": "en",
      "description": "def factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    if n == 0 or n == 1:\n        re...",
      "num_tokens": 43,
      "model_id": "Qwen/Qwen3-4B-Instruct-2507",
      "file": "en/en-003-full-Qwen-Qwen3-4B-Instruct-2507.json",
      "source": "Python code - recursive factorial function"
    },
    {
      "id": "en-003-full-allenai-Olmo-3-7B-Think",
      "type": "training",
      "prompt": "def factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    if n == 0 or n == 1:\n        re...",
      "language": "en",
      "description": "def factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    if n == 0 or n == 1:\n        re...",
      "num_tokens": 43,
      "model_id": "allenai/Olmo-3-7B-Think",
      "file": "en/en-003-full-allenai-Olmo-3-7B-Think.json",
      "source": "Python code - recursive factorial function"
    },
    {
      "id": "en-003-full-meta-llama-Llama-3.2-1B-Instruct",
      "type": "training",
      "prompt": "def factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    if n == 0 or n == 1:\n        re...",
      "language": "en",
      "description": "def factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    if n == 0 or n == 1:\n        re...",
      "num_tokens": 44,
      "model_id": "meta-llama/Llama-3.2-1B-Instruct",
      "file": "en/en-003-full-meta-llama-Llama-3.2-1B-Instruct.json",
      "source": "Python code - recursive factorial function"
    },
    {
      "id": "fr-001-full-CohereForAI-aya-expanse-8b",
      "type": "training",
      "prompt": "Un grand modèle de langage (abrégé LLM de l'anglais large language model) est un modèle de langage p...",
      "language": "fr",
      "description": "Un grand modèle de langage (abrégé LLM de l'anglais large language model) est un modèle de langage p...",
      "num_tokens": 39,
      "model_id": "CohereForAI/aya-expanse-8b",
      "file": "fr/fr-001-full-CohereForAI-aya-expanse-8b.json",
      "source": "https://fr.wikipedia.org/wiki/Grand_modèle_de_langage"
    },
    {
      "id": "fr-001-full-Qwen-Qwen3-4B-Instruct-2507",
      "type": "training",
      "prompt": "Un grand modèle de langage (abrégé LLM de l'anglais large language model) est un modèle de langage p...",
      "language": "fr",
      "description": "Un grand modèle de langage (abrégé LLM de l'anglais large language model) est un modèle de langage p...",
      "num_tokens": 48,
      "model_id": "Qwen/Qwen3-4B-Instruct-2507",
      "file": "fr/fr-001-full-Qwen-Qwen3-4B-Instruct-2507.json",
      "source": "https://fr.wikipedia.org/wiki/Grand_modèle_de_langage"
    },
    {
      "id": "fr-001-full-allenai-Olmo-3-7B-Think",
      "type": "training",
      "prompt": "Un grand modèle de langage (abrégé LLM de l'anglais large language model) est un modèle de langage p...",
      "language": "fr",
      "description": "Un grand modèle de langage (abrégé LLM de l'anglais large language model) est un modèle de langage p...",
      "num_tokens": 48,
      "model_id": "allenai/Olmo-3-7B-Think",
      "file": "fr/fr-001-full-allenai-Olmo-3-7B-Think.json",
      "source": "https://fr.wikipedia.org/wiki/Grand_modèle_de_langage"
    },
    {
      "id": "fr-001-full-meta-llama-Llama-3.2-1B-Instruct",
      "type": "training",
      "prompt": "Un grand modèle de langage (abrégé LLM de l'anglais large language model) est un modèle de langage p...",
      "language": "fr",
      "description": "Un grand modèle de langage (abrégé LLM de l'anglais large language model) est un modèle de langage p...",
      "num_tokens": 48,
      "model_id": "meta-llama/Llama-3.2-1B-Instruct",
      "file": "fr/fr-001-full-meta-llama-Llama-3.2-1B-Instruct.json",
      "source": "https://fr.wikipedia.org/wiki/Grand_modèle_de_langage"
    },
    {
      "id": "fr-002-full-CohereForAI-aya-expanse-8b",
      "type": "training",
      "prompt": "La maison se tenait, isolée, sur une légère éminence juste à la sortie du village, et donnait sur le...",
      "language": "fr",
      "description": "La maison se tenait, isolée, sur une légère éminence juste à la sortie du village, et donnait sur le...",
      "num_tokens": 90,
      "model_id": "CohereForAI/aya-expanse-8b",
      "file": "fr/fr-002-full-CohereForAI-aya-expanse-8b.json",
      "source": "Douglas Adams - Le Guide du voyageur galactique"
    },
    {
      "id": "fr-002-full-Qwen-Qwen3-4B-Instruct-2507",
      "type": "training",
      "prompt": "La maison se tenait, isolée, sur une légère éminence juste à la sortie du village, et donnait sur le...",
      "language": "fr",
      "description": "La maison se tenait, isolée, sur une légère éminence juste à la sortie du village, et donnait sur le...",
      "num_tokens": 110,
      "model_id": "Qwen/Qwen3-4B-Instruct-2507",
      "file": "fr/fr-002-full-Qwen-Qwen3-4B-Instruct-2507.json",
      "source": "Douglas Adams - Le Guide du voyageur galactique"
    },
    {
      "id": "fr-002-full-allenai-Olmo-3-7B-Think",
      "type": "training",
      "prompt": "La maison se tenait, isolée, sur une légère éminence juste à la sortie du village, et donnait sur le...",
      "language": "fr",
      "description": "La maison se tenait, isolée, sur une légère éminence juste à la sortie du village, et donnait sur le...",
      "num_tokens": 111,
      "model_id": "allenai/Olmo-3-7B-Think",
      "file": "fr/fr-002-full-allenai-Olmo-3-7B-Think.json",
      "source": "Douglas Adams - Le Guide du voyageur galactique"
    },
    {
      "id": "fr-002-full-meta-llama-Llama-3.2-1B-Instruct",
      "type": "training",
      "prompt": "La maison se tenait, isolée, sur une légère éminence juste à la sortie du village, et donnait sur le...",
      "language": "fr",
      "description": "La maison se tenait, isolée, sur une légère éminence juste à la sortie du village, et donnait sur le...",
      "num_tokens": 112,
      "model_id": "meta-llama/Llama-3.2-1B-Instruct",
      "file": "fr/fr-002-full-meta-llama-Llama-3.2-1B-Instruct.json",
      "source": "Douglas Adams - Le Guide du voyageur galactique"
    },
    {
      "id": "fr-003-full-CohereForAI-aya-expanse-8b",
      "type": "training",
      "prompt": "def factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    if n == 0 or n == 1:\n        re...",
      "language": "fr",
      "description": "def factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    if n == 0 or n == 1:\n        re...",
      "num_tokens": 48,
      "model_id": "CohereForAI/aya-expanse-8b",
      "file": "fr/fr-003-full-CohereForAI-aya-expanse-8b.json",
      "source": "Code Python - fonction factorielle récursive"
    },
    {
      "id": "fr-003-full-Qwen-Qwen3-4B-Instruct-2507",
      "type": "training",
      "prompt": "def factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    if n == 0 or n == 1:\n        re...",
      "language": "fr",
      "description": "def factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    if n == 0 or n == 1:\n        re...",
      "num_tokens": 43,
      "model_id": "Qwen/Qwen3-4B-Instruct-2507",
      "file": "fr/fr-003-full-Qwen-Qwen3-4B-Instruct-2507.json",
      "source": "Code Python - fonction factorielle récursive"
    },
    {
      "id": "fr-003-full-allenai-Olmo-3-7B-Think",
      "type": "training",
      "prompt": "def factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    if n == 0 or n == 1:\n        re...",
      "language": "fr",
      "description": "def factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    if n == 0 or n == 1:\n        re...",
      "num_tokens": 43,
      "model_id": "allenai/Olmo-3-7B-Think",
      "file": "fr/fr-003-full-allenai-Olmo-3-7B-Think.json",
      "source": "Code Python - fonction factorielle récursive"
    },
    {
      "id": "fr-003-full-meta-llama-Llama-3.2-1B-Instruct",
      "type": "training",
      "prompt": "def factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    if n == 0 or n == 1:\n        re...",
      "language": "fr",
      "description": "def factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    if n == 0 or n == 1:\n        re...",
      "num_tokens": 44,
      "model_id": "meta-llama/Llama-3.2-1B-Instruct",
      "file": "fr/fr-003-full-meta-llama-Llama-3.2-1B-Instruct.json",
      "source": "Code Python - fonction factorielle récursive"
    },
    {
      "id": "zh-001-full-CohereForAI-aya-expanse-8b",
      "type": "training",
      "prompt": "大型语言模型（英語：large language model，LLM），也称大语言模型，简称大模型，是一種基於人工神经网络的语言模型。",
      "language": "zh",
      "description": "大型语言模型（英語：large language model，LLM），也称大语言模型，简称大模型，是一種基於人工神经网络的语言模型。",
      "num_tokens": 32,
      "model_id": "CohereForAI/aya-expanse-8b",
      "file": "zh/zh-001-full-CohereForAI-aya-expanse-8b.json",
      "source": "https://zh.wikipedia.org/wiki/大型语言模型"
    },
    {
      "id": "zh-001-full-Qwen-Qwen3-4B-Instruct-2507",
      "type": "training",
      "prompt": "大型语言模型（英語：large language model，LLM），也称大语言模型，简称大模型，是一種基於人工神经网络的语言模型。",
      "language": "zh",
      "description": "大型语言模型（英語：large language model，LLM），也称大语言模型，简称大模型，是一種基於人工神经网络的语言模型。",
      "num_tokens": 34,
      "model_id": "Qwen/Qwen3-4B-Instruct-2507",
      "file": "zh/zh-001-full-Qwen-Qwen3-4B-Instruct-2507.json",
      "source": "https://zh.wikipedia.org/wiki/大型语言模型"
    },
    {
      "id": "zh-001-full-allenai-Olmo-3-7B-Think",
      "type": "training",
      "prompt": "大型语言模型（英語：large language model，LLM），也称大语言模型，简称大模型，是一種基於人工神经网络的语言模型。",
      "language": "zh",
      "description": "大型语言模型（英語：large language model，LLM），也称大语言模型，简称大模型，是一種基於人工神经网络的语言模型。",
      "num_tokens": 51,
      "model_id": "allenai/Olmo-3-7B-Think",
      "file": "zh/zh-001-full-allenai-Olmo-3-7B-Think.json",
      "source": "https://zh.wikipedia.org/wiki/大型语言模型"
    },
    {
      "id": "zh-001-full-meta-llama-Llama-3.2-1B-Instruct",
      "type": "training",
      "prompt": "大型语言模型（英語：large language model，LLM），也称大语言模型，简称大模型，是一種基於人工神经网络的语言模型。",
      "language": "zh",
      "description": "大型语言模型（英語：large language model，LLM），也称大语言模型，简称大模型，是一種基於人工神经网络的语言模型。",
      "num_tokens": 39,
      "model_id": "meta-llama/Llama-3.2-1B-Instruct",
      "file": "zh/zh-001-full-meta-llama-Llama-3.2-1B-Instruct.json",
      "source": "https://zh.wikipedia.org/wiki/大型语言模型"
    },
    {
      "id": "zh-002-full-CohereForAI-aya-expanse-8b",
      "type": "training",
      "prompt": "这幢屋子孤零零地坐落在村庄边缘的缓坡上，放眼望去是无边无际的英国西南部 农田。这幢屋子不管从任何意义上说都平平常常，房龄快三十年了，矮胖短粗，方头方脑，砖木结构，正面的四扇窗户不管是尺寸还是比例都或多...",
      "language": "zh",
      "description": "这幢屋子孤零零地坐落在村庄边缘的缓坡上，放眼望去是无边无际的英国西南部 农田。这幢屋子不管从任何意义上说都平平常常，房龄快三十年了，矮胖短粗，方头方脑，砖木结构，正面的四扇窗户不管是尺寸还是比例都或多...",
      "num_tokens": 93,
      "model_id": "CohereForAI/aya-expanse-8b",
      "file": "zh/zh-002-full-CohereForAI-aya-expanse-8b.json",
      "source": "银河系漫游指南系"
    },
    {
      "id": "zh-002-full-Qwen-Qwen3-4B-Instruct-2507",
      "type": "training",
      "prompt": "这幢屋子孤零零地坐落在村庄边缘的缓坡上，放眼望去是无边无际的英国西南部 农田。这幢屋子不管从任何意义上说都平平常常，房龄快三十年了，矮胖短粗，方头方脑，砖木结构，正面的四扇窗户不管是尺寸还是比例都或多...",
      "language": "zh",
      "description": "这幢屋子孤零零地坐落在村庄边缘的缓坡上，放眼望去是无边无际的英国西南部 农田。这幢屋子不管从任何意义上说都平平常常，房龄快三十年了，矮胖短粗，方头方脑，砖木结构，正面的四扇窗户不管是尺寸还是比例都或多...",
      "num_tokens": 79,
      "model_id": "Qwen/Qwen3-4B-Instruct-2507",
      "file": "zh/zh-002-full-Qwen-Qwen3-4B-Instruct-2507.json",
      "source": "银河系漫游指南系"
    },
    {
      "id": "zh-002-full-allenai-Olmo-3-7B-Think",
      "type": "training",
      "prompt": "这幢屋子孤零零地坐落在村庄边缘的缓坡上，放眼望去是无边无际的英国西南部 农田。这幢屋子不管从任何意义上说都平平常常，房龄快三十年了，矮胖短粗，方头方脑，砖木结构，正面的四扇窗户不管是尺寸还是比例都或多...",
      "language": "zh",
      "description": "这幢屋子孤零零地坐落在村庄边缘的缓坡上，放眼望去是无边无际的英国西南部 农田。这幢屋子不管从任何意义上说都平平常常，房龄快三十年了，矮胖短粗，方头方脑，砖木结构，正面的四扇窗户不管是尺寸还是比例都或多...",
      "num_tokens": 150,
      "model_id": "allenai/Olmo-3-7B-Think",
      "file": "zh/zh-002-full-allenai-Olmo-3-7B-Think.json",
      "source": "银河系漫游指南系"
    },
    {
      "id": "zh-002-full-meta-llama-Llama-3.2-1B-Instruct",
      "type": "training",
      "prompt": "这幢屋子孤零零地坐落在村庄边缘的缓坡上，放眼望去是无边无际的英国西南部 农田。这幢屋子不管从任何意义上说都平平常常，房龄快三十年了，矮胖短粗，方头方脑，砖木结构，正面的四扇窗户不管是尺寸还是比例都或多...",
      "language": "zh",
      "description": "这幢屋子孤零零地坐落在村庄边缘的缓坡上，放眼望去是无边无际的英国西南部 农田。这幢屋子不管从任何意义上说都平平常常，房龄快三十年了，矮胖短粗，方头方脑，砖木结构，正面的四扇窗户不管是尺寸还是比例都或多...",
      "num_tokens": 110,
      "model_id": "meta-llama/Llama-3.2-1B-Instruct",
      "file": "zh/zh-002-full-meta-llama-Llama-3.2-1B-Instruct.json",
      "source": "银河系漫游指南系"
    },
    {
      "id": "zh-003-full-CohereForAI-aya-expanse-8b",
      "type": "training",
      "prompt": "def factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    if n == 0 or n == 1:\n        re...",
      "language": "zh",
      "description": "def factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    if n == 0 or n == 1:\n        re...",
      "num_tokens": 48,
      "model_id": "CohereForAI/aya-expanse-8b",
      "file": "zh/zh-003-full-CohereForAI-aya-expanse-8b.json",
      "source": "Python 代码 - 递归阶乘函数"
    },
    {
      "id": "zh-003-full-Qwen-Qwen3-4B-Instruct-2507",
      "type": "training",
      "prompt": "def factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    if n == 0 or n == 1:\n        re...",
      "language": "zh",
      "description": "def factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    if n == 0 or n == 1:\n        re...",
      "num_tokens": 43,
      "model_id": "Qwen/Qwen3-4B-Instruct-2507",
      "file": "zh/zh-003-full-Qwen-Qwen3-4B-Instruct-2507.json",
      "source": "Python 代码 - 递归阶乘函数"
    },
    {
      "id": "zh-003-full-allenai-Olmo-3-7B-Think",
      "type": "training",
      "prompt": "def factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    if n == 0 or n == 1:\n        re...",
      "language": "zh",
      "description": "def factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    if n == 0 or n == 1:\n        re...",
      "num_tokens": 43,
      "model_id": "allenai/Olmo-3-7B-Think",
      "file": "zh/zh-003-full-allenai-Olmo-3-7B-Think.json",
      "source": "Python 代码 - 递归阶乘函数"
    },
    {
      "id": "zh-003-full-meta-llama-Llama-3.2-1B-Instruct",
      "type": "training",
      "prompt": "def factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    if n == 0 or n == 1:\n        re...",
      "language": "zh",
      "description": "def factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    if n == 0 or n == 1:\n        re...",
      "num_tokens": 44,
      "model_id": "meta-llama/Llama-3.2-1B-Instruct",
      "file": "zh/zh-003-full-meta-llama-Llama-3.2-1B-Instruct.json",
      "source": "Python 代码 - 递归阶乘函数"
    },
    {
      "id": "uk-001-full-CohereForAI-aya-expanse-8b",
      "type": "training",
      "prompt": "Велика мовна модель (ВММ, або LLM від англ. large language model) — це модель мови, що складається з...",
      "language": "uk",
      "description": "Велика мовна модель (ВММ, або LLM від англ. large language model) — це модель мови, що складається з...",
      "num_tokens": 69,
      "model_id": "CohereForAI/aya-expanse-8b",
      "file": "uk/uk-001-full-CohereForAI-aya-expanse-8b.json",
      "source": "https://uk.wikipedia.org/wiki/Велика_мовна_модель"
    },
    {
      "id": "uk-001-full-Qwen-Qwen3-4B-Instruct-2507",
      "type": "training",
      "prompt": "Велика мовна модель (ВММ, або LLM від англ. large language model) — це модель мови, що складається з...",
      "language": "uk",
      "description": "Велика мовна модель (ВММ, або LLM від англ. large language model) — це модель мови, що складається з...",
      "num_tokens": 131,
      "model_id": "Qwen/Qwen3-4B-Instruct-2507",
      "file": "uk/uk-001-full-Qwen-Qwen3-4B-Instruct-2507.json",
      "source": "https://uk.wikipedia.org/wiki/Велика_мовна_модель"
    },
    {
      "id": "uk-001-full-allenai-Olmo-3-7B-Think",
      "type": "training",
      "prompt": "Велика мовна модель (ВММ, або LLM від англ. large language model) — це модель мови, що складається з...",
      "language": "uk",
      "description": "Велика мовна модель (ВММ, або LLM від англ. large language model) — це модель мови, що складається з...",
      "num_tokens": 150,
      "model_id": "allenai/Olmo-3-7B-Think",
      "file": "uk/uk-001-full-allenai-Olmo-3-7B-Think.json",
      "source": "https://uk.wikipedia.org/wiki/Велика_мовна_модель"
    },
    {
      "id": "uk-001-full-meta-llama-Llama-3.2-1B-Instruct",
      "type": "training",
      "prompt": "Велика мовна модель (ВММ, або LLM від англ. large language model) — це модель мови, що складається з...",
      "language": "uk",
      "description": "Велика мовна модель (ВММ, або LLM від англ. large language model) — це модель мови, що складається з...",
      "num_tokens": 81,
      "model_id": "meta-llama/Llama-3.2-1B-Instruct",
      "file": "uk/uk-001-full-meta-llama-Llama-3.2-1B-Instruct.json",
      "source": "https://uk.wikipedia.org/wiki/Велика_мовна_модель"
    },
    {
      "id": "uk-001-full-openai-community-gpt2-xl",
      "type": "training",
      "prompt": "Велика мовна модель (ВММ, або LLM від англ. large language model) — це модель мови, що складається з...",
      "language": "uk",
      "description": "Велика мовна модель (ВММ, або LLM від англ. large language model) — це модель мови, що складається з...",
      "num_tokens": 296,
      "model_id": "openai-community/gpt2-xl",
      "file": "uk/uk-001-full-openai-community-gpt2-xl.json",
      "source": "https://uk.wikipedia.org/wiki/Велика_мовна_модель"
    },
    {
      "id": "uk-002-full-CohereForAI-aya-expanse-8b",
      "type": "training",
      "prompt": "На околиці села, на пагорбі, стояв дім. Фасадом він був повернутий до безкраїх нив Західної Англії. ...",
      "language": "uk",
      "description": "На околиці села, на пагорбі, стояв дім. Фасадом він був повернутий до безкраїх нив Західної Англії. ...",
      "num_tokens": 83,
      "model_id": "CohereForAI/aya-expanse-8b",
      "file": "uk/uk-002-full-CohereForAI-aya-expanse-8b.json",
      "source": "Дуглас Адамс – Путівник по Галактиці"
    },
    {
      "id": "uk-002-full-Qwen-Qwen3-4B-Instruct-2507",
      "type": "training",
      "prompt": "На околиці села, на пагорбі, стояв дім. Фасадом він був повернутий до безкраїх нив Західної Англії. ...",
      "language": "uk",
      "description": "На околиці села, на пагорбі, стояв дім. Фасадом він був повернутий до безкраїх нив Західної Англії. ...",
      "num_tokens": 148,
      "model_id": "Qwen/Qwen3-4B-Instruct-2507",
      "file": "uk/uk-002-full-Qwen-Qwen3-4B-Instruct-2507.json",
      "source": "Дуглас Адамс – Путівник по Галактиці"
    },
    {
      "id": "uk-002-full-allenai-Olmo-3-7B-Think",
      "type": "training",
      "prompt": "На околиці села, на пагорбі, стояв дім. Фасадом він був повернутий до безкраїх нив Західної Англії. ...",
      "language": "uk",
      "description": "На околиці села, на пагорбі, стояв дім. Фасадом він був повернутий до безкраїх нив Західної Англії. ...",
      "num_tokens": 171,
      "model_id": "allenai/Olmo-3-7B-Think",
      "file": "uk/uk-002-full-allenai-Olmo-3-7B-Think.json",
      "source": "Дуглас Адамс – Путівник по Галактиці"
    },
    {
      "id": "uk-002-full-meta-llama-Llama-3.2-1B-Instruct",
      "type": "training",
      "prompt": "На околиці села, на пагорбі, стояв дім. Фасадом він був повернутий до безкраїх нив Західної Англії. ...",
      "language": "uk",
      "description": "На околиці села, на пагорбі, стояв дім. Фасадом він був повернутий до безкраїх нив Західної Англії. ...",
      "num_tokens": 99,
      "model_id": "meta-llama/Llama-3.2-1B-Instruct",
      "file": "uk/uk-002-full-meta-llama-Llama-3.2-1B-Instruct.json",
      "source": "Дуглас Адамс – Путівник по Галактиці"
    },
    {
      "id": "uk-002-full-openai-community-gpt2-xl",
      "type": "training",
      "prompt": "На околиці села, на пагорбі, стояв дім. Фасадом він був повернутий до безкраїх нив Західної Англії. ...",
      "language": "uk",
      "description": "На околиці села, на пагорбі, стояв дім. Фасадом він був повернутий до безкраїх нив Західної Англії. ...",
      "num_tokens": 332,
      "model_id": "openai-community/gpt2-xl",
      "file": "uk/uk-002-full-openai-community-gpt2-xl.json",
      "source": "Дуглас Адамс – Путівник по Галактиці"
    },
    {
      "id": "uk-003-full-CohereForAI-aya-expanse-8b",
      "type": "training",
      "prompt": "def factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    if n == 0 or n == 1:\n        re...",
      "language": "uk",
      "description": "def factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    if n == 0 or n == 1:\n        re...",
      "num_tokens": 48,
      "model_id": "CohereForAI/aya-expanse-8b",
      "file": "uk/uk-003-full-CohereForAI-aya-expanse-8b.json",
      "source": "Код Python - рекурсивне обчислення факторіала"
    },
    {
      "id": "uk-003-full-Qwen-Qwen3-4B-Instruct-2507",
      "type": "training",
      "prompt": "def factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    if n == 0 or n == 1:\n        re...",
      "language": "uk",
      "description": "def factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    if n == 0 or n == 1:\n        re...",
      "num_tokens": 43,
      "model_id": "Qwen/Qwen3-4B-Instruct-2507",
      "file": "uk/uk-003-full-Qwen-Qwen3-4B-Instruct-2507.json",
      "source": "Код Python - рекурсивне обчислення факторіала"
    },
    {
      "id": "uk-003-full-allenai-Olmo-3-7B-Think",
      "type": "training",
      "prompt": "def factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    if n == 0 or n == 1:\n        re...",
      "language": "uk",
      "description": "def factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    if n == 0 or n == 1:\n        re...",
      "num_tokens": 43,
      "model_id": "allenai/Olmo-3-7B-Think",
      "file": "uk/uk-003-full-allenai-Olmo-3-7B-Think.json",
      "source": "Код Python - рекурсивне обчислення факторіала"
    },
    {
      "id": "uk-003-full-meta-llama-Llama-3.2-1B-Instruct",
      "type": "training",
      "prompt": "def factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    if n == 0 or n == 1:\n        re...",
      "language": "uk",
      "description": "def factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    if n == 0 or n == 1:\n        re...",
      "num_tokens": 44,
      "model_id": "meta-llama/Llama-3.2-1B-Instruct",
      "file": "uk/uk-003-full-meta-llama-Llama-3.2-1B-Instruct.json",
      "source": "Код Python - рекурсивне обчислення факторіала"
    },
    {
      "id": "uk-003-full-openai-community-gpt2-xl",
      "type": "training",
      "prompt": "def factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    if n == 0 or n == 1:\n        re...",
      "language": "uk",
      "description": "def factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    if n == 0 or n == 1:\n        re...",
      "num_tokens": 69,
      "model_id": "openai-community/gpt2-xl",
      "file": "uk/uk-003-full-openai-community-gpt2-xl.json",
      "source": "Код Python - рекурсивне обчислення факторіала"
    }
  ]
}